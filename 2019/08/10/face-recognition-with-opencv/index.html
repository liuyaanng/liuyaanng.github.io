
<script src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@1.1/blog_source/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('Please enter the password')).toString(CryptoJS.enc.Hex)) {
                alert('Wrong! Return main page.');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_images/Face-Recognition-with-OpenCV/img.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        Face Recognition
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@1.1/blog_source/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card" id="article-content">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/OpenCV/" target="_blank">
                                <span class="chip bg-color">OpenCV</span>
                            </a>
                        
                            <a href="/tags/c/" target="_blank">
                                <span class="chip bg-color">c++</span>
                            </a>
                        
                            <a href="/tags/python/" target="_blank">
                                <span class="chip bg-color">python</span>
                            </a>
                        
                            <a href="/tags/Face-Recongnition/" target="_blank">
                                <span class="chip bg-color">Face Recongnition</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Face-Recognition/" class="post-category" target="_blank">
                                Face Recognition
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-08-10
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        2.9k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        18 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Face-Recognition-with-OpenCV"><a href="#Face-Recognition-with-OpenCV" class="headerlink" title="Face Recognition with OpenCV"></a>Face Recognition with OpenCV</h1><h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>My Particular Environment:<br>Ubuntu16.04 + OpenCV3.3.0 + OpenCV_contrib3.3.0</p>
<h2 id="1-Image-Acquisition-and-Face-Database-Creation"><a href="#1-Image-Acquisition-and-Face-Database-Creation" class="headerlink" title="1. Image Acquisition and Face Database Creation"></a>1. Image Acquisition and Face Database Creation</h2><h3 id="1-1-Image-Acquisition"><a href="#1-1-Image-Acquisition" class="headerlink" title="1.1 Image Acquisition"></a>1.1 Image Acquisition</h3><h4 id="1-1-1-Steps-and-methods"><a href="#1-1-1-Steps-and-methods" class="headerlink" title="1.1.1 Steps and methods"></a>1.1.1 Steps and methods</h4><ol>
<li>Open the camera and capture images;</li>
<li>Loading the face classifier;</li>
<li>Start face detection, frame the face part and display;</li>
<li>Under the condition that the face is detected, take a picture with one button;</li>
<li>For the face part, resize and write the image file in the specified directory;</li>
</ol>
<h4 id="1-1-2-Code"><a href="#1-1-2-Code" class="headerlink" title="1.1.2 Code"></a>1.1.2 Code</h4><pre><code class="line-numbers language-cpp">#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;stdio.h&gt;
#include &lt;opencv2/face.hpp&gt;
#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;sstream&gt; 
using namespace cv;
using namespace std;
using namespace cv::face;

#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)

int resize_save(Mat&amp; faceIn, char* path, int  faceseq);
//Input: current image, the path of file, the name or faceseq of images.
//Output: None
//Function: resize the current image to (92, 112), which is same to the train data.
int get_face(char* path);
//Input: the path of file.
//Output: None
//Function: Use face_cascade to detect if there are faces in the window, and save the faces through function reszie_save.


int resize_save(Mat&amp; faceIn, char* path, int  faceseq)&#123;
  string strname;
  Mat faceOut;
  bool ret;
  if(faceIn.empty())&#123;
    printf(&quot;FaceIn is empty.\n&quot;);
    return -1;
  &#125;

  if(faceIn.cols &gt; 100)&#123;
    resize(faceIn, faceOut, Size(92, 112));
    //Resize and Keep a match with the train database.
    strname = format(&quot;%s/%d.jpg&quot;, path, faceseq); //mkdir
    ret = imwrite(strname, faceOut); //save image. Note the file suffix.
    if(ret == false)&#123;
      printf(&quot;Image write failed!\n&quot;);
      printf(&quot;Please check filename[%s] is legal!\n&quot;, strname.c_str());
      return -1;
    &#125;
    imshow(strname, faceOut);
  &#125;
  waitKey(20);
  return 0;
&#125;

int get_face(char* path)&#123;
  CascadeClassifier face_cascade;
  VideoCapture camera;
  int ret;
  Mat frame;  //camera frame
  vector&lt;Rect&gt; objects; //The faces coordinates.
  Mat img_gary; //Gradation pictures.
  Mat faceImg;
  int faceNum = 1; //
  char key;
  camera.open(0);
  if(!camera.isOpened())&#123;
    cout &lt;&lt; &quot;Open camera failed.&quot; &lt;&lt; endl;
    return -1;
  &#125;
  cout &lt;&lt; &quot;Open camera succeed. &quot; &lt;&lt; endl;

  //Load the face cascadeclassifier.
  ret = face_cascade.load(&quot;haarcascade_frontalface_alt2.xml&quot;);
  if(!ret)&#123;
    cout &lt;&lt; &quot;Load xml failed.&quot; &lt;&lt; endl;
    return -1;
  &#125;
  cout &lt;&lt; &quot;Load xml succeed.&quot; &lt;&lt; endl;

  while(1)&#123;
    camera &gt;&gt; frame;
    if(frame.empty())&#123;
      continue;
    &#125;
    cvtColor(frame, img_gary, COLOR_BGR2GRAY); //Transform frame as the gradation picture, note imshow is still the original frame.
    equalizeHist(img_gary, img_gary); //Histogram equalization, which is helpful to improve the quality of pictures.

    //Face detection
    face_cascade.detectMultiScale(img_gary, objects, 1.1,3 , 0, Size(50,50));
    for(size_t i = 0; i &lt; objects.size(); i++)&#123;
      rectangle(frame, objects[i], CV_COLOR_GREEN);
    &#125;
    imshow(&quot;Camera&quot;, frame);
    key = waitKey(1);
    switch (key)&#123;
      case &#39;p&#39;: //tap &#39;P&#39; to save.
        if(objects.size() == 1)&#123;
          faceImg = frame(objects[0]);
          ret = resize_save(faceImg, path, faceNum);
          if(ret == 0)&#123;
            cout &lt;&lt; &quot;resize_save succeed.\n&quot; &lt;&lt; endl;
            faceNum++;
          &#125;
        &#125;
        break;
      case 27:   //switch to ESC
        cout &lt;&lt; &quot;Esc ...&quot; &lt;&lt; endl;
        return 0;
      default:
        break;
    &#125;
  &#125;
&#125;



int main(int argc, char* argv[])&#123;
  if(argc != 2)
      &#123;
        printf(&quot;usage: %s &lt;path&gt;\n&quot;, argv[0]);
        return -1;
      &#125;
  get_face(argv[1]);
  return 0;
&#125;</code></pre>
<p><img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_images/Face-Recognition-with-OpenCV/4.jpg"><br>Note:    </p>
<ol>
<li>After the compilation is successful, the execution executable file must provide parameters, which are the directories for storing the face image, and it must be an existing directory.(E.g: ./program_name Img/s41)    </li>
<li>Press the “P” button to take a photo and save the face. Press the “Esc” button to exit.</li>
</ol>
<h3 id="1-2-Face-Database-Creation"><a href="#1-2-Face-Database-Creation" class="headerlink" title="1.2 Face Database Creation"></a>1.2 Face Database Creation</h3><p>The official document provides a download of the face database, and i use the <a target="_blank" rel="noopener" href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">AT&amp;T Facedatabase</a> to create my face database. I have updated this zip file to my github, you can download it from <a href="att_faces.zip">here</a> faster.<br>AT&amp;T Face Database is also known as the OCR face database, 40 people, 10 photos per person. The photos are token at different times, different lighting, different expressions(closed eyes, laughing or not laughing), different face details(with or without glasses). All images were captured on a dark , even background with a vertical face o the front(some with a slight rotation).<br>You can download the compressed package from the website, and first extract the att_faces folder. There are 40 folders under the folder, which named from “s1” to “s40”. Each folder has the same person’s photos with different expressions, and there are 10 face photos.<br>The format of these images is “.pgm”<br><img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_images/Face-Recognition-with-OpenCV/1.png"><br><img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_images/Face-Recognition-with-OpenCV/2.png"></p>
<p>Note:<br>If you want to add your own photos to the face database through the program, the number of added pictures must be no less than 2.</p>
<h2 id="2-Face-Recognition-Model-training"><a href="#2-Face-Recognition-Model-training" class="headerlink" title="2. Face Recognition Model training"></a>2. Face Recognition Model training</h2><h3 id="2-1-Create-a-label-file-CSV"><a href="#2-1-Create-a-label-file-CSV" class="headerlink" title="2.1 Create a label file CSV"></a>2.1 Create a label file CSV</h3><p>With the face database data, we need to read it in the program, here we need to use csv file to read the image data in the face database.<br>The format of a csv file: image path name + label, such as /Img/s1/image.jpg;1<br>Assume the face image path is: /Img/s1/01..jpg<br>And we give this face image a label “1”, this label represents the person’s name. One person’s face image label must be the same.<br>You can create a csv file manually and then enter the data one by one. But if you use python, you don’t have to do this tedious and boring work.<br>The following is a piece of code which can write data in the CSV file automatically.</p>
<pre><code class="line-numbers language-python">#!/usr/bin/env python

import sys
import os.path

# This is a tiny script to help you creating a CSV file from a face
# database with a similar hierarchie:
#
#  
#  
#  |-- s1
#  |   |-- 1.pgm
#  |   |-- ...
#  |   |-- 10.pgm
#  |-- s2
#  |   |-- 1.pgm
#  |   |-- ...
#  |   |-- 10.pgm
#  ...
#  |-- s40
#  |   |-- 1.pgm
#  |   |-- ...
#  |   |-- 10.pgm
#

if __name__ == &quot;__main__&quot;:

    if len(sys.argv) != 2:
        print &quot;usage: create_csv &lt;base_path&gt;&quot;
        sys.exit(1)

    BASE_PATH=sys.argv[1]        
    SEPARATOR=&quot;;&quot;
    # This is output csv file.
    fh = open(&quot;../at.csv&quot;,&#39;w&#39;)

    for dirname, dirnames, filenames in os.walk(BASE_PATH):
        for subdirname in dirnames:
            subject_path = os.path.join(dirname, subdirname)
            for filename in os.listdir(subject_path):
                abs_path = &quot;%s/%s&quot; % (subject_path, filename)
                print(&quot;%s%s%s&quot; % (abs_path, SEPARATOR, subdirname[1:]))
                fh.write(abs_path)
                fh.write(SEPARATOR)
                fh.write(subdirname[1:])
                fh.write(&quot;\n&quot;)
    fh.close()</code></pre>
<p>You should set the image path parameter (absolute path) when running.(E.g: <strong>python filename.py /home/kevin/OpenCV/face_rec/Img</strong> ) and you can get a CSV file like this:<br><img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_images/Face-Recognition-with-OpenCV/5.png"><br>This CSV file is created.</p>
<h3 id="2-2-Model-training"><a href="#2-2-Model-training" class="headerlink" title="2.2 Model training"></a>2.2 Model training</h3><p>This is the official example of OpenCV: <a target="_blank" rel="noopener" href="https://docs.opencv.org/3.2.0/da/d60/tutorial_face_main.html">Click here</a><br>They offer three models: Eigenfaces, Fisherfaces and Local Binary Patterns Histograms(LBPH)    </p>
<p>Then I will train my own face database based on these models on the first step.</p>
<pre><code class="line-numbers language-cpp">static Mat norm_0_255(InputArray _src)&#123;
  Mat src = _src.getMat();
  Mat dst; //Create and return a normalized image matrix:
  switch(src.channels()) &#123;
    case 1:
        cv::normalize(_src, dst, 0, 255, NORM_MINMAX, CV_8UC1);
        break;
    case 3:
        cv::normalize(_src, dst, 0, 255, NORM_MINMAX, CV_8UC3);
        break;
    default:
        src.copyTo(dst);
        break;
  &#125;
  return dst;
&#125;
//load CSV file
static void read_csv(const string&amp; filename, vector&lt;Mat&gt;&amp; images, vector&lt;int&gt;&amp; labels, char separator = &#39;;&#39;)&#123;
  std::ifstream file(filename.c_str(), ifstream::in);
    if (!file) &#123;
        string error_message = &quot;No valid input file was given, please check the given filename.&quot;;
        CV_Error(Error::StsBadArg, error_message);
    &#125;
    string line, path, classlabel;
    while (getline(file, line)) &#123;
        stringstream liness(line);
        getline(liness, path, separator);
        getline(liness, classlabel);
        if(!path.empty() &amp;&amp; !classlabel.empty()) &#123;
            images.push_back(imread(path, 0));
            labels.push_back(atoi(classlabel.c_str()));
        &#125;
    &#125;
&#125;

void train_model(const string&amp; fn_csv)&#123;
  // 2 containers to store image data and corresponding labels
    vector&lt;Mat&gt; images;
    vector&lt;int&gt; labels;
    // load data
    try
    &#123;
        read_csv(fn_csv, images, labels);
    &#125;
    catch (cv::Exception&amp; e)
    &#123;
        cerr &lt;&lt; &quot;Error opening file \&quot;&quot; &lt;&lt; fn_csv &lt;&lt; &quot;\&quot;. Reason: &quot; &lt;&lt; e.msg &lt;&lt; endl;
        exit(1);
    &#125;
    if (images.size() &lt;= 1) &#123;
        string error_message = &quot;This demo needs at least 2 images to work. Please add more images to your data set!&quot;;
        CV_Error(CV_StsError, error_message);
    &#125;

    Mat testSample = images[images.size() - 1];
    int testLabel = labels[labels.size() - 1];
    images.pop_back();
    labels.pop_back();
    // The following lines create a feature face model for face recognition.
     // Train it with images and tags read from a CSV file.
     // Here is a complete PCA transform
     //If you only want to keep 10 principal components, use the following code
     // cv::EigenFaceRecognizer::create(10);
     // cv::FisherFaceRecognizer::create(10);
     //
     // If you also want to initialize with a confidence threshold, use the following statement:
     // cv::EigenFaceRecognizer::create(10, 123.0);
     //
     // If you use all features and use a threshold, use the following statement:
     // cv::EigenFaceRecognizer::create(0, 123.0);
     // cv::FisherFaceRecognizer::create(0, 123.0);

    Ptr&lt;BasicFaceRecognizer&gt; model0 = EigenFaceRecognizer::create();
    model0-&gt;train(images, labels);
    model0-&gt;write(&quot;MyFacePCAModel.xml&quot;);

    Ptr&lt;BasicFaceRecognizer&gt; model1 = FisherFaceRecognizer::create();
    model1-&gt;train(images, labels);
    model1-&gt;write(&quot;MyFaceFisherModel.xml&quot;);

     Ptr&lt;LBPHFaceRecognizer&gt; model2 = LBPHFaceRecognizer::create();
    model2-&gt;train(images, labels);
    model2-&gt;write(&quot;MyFaceLBPHModel.xml&quot;);


    // The test image is predicted below, predictedLabel is the predicted label result
    int predictedLabel0 = model0-&gt;predict(testSample);
    int predictedLabel1 = model1-&gt;predict(testSample);
    int predictedLabel2 = model2-&gt;predict(testSample);

    // There is also a way to get the result and get the threshold:
    //      int predictedLabel = -1;
    //      double confidence = 0.0;
    //      model-&gt;predict(testSample, predictedLabel, confidence);

    string result_message0 = format(&quot;Predicted class = %d / Actual class = %d.&quot;, predictedLabel0, testLabel);
    string result_message1 = format(&quot;Predicted class = %d / Actual class = %d.&quot;, predictedLabel1, testLabel);
    string result_message2 = format(&quot;Predicted class = %d / Actual class = %d.&quot;, predictedLabel2, testLabel);
    cout &lt;&lt; result_message0 &lt;&lt; endl;
    cout &lt;&lt; result_message1 &lt;&lt; endl;
    cout &lt;&lt; result_message2 &lt;&lt; endl;

    waitKey(0);
&#125;

int main(int argc, char* argv[])&#123;
  if(argc != 2)
      &#123;
        printf(&quot;usage: %s &lt;csv_file&gt;\n&quot;, argv[0]);
        return -1;
      &#125;
  string fn_csv = string(argv[1]);
  train_model(fn_csv);
  return 0;
&#125;</code></pre>
<p>At this point, we have completed the training of the face model. And we get three files:     </p>
<p><code>MyFaceFisherModel.xml、MyFaceLBPHModel.xml、MyFacePCAModel.xml</code></p>
<p><img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_images/Face-Recognition-with-OpenCV/6.png"><br>Note:    </p>
<ol>
<li><p>Changes to the API of the OpenCV3.3 Face Recognition Module</p>
<p>a. Facerec.hpp before opencv3.3</p>
<pre><code class="line-numbers language-cpp">#ifndef __OPENCV_FACEREC_HPP__
#define __OPENCV_FACEREC_HPP__

#include &quot;opencv2/face.hpp&quot;
#include &quot;opencv2/core.hpp&quot;

namespace cv &#123; namespace face &#123;

// base for two classes
class CV_EXPORTS_W BasicFaceRecognizer : public FaceRecognizer
&#123;
public:
    /** @see setNumComponents */
    CV_WRAP virtual int getNumComponents() const = 0;
    // ----------- ...... -----------

    CV_WRAP virtual cv::Mat getEigenValues() const = 0;
    CV_WRAP virtual cv::Mat getEigenVectors() const = 0;
    CV_WRAP virtual cv::Mat getMean() const = 0;
&#125;;

CV_EXPORTS_W Ptr&lt;BasicFaceRecognizer&gt; createEigenFaceRecognizer(int num_components = 0, double threshold = DBL_MAX);

CV_EXPORTS_W Ptr&lt;BasicFaceRecognizer&gt; createFisherFaceRecognizer(int num_components = 0, double threshold = DBL_MAX);

class CV_EXPORTS_W LBPHFaceRecognizer : public FaceRecognizer
&#123;
public:
    /** @see setGridX */
    CV_WRAP virtual int getGridX() const = 0;
    /** @copybrief getGridX @see getGridX */
    CV_WRAP virtual void setGridX(int val) = 0;
    // ----------- ...... -----------
    CV_WRAP virtual cv::Mat getLabels() const = 0;
&#125;;

CV_EXPORTS_W Ptr&lt;LBPHFaceRecognizer&gt; createLBPHFaceRecognizer(int radius=1, int neighbors=8, int grid_x=8, int grid_y=8, double threshold = DBL_MAX);

&#125;&#125; //namespace cv::face

#endif //__OPENCV_FACEREC_HPP__</code></pre>
<ul>
<li><p>Comment section of the ninth line: <code>// base for two classes</code>,  This shows that BasicFaceRecognizer is the base class of two classes: EigenFaceRecognizer and FisherFaceRecognizer. With LBPHFaceRecognizer is irrelevant. Even the new API is still the case.</p>
</li>
<li><p>Method of creating three face recognizers.</p>
<pre><code class="line-numbers language-cpp">Ptr&lt;BasicFaceRecognizer&gt; model =  createEigenFaceRecognizer();
Ptr&lt;BasicFaceRecognizer&gt; model =  createFisherFaceRecognizer();
Ptr&lt;LBPHFaceRecognizer&gt; model  =  createLBPHFaceRecognizer();</code></pre>
</li>
</ul>
<p>b. Facerec.hpp after opencv3.3</p>
</li>
</ol>
<pre><code class="line-numbers language-cpp">#ifndef __OPENCV_FACEREC_HPP__
#define __OPENCV_FACEREC_HPP__

#include &quot;opencv2/face.hpp&quot;
#include &quot;opencv2/core.hpp&quot;

namespace cv &#123; namespace face &#123;

// base for two classes
class CV_EXPORTS_W BasicFaceRecognizer : public FaceRecognizer
&#123;
public:
    /** @see setNumComponents */
    CV_WRAP int getNumComponents() const;
    // ----------- ...... -----------
    CV_WRAP cv::Mat getEigenValues() const;
    CV_WRAP cv::Mat getEigenVectors() const;
    CV_WRAP cv::Mat getMean() const;

    virtual void read(const FileNode&amp; fn);
    virtual void write(FileStorage&amp; fs) const;
    virtual bool empty() const;

    using FaceRecognizer::read;
    using FaceRecognizer::write;

protected:
    int _num_components;
    double _threshold;
    std::vector&lt;Mat&gt; _projections;
    Mat _labels;
    Mat _eigenvectors;
    Mat _eigenvalues;
    Mat _mean;
&#125;;
class CV_EXPORTS_W EigenFaceRecognizer : public BasicFaceRecognizer
&#123;
public:
    CV_WRAP static Ptr&lt;EigenFaceRecognizer&gt; create(int num_components = 0, double threshold = DBL_MAX);
&#125;;

class CV_EXPORTS_W FisherFaceRecognizer : public BasicFaceRecognizer
&#123;
public:
    CV_WRAP static Ptr&lt;FisherFaceRecognizer&gt; create(int num_components = 0, double threshold = DBL_MAX);
&#125;;
class CV_EXPORTS_W LBPHFaceRecognizer : public FaceRecognizer
&#123;
public:
    /** @see setGridX */
    CV_WRAP virtual int getGridX() const = 0;
    // ----------- ...... -----------
    CV_WRAP virtual cv::Mat getLabels() const = 0;
    CV_WRAP static Ptr&lt;LBPHFaceRecognizer&gt; create(int radius=1, int neighbors=8, int grid_x=8, int grid_y=8, double threshold = DBL_MAX);
&#125;;
&#125;&#125; //namespace cv::face

#endif //__OPENCV_FACEREC_HPP__</code></pre>
<ul>
<li>Both EigenFaceRecognizer and FisherFaceRecognizer are inherited from BasicFaceRecognizer. However, the LBFPHaceRecognizer, like the BasicFaceRecognizer, inherits from FaceRecognizer.    </li>
<li>Method of creating three face recognizer</li>
</ul>
<pre><code class="line-numbers language-cpp">Ptr&lt;EigenFaceRecognizer&gt; model  = EigenFaceRecognizer::create();
Ptr&lt;FisherFaceRecognizer&gt; model = FisherFaceRecognizer::create();
Ptr&lt;LBPHFaceRecognizer&gt; model   = LBPHFaceRecognizer::create();</code></pre>
<h2 id="3-Identify-faces-in-the-video-stream-camera"><a href="#3-Identify-faces-in-the-video-stream-camera" class="headerlink" title="3. Identify faces in the video stream (camera)"></a>3. Identify faces in the video stream (camera)</h2><h3 id="3-1-Ready-to-work"><a href="#3-1-Ready-to-work" class="headerlink" title="3.1 Ready to work."></a>3.1 Ready to work.</h3><h4 id="3-1-1-Copy-the-training-file-obtained-in-the-second-step-to-the-current-folder"><a href="#3-1-1-Copy-the-training-file-obtained-in-the-second-step-to-the-current-folder" class="headerlink" title="3.1.1 Copy the training file obtained in the second step to the current folder."></a>3.1.1 Copy the training file obtained in the second step to the current folder.</h4><h4 id="3-1-2-The-process-or-method-of-Face-Recognition"><a href="#3-1-2-The-process-or-method-of-Face-Recognition" class="headerlink" title="3.1.2 The process or method of Face Recognition"></a>3.1.2 The process or method of Face Recognition</h4><p>This step has a similar part to the creation of a face recognition database.</p>
<ul>
<li>Open the camera</li>
<li>Loading face detector, face model</li>
<li>Scale the image (for efficiency)</li>
<li>Face recognition (compare to face model)</li>
<li>Label faces with rectangular wireframes and add text labels</li>
</ul>
<h4 id="3-2-Code"><a href="#3-2-Code" class="headerlink" title="3.2 Code"></a>3.2 Code</h4><pre><code class="line-numbers language-cpp">#include &lt;opencv2/opencv.hpp&gt;  
#include &quot;opencv2/core.hpp&quot;
#include &quot;opencv2/face.hpp&quot;
#include &quot;opencv2/highgui.hpp&quot;
#include &quot;opencv2/imgproc.hpp&quot;
#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;sstream&gt;

using namespace cv;
using namespace cv::face;
using namespace std;

#define ROW_MIN        45

int exitFlag = 0;

int Recognition_And_Draw();

int Recognition_And_Draw()&#123;
  int ret = 0; //
  double scale = 4; //Zoom factor
  double fx = 1 / scale;
  Mat frame;  //Video frame
  VideoCapture cap(0);    //Open the camera
  if(!cap.isOpened())&#123;
    cout &lt;&lt; &quot;Open camera failed.\n&quot; &lt;&lt; endl;
    return -1;
  &#125;

  //Load cascade classifier
  CascadeClassifier cascade;
  ret = cascade.load(&quot;haarcascade_frontalface_alt2.xml&quot;);

  if(!ret)&#123;
    printf(&quot;Load xml failed[ret = %d]. \n&quot;, ret);
    return -1;
  &#125;
  cout &lt;&lt; &quot;Load xml succeed.&quot; &lt;&lt; endl;

  // Loading trained face models
  Ptr&lt;BasicFaceRecognizer&gt; modelPCA = EigenFaceRecognizer::create();  
  modelPCA-&gt;read(&quot;MyFacePCAModel.xml&quot;);  
  Ptr&lt;BasicFaceRecognizer&gt; modelFisher = FisherFaceRecognizer::create();
  modelFisher-&gt;read(&quot;MyFaceFisherModel.xml&quot;);  
  Ptr&lt;LBPHFaceRecognizer&gt; modelLBPH = LBPHFaceRecognizer::create();  
  modelLBPH-&gt;read(&quot;MyFaceLBPHModel.xml&quot;);  

  while(!exitFlag)&#123;
    cap &gt;&gt; frame;
    if(frame.empty())
      continue;

    Mat facesImg;  //
    vector&lt;Rect&gt; faces;  //Create a vector container for storing faces
    Mat gary_img; //grayscale image
    Mat scl_gary_img; //Scaled grayscale image

    cvtColor(frame, gary_img, COLOR_BGR2GRAY); //Convert the original image to a grayscale image
    resize(gary_img, scl_gary_img, Size(), fx, fx, INTER_LINEAR); //resize img
    equalizeHist( scl_gary_img, scl_gary_img );

  //face detection
    cascade.detectMultiScale(scl_gary_img, faces, 1.1, 2, 0|CASCADE_SCALE_IMAGE,Size(30, 30));
    printf(&quot;Face.size = %ld\n&quot;, faces.size());
  //facesImg = scl_gary_img(faces[0]);

    Mat face_resize;  //To prevent the picture is too small (that is, people too far away from the camera)
    int predictPCA = 0;  
    int predictFisher = 0;  
    int predictLBPH = 0;
    for(size_t i = 0; i &lt; faces.size(); i++)&#123;

      Rect rectFace = faces[i];
      facesImg = scl_gary_img(faces[i]);
      if(facesImg.rows &gt;= ROW_MIN)&#123;
        resize(facesImg, face_resize, Size(92, 112));
      &#125;
      else&#123;
        printf(&quot;faceImg.rows[%d] &lt; %d \n&quot;, facesImg.rows, ROW_MIN);
        continue;
      &#125;
      if(!face_resize.empty())&#123;
        predictPCA = modelPCA-&gt;predict(face_resize);  
        predictFisher = modelFisher-&gt;predict(face_resize);  
        predictLBPH = modelLBPH-&gt;predict(face_resize); 
      &#125;
      cout &lt;&lt; &quot;predictPCA   : &quot; &lt;&lt; predictPCA    &lt;&lt; endl;
      cout &lt;&lt; &quot;predictFisher: &quot; &lt;&lt; predictFisher &lt;&lt; endl;
      cout &lt;&lt; &quot;predictLBPH  : &quot; &lt;&lt; predictLBPH   &lt;&lt; endl;
      rectangle(frame, Point(rectFace.x, rectFace.y) * scale, Point(rectFace.x + rectFace.width, rectFace.y + rectFace.height) * scale, Scalar(0, 255, 0), 2, 8);
      if (predictPCA == 41)&#123;
        putText(frame, &quot;Liuyang&quot;, Point(faces[i].x, faces[i].y) * scale, FONT_HERSHEY_SIMPLEX, 1, Scalar(0, 0, 255), 2);
      &#125;
      else&#123;
        putText(frame, &quot;X&quot;, Point(faces[i].x, faces[i].y) * scale, FONT_HERSHEY_SIMPLEX, 1.5, Scalar(0, 0, 255), 2);
      &#125;

  // if(faces.size() &lt;= 0)&#123;
  //  cout &lt;&lt; &quot;There are no faces in the camera.\n&quot; &lt;&lt; endl;
 // &#125;
    &#125;
    imshow(&quot;frame&quot;, frame);
      if (waitKey(1) == 27)&#123;
                exitFlag = 1;
                cout &lt;&lt; &quot;Esc...&quot; &lt;&lt; endl;
                break;
      &#125;
  &#125;
&#125;

int main()&#123;
  Recognition_And_Draw();
  return 0;
&#125;</code></pre>
<p><img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_images/Face-Recognition-with-OpenCV/7.jpg"></p>
<p>Note:    </p>
<ol>
<li>This program supports multiple face recognition at the same time</li>
<li>Face recognition accuracy is not high, and it is susceptible to environmental factors such as light.</li>
</ol>

            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward" class="reward-content">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">如果觉得本文对你有帮助，请赏杯咖啡呗！</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@master/blog_source/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>转载规则</span>
        </p>
        
            <div class="center-align">
                <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《Face Recognition》
                </span> 由
            <a xmlns:cc="http://creativecommons.org/ns#" href="/2019/08/10/face-recognition-with-opencv/" property="cc:attributionName"
               rel="cc:attributionURL">
                留洋
            </a> 采用
            <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                知识共享署名 4.0 国际许可协议
            </a>进行许可。
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'hDkKfARtq15Qmzk62bNg9BR6-gzGzoHsz',
        appKey: 'kLSDOxY3iclKHGiVHrAzoNoR',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'false' === 'true',
        avatar: '',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!'
    });
</script>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2019/08/24/manjaro-i3wm-huan-jing-pei-zhi-pian/">
                    <div class="card-image">
                        
                        <img src="https://cdn.jsdelivr.net/gh/liuyaanng/blog_source@master/blog_images/Manjaro-i3wm-环境配置篇/paper.jpg" class="responsive-img" alt="Manjaro i3wm 高效率环境配置篇(持续更新)">
                        
                        <span class="card-title">Manjaro i3wm 高效率环境配置篇(持续更新)</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Manjaro i3wm配置教程
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-08-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%95%99%E7%A8%8B/" class="post-category" target="_blank">
                                    教程
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Manjaro/" target="_blank">
                        <span class="chip bg-color">Manjaro</span>
                    </a>
                    
                    <a href="/tags/i3wm/" target="_blank">
                        <span class="chip bg-color">i3wm</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/08/09/how-to-install-opencv-and-opencv-contrib-in-ubuntu16-04/">
                    <div class="card-image">
                        
                        <img src="https://i.loli.net/2019/08/15/T7lJf18cUGmQnHh.jpg" class="responsive-img" alt="How to install OpenCV and OpenCV_contrib in Ubuntu16.04">
                        
                        <span class="card-title">How to install OpenCV and OpenCV_contrib in Ubuntu16.04</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-08-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-user fa-fw"></i>
                            留洋
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: Kevin<br />'
            + '作者: 留洋<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/liuyaanng/Blog_source@1.1/blog_source/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
