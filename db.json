{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/matery/source/favicon.jpg","path":"favicon.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/css/gitment.css","path":"css/gitment.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/matery.css","path":"css/matery.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/css/my.css","path":"css/my.css","modified":1,"renderable":1},{"_id":"themes/matery/source/js/matery.js","path":"js/matery.js","modified":1,"renderable":1},{"_id":"themes/matery/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/avatar.jpg","path":"medias/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/logo.png","path":"medias/logo.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/alipay.jpg","path":"medias/reward/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/cover.jpg","path":"medias/cover.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","path":"libs/jquery/jquery-2.2.0.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/reward/wechat.jpg","path":"medias/reward/wechat.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/photo/2.jpg","path":"medias/photo/2.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","path":"libs/awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","path":"libs/awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","path":"libs/awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","path":"libs/awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","path":"libs/awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","path":"libs/awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","path":"libs/awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/photo/6.jpg","path":"medias/photo/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/photo/3.jpg","path":"medias/photo/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/photo/5.jpg","path":"medias/photo/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/photo/4.jpg","path":"medias/photo/4.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/photo/1.jpg","path":"medias/photo/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/LeavingAkina.mp3","path":"medias/music/LeavingAkina.mp3","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/music/wecantstop.mp3","path":"medias/music/wecantstop.mp3","modified":1,"renderable":1},{"_id":"themes/matery/source/medias/photo/0.jpg","path":"medias/photo/0.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/404.md","hash":"9e6f55d7c01343e1ffd36d55860587fd269d6cb6","modified":1565434053782},{"_id":"source/CNAME","hash":"64f12ba4fc85e919e927bf1750221800453187cd","modified":1565434053786},{"_id":"source/friends.json","hash":"ed2bc844047e1dde553d4b3a1910b8f736f7417e","modified":1565434054326},{"_id":"source/_bbs/index.md","hash":"eb40bcb5ee1e5741f25463f7791ea1d288b51811","modified":1565434053786},{"_id":"source/_data/friends.json","hash":"a504fe2f7e2c013c06d443bf8b6b8c3b520c1a17","modified":1565434053786},{"_id":"source/_data/musics.json","hash":"66260ade69d134f872dffb45754b2700f961ae44","modified":1565434053786},{"_id":"source/_posts/Day01.md","hash":"bce749cfbcab006601e3fec1f312d5e108605846","modified":1565434053786},{"_id":"source/_posts/Day02.md","hash":"c51455a0d1fdb59856af3d771dba951785d4cf02","modified":1565434053786},{"_id":"source/_posts/Day03.md","hash":"fa3590c09fc5d0d01a0dbf69e9877497868745a5","modified":1565434053786},{"_id":"source/_posts/Day04.md","hash":"38ad692bb376bd2113ce0f2b718fb15b6b327dd7","modified":1565434053786},{"_id":"source/_posts/Day05.md","hash":"6a9e7f37037f183a14728a3e95b5ace772f04bdd","modified":1565434053786},{"_id":"source/_posts/Day06.md","hash":"c3f8b99acd6889a0d356d4631e25b49c9114cb4f","modified":1565434054074},{"_id":"source/_posts/Day07.md","hash":"180c7e4dde29374fd16444c702428e97b58b800f","modified":1565434054074},{"_id":"source/_posts/Day08.md","hash":"80868ade9426315ef9787aa2842cb6740291f219","modified":1565434054074},{"_id":"source/_posts/Day09.md","hash":"e762e5d0957e2bf7c90a59f6c7c6c647a13e6503","modified":1565434054074},{"_id":"source/_posts/Day10.md","hash":"1dfa9edee6e9725555b790f6570668311cfa64de","modified":1565434054074},{"_id":"source/_posts/Day11.md","hash":"18e47e0eaeabf6d91c10036f9e99e6e5c1598386","modified":1565434054074},{"_id":"source/_posts/Day12.md","hash":"f247b307c03f65d666174415312823786796184e","modified":1565434054074},{"_id":"source/_posts/Day13.md","hash":"a74f3b7ca10f702bbcaa44078087191663d5bad8","modified":1565434054074},{"_id":"source/_posts/Day14.md","hash":"a65f5d7a433589bf32372aa4510d57a24844982f","modified":1565434054074},{"_id":"source/_posts/Day15.md","hash":"928b29b0d50ff05011b380f88ddbba10db818b26","modified":1565434054074},{"_id":"source/_posts/Day16.md","hash":"77cbc9d730f703c8296214632853b89e92e46ab5","modified":1565434054074},{"_id":"source/_posts/Day17.md","hash":"1e4d574674dcdca835919f28959d3cd48f4ca98a","modified":1565434054078},{"_id":"source/_posts/Day18.md","hash":"307f85a02029c05c9b8836b658af2629ff78ad65","modified":1565434054078},{"_id":"source/_posts/Day19.md","hash":"02022df683afc760b70e5ed76fe87b64c530415b","modified":1565434054078},{"_id":"source/_posts/Enjoy-PyTorch-Task1.md","hash":"472b6199b1759ddb0152db0c9282d81e6dc17c21","modified":1565434054078},{"_id":"source/_posts/Enjoy-PyTorch.md","hash":"daba0616694264482aec01827e37912c76c55a5d","modified":1565434054078},{"_id":"source/_posts/Face-Recognition-with-OpenCV.md","hash":"d0ed411046fac5df0231f0b72ca9e2eaa0b7b1f0","modified":1565434054078},{"_id":"source/_posts/How-to-install-OpenCV-and-OpenCV-contrib-in-Ubuntu16-04.md","hash":"da98426951430b135c756be77124bab82469be7e","modified":1565434054114},{"_id":"source/_posts/Markdown数学公式汇总.md","hash":"10fc35ba6adaf8e18f7f302238dafdba4f84bbf9","modified":1565434054114},{"_id":"source/_posts/My-plan.md","hash":"a34f2d3daa93bb5aaafff076852a683bdea09e76","modified":1565434054114},{"_id":"source/_posts/OpenCV入坑指南-环境搭建篇.md","hash":"69b649038a2a023a4c635f0fe5ca34bca7889318","modified":1565434054114},{"_id":"source/_posts/PCA原理分析.md","hash":"b614c9a1adb7a6f1ef71b32256f37371a60b71b3","modified":1565434054114},{"_id":"source/_posts/PCA算法实现.md","hash":"bcdfc8b8f1573fe581fe0f2bf93f4bf486448648","modified":1565434054322},{"_id":"source/_posts/hello-world.md","hash":"55f2568e5f31037eb34c7b1d66258b75f5ef3f42","modified":1565434054326},{"_id":"source/_posts/hexo大坑.md","hash":"d3be0ae0abfd290ea799eb0ec5bafceb6af3340d","modified":1565434054326},{"_id":"source/_posts/实习第一周.md","hash":"5e82d4c4d10a047634da4ceae1e32f596190735e","modified":1565434054326},{"_id":"source/_posts/实习第二周.md","hash":"27a7dd4099bfd7084ea31bd33ac34b903b38b8f2","modified":1565434054326},{"_id":"source/about/index.md","hash":"863e56477447bb1ac8c24c61acf01ced2d955a54","modified":1565434054326},{"_id":"source/categories/index.md","hash":"444b7cf46adaad3f5f898cf928c8b8d2a81739ad","modified":1565434054326},{"_id":"source/friends/index.md","hash":"067eda63e1207b3f40d36a17f4c9c77bcba1db0b","modified":1565434054326},{"_id":"source/tags/index.md","hash":"9bea216a33b3e5b31ee760ba18e1f390070a4933","modified":1565434054326},{"_id":"source/_posts/Enjoy-PyTorch/1.png","hash":"27216299db2dde24c97eb5c79b56beab42cf36b9","modified":1565434054078},{"_id":"source/_posts/Enjoy-PyTorch-Task1/1.png","hash":"62b8d8e55ec4e7985bd78c520aabf90ba84c9ec9","modified":1565434054078},{"_id":"source/_posts/PCA原理分析/03.png","hash":"6cc32153244ba33af752159cb71ff7a0ac417d06","modified":1565434054118},{"_id":"source/_posts/PCA原理分析/05.png","hash":"1acd87f837814fb46cfaa0b029445caa57fc9c12","modified":1565434054118},{"_id":"source/_posts/PCA原理分析/06.png","hash":"b4dce1b49516ac0527c9e1423c0d30138b345efd","modified":1565434054118},{"_id":"source/_posts/PCA原理分析/02.png","hash":"03f787abd87e8ac5c51ef9951da4c0dbc360d4c5","modified":1565434054118},{"_id":"source/_posts/PCA原理分析/07.png","hash":"3accf1b5326def91e3698dd848bf5049a9e79094","modified":1565434054186},{"_id":"source/_posts/PCA原理分析/01.png","hash":"8589b73b17a5b40615619ba7f8d76420315fa53d","modified":1565434054118},{"_id":"source/_posts/PCA算法实现/02.png","hash":"3accf1b5326def91e3698dd848bf5049a9e79094","modified":1565434054326},{"_id":"source/_posts/PCA算法实现/01.png","hash":"32e72c36f17cee27412c321469812ef99bc2b0b9","modified":1565434054326},{"_id":"source/_posts/Face-Recognition-with-OpenCV/att_faces.zip","hash":"6c6d27116725c51910e639009c35117eaa8b0716","modified":1565434054114},{"_id":"source/_posts/PCA原理分析/PCA.pdf","hash":"5346883e784b16b146048413df0c647a518dbcee","modified":1565434054322},{"_id":"public/friends.json","hash":"3e0a0172ce25c9e003d762b6e2481ccb985e135b","modified":1565434193521},{"_id":"public/atom.xml","hash":"89e8dfedd6da2917fd5e97e6574ba930fd6d9c72","modified":1565434193521},{"_id":"public/search.xml","hash":"0634418629a8f3c22303748882ce8eb3a49ebefa","modified":1565434193522},{"_id":"public/404.html","hash":"5291b6513c5f428efe033e0b77efc717b3d045b6","modified":1565437877786},{"_id":"public/about/index.html","hash":"350e00af1acd8c7175174a40d5af14c61def5553","modified":1565437878806},{"_id":"public/categories/index.html","hash":"950e9e6ac6be24b7969ff2cf0f68e4cdc6c0b7c3","modified":1565437878807},{"_id":"public/tags/index.html","hash":"4749256f01e37ae4ff6b41f7e53654100385aecf","modified":1565437878806},{"_id":"public/friends/index.html","hash":"f212f38417e8ab864a154c5fa60a87877336bcbc","modified":1565437878807},{"_id":"public/2019/08/09/face-recognition-with-opencv/index.html","hash":"cf7a5217aced5bb8107eff2ebc71540910a0c9d8","modified":1565437878807},{"_id":"public/2019/08/09/how-to-install-opencv-and-opencv-contrib-in-ubuntu16-04/index.html","hash":"47a594d847b52c9dd57a488271b6a6c1539af1bd","modified":1565437878807},{"_id":"public/2019/08/07/enjoy-pytorch-task1/index.html","hash":"3102e7e08f4761cc85b8baf27635b20c5d232c1d","modified":1565437878807},{"_id":"public/2019/08/07/enjoy-pytorch/index.html","hash":"92dc111d40f5e222633227cc21874d86b78ac43d","modified":1565437878807},{"_id":"public/2019/08/07/pca-suan-fa-shi-xian/index.html","hash":"4d9319eb8c7557aa34cdfbec75efcc2a9583f9f1","modified":1565437878807},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/index.html","hash":"7a2422bc89d9a852b9a97ab64f4f4cd7e0b2692f","modified":1565437878807},{"_id":"public/2019/08/02/day19/index.html","hash":"23155d748cd934e9383566dcf617e2669793c05a","modified":1565437878807},{"_id":"public/2019/08/01/day18/index.html","hash":"a3489add8c1de6c45c13bed5befeb9be25af8178","modified":1565437878807},{"_id":"public/2019/07/31/day17/index.html","hash":"ca84f6420b905510716424f5adc6bfa050967846","modified":1565437878807},{"_id":"public/2019/07/30/day16/index.html","hash":"b3cd1890edc200b02b5b8965402292ed51e20a8f","modified":1565437878807},{"_id":"public/2019/07/29/day15/index.html","hash":"f7a1571e1c9d9ea7ffe614e567bca3a9b62eef7f","modified":1565437878807},{"_id":"public/2019/07/28/day14/index.html","hash":"11ecc06bdeffdd252b1e80e6200f3a4a9ddd10b2","modified":1565437878807},{"_id":"public/2019/07/27/day13/index.html","hash":"48a9f740eef03e2ff0aacf36d4eac1c88e4279b8","modified":1565437878808},{"_id":"public/2019/07/26/day12/index.html","hash":"d8235263e11ca3360691a7051702ac360f2d4625","modified":1565437878808},{"_id":"public/2019/07/25/opencv-ru-keng-zhi-nan-huan-jing-da-jian-pian/index.html","hash":"34ddae1cbd2aea4b6a84db4feba01f99d29e43fb","modified":1565437878808},{"_id":"public/2019/07/25/day11/index.html","hash":"4258082422e350535f37fe35e8663484ed1bb264","modified":1565437878808},{"_id":"public/2019/07/24/day10/index.html","hash":"b36da032e37e8ecc60150eb2fd15757e4e64f3fe","modified":1565437878808},{"_id":"public/2019/07/23/day09/index.html","hash":"ef6b7ff56d4da5024f1d548e8bd0b746b807ae62","modified":1565437878808},{"_id":"public/2019/07/22/hexo-da-keng/index.html","hash":"42131add592f8f5a35947301911547d2b46ebea9","modified":1565437878808},{"_id":"public/2019/07/22/day08/index.html","hash":"473c95b9a488f5b21610d587328f8390b4016cce","modified":1565437878808},{"_id":"public/2019/07/21/shi-xi-di-er-zhou/index.html","hash":"f50fd02de4fb3ee1a2e3c83ac9525cf63a6405e4","modified":1565437878808},{"_id":"public/2019/07/21/day07/index.html","hash":"d97edc2fb49f81c99eb3c6de116805f2bc1d08ab","modified":1565437878808},{"_id":"public/2019/07/20/day06/index.html","hash":"23861e58cc080da33b23b290830fda52a981b223","modified":1565437878808},{"_id":"public/2019/07/19/markdown-shu-xue-gong-shi-hui-zong/index.html","hash":"fda2b2c53c1d01a454650061e544ec18f6719623","modified":1565437878808},{"_id":"public/2019/07/19/day05/index.html","hash":"c782c0470a4aa91dead1d79859e3e0de0bca496e","modified":1565437878808},{"_id":"public/2019/07/18/day04/index.html","hash":"ebc924861fd26da02f1d067abaa1409775fe4c68","modified":1565437878808},{"_id":"public/2019/07/17/day03/index.html","hash":"c812687f681cc2d1249c63dbafa637fd80667106","modified":1565437878809},{"_id":"public/2019/07/16/day02/index.html","hash":"3e37be6f21f63f67ae81c62380324c5717c0f228","modified":1565437878809},{"_id":"public/2019/07/15/day01/index.html","hash":"7bd32056a4f93e2a93b560d063041dbdbd1c5c1f","modified":1565437878809},{"_id":"public/2019/07/14/shi-xi-di-yi-zhou/index.html","hash":"91286acb576ee649c93c837fbba315a52d786a2b","modified":1565437878809},{"_id":"public/2019/07/05/my-plan/index.html","hash":"ed181fe255b6a7a652a77d1087f33e35cc52ffbb","modified":1565437878809},{"_id":"public/2019/07/01/hello-world/index.html","hash":"04b9c0edd3cb6377361edf23826dbe7717983a30","modified":1565437878809},{"_id":"public/categories/OpenCV/index.html","hash":"ddfece3e2e2d15d5c1f5c38e4f16a46878bce753","modified":1565437878809},{"_id":"public/categories/OpenCV/C/index.html","hash":"8c66b46892db4bc241f1c7ffaf55df5e732acdfc","modified":1565437878809},{"_id":"public/categories/算法/index.html","hash":"d0dcc574e43361d27def9d0a4f7d5838b1cc0eac","modified":1565437878809},{"_id":"public/archives/index.html","hash":"90ae4204e269aebc1a9079d01cc3f4af9006461e","modified":1565437878809},{"_id":"public/archives/page/2/index.html","hash":"ff8dffe24813279ef87948902430df6ebade4e9c","modified":1565437878809},{"_id":"public/archives/page/3/index.html","hash":"254dcd618231545dbba052250e2662df571b0903","modified":1565437878810},{"_id":"public/archives/2019/index.html","hash":"dcd7da506d7d09da61b3836178e828876a1834f5","modified":1565437878809},{"_id":"public/archives/2019/page/2/index.html","hash":"82fd1496f185e57cb1fdd2696adbe792c2b9a363","modified":1565437878810},{"_id":"public/archives/2019/page/3/index.html","hash":"d415bd6de50b093712bedabc92176803f43d7650","modified":1565437878810},{"_id":"public/archives/2019/07/index.html","hash":"2b0d07910b3a19664e3a7228d38fa7bec3dbc2cd","modified":1565437878809},{"_id":"public/archives/2019/07/page/2/index.html","hash":"c2f157d13f9abe00b5d87c92aabe8f04ee73d33c","modified":1565437878810},{"_id":"public/archives/2019/08/index.html","hash":"c704775ad8d86b6911d999101cf211592191fe5a","modified":1565437878810},{"_id":"public/tags/实习/index.html","hash":"286fa0fab011349f082f610db9f73327de0b9694","modified":1565437878810},{"_id":"public/tags/实习/page/2/index.html","hash":"e161617fa413bff490840d0520ce63c6e0974c8e","modified":1565437878810},{"_id":"public/tags/实习-OpenCV/index.html","hash":"4838a89e5ec4633ae395697c0b64d7941df83814","modified":1565437878810},{"_id":"public/tags/Markdown/index.html","hash":"91d26752173dfbeeb210f21856969d49e36c22fb","modified":1565437878810},{"_id":"public/tags/plan/index.html","hash":"09109e1bf8552450dc0b99270e741a0fdcb0132b","modified":1565437878810},{"_id":"public/tags/OpenCV/index.html","hash":"076a644b7824e6190b4d1d2bb25ab5004f4eb2da","modified":1565437878810},{"_id":"public/tags/hexo/index.html","hash":"ab9f0a9b6f874f90ba2dae6c2e5989cc5bfa1808","modified":1565437878810},{"_id":"public/tags/PCA/index.html","hash":"7d396843b4e7273b8431d694f0cca74057b596b8","modified":1565437878810},{"_id":"public/index.html","hash":"a8918673ce507829cd3c86c624b73623ec54b7f3","modified":1565437878809},{"_id":"public/page/2/index.html","hash":"8568f8585750b1dbe577242c69d6235188b1d789","modified":1565437878809},{"_id":"public/page/3/index.html","hash":"90ed3701a51fcddb032bd7cf928ccfe2379e31e1","modified":1565437878809},{"_id":"public/CNAME","hash":"64f12ba4fc85e919e927bf1750221800453187cd","modified":1565434193536},{"_id":"public/2019/08/07/enjoy-pytorch-task1/1.png","hash":"62b8d8e55ec4e7985bd78c520aabf90ba84c9ec9","modified":1565434193536},{"_id":"public/2019/08/07/enjoy-pytorch/1.png","hash":"27216299db2dde24c97eb5c79b56beab42cf36b9","modified":1565434193536},{"_id":"public/2019/08/07/pca-suan-fa-shi-xian/02.png","hash":"3accf1b5326def91e3698dd848bf5049a9e79094","modified":1565434193536},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/01.png","hash":"8589b73b17a5b40615619ba7f8d76420315fa53d","modified":1565434193537},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/02.png","hash":"03f787abd87e8ac5c51ef9951da4c0dbc360d4c5","modified":1565434193537},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/03.png","hash":"6cc32153244ba33af752159cb71ff7a0ac417d06","modified":1565434193537},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/05.png","hash":"1acd87f837814fb46cfaa0b029445caa57fc9c12","modified":1565434193537},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/06.png","hash":"b4dce1b49516ac0527c9e1423c0d30138b345efd","modified":1565434193537},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/07.png","hash":"3accf1b5326def91e3698dd848bf5049a9e79094","modified":1565434193537},{"_id":"public/css/prism-tomorrow.css","hash":"3b99487dfc9b4e51e9105a93743b92a761840e34","modified":1565434193537},{"_id":"public/2019/08/07/pca-suan-fa-shi-xian/01.png","hash":"32e72c36f17cee27412c321469812ef99bc2b0b9","modified":1565434193557},{"_id":"public/2019/08/09/face-recognition-with-opencv/att_faces.zip","hash":"6c6d27116725c51910e639009c35117eaa8b0716","modified":1565434193593},{"_id":"public/2019/08/05/pca-yuan-li-fen-xi/PCA.pdf","hash":"5346883e784b16b146048413df0c647a518dbcee","modified":1565434193597},{"_id":"themes/matery/README_CN.md","hash":"302393db1fa6c0911558402ab8c75745516fa5ed","modified":1565436517773},{"_id":"themes/matery/_config.yml","hash":"1c378544792f9f4607e2d01e91bd99dac2bd97c5","modified":1565436517773},{"_id":"themes/matery/LICENSE","hash":"7df059597099bb7dcf25d2a9aedfaf4465f72d8d","modified":1565436517773},{"_id":"themes/matery/README.md","hash":"c46e2a112951e49af60ad6ad7a2893738e3e413d","modified":1565436517773},{"_id":"themes/matery/languages/zh-CN.yml","hash":"a34ae486c288a4966c5968abc29d3f40207d6d2f","modified":1565436517777},{"_id":"themes/matery/languages/default.yml","hash":"0dabf7ed059bfe20561288c2e178f0640d9a0b3b","modified":1565436517773},{"_id":"themes/matery/layout/404.ejs","hash":"03952ff773d83a5b418a5d3a80d05871097bf29e","modified":1565436517777},{"_id":"themes/matery/layout/categories.ejs","hash":"8e54665cc25d7c333da7d9f312987190be6215da","modified":1565436517781},{"_id":"themes/matery/layout/about.ejs","hash":"ee639d0310867976b3e5fb9f92c215a17a433703","modified":1565436517781},{"_id":"themes/matery/layout/bbs.ejs","hash":"21ca6d5ff2bb98cc95c996bfb0a479bfea31a23c","modified":1565436517781},{"_id":"themes/matery/layout/category.ejs","hash":"dff72c3a6f3ec6022886e526e6c404e8a0e630bf","modified":1565436517781},{"_id":"themes/matery/layout/friends.ejs","hash":"1c08e2257a756d7ce40eedfdb80e642fbd5215ed","modified":1565436517781},{"_id":"themes/matery/layout/archive.ejs","hash":"aef83631460e091af8130cf3f9614477ee24914f","modified":1565436517781},{"_id":"themes/matery/layout/tag.ejs","hash":"4305eeeb3434c24ba2493fa08d1f1bd9f2efa9aa","modified":1565436517781},{"_id":"themes/matery/layout/tags.ejs","hash":"cf9517aa6a0111355121f44615d6923e312283c7","modified":1565436517781},{"_id":"themes/matery/layout/index.ejs","hash":"57ab845a407baad6e6cc573b2c32b2dbcc972258","modified":1565436517781},{"_id":"themes/matery/source/favicon.jpg","hash":"f78e544a4aa6ec66ea8d25b18ea220880580b126","modified":1565436517781},{"_id":"themes/matery/layout/layout.ejs","hash":"10f20cf017af6f46c035e5f7080fa4b70a9dd239","modified":1565436517781},{"_id":"themes/matery/layout/post.ejs","hash":"37c6888af845cfa4204b6f490d332442d0db3656","modified":1565436517781},{"_id":"themes/matery/layout/_partial/back-top.ejs","hash":"8c91d2088c9bb323246b054d4940bde6cead6828","modified":1565436517777},{"_id":"themes/matery/layout/_partial/bg-cover-content.ejs","hash":"04e11ad052befe3e7fe0ce86bf67db95c11cb762","modified":1565436517777},{"_id":"themes/matery/layout/_partial/gitalk.ejs","hash":"e4c5bf28ddc29519eee8debe79cce45bf279adeb","modified":1565436517777},{"_id":"themes/matery/layout/_partial/footer.ejs","hash":"bddb924c4be02e92a625a1545972f4e8ff3efb4c","modified":1565436517777},{"_id":"themes/matery/layout/_partial/github-link.ejs","hash":"3aeb581bd78ab8e15b858e4c44c03bcf92f20b9e","modified":1565436517777},{"_id":"themes/matery/layout/_partial/gitment.ejs","hash":"0abfb51dc80ad063fb2118bee28de6bb8d99ed4e","modified":1565436517777},{"_id":"themes/matery/layout/_partial/google-analytics.ejs","hash":"5f4992205617da5f8cc5863c62b5ec46e414e2fb","modified":1565436517777},{"_id":"themes/matery/layout/_partial/head.ejs","hash":"1f337fe1343f87fc958eded799a9ac93fc194e87","modified":1565436517777},{"_id":"themes/matery/layout/_partial/header.ejs","hash":"e253c813b3ee5ed924700a95133741802e58adc5","modified":1565436517777},{"_id":"themes/matery/layout/_partial/index-cover.ejs","hash":"6583c00323d891a03343b6a621a0484a68d74f8a","modified":1565436517777},{"_id":"themes/matery/layout/_partial/livere.ejs","hash":"9c3401b42ea7f26410a5593bae93ada7e57b43be","modified":1565436517777},{"_id":"themes/matery/layout/_partial/mobile-nav.ejs","hash":"b70a2d40677d64d6b56fc51ac1331ad3a50e777c","modified":1565436517777},{"_id":"themes/matery/layout/_partial/navigation.ejs","hash":"20216e7ad6b48d4a4f8d11d6881e667e5186820f","modified":1565436517777},{"_id":"themes/matery/layout/_partial/paging.ejs","hash":"68a24cad2b2049c4dc3a250aa30bf4256f9e50cb","modified":1565436517777},{"_id":"themes/matery/layout/_partial/post-cover.ejs","hash":"5b423384b9c0fe77acc4247a8a85304022e5bd2a","modified":1565436517777},{"_id":"themes/matery/layout/_partial/post-detail-toc.ejs","hash":"d4114c22126704cc1754d6d28cb00aec020b428b","modified":1565436517777},{"_id":"themes/matery/layout/_partial/post-detail.ejs","hash":"f06a29c00cd58fe8159e7b1e7a5ea8277b97f25b","modified":1565436517777},{"_id":"themes/matery/layout/_partial/post-statis.ejs","hash":"2b2fe8e8e94e65c52a4dbd454168e9b9df6baf10","modified":1565436517777},{"_id":"themes/matery/layout/_partial/prev-next.ejs","hash":"30b51f344d6ab2856dfe2393e2a32556eb54bb10","modified":1565436517777},{"_id":"themes/matery/layout/_partial/reprint-statement.ejs","hash":"3d61d4acde8d27a63072145130d2661df8c05df7","modified":1565436517777},{"_id":"themes/matery/layout/_partial/reward.ejs","hash":"3dff4f6a73973b0b32f40604244255f3c2a5bb78","modified":1565436517777},{"_id":"themes/matery/layout/_partial/search.ejs","hash":"942609b9240d5c8c09b24562fc8fb31eabe1cae4","modified":1565436517777},{"_id":"themes/matery/layout/_partial/share.ejs","hash":"34f8e4250bb66012026aa50686a7c89a0414ca1b","modified":1565436517777},{"_id":"themes/matery/layout/_partial/social-link.ejs","hash":"62e10bf4577946190e9c31dcdc2799a4ad1d00dd","modified":1565436517777},{"_id":"themes/matery/layout/_widget/category-cloud.ejs","hash":"a5a10d6fa66a389d0253d7a52e0a646af6e8e9be","modified":1565436517777},{"_id":"themes/matery/layout/_widget/dream.ejs","hash":"684450f0b42f89ab70370c5248b34e55b7adf6fc","modified":1565436517777},{"_id":"themes/matery/layout/_widget/category-radar.ejs","hash":"f5561dd7d53d68897a33090bf677719213459b19","modified":1565436517777},{"_id":"themes/matery/layout/_widget/music.ejs","hash":"8eafddbd73fed80e85c66d49837c1a241b087258","modified":1565436517777},{"_id":"themes/matery/layout/_widget/my-gallery.ejs","hash":"f81eb2891bea326908057029e2a063001371ba9b","modified":1565436517777},{"_id":"themes/matery/layout/_widget/my-skills.ejs","hash":"bd0edf8dad95b2255890d59fb6d6ed6f2eab9c2f","modified":1565436517777},{"_id":"themes/matery/layout/_widget/my-projects.ejs","hash":"b9bf70ec5d97b0e14bb1b4f60f92db7680be5949","modified":1565436517777},{"_id":"themes/matery/layout/_widget/post-calendar.ejs","hash":"0b0a3eb6af29bf0d55d535958c44b01c0f18d10d","modified":1565436517777},{"_id":"themes/matery/layout/_widget/post-charts.ejs","hash":"af0604623db37ef800bb7ad48028d18d99efbbc3","modified":1565436517777},{"_id":"themes/matery/layout/_widget/recommend.ejs","hash":"babaa0cb32146870785449c70748721235e4eff0","modified":1565436517777},{"_id":"themes/matery/layout/_widget/tag-cloud.ejs","hash":"a3725f0e3a405acb595b04630a27765b537fb580","modified":1565436517781},{"_id":"themes/matery/layout/_widget/video.ejs","hash":"bda810cc135b52f834f1c1ccf52defccacace714","modified":1565436517781},{"_id":"themes/matery/layout/_widget/tag-wordcloud.ejs","hash":"cb7a0151cd20e90351e151c22bca9d4c3112f234","modified":1565436517781},{"_id":"themes/matery/layout/_partial/valine.ejs","hash":"90527186fc8ed906eb1f20b59bc7f86caab9087b","modified":1565436517777},{"_id":"themes/matery/source/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1565436517781},{"_id":"themes/matery/source/css/matery.css","hash":"f4117de0e9e3ef31403ef96fcff036d8478aae4d","modified":1565436517781},{"_id":"themes/matery/source/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1565436517781},{"_id":"themes/matery/source/css/my.css","hash":"497e50351f7838f8546cac76850a42e7e380a110","modified":1565436517781},{"_id":"themes/matery/source/js/matery.js","hash":"92f07106944f5ef7cd72e84bb3534513d00eebe1","modified":1565436517781},{"_id":"themes/matery/source/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1565436517781},{"_id":"themes/matery/source/medias/avatar.jpg","hash":"f78e544a4aa6ec66ea8d25b18ea220880580b126","modified":1565436517989},{"_id":"themes/matery/source/medias/logo.png","hash":"4050259723bd418648ec40028a8020364e57a6a3","modified":1565436518113},{"_id":"themes/matery/source/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1565436517781},{"_id":"themes/matery/source/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1565436517785},{"_id":"themes/matery/source/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1565436517785},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1565436517785},{"_id":"themes/matery/source/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1565436517809},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1565436517809},{"_id":"themes/matery/source/libs/gitalk/gitalk.css","hash":"3aac1db83b0135c521187254ff302d125cc30706","modified":1565436517817},{"_id":"themes/matery/source/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1565436517817},{"_id":"themes/matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1565436517817},{"_id":"themes/matery/source/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1565436517817},{"_id":"themes/matery/source/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1565436517873},{"_id":"themes/matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1565436517981},{"_id":"themes/matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1565436517981},{"_id":"themes/matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1565436517981},{"_id":"themes/matery/source/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1565436517985},{"_id":"themes/matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1565436517985},{"_id":"themes/matery/source/medias/reward/alipay.jpg","hash":"359852e00bf6ffa8985958a987311dedd7e0e22b","modified":1565436518769},{"_id":"themes/matery/source/medias/cover.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1565436518113},{"_id":"themes/matery/source/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1565436517785},{"_id":"themes/matery/source/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1565436517817},{"_id":"themes/matery/source/libs/jquery/jquery-2.2.0.min.js","hash":"5d7e5bbfa540f0e53bd599e4305e1a4e815b5dd1","modified":1565436517821},{"_id":"themes/matery/source/libs/valine/Valine.min.js","hash":"031c1a5640d64ab3b829395ad5a7596b9fb122e6","modified":1565436517985},{"_id":"themes/matery/source/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1565436517809},{"_id":"themes/matery/source/libs/gitalk/gitalk.min.js","hash":"734f56442e62fe55f677e8ccae7f175445667767","modified":1565436517817},{"_id":"themes/matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1565436517821},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1565436517821},{"_id":"themes/matery/layout/_partial/disqus.ejs","hash":"a0f53d1a9b579d52e52ccad8c6e330bf3b89547e","modified":1565436517777},{"_id":"themes/matery/layout/_partial/bg-cover.ejs","hash":"02191109712f61c0e487b8f0b8466597181a9004","modified":1565436517777},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1565436517821},{"_id":"themes/matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1565436517821},{"_id":"themes/matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1565436517821},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1565436517821},{"_id":"themes/matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1565436517821},{"_id":"themes/matery/source/libs/materialize/materialize.min.css","hash":"80ae4aa0dba3634dd9bf59586d541d2dd8d8191c","modified":1565436517937},{"_id":"themes/matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1565436517821},{"_id":"themes/matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1565436517821},{"_id":"themes/matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1565436517981},{"_id":"themes/matery/source/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1565436517981},{"_id":"themes/matery/source/libs/share/fonts/iconfont.svg","hash":"f0a1b849868a6bf351ff98dc3924a4e7254eb88b","modified":1565436517981},{"_id":"themes/matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1565436517981},{"_id":"themes/matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1565436517981},{"_id":"themes/matery/source/libs/valine/av-min.js","hash":"2577e72b52b736d99649f9e95be8976d58563333","modified":1565436517989},{"_id":"themes/matery/source/medias/reward/wechat.jpg","hash":"20f7dc6b4753bec2a6367693ac0900334b8d2209","modified":1565436518773},{"_id":"themes/matery/source/medias/banner/2.jpg","hash":"8d3c8391ff161eec70f66d69e5545a9468cc52ef","modified":1565436518085},{"_id":"themes/matery/source/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1565436517981},{"_id":"themes/matery/source/medias/photo/2.jpg","hash":"8d3c8391ff161eec70f66d69e5545a9468cc52ef","modified":1565436518745},{"_id":"themes/matery/source/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1565436517985},{"_id":"themes/matery/source/libs/awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1565436517785},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1565436517805},{"_id":"themes/matery/source/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1565436517789},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1565436517805},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1565436517809},{"_id":"themes/matery/source/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1565436517937},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1565436517793},{"_id":"themes/matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1565436517821},{"_id":"themes/matery/source/libs/awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1565436517801},{"_id":"themes/matery/source/medias/photo/6.jpg","hash":"04e60da4ae7625da3798052c22bcf1396f0ffc57","modified":1565436518769},{"_id":"themes/matery/source/medias/banner/6.jpg","hash":"04e60da4ae7625da3798052c22bcf1396f0ffc57","modified":1565436518109},{"_id":"themes/matery/source/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1565436517817},{"_id":"themes/matery/source/medias/photo/3.jpg","hash":"2376fd0a08925906fde4c67ade2cb2c0b853f38b","modified":1565436518753},{"_id":"themes/matery/source/medias/photo/5.jpg","hash":"cea89ba2b56b36e33889ad4676aa1e06c57004ff","modified":1565436518769},{"_id":"themes/matery/source/medias/banner/5.jpg","hash":"cea89ba2b56b36e33889ad4676aa1e06c57004ff","modified":1565436518109},{"_id":"themes/matery/source/medias/banner/4.jpg","hash":"0ac255cfb6bbd62e09c15967828262bf450239bb","modified":1565436518105},{"_id":"themes/matery/source/medias/photo/4.jpg","hash":"0ac255cfb6bbd62e09c15967828262bf450239bb","modified":1565436518761},{"_id":"themes/matery/source/medias/banner/3.jpg","hash":"2376fd0a08925906fde4c67ade2cb2c0b853f38b","modified":1565436518093},{"_id":"themes/matery/source/medias/photo/1.jpg","hash":"2f384c9b7dc8a639ab73b7d33014f923c2540b9b","modified":1565436518745},{"_id":"themes/matery/source/medias/banner/1.jpg","hash":"2f384c9b7dc8a639ab73b7d33014f923c2540b9b","modified":1565436518085},{"_id":"themes/matery/source/medias/music/LeavingAkina.mp3","hash":"947133ccfa2d46745b859acce5a7bee974720b98","modified":1565436518121},{"_id":"themes/matery/source/medias/banner/0.jpg","hash":"2b5dba18c130df5c69bf7c33f1cfef6eb576e789","modified":1565436518077},{"_id":"themes/matery/source/medias/music/wecantstop.mp3","hash":"ff63acedb5c200f53b7836b7471ea9ea5f8d9a41","modified":1565436518169},{"_id":"themes/matery/source/medias/photo/0.jpg","hash":"2b5dba18c130df5c69bf7c33f1cfef6eb576e789","modified":1565436518725},{"_id":"public/medias/avatar.jpg","hash":"f78e544a4aa6ec66ea8d25b18ea220880580b126","modified":1565437878817},{"_id":"public/medias/logo.png","hash":"4050259723bd418648ec40028a8020364e57a6a3","modified":1565437878817},{"_id":"public/medias/reward/alipay.jpg","hash":"359852e00bf6ffa8985958a987311dedd7e0e22b","modified":1565437878817},{"_id":"public/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1565437878817},{"_id":"public/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1565437878817},{"_id":"public/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1565437878817},{"_id":"public/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1565437878817},{"_id":"public/libs/lightGallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1565437878817},{"_id":"public/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1565437878817},{"_id":"public/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1565437878818},{"_id":"public/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1565437878818},{"_id":"public/libs/share/fonts/iconfont.svg","hash":"f0a1b849868a6bf351ff98dc3924a4e7254eb88b","modified":1565437878818},{"_id":"public/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1565437878818},{"_id":"public/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1565437878818},{"_id":"public/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1565437878818},{"_id":"public/favicon.jpg","hash":"f78e544a4aa6ec66ea8d25b18ea220880580b126","modified":1565437878823},{"_id":"public/medias/banner/2.jpg","hash":"8d3c8391ff161eec70f66d69e5545a9468cc52ef","modified":1565437878823},{"_id":"public/medias/reward/wechat.jpg","hash":"20f7dc6b4753bec2a6367693ac0900334b8d2209","modified":1565437878823},{"_id":"public/medias/photo/2.jpg","hash":"8d3c8391ff161eec70f66d69e5545a9468cc52ef","modified":1565437878823},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1565437878823},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1565437878824},{"_id":"public/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1565437878830},{"_id":"public/css/my.css","hash":"497e50351f7838f8546cac76850a42e7e380a110","modified":1565437878830},{"_id":"public/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1565437878830},{"_id":"public/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1565437878830},{"_id":"public/js/matery.js","hash":"92f07106944f5ef7cd72e84bb3534513d00eebe1","modified":1565437878830},{"_id":"public/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1565437878830},{"_id":"public/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1565437878830},{"_id":"public/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1565437878830},{"_id":"public/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1565437878830},{"_id":"public/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1565437878830},{"_id":"public/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1565437878830},{"_id":"public/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1565437878830},{"_id":"public/medias/cover.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1565437878830},{"_id":"public/libs/awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1565437878831},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1565437878831},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1565437878831},{"_id":"public/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1565437878840},{"_id":"public/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1565437878840},{"_id":"public/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1565437878842},{"_id":"public/libs/gitalk/gitalk.css","hash":"3aac1db83b0135c521187254ff302d125cc30706","modified":1565437878849},{"_id":"public/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1565437878849},{"_id":"public/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1565437878849},{"_id":"public/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1565437878850},{"_id":"public/libs/share/js/social-share.min.js","hash":"4df722bafde2c5d8faaace0d1f894798385a8793","modified":1565437878850},{"_id":"public/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1565437878851},{"_id":"public/libs/share/js/jquery.share.min.js","hash":"16ce82901ca0e302cf47a35fb10f59009a5e7eb9","modified":1565437878851},{"_id":"public/libs/awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1565437878851},{"_id":"public/css/matery.css","hash":"f4117de0e9e3ef31403ef96fcff036d8478aae4d","modified":1565437878870},{"_id":"public/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1565437878878},{"_id":"public/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1565437878878},{"_id":"public/libs/awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1565437878879},{"_id":"public/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1565437878880},{"_id":"public/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1565437878880},{"_id":"public/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1565437878903},{"_id":"public/libs/valine/Valine.min.js","hash":"031c1a5640d64ab3b829395ad5a7596b9fb122e6","modified":1565437878909},{"_id":"public/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1565437878918},{"_id":"public/libs/jquery/jquery-2.2.0.min.js","hash":"5d7e5bbfa540f0e53bd599e4305e1a4e815b5dd1","modified":1565437878924},{"_id":"public/medias/banner/6.jpg","hash":"04e60da4ae7625da3798052c22bcf1396f0ffc57","modified":1565437878930},{"_id":"public/medias/photo/6.jpg","hash":"04e60da4ae7625da3798052c22bcf1396f0ffc57","modified":1565437878933},{"_id":"public/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1565437878942},{"_id":"public/libs/materialize/materialize.min.css","hash":"580459a012f556fba86438953062013a94b201af","modified":1565437878953},{"_id":"public/libs/valine/av-min.js","hash":"2577e72b52b736d99649f9e95be8976d58563333","modified":1565437878954},{"_id":"public/libs/gitalk/gitalk.min.js","hash":"734f56442e62fe55f677e8ccae7f175445667767","modified":1565437878959},{"_id":"public/medias/banner/5.jpg","hash":"cea89ba2b56b36e33889ad4676aa1e06c57004ff","modified":1565437878959},{"_id":"public/medias/photo/5.jpg","hash":"cea89ba2b56b36e33889ad4676aa1e06c57004ff","modified":1565437878961},{"_id":"public/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1565437878969},{"_id":"public/medias/photo/3.jpg","hash":"2376fd0a08925906fde4c67ade2cb2c0b853f38b","modified":1565437878969},{"_id":"public/medias/banner/3.jpg","hash":"2376fd0a08925906fde4c67ade2cb2c0b853f38b","modified":1565437878969},{"_id":"public/medias/banner/4.jpg","hash":"0ac255cfb6bbd62e09c15967828262bf450239bb","modified":1565437878976},{"_id":"public/medias/photo/4.jpg","hash":"0ac255cfb6bbd62e09c15967828262bf450239bb","modified":1565437878979},{"_id":"public/medias/photo/1.jpg","hash":"2f384c9b7dc8a639ab73b7d33014f923c2540b9b","modified":1565437878979},{"_id":"public/medias/banner/1.jpg","hash":"2f384c9b7dc8a639ab73b7d33014f923c2540b9b","modified":1565437878982},{"_id":"public/medias/music/LeavingAkina.mp3","hash":"947133ccfa2d46745b859acce5a7bee974720b98","modified":1565437878991},{"_id":"public/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1565437879039},{"_id":"public/medias/music/wecantstop.mp3","hash":"ff63acedb5c200f53b7836b7471ea9ea5f8d9a41","modified":1565437879058},{"_id":"public/medias/banner/0.jpg","hash":"2b5dba18c130df5c69bf7c33f1cfef6eb576e789","modified":1565437879070},{"_id":"public/medias/photo/0.jpg","hash":"2b5dba18c130df5c69bf7c33f1cfef6eb576e789","modified":1565437879081}],"Category":[{"name":"OpenCV","_id":"cjz5f3ltj0011e5g68ocr600o"},{"name":"C++","parent":"cjz5f3ltj0011e5g68ocr600o","_id":"cjz5f3ltn0019e5g6tay44ux3"},{"name":"算法","_id":"cjz5f3lu50023e5g6bch872nf"}],"Data":[{"_id":"friends","data":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}]},{"_id":"musics","data":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}],"Page":[{"title":"404","date":"2019-07-19T08:41:10.000Z","type":"404","layout":"404","description":"你来到了没有知识的荒原 :(","_content":"","source":"404.md","raw":"---\ntitle: 404\ndate: 2019-07-19 16:41:10\ntype: \"404\"\nlayout: \"404\"\ndescription: \"你来到了没有知识的荒原 :(\"\n---\n","updated":"2019-08-10T10:47:33.782Z","path":"404.html","comments":1,"_id":"cjz5f3lrr0000e5g68oq0h02z","content":"","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":""},{"_content":"[{\n    \"avatar\": \"http://image.luokangyuan.com/1_qq_27922023.jpg\",\n    \"name\": \"码酱\",\n    \"introduction\": \"我不是大佬，只是在追寻大佬的脚步\",\n    \"url\": \"http://luokangyuan.com/\",\n    \"title\": \"前去学习\"\n}, {\n    \"avatar\": \"http://image.luokangyuan.com/4027734.jpeg\",\n    \"name\": \"闪烁之狐\",\n    \"introduction\": \"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬\",\n    \"url\": \"https://blinkfox.github.io/\",\n    \"title\": \"前去学习\"\n}, {\n    \"avatar\": \"http://image.luokangyuan.com/avatar.jpg\",\n    \"name\": \"ja_rome\",\n    \"introduction\": \"平凡的脚步也可以走出伟大的行程\",\n    \"url\": \"ttps://me.csdn.net/jlh912008548\",\n    \"title\": \"前去学习\"\n}]\n","source":"friends.json","raw":"[{\n    \"avatar\": \"http://image.luokangyuan.com/1_qq_27922023.jpg\",\n    \"name\": \"码酱\",\n    \"introduction\": \"我不是大佬，只是在追寻大佬的脚步\",\n    \"url\": \"http://luokangyuan.com/\",\n    \"title\": \"前去学习\"\n}, {\n    \"avatar\": \"http://image.luokangyuan.com/4027734.jpeg\",\n    \"name\": \"闪烁之狐\",\n    \"introduction\": \"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬\",\n    \"url\": \"https://blinkfox.github.io/\",\n    \"title\": \"前去学习\"\n}, {\n    \"avatar\": \"http://image.luokangyuan.com/avatar.jpg\",\n    \"name\": \"ja_rome\",\n    \"introduction\": \"平凡的脚步也可以走出伟大的行程\",\n    \"url\": \"ttps://me.csdn.net/jlh912008548\",\n    \"title\": \"前去学习\"\n}]\n","date":"2019-08-10T10:47:34.326Z","updated":"2019-08-10T10:47:34.326Z","path":"friends.json","layout":"false","title":"","comments":1,"_id":"cjz5f3lrw0001e5g634z1igju","content":"[{\"avatar\":\"http://image.luokangyuan.com/1_qq_27922023.jpg\",\"name\":\"码酱\",\"introduction\":\"我不是大佬，只是在追寻大佬的脚步\",\"url\":\"http://luokangyuan.com/\",\"title\":\"前去学习\"},{\"avatar\":\"http://image.luokangyuan.com/4027734.jpeg\",\"name\":\"闪烁之狐\",\"introduction\":\"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬\",\"url\":\"https://blinkfox.github.io/\",\"title\":\"前去学习\"},{\"avatar\":\"http://image.luokangyuan.com/avatar.jpg\",\"name\":\"ja_rome\",\"introduction\":\"平凡的脚步也可以走出伟大的行程\",\"url\":\"ttps://me.csdn.net/jlh912008548\",\"title\":\"前去学习\"}]","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"[{\"avatar\":\"http://image.luokangyuan.com/1_qq_27922023.jpg\",\"name\":\"码酱\",\"introduction\":\"我不是大佬，只是在追寻大佬的脚步\",\"url\":\"http://luokangyuan.com/\",\"title\":\"前去学习\"},{\"avatar\":\"http://image.luokangyuan.com/4027734.jpeg\",\"name\":\"闪烁之狐\",\"introduction\":\"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬\",\"url\":\"https://blinkfox.github.io/\",\"title\":\"前去学习\"},{\"avatar\":\"http://image.luokangyuan.com/avatar.jpg\",\"name\":\"ja_rome\",\"introduction\":\"平凡的脚步也可以走出伟大的行程\",\"url\":\"ttps://me.csdn.net/jlh912008548\",\"title\":\"前去学习\"}]"},{"title":"about","date":"2019-08-02T08:20:53.000Z","type":"about","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-08-02 16:20:53\ntype: \"about\"\nlayout: \"about\"\n---\n","updated":"2019-08-10T10:47:34.326Z","path":"about/index.html","comments":1,"_id":"cjz5f3ltv001le5g6fj576p3z","content":"","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":""},{"title":"categories","date":"2019-08-02T08:20:25.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-08-02 16:20:25\ntype: \"categories\"\nlayout: \"categories\"\n---\n","updated":"2019-08-10T10:47:34.326Z","path":"categories/index.html","comments":1,"_id":"cjz5f3ltx001ne5g6syrj65no","content":"","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":""},{"title":"tags","date":"2019-08-02T08:20:40.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-08-02 16:20:40\ntype: \"tags\"\nlayout: \"tags\"\n---\n","updated":"2019-08-10T10:47:34.326Z","path":"tags/index.html","comments":1,"_id":"cjz5f3lty001qe5g6x0vg74w4","content":"","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":""},{"title":"friends","date":"2019-08-02T08:21:09.000Z","type":"friends","layout":"friends","_content":"","source":"friends/index.md","raw":"---\ntitle: friends\ndate: 2019-08-02 16:21:09\ntype: \"friends\"\nlayout: \"friends\"\n---\n","updated":"2019-08-10T10:47:34.326Z","path":"friends/index.html","comments":1,"_id":"cjz5f3ltz001te5g6w3s5etfc","content":"","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":""}],"Post":[{"title":"Day01","date":"2019-07-15T01:09:10.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n## Digital Image Processing notes:\n- 图像处理的步骤：\n    1. 图像获取 包括图像预处理\n    2. 图像滤波与增强 使之适用于==特定应用==\n    3. 图像复原 倾向于以图像退化的数学或概率模型为基础\n    4. 彩色图像处理\n    5. 压缩 减少图像存储量或降低传输图像带宽 \n    6. 形态学处理\n    7. 图像分割\n    8. 目标识别\n### 数字图像基础\n- 灰度概念\n    灰度是表明图像明暗的数值，即黑白图像中点的颜色深度，范围一般是0-255,白色为255,黑色为0,归一化处理之后[0,1],0代表黑色，1代表白色。\n- 图像取样与量化\n    - 对坐标值数字化称为取样，对幅度值数字化称为量化\n- 数字的图像表示       \n    将连续图像取样表示为一个二维阵列f(x,y)\n    1. 函数图表示：用x和y两个坐标轴来表示空间位置，第三个坐标为f(灰度)值，即f(x,y,z)，\n    2. 一般的表示：显示的是f(x,y)在监视器或照片上的情况，每个点的灰度与该点处的f值成正比，例如归一化[0,1],三个等间隔点分别为0,0.5,1\n    3. 矩阵： 将f(x,y)的值打印成矩阵     \n    注意坐标为右手笛卡尔系\n- 对比度： 最高和最低的灰度级的差\n- 典型灰度级：\n\n    ``` math\n    2^k\n    ```\n    称为一副'k bit图像'\n\n- 图像内插\n    - 最邻近内插\n    - 双线性内插\n    - 双三次内插\n- 图像处理的算术操作\n    - 图片相加  平均 -> 降噪\n    - 图片相减  增强图像差别\n    - 图片想乘除  校正阴影\n- 灰度变换\n    - s = T(r)\n    - Matlab中的灰度变换函数     \n        imadjust(f,[LOW_IN,HIGH_IN],[LOW_OUT,HIGH_OUT],grmma)\n- 直方图的处理和函数绘图\n    - 生成图像的直方图\n        ```\n        >> h = imhist(f)\n       ```\n    - 也可以用条形图来表示\n        ```\n        >> h = imhist(f,25);\n        >> horz = linespace(0,255,25);\n        >> bar(horz,h)\n        >> axis(0 255 0 60000);\n        >> set(gca, 'xtick', 0:50:255)\n        >> set(gca, 'ytick', 0:20000:60000)\n        ```\n    - 杆状图    \n    stem(horz, z , 'LineSpec', 'fill')\n    - plot函数    \n    plot(horz, z, 'LineSpec')\n    - 当处理函数句柄时     \n    fplot(fhandle, limits, 'LineSpec')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Day01.md","raw":"---\ntitle: Day01\ndate: 2019-07-15 09:09:10\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n## Digital Image Processing notes:\n- 图像处理的步骤：\n    1. 图像获取 包括图像预处理\n    2. 图像滤波与增强 使之适用于==特定应用==\n    3. 图像复原 倾向于以图像退化的数学或概率模型为基础\n    4. 彩色图像处理\n    5. 压缩 减少图像存储量或降低传输图像带宽 \n    6. 形态学处理\n    7. 图像分割\n    8. 目标识别\n### 数字图像基础\n- 灰度概念\n    灰度是表明图像明暗的数值，即黑白图像中点的颜色深度，范围一般是0-255,白色为255,黑色为0,归一化处理之后[0,1],0代表黑色，1代表白色。\n- 图像取样与量化\n    - 对坐标值数字化称为取样，对幅度值数字化称为量化\n- 数字的图像表示       \n    将连续图像取样表示为一个二维阵列f(x,y)\n    1. 函数图表示：用x和y两个坐标轴来表示空间位置，第三个坐标为f(灰度)值，即f(x,y,z)，\n    2. 一般的表示：显示的是f(x,y)在监视器或照片上的情况，每个点的灰度与该点处的f值成正比，例如归一化[0,1],三个等间隔点分别为0,0.5,1\n    3. 矩阵： 将f(x,y)的值打印成矩阵     \n    注意坐标为右手笛卡尔系\n- 对比度： 最高和最低的灰度级的差\n- 典型灰度级：\n\n    ``` math\n    2^k\n    ```\n    称为一副'k bit图像'\n\n- 图像内插\n    - 最邻近内插\n    - 双线性内插\n    - 双三次内插\n- 图像处理的算术操作\n    - 图片相加  平均 -> 降噪\n    - 图片相减  增强图像差别\n    - 图片想乘除  校正阴影\n- 灰度变换\n    - s = T(r)\n    - Matlab中的灰度变换函数     \n        imadjust(f,[LOW_IN,HIGH_IN],[LOW_OUT,HIGH_OUT],grmma)\n- 直方图的处理和函数绘图\n    - 生成图像的直方图\n        ```\n        >> h = imhist(f)\n       ```\n    - 也可以用条形图来表示\n        ```\n        >> h = imhist(f,25);\n        >> horz = linespace(0,255,25);\n        >> bar(horz,h)\n        >> axis(0 255 0 60000);\n        >> set(gca, 'xtick', 0:50:255)\n        >> set(gca, 'ytick', 0:20000:60000)\n        ```\n    - 杆状图    \n    stem(horz, z , 'LineSpec', 'fill')\n    - plot函数    \n    plot(horz, z, 'LineSpec')\n    - 当处理函数句柄时     \n    fplot(fhandle, limits, 'LineSpec')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Day01","published":1,"updated":"2019-08-10T10:47:33.786Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lsk0002e5g6z4zfajte","content":"<h2 id=\"Digital-Image-Processing-notes\"><a href=\"#Digital-Image-Processing-notes\" class=\"headerlink\" title=\"Digital Image Processing notes:\"></a>Digital Image Processing notes:</h2><ul>\n<li><p>图像处理的步骤：</p>\n<ol>\n<li>图像获取 包括图像预处理</li>\n<li>图像滤波与增强 使之适用于==特定应用==</li>\n<li>图像复原 倾向于以图像退化的数学或概率模型为基础</li>\n<li>彩色图像处理</li>\n<li>压缩 减少图像存储量或降低传输图像带宽 </li>\n<li>形态学处理</li>\n<li>图像分割</li>\n<li>目标识别<h3 id=\"数字图像基础\"><a href=\"#数字图像基础\" class=\"headerlink\" title=\"数字图像基础\"></a>数字图像基础</h3></li>\n</ol>\n</li>\n<li><p>灰度概念<br>  灰度是表明图像明暗的数值，即黑白图像中点的颜色深度，范围一般是0-255,白色为255,黑色为0,归一化处理之后[0,1],0代表黑色，1代表白色。</p>\n</li>\n<li><p>图像取样与量化</p>\n<ul>\n<li>对坐标值数字化称为取样，对幅度值数字化称为量化</li>\n</ul>\n</li>\n<li><p>数字的图像表示<br>  将连续图像取样表示为一个二维阵列f(x,y)</p>\n<ol>\n<li>函数图表示：用x和y两个坐标轴来表示空间位置，第三个坐标为f(灰度)值，即f(x,y,z)，</li>\n<li>一般的表示：显示的是f(x,y)在监视器或照片上的情况，每个点的灰度与该点处的f值成正比，例如归一化[0,1],三个等间隔点分别为0,0.5,1</li>\n<li>矩阵： 将f(x,y)的值打印成矩阵<br>注意坐标为右手笛卡尔系</li>\n</ol>\n</li>\n<li><p>对比度： 最高和最低的灰度级的差</p>\n</li>\n<li><p>典型灰度级：</p>\n<pre class=\" language-math\"><code class=\"language-math\">  2^k</code></pre>\n<p>  称为一副’k bit图像’</p>\n</li>\n<li><p>图像内插</p>\n<ul>\n<li>最邻近内插</li>\n<li>双线性内插</li>\n<li>双三次内插</li>\n</ul>\n</li>\n<li><p>图像处理的算术操作</p>\n<ul>\n<li>图片相加  平均 -&gt; 降噪</li>\n<li>图片相减  增强图像差别</li>\n<li>图片想乘除  校正阴影</li>\n</ul>\n</li>\n<li><p>灰度变换</p>\n<ul>\n<li>s = T(r)</li>\n<li>Matlab中的灰度变换函数<br>  imadjust(f,[LOW_IN,HIGH_IN],[LOW_OUT,HIGH_OUT],grmma)</li>\n</ul>\n</li>\n<li><p>直方图的处理和函数绘图</p>\n<ul>\n<li>生成图像的直方图<pre><code>  &gt;&gt; h = imhist(f)</code></pre></li>\n<li>也可以用条形图来表示<pre><code>  &gt;&gt; h = imhist(f,25);\n  &gt;&gt; horz = linespace(0,255,25);\n  &gt;&gt; bar(horz,h)\n  &gt;&gt; axis(0 255 0 60000);\n  &gt;&gt; set(gca, &#39;xtick&#39;, 0:50:255)\n  &gt;&gt; set(gca, &#39;ytick&#39;, 0:20000:60000)</code></pre></li>\n<li>杆状图<br>stem(horz, z , ‘LineSpec’, ‘fill’)</li>\n<li>plot函数<br>plot(horz, z, ‘LineSpec’)</li>\n<li>当处理函数句柄时<br>fplot(fhandle, limits, ‘LineSpec’)</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"Digital-Image-Processing-notes\"><a href=\"#Digital-Image-Processing-notes\" class=\"headerlink\" title=\"Digital Image Processing notes:\"></a>Digital Image Processing notes:</h2><ul>\n<li><p>图像处理的步骤：</p>\n<ol>\n<li>图像获取 包括图像预处理</li>\n<li>图像滤波与增强 使之适用于==特定应用==</li>\n<li>图像复原 倾向于以图像退化的数学或概率模型为基础</li>\n<li>彩色图像处理</li>\n<li>压缩 减少图像存储量或降低传输图像带宽 </li>\n<li>形态学处理</li>\n<li>图像分割</li>\n<li>目标识别<h3 id=\"数字图像基础\"><a href=\"#数字图像基础\" class=\"headerlink\" title=\"数字图像基础\"></a>数字图像基础</h3></li>\n</ol>\n</li>\n<li><p>灰度概念<br>  灰度是表明图像明暗的数值，即黑白图像中点的颜色深度，范围一般是0-255,白色为255,黑色为0,归一化处理之后[0,1],0代表黑色，1代表白色。</p>\n</li>\n<li><p>图像取样与量化</p>\n<ul>\n<li>对坐标值数字化称为取样，对幅度值数字化称为量化</li>\n</ul>\n</li>\n<li><p>数字的图像表示<br>  将连续图像取样表示为一个二维阵列f(x,y)</p>\n<ol>\n<li>函数图表示：用x和y两个坐标轴来表示空间位置，第三个坐标为f(灰度)值，即f(x,y,z)，</li>\n<li>一般的表示：显示的是f(x,y)在监视器或照片上的情况，每个点的灰度与该点处的f值成正比，例如归一化[0,1],三个等间隔点分别为0,0.5,1</li>\n<li>矩阵： 将f(x,y)的值打印成矩阵<br>注意坐标为右手笛卡尔系</li>\n</ol>\n</li>\n<li><p>对比度： 最高和最低的灰度级的差</p>\n</li>\n<li><p>典型灰度级：</p>\n<pre><code class=\"math\">  2^k</code></pre>\n<p>  称为一副’k bit图像’</p>\n</li>\n<li><p>图像内插</p>\n<ul>\n<li>最邻近内插</li>\n<li>双线性内插</li>\n<li>双三次内插</li>\n</ul>\n</li>\n<li><p>图像处理的算术操作</p>\n<ul>\n<li>图片相加  平均 -&gt; 降噪</li>\n<li>图片相减  增强图像差别</li>\n<li>图片想乘除  校正阴影</li>\n</ul>\n</li>\n<li><p>灰度变换</p>\n<ul>\n<li>s = T(r)</li>\n<li>Matlab中的灰度变换函数<br>  imadjust(f,[LOW_IN,HIGH_IN],[LOW_OUT,HIGH_OUT],grmma)</li>\n</ul>\n</li>\n<li><p>直方图的处理和函数绘图</p>\n<ul>\n<li>生成图像的直方图<pre><code>  &gt;&gt; h = imhist(f)</code></pre></li>\n<li>也可以用条形图来表示<pre><code>  &gt;&gt; h = imhist(f,25);\n  &gt;&gt; horz = linespace(0,255,25);\n  &gt;&gt; bar(horz,h)\n  &gt;&gt; axis(0 255 0 60000);\n  &gt;&gt; set(gca, &#39;xtick&#39;, 0:50:255)\n  &gt;&gt; set(gca, &#39;ytick&#39;, 0:20000:60000)</code></pre></li>\n<li>杆状图<br>stem(horz, z , ‘LineSpec’, ‘fill’)</li>\n<li>plot函数<br>plot(horz, z, ‘LineSpec’)</li>\n<li>当处理函数句柄时<br>fplot(fhandle, limits, ‘LineSpec’)</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Day02","date":"2019-07-16T02:59:03.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","author":"留洋","marhjax":true,"_content":"## 空间滤波基础\n\n\n- 滤波的原理：     空间滤波是采用滤波处理的图像增强的方法，理论基础是空间卷积和空间相关，目的是改善图片质量\n- 线性空间滤波\n    - 移动滤波的模板w称为滤波器\n    - 相关 与 卷积：    \n        相关是指模板w按下图所示的方式进行图像数组的处理。在原理上，卷积是相同的处理过程，只不过在w通过之前先将它选旋转180度\n        ![](https://i.loli.net/2019/07/16/5d2d9d9ea213761403.jpg)\n        相关与卷积操作说明\n        ![](https://i.loli.net/2019/07/16/5d2d9dffdbc4911045.jpg)\n        需要注意的地方：    \n        1. 相关是滤波器位移的函数\n        2. 滤波器w与一个只包含一个1其余全是0的函数相关，得到的是旋转了180度的滤波器w，将这个函数称之为**离散单位冲激**     \n        结论: 一个函数与离散单位冲激相关，在该冲激位置产生这个函数的一个翻转版本    \n        一个函数与离散单位冲激相关激卷积，得到的是在该冲激处的这个函数的拷贝，这个复制的性质称为筛选    \n        这种定义推广到图像如下图所示\n        ![](https://i.loli.net/2019/07/17/5d2e77c7afba429201.jpg)\n        为了便于表达，以公式形式总结两种形式\n        +  大小为m×n的滤波模板w(x,y)与函数f(x,y)的相关\n            ![](https://i.loli.net/2019/07/17/5d2e78e52323950837.jpg)\n        +  大小为m×n的滤波模板w(x,y)与函数f(x,y)的卷积\n            $$w(x,y)\\bigstar f(x,y)=\\sum_{s=-a}^{a}\\sum_{t=-b}^{b}w(s,t)f(x+s,y+t)$$\n    - Matlab的实现:    \n        工具箱使用imfilter来实现线性空间滤波，语法如下:\n        ```\n        g = imfilter(f, w, filtering_mode, boundary_options, size_options)\n        ```\n        默认值为相关，若想执行卷积操作，有以下两种做法：\n        ```\n        g = imfilter(f, w, 'conv')\n        ```\n        或者使用`rot90(w, 2)`来将w旋转180度\n        ```\n        g = imfilter(f, rot90(w, 2))\n        ```\n        f是输入图像，w为滤波模板，g为滤波结果\n        其他参数如下\n        ![](https://i.loli.net/2019/07/17/5d2e84e556ad615011.jpg)\n        使用matlab实现为\n        ```\n        f = imread('filter.jpg');\n        F = im2double(f);\n        imshow(F);\n        title('current image');\n\n        w = ones(31);\n        gd = imfilter(F, w);\n        figure,imshow(gd, [ ]);\n        title('Default');\n\n        gr = imfilter(F, w, 'replicate');\n        figure,imshow(gr, [ ]);\n        title('replicate');\n\n        gs = imfilter(F, w, 'symmetric');\n        figure,imshow(gs, [ ]);\n        title('symmetric');\n\n        gc = imfilter(F, w, 'circular');\n        figure,imshow(gc, [ ]);\n        title('circular');\n\n        g = imfilter(f, w, 'replicate');\n        figure,imshow(g, [ ]);\n        title('replicate unit8');\n        ```\n        这里开始读取的filter.jpg为uint8格式，故在处理之前先使用`im2double`将其转化为double类型以提高精度     \n        滤波结果如下\n        ![](https://i.loli.net/2019/07/17/5d2e8517ac67e80281.jpg)\n- 非线性空间滤波：     \n线性空间滤波基于计算乘积和，即线性操作，非线性空间滤波基于涉及邻域像素内的非线性操作，例如，使每个中心点的响应等于邻域内像素最大值的操作可以称为是非线性滤波操作      \n    - Matlab工具\n        1. nlfilter：直接执行二维操作\n        2. coldilt：按列组织数据，更多采用\n\n\n","source":"_posts/Day02.md","raw":"---\ntitle: Day02\ndate: 2019-07-16 10:59:03\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\nauthor: 留洋\nmarhjax: true\n---\n## 空间滤波基础\n\n\n- 滤波的原理：     空间滤波是采用滤波处理的图像增强的方法，理论基础是空间卷积和空间相关，目的是改善图片质量\n- 线性空间滤波\n    - 移动滤波的模板w称为滤波器\n    - 相关 与 卷积：    \n        相关是指模板w按下图所示的方式进行图像数组的处理。在原理上，卷积是相同的处理过程，只不过在w通过之前先将它选旋转180度\n        ![](https://i.loli.net/2019/07/16/5d2d9d9ea213761403.jpg)\n        相关与卷积操作说明\n        ![](https://i.loli.net/2019/07/16/5d2d9dffdbc4911045.jpg)\n        需要注意的地方：    \n        1. 相关是滤波器位移的函数\n        2. 滤波器w与一个只包含一个1其余全是0的函数相关，得到的是旋转了180度的滤波器w，将这个函数称之为**离散单位冲激**     \n        结论: 一个函数与离散单位冲激相关，在该冲激位置产生这个函数的一个翻转版本    \n        一个函数与离散单位冲激相关激卷积，得到的是在该冲激处的这个函数的拷贝，这个复制的性质称为筛选    \n        这种定义推广到图像如下图所示\n        ![](https://i.loli.net/2019/07/17/5d2e77c7afba429201.jpg)\n        为了便于表达，以公式形式总结两种形式\n        +  大小为m×n的滤波模板w(x,y)与函数f(x,y)的相关\n            ![](https://i.loli.net/2019/07/17/5d2e78e52323950837.jpg)\n        +  大小为m×n的滤波模板w(x,y)与函数f(x,y)的卷积\n            $$w(x,y)\\bigstar f(x,y)=\\sum_{s=-a}^{a}\\sum_{t=-b}^{b}w(s,t)f(x+s,y+t)$$\n    - Matlab的实现:    \n        工具箱使用imfilter来实现线性空间滤波，语法如下:\n        ```\n        g = imfilter(f, w, filtering_mode, boundary_options, size_options)\n        ```\n        默认值为相关，若想执行卷积操作，有以下两种做法：\n        ```\n        g = imfilter(f, w, 'conv')\n        ```\n        或者使用`rot90(w, 2)`来将w旋转180度\n        ```\n        g = imfilter(f, rot90(w, 2))\n        ```\n        f是输入图像，w为滤波模板，g为滤波结果\n        其他参数如下\n        ![](https://i.loli.net/2019/07/17/5d2e84e556ad615011.jpg)\n        使用matlab实现为\n        ```\n        f = imread('filter.jpg');\n        F = im2double(f);\n        imshow(F);\n        title('current image');\n\n        w = ones(31);\n        gd = imfilter(F, w);\n        figure,imshow(gd, [ ]);\n        title('Default');\n\n        gr = imfilter(F, w, 'replicate');\n        figure,imshow(gr, [ ]);\n        title('replicate');\n\n        gs = imfilter(F, w, 'symmetric');\n        figure,imshow(gs, [ ]);\n        title('symmetric');\n\n        gc = imfilter(F, w, 'circular');\n        figure,imshow(gc, [ ]);\n        title('circular');\n\n        g = imfilter(f, w, 'replicate');\n        figure,imshow(g, [ ]);\n        title('replicate unit8');\n        ```\n        这里开始读取的filter.jpg为uint8格式，故在处理之前先使用`im2double`将其转化为double类型以提高精度     \n        滤波结果如下\n        ![](https://i.loli.net/2019/07/17/5d2e8517ac67e80281.jpg)\n- 非线性空间滤波：     \n线性空间滤波基于计算乘积和，即线性操作，非线性空间滤波基于涉及邻域像素内的非线性操作，例如，使每个中心点的响应等于邻域内像素最大值的操作可以称为是非线性滤波操作      \n    - Matlab工具\n        1. nlfilter：直接执行二维操作\n        2. coldilt：按列组织数据，更多采用\n\n\n","slug":"Day02","published":1,"updated":"2019-08-10T10:47:33.786Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lss0003e5g6jra3ljn3","content":"<h2 id=\"空间滤波基础\"><a href=\"#空间滤波基础\" class=\"headerlink\" title=\"空间滤波基础\"></a>空间滤波基础</h2><ul>\n<li><p>滤波的原理：     空间滤波是采用滤波处理的图像增强的方法，理论基础是空间卷积和空间相关，目的是改善图片质量</p>\n</li>\n<li><p>线性空间滤波</p>\n<ul>\n<li><p>移动滤波的模板w称为滤波器</p>\n</li>\n<li><p>相关 与 卷积：<br>  相关是指模板w按下图所示的方式进行图像数组的处理。在原理上，卷积是相同的处理过程，只不过在w通过之前先将它选旋转180度<br>  <img src=\"https://i.loli.net/2019/07/16/5d2d9d9ea213761403.jpg\" alt><br>  相关与卷积操作说明<br>  <img src=\"https://i.loli.net/2019/07/16/5d2d9dffdbc4911045.jpg\" alt><br>  需要注意的地方：    </p>\n<ol>\n<li>相关是滤波器位移的函数</li>\n<li>滤波器w与一个只包含一个1其余全是0的函数相关，得到的是旋转了180度的滤波器w，将这个函数称之为<strong>离散单位冲激</strong><br>结论: 一个函数与离散单位冲激相关，在该冲激位置产生这个函数的一个翻转版本<br>一个函数与离散单位冲激相关激卷积，得到的是在该冲激处的这个函数的拷贝，这个复制的性质称为筛选<br>这种定义推广到图像如下图所示<br><img src=\"https://i.loli.net/2019/07/17/5d2e77c7afba429201.jpg\" alt><br>为了便于表达，以公式形式总结两种形式</li>\n</ol>\n<ul>\n<li>大小为m×n的滤波模板w(x,y)与函数f(x,y)的相关<br> <img src=\"https://i.loli.net/2019/07/17/5d2e78e52323950837.jpg\" alt></li>\n<li>大小为m×n的滤波模板w(x,y)与函数f(x,y)的卷积<br> $$w(x,y)\\bigstar f(x,y)=\\sum_{s=-a}^{a}\\sum_{t=-b}^{b}w(s,t)f(x+s,y+t)$$</li>\n</ul>\n</li>\n<li><p>Matlab的实现:<br>  工具箱使用imfilter来实现线性空间滤波，语法如下:</p>\n<pre><code>  g = imfilter(f, w, filtering_mode, boundary_options, size_options)</code></pre><p>  默认值为相关，若想执行卷积操作，有以下两种做法：</p>\n<pre><code>  g = imfilter(f, w, &#39;conv&#39;)</code></pre><p>  或者使用<code>rot90(w, 2)</code>来将w旋转180度</p>\n<pre><code>  g = imfilter(f, rot90(w, 2))</code></pre><p>  f是输入图像，w为滤波模板，g为滤波结果<br>  其他参数如下<br>  <img src=\"https://i.loli.net/2019/07/17/5d2e84e556ad615011.jpg\" alt><br>  使用matlab实现为</p>\n<pre><code>  f = imread(&#39;filter.jpg&#39;);\n  F = im2double(f);\n  imshow(F);\n  title(&#39;current image&#39;);\n\n  w = ones(31);\n  gd = imfilter(F, w);\n  figure,imshow(gd, [ ]);\n  title(&#39;Default&#39;);\n\n  gr = imfilter(F, w, &#39;replicate&#39;);\n  figure,imshow(gr, [ ]);\n  title(&#39;replicate&#39;);\n\n  gs = imfilter(F, w, &#39;symmetric&#39;);\n  figure,imshow(gs, [ ]);\n  title(&#39;symmetric&#39;);\n\n  gc = imfilter(F, w, &#39;circular&#39;);\n  figure,imshow(gc, [ ]);\n  title(&#39;circular&#39;);\n\n  g = imfilter(f, w, &#39;replicate&#39;);\n  figure,imshow(g, [ ]);\n  title(&#39;replicate unit8&#39;);</code></pre><p>  这里开始读取的filter.jpg为uint8格式，故在处理之前先使用<code>im2double</code>将其转化为double类型以提高精度<br>  滤波结果如下<br>  <img src=\"https://i.loli.net/2019/07/17/5d2e8517ac67e80281.jpg\" alt></p>\n</li>\n</ul>\n</li>\n<li><p>非线性空间滤波：<br>线性空间滤波基于计算乘积和，即线性操作，非线性空间滤波基于涉及邻域像素内的非线性操作，例如，使每个中心点的响应等于邻域内像素最大值的操作可以称为是非线性滤波操作      </p>\n<ul>\n<li>Matlab工具<ol>\n<li>nlfilter：直接执行二维操作</li>\n<li>coldilt：按列组织数据，更多采用</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"空间滤波基础\"><a href=\"#空间滤波基础\" class=\"headerlink\" title=\"空间滤波基础\"></a>空间滤波基础</h2><ul>\n<li><p>滤波的原理：     空间滤波是采用滤波处理的图像增强的方法，理论基础是空间卷积和空间相关，目的是改善图片质量</p>\n</li>\n<li><p>线性空间滤波</p>\n<ul>\n<li><p>移动滤波的模板w称为滤波器</p>\n</li>\n<li><p>相关 与 卷积：<br>  相关是指模板w按下图所示的方式进行图像数组的处理。在原理上，卷积是相同的处理过程，只不过在w通过之前先将它选旋转180度<br>  <img src=\"https://i.loli.net/2019/07/16/5d2d9d9ea213761403.jpg\" alt><br>  相关与卷积操作说明<br>  <img src=\"https://i.loli.net/2019/07/16/5d2d9dffdbc4911045.jpg\" alt><br>  需要注意的地方：    </p>\n<ol>\n<li>相关是滤波器位移的函数</li>\n<li>滤波器w与一个只包含一个1其余全是0的函数相关，得到的是旋转了180度的滤波器w，将这个函数称之为<strong>离散单位冲激</strong><br>结论: 一个函数与离散单位冲激相关，在该冲激位置产生这个函数的一个翻转版本<br>一个函数与离散单位冲激相关激卷积，得到的是在该冲激处的这个函数的拷贝，这个复制的性质称为筛选<br>这种定义推广到图像如下图所示<br><img src=\"https://i.loli.net/2019/07/17/5d2e77c7afba429201.jpg\" alt><br>为了便于表达，以公式形式总结两种形式</li>\n</ol>\n<ul>\n<li>大小为m×n的滤波模板w(x,y)与函数f(x,y)的相关<br> <img src=\"https://i.loli.net/2019/07/17/5d2e78e52323950837.jpg\" alt></li>\n<li>大小为m×n的滤波模板w(x,y)与函数f(x,y)的卷积<br> $$w(x,y)\\bigstar f(x,y)=\\sum_{s=-a}^{a}\\sum_{t=-b}^{b}w(s,t)f(x+s,y+t)$$</li>\n</ul>\n</li>\n<li><p>Matlab的实现:<br>  工具箱使用imfilter来实现线性空间滤波，语法如下:</p>\n<pre><code>  g = imfilter(f, w, filtering_mode, boundary_options, size_options)</code></pre><p>  默认值为相关，若想执行卷积操作，有以下两种做法：</p>\n<pre><code>  g = imfilter(f, w, &#39;conv&#39;)</code></pre><p>  或者使用<code>rot90(w, 2)</code>来将w旋转180度</p>\n<pre><code>  g = imfilter(f, rot90(w, 2))</code></pre><p>  f是输入图像，w为滤波模板，g为滤波结果<br>  其他参数如下<br>  <img src=\"https://i.loli.net/2019/07/17/5d2e84e556ad615011.jpg\" alt><br>  使用matlab实现为</p>\n<pre><code>  f = imread(&#39;filter.jpg&#39;);\n  F = im2double(f);\n  imshow(F);\n  title(&#39;current image&#39;);\n\n  w = ones(31);\n  gd = imfilter(F, w);\n  figure,imshow(gd, [ ]);\n  title(&#39;Default&#39;);\n\n  gr = imfilter(F, w, &#39;replicate&#39;);\n  figure,imshow(gr, [ ]);\n  title(&#39;replicate&#39;);\n\n  gs = imfilter(F, w, &#39;symmetric&#39;);\n  figure,imshow(gs, [ ]);\n  title(&#39;symmetric&#39;);\n\n  gc = imfilter(F, w, &#39;circular&#39;);\n  figure,imshow(gc, [ ]);\n  title(&#39;circular&#39;);\n\n  g = imfilter(f, w, &#39;replicate&#39;);\n  figure,imshow(g, [ ]);\n  title(&#39;replicate unit8&#39;);</code></pre><p>  这里开始读取的filter.jpg为uint8格式，故在处理之前先使用<code>im2double</code>将其转化为double类型以提高精度<br>  滤波结果如下<br>  <img src=\"https://i.loli.net/2019/07/17/5d2e8517ac67e80281.jpg\" alt></p>\n</li>\n</ul>\n</li>\n<li><p>非线性空间滤波：<br>线性空间滤波基于计算乘积和，即线性操作，非线性空间滤波基于涉及邻域像素内的非线性操作，例如，使每个中心点的响应等于邻域内像素最大值的操作可以称为是非线性滤波操作      </p>\n<ul>\n<li>Matlab工具<ol>\n<li>nlfilter：直接执行二维操作</li>\n<li>coldilt：按列组织数据，更多采用</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Day06","date":"2019-07-20T06:18:08.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n## 使用频率域滤波器平滑图像\n----\n### 理想低通滤波器\n\n在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为\n$$y=\\begin{cases}\n1,\\quad D(x,y)\\leq 0\\\\\n0, \\quad D(x,y) > 0\n\\end{cases}$$\n$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即\n$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$\n过渡点称为**截止频率**\n![](https://i.loli.net/2019/07/21/5d341bf1f0cb755202.jpg)\n\n### 布特沃斯低通滤波器\n截止频率位于距原点$D_0$处的n阶布特沃斯低通滤波器(BLPF)的传递函数的定义为:\n$$H(u,v)=\\frac{1}{1+{[D(u,v)/D_0]}^{2n}}$$\n截止频率点是当D(u,v) = $D_0$时的点\n![](https://i.loli.net/2019/07/21/5d341bf1f101518273.jpg)\n\n### 高斯低通滤波器\n二维形式:\n$$H(u,v) = e^{-D^2(u,v)/2{D_0}^2} $$\n$D_0$ 是截止频率\n![](https://i.loli.net/2019/07/21/5d341bf1f163e99741.jpg)\n\n### MATLAB中低通滤波器的实现\n#### 1. 高斯低通滤波器\n\n```\nf = imread('1.jpg');\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(2);\nF = fft2(f, PQ(1), PQ(2));\nH = exp(-(D .^ 2)/(2 * (D0^2))); %高斯低通滤波器\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure, imshow(fftshift(H));\nfigure, imshow(log(1 + abs(fftshift(F))), [])\nfigure, imshow(g);\n```\n滤波结果：\n![](https://i.loli.net/2019/07/20/5d32d02f5468855048.jpg)\n\n除了之前说的几个M函数外，还需要用到`dftfilt()`函数\n```\nfunction g=dftfilt(f,H)\n%DFTFILT Performs frequency domain filtering.\n%   G=DFTFILT(F,H) filters F in the frequency domain using the\n%   filter transfer function H. The output, G, is the filtered\n%   image, which has the same size as F. DFTFILT automatically pads\n%   F to be the same size as H. Function PADDEDSIZE can be used\n%   to determine an appropriate size for H.\n%\n%   DFTFILT assumes that F is real and that H is a real, uncentered,\n%   circularly-symmetric filter function.\n\n%Obtain the FFT of the padded input.\nF=fft2(f,size(H,1),size(H,2));\n\n%Perform filtering.\ng=real(ifft2(H.*F));\n\n%Crop to original size.\ng=g(1:size(f,1),1:size(f,2));\n```\n\n#### 2. Butterworth滤波\n\n该函数输入为灰度图像，自由设置截止频率$D_0$和BLPF的阶数n，输出为滤波后的图像(已归一化到[0,255])\n```\nfunction [image_out] = Bfilter(image_in, D0, N)\n% Butterworth滤波器，在频率域进行滤波\n% 输入为需要进行滤波的灰度图像，Butterworth滤波器的截止频率D0，阶数N\n% 输出为滤波之后的灰度图像\n\n[m, n] = size(image_in);\nP = 2 * m;\nQ = 2 * n;\n\nfp = zeros(P, Q);\n%对图像填充0,并且乘以(-1)^(x+y) 以移到变换中心\nfor i = 1 : m\n    for j = 1 : n\n        fp(i, j) = double(image_in(i, j)) * (-1)^(i+j);\n    end\nend\n% 对填充后的图像进行傅里叶变换\nF1 = fft2(fp);\n\n% 生成Butterworth滤波函数，中心在(m+1,n+1)\nBw = zeros(P, Q);\na = D0^(2 * N);\nfor u = 1 : P\n    for v = 1 : Q\n        temp = (u-(m+1.0))^2 + (v-(n+1.0))^2;\n        Bw(u, v) = 1 / (1 + (temp^N) / a);\n    end\nend\n\n%进行滤波\nG = F1 .* Bw;\n\n% 反傅里叶变换\ngp = ifft2(G);\n\n% 处理得到的图像\nimage_out = zeros(m, n, 'uint8');\ngp = real(gp);\ng = zeros(m, n);\nfor i = 1 : m\n    for j = 1 : n\n        g(i, j) = gp(i, j) * (-1)^(i+j);\n        \n    end\nend\nmmax = max(g(:));\nmmin = min(g(:));\nrange = mmax-mmin;\nfor i = 1 : m\n    for j = 1 : n\n        image_out(i,j) = uint8(255 * (g(i, j)-mmin) / range);\n    end\nend\nend\n```\n测试BLPF的阶数为2,截止频率分别为10,40,80,150,450\n```\nclear all;\nclose all;\nclc;\n\nimage1 = imread('2.jpg');\n\nimage2 = Bfilter(image1, 10, 2);\nimage3 = Bfilter(image1, 40, 2);\nimage4 = Bfilter(image1, 80, 2);\nimage5 = Bfilter(image1, 150, 2);\nimage6 = Bfilter(image1, 450, 2);\n\n% 显示图像\nsubplot(2,3,1), imshow(image1), title('原图像');\nsubplot(2,3,2), imshow(image2), title('D0 = 10, n = 2');\nsubplot(2,3,3), imshow(image3), title('D0 = 40, n = 2');\nsubplot(2,3,4), imshow(image4), title('D0 = 80, n = 2');\nsubplot(2,3,5), imshow(image5), title('D0 = 150, n = 2');\nsubplot(2,3,6), imshow(image6), title('D0 = 450, n = 2');\n```\n滤波结果如下:\n![](https://i.loli.net/2019/07/20/5d32d02f43bc610556.jpg)\n分析结果:    \n1. 模糊的平滑过渡是截止频率增大的函数\n2. 滤波后输出三副连续的色图，原因是rgb图像的分三次呈现    \n   一副彩图是由三色组成,红绿蓝三色，图像读取到matlab后，有三个参数m × n × 3, 代表的是三色叠加，处理之后的图将三色展开分别呈现了，所以才会出现三副连续的色图    \n![](https://i.loli.net/2019/07/20/5d32d80a09a9124012.jpg)\n\n换成彩色图可以明显看到\n![](https://i.loli.net/2019/07/20/5d32d80a3073491464.jpg)\n\n\n\n","source":"_posts/Day06.md","raw":"---\ntitle: Day06\ndate: 2019-07-20 14:18:08\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n## 使用频率域滤波器平滑图像\n----\n### 理想低通滤波器\n\n在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为\n$$y=\\begin{cases}\n1,\\quad D(x,y)\\leq 0\\\\\n0, \\quad D(x,y) > 0\n\\end{cases}$$\n$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即\n$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$\n过渡点称为**截止频率**\n![](https://i.loli.net/2019/07/21/5d341bf1f0cb755202.jpg)\n\n### 布特沃斯低通滤波器\n截止频率位于距原点$D_0$处的n阶布特沃斯低通滤波器(BLPF)的传递函数的定义为:\n$$H(u,v)=\\frac{1}{1+{[D(u,v)/D_0]}^{2n}}$$\n截止频率点是当D(u,v) = $D_0$时的点\n![](https://i.loli.net/2019/07/21/5d341bf1f101518273.jpg)\n\n### 高斯低通滤波器\n二维形式:\n$$H(u,v) = e^{-D^2(u,v)/2{D_0}^2} $$\n$D_0$ 是截止频率\n![](https://i.loli.net/2019/07/21/5d341bf1f163e99741.jpg)\n\n### MATLAB中低通滤波器的实现\n#### 1. 高斯低通滤波器\n\n```\nf = imread('1.jpg');\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(2);\nF = fft2(f, PQ(1), PQ(2));\nH = exp(-(D .^ 2)/(2 * (D0^2))); %高斯低通滤波器\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure, imshow(fftshift(H));\nfigure, imshow(log(1 + abs(fftshift(F))), [])\nfigure, imshow(g);\n```\n滤波结果：\n![](https://i.loli.net/2019/07/20/5d32d02f5468855048.jpg)\n\n除了之前说的几个M函数外，还需要用到`dftfilt()`函数\n```\nfunction g=dftfilt(f,H)\n%DFTFILT Performs frequency domain filtering.\n%   G=DFTFILT(F,H) filters F in the frequency domain using the\n%   filter transfer function H. The output, G, is the filtered\n%   image, which has the same size as F. DFTFILT automatically pads\n%   F to be the same size as H. Function PADDEDSIZE can be used\n%   to determine an appropriate size for H.\n%\n%   DFTFILT assumes that F is real and that H is a real, uncentered,\n%   circularly-symmetric filter function.\n\n%Obtain the FFT of the padded input.\nF=fft2(f,size(H,1),size(H,2));\n\n%Perform filtering.\ng=real(ifft2(H.*F));\n\n%Crop to original size.\ng=g(1:size(f,1),1:size(f,2));\n```\n\n#### 2. Butterworth滤波\n\n该函数输入为灰度图像，自由设置截止频率$D_0$和BLPF的阶数n，输出为滤波后的图像(已归一化到[0,255])\n```\nfunction [image_out] = Bfilter(image_in, D0, N)\n% Butterworth滤波器，在频率域进行滤波\n% 输入为需要进行滤波的灰度图像，Butterworth滤波器的截止频率D0，阶数N\n% 输出为滤波之后的灰度图像\n\n[m, n] = size(image_in);\nP = 2 * m;\nQ = 2 * n;\n\nfp = zeros(P, Q);\n%对图像填充0,并且乘以(-1)^(x+y) 以移到变换中心\nfor i = 1 : m\n    for j = 1 : n\n        fp(i, j) = double(image_in(i, j)) * (-1)^(i+j);\n    end\nend\n% 对填充后的图像进行傅里叶变换\nF1 = fft2(fp);\n\n% 生成Butterworth滤波函数，中心在(m+1,n+1)\nBw = zeros(P, Q);\na = D0^(2 * N);\nfor u = 1 : P\n    for v = 1 : Q\n        temp = (u-(m+1.0))^2 + (v-(n+1.0))^2;\n        Bw(u, v) = 1 / (1 + (temp^N) / a);\n    end\nend\n\n%进行滤波\nG = F1 .* Bw;\n\n% 反傅里叶变换\ngp = ifft2(G);\n\n% 处理得到的图像\nimage_out = zeros(m, n, 'uint8');\ngp = real(gp);\ng = zeros(m, n);\nfor i = 1 : m\n    for j = 1 : n\n        g(i, j) = gp(i, j) * (-1)^(i+j);\n        \n    end\nend\nmmax = max(g(:));\nmmin = min(g(:));\nrange = mmax-mmin;\nfor i = 1 : m\n    for j = 1 : n\n        image_out(i,j) = uint8(255 * (g(i, j)-mmin) / range);\n    end\nend\nend\n```\n测试BLPF的阶数为2,截止频率分别为10,40,80,150,450\n```\nclear all;\nclose all;\nclc;\n\nimage1 = imread('2.jpg');\n\nimage2 = Bfilter(image1, 10, 2);\nimage3 = Bfilter(image1, 40, 2);\nimage4 = Bfilter(image1, 80, 2);\nimage5 = Bfilter(image1, 150, 2);\nimage6 = Bfilter(image1, 450, 2);\n\n% 显示图像\nsubplot(2,3,1), imshow(image1), title('原图像');\nsubplot(2,3,2), imshow(image2), title('D0 = 10, n = 2');\nsubplot(2,3,3), imshow(image3), title('D0 = 40, n = 2');\nsubplot(2,3,4), imshow(image4), title('D0 = 80, n = 2');\nsubplot(2,3,5), imshow(image5), title('D0 = 150, n = 2');\nsubplot(2,3,6), imshow(image6), title('D0 = 450, n = 2');\n```\n滤波结果如下:\n![](https://i.loli.net/2019/07/20/5d32d02f43bc610556.jpg)\n分析结果:    \n1. 模糊的平滑过渡是截止频率增大的函数\n2. 滤波后输出三副连续的色图，原因是rgb图像的分三次呈现    \n   一副彩图是由三色组成,红绿蓝三色，图像读取到matlab后，有三个参数m × n × 3, 代表的是三色叠加，处理之后的图将三色展开分别呈现了，所以才会出现三副连续的色图    \n![](https://i.loli.net/2019/07/20/5d32d80a09a9124012.jpg)\n\n换成彩色图可以明显看到\n![](https://i.loli.net/2019/07/20/5d32d80a3073491464.jpg)\n\n\n\n","slug":"Day06","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lsw0005e5g6ew0ni2nj","content":"<h2 id=\"使用频率域滤波器平滑图像\"><a href=\"#使用频率域滤波器平滑图像\" class=\"headerlink\" title=\"使用频率域滤波器平滑图像\"></a>使用频率域滤波器平滑图像</h2><hr>\n<h3 id=\"理想低通滤波器\"><a href=\"#理想低通滤波器\" class=\"headerlink\" title=\"理想低通滤波器\"></a>理想低通滤波器</h3><p>在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为<br>$$y=\\begin{cases}<br>1,\\quad D(x,y)\\leq 0\\<br>0, \\quad D(x,y) &gt; 0<br>\\end{cases}$$<br>$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即<br>$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$<br>过渡点称为<strong>截止频率</strong><br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f0cb755202.jpg\" alt></p>\n<h3 id=\"布特沃斯低通滤波器\"><a href=\"#布特沃斯低通滤波器\" class=\"headerlink\" title=\"布特沃斯低通滤波器\"></a>布特沃斯低通滤波器</h3><p>截止频率位于距原点$D_0$处的n阶布特沃斯低通滤波器(BLPF)的传递函数的定义为:<br>$$H(u,v)=\\frac{1}{1+{[D(u,v)/D_0]}^{2n}}$$<br>截止频率点是当D(u,v) = $D_0$时的点<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f101518273.jpg\" alt></p>\n<h3 id=\"高斯低通滤波器\"><a href=\"#高斯低通滤波器\" class=\"headerlink\" title=\"高斯低通滤波器\"></a>高斯低通滤波器</h3><p>二维形式:<br>$$H(u,v) = e^{-D^2(u,v)/2{D_0}^2} $$<br>$D_0$ 是截止频率<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f163e99741.jpg\" alt></p>\n<h3 id=\"MATLAB中低通滤波器的实现\"><a href=\"#MATLAB中低通滤波器的实现\" class=\"headerlink\" title=\"MATLAB中低通滤波器的实现\"></a>MATLAB中低通滤波器的实现</h3><h4 id=\"1-高斯低通滤波器\"><a href=\"#1-高斯低通滤波器\" class=\"headerlink\" title=\"1. 高斯低通滤波器\"></a>1. 高斯低通滤波器</h4><pre><code>f = imread(&#39;1.jpg&#39;);\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(2);\nF = fft2(f, PQ(1), PQ(2));\nH = exp(-(D .^ 2)/(2 * (D0^2))); %高斯低通滤波器\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure, imshow(fftshift(H));\nfigure, imshow(log(1 + abs(fftshift(F))), [])\nfigure, imshow(g);</code></pre><p>滤波结果：<br><img src=\"https://i.loli.net/2019/07/20/5d32d02f5468855048.jpg\" alt></p>\n<p>除了之前说的几个M函数外，还需要用到<code>dftfilt()</code>函数</p>\n<pre><code>function g=dftfilt(f,H)\n%DFTFILT Performs frequency domain filtering.\n%   G=DFTFILT(F,H) filters F in the frequency domain using the\n%   filter transfer function H. The output, G, is the filtered\n%   image, which has the same size as F. DFTFILT automatically pads\n%   F to be the same size as H. Function PADDEDSIZE can be used\n%   to determine an appropriate size for H.\n%\n%   DFTFILT assumes that F is real and that H is a real, uncentered,\n%   circularly-symmetric filter function.\n\n%Obtain the FFT of the padded input.\nF=fft2(f,size(H,1),size(H,2));\n\n%Perform filtering.\ng=real(ifft2(H.*F));\n\n%Crop to original size.\ng=g(1:size(f,1),1:size(f,2));</code></pre><h4 id=\"2-Butterworth滤波\"><a href=\"#2-Butterworth滤波\" class=\"headerlink\" title=\"2. Butterworth滤波\"></a>2. Butterworth滤波</h4><p>该函数输入为灰度图像，自由设置截止频率$D_0$和BLPF的阶数n，输出为滤波后的图像(已归一化到[0,255])</p>\n<pre><code>function [image_out] = Bfilter(image_in, D0, N)\n% Butterworth滤波器，在频率域进行滤波\n% 输入为需要进行滤波的灰度图像，Butterworth滤波器的截止频率D0，阶数N\n% 输出为滤波之后的灰度图像\n\n[m, n] = size(image_in);\nP = 2 * m;\nQ = 2 * n;\n\nfp = zeros(P, Q);\n%对图像填充0,并且乘以(-1)^(x+y) 以移到变换中心\nfor i = 1 : m\n    for j = 1 : n\n        fp(i, j) = double(image_in(i, j)) * (-1)^(i+j);\n    end\nend\n% 对填充后的图像进行傅里叶变换\nF1 = fft2(fp);\n\n% 生成Butterworth滤波函数，中心在(m+1,n+1)\nBw = zeros(P, Q);\na = D0^(2 * N);\nfor u = 1 : P\n    for v = 1 : Q\n        temp = (u-(m+1.0))^2 + (v-(n+1.0))^2;\n        Bw(u, v) = 1 / (1 + (temp^N) / a);\n    end\nend\n\n%进行滤波\nG = F1 .* Bw;\n\n% 反傅里叶变换\ngp = ifft2(G);\n\n% 处理得到的图像\nimage_out = zeros(m, n, &#39;uint8&#39;);\ngp = real(gp);\ng = zeros(m, n);\nfor i = 1 : m\n    for j = 1 : n\n        g(i, j) = gp(i, j) * (-1)^(i+j);\n\n    end\nend\nmmax = max(g(:));\nmmin = min(g(:));\nrange = mmax-mmin;\nfor i = 1 : m\n    for j = 1 : n\n        image_out(i,j) = uint8(255 * (g(i, j)-mmin) / range);\n    end\nend\nend</code></pre><p>测试BLPF的阶数为2,截止频率分别为10,40,80,150,450</p>\n<pre><code>clear all;\nclose all;\nclc;\n\nimage1 = imread(&#39;2.jpg&#39;);\n\nimage2 = Bfilter(image1, 10, 2);\nimage3 = Bfilter(image1, 40, 2);\nimage4 = Bfilter(image1, 80, 2);\nimage5 = Bfilter(image1, 150, 2);\nimage6 = Bfilter(image1, 450, 2);\n\n% 显示图像\nsubplot(2,3,1), imshow(image1), title(&#39;原图像&#39;);\nsubplot(2,3,2), imshow(image2), title(&#39;D0 = 10, n = 2&#39;);\nsubplot(2,3,3), imshow(image3), title(&#39;D0 = 40, n = 2&#39;);\nsubplot(2,3,4), imshow(image4), title(&#39;D0 = 80, n = 2&#39;);\nsubplot(2,3,5), imshow(image5), title(&#39;D0 = 150, n = 2&#39;);\nsubplot(2,3,6), imshow(image6), title(&#39;D0 = 450, n = 2&#39;);</code></pre><p>滤波结果如下:<br><img src=\"https://i.loli.net/2019/07/20/5d32d02f43bc610556.jpg\" alt><br>分析结果:    </p>\n<ol>\n<li>模糊的平滑过渡是截止频率增大的函数</li>\n<li>滤波后输出三副连续的色图，原因是rgb图像的分三次呈现<br>一副彩图是由三色组成,红绿蓝三色，图像读取到matlab后，有三个参数m × n × 3, 代表的是三色叠加，处理之后的图将三色展开分别呈现了，所以才会出现三副连续的色图<br><img src=\"https://i.loli.net/2019/07/20/5d32d80a09a9124012.jpg\" alt></li>\n</ol>\n<p>换成彩色图可以明显看到<br><img src=\"https://i.loli.net/2019/07/20/5d32d80a3073491464.jpg\" alt></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"使用频率域滤波器平滑图像\"><a href=\"#使用频率域滤波器平滑图像\" class=\"headerlink\" title=\"使用频率域滤波器平滑图像\"></a>使用频率域滤波器平滑图像</h2><hr>\n<h3 id=\"理想低通滤波器\"><a href=\"#理想低通滤波器\" class=\"headerlink\" title=\"理想低通滤波器\"></a>理想低通滤波器</h3><p>在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为<br>$$y=\\begin{cases}<br>1,\\quad D(x,y)\\leq 0\\<br>0, \\quad D(x,y) &gt; 0<br>\\end{cases}$$<br>$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即<br>$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$<br>过渡点称为<strong>截止频率</strong><br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f0cb755202.jpg\" alt></p>\n<h3 id=\"布特沃斯低通滤波器\"><a href=\"#布特沃斯低通滤波器\" class=\"headerlink\" title=\"布特沃斯低通滤波器\"></a>布特沃斯低通滤波器</h3><p>截止频率位于距原点$D_0$处的n阶布特沃斯低通滤波器(BLPF)的传递函数的定义为:<br>$$H(u,v)=\\frac{1}{1+{[D(u,v)/D_0]}^{2n}}$$<br>截止频率点是当D(u,v) = $D_0$时的点<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f101518273.jpg\" alt></p>\n<h3 id=\"高斯低通滤波器\"><a href=\"#高斯低通滤波器\" class=\"headerlink\" title=\"高斯低通滤波器\"></a>高斯低通滤波器</h3><p>二维形式:<br>$$H(u,v) = e^{-D^2(u,v)/2{D_0}^2} $$<br>$D_0$ 是截止频率<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f163e99741.jpg\" alt></p>\n<h3 id=\"MATLAB中低通滤波器的实现\"><a href=\"#MATLAB中低通滤波器的实现\" class=\"headerlink\" title=\"MATLAB中低通滤波器的实现\"></a>MATLAB中低通滤波器的实现</h3><h4 id=\"1-高斯低通滤波器\"><a href=\"#1-高斯低通滤波器\" class=\"headerlink\" title=\"1. 高斯低通滤波器\"></a>1. 高斯低通滤波器</h4><pre><code>f = imread(&#39;1.jpg&#39;);\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(2);\nF = fft2(f, PQ(1), PQ(2));\nH = exp(-(D .^ 2)/(2 * (D0^2))); %高斯低通滤波器\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure, imshow(fftshift(H));\nfigure, imshow(log(1 + abs(fftshift(F))), [])\nfigure, imshow(g);</code></pre><p>滤波结果：<br><img src=\"https://i.loli.net/2019/07/20/5d32d02f5468855048.jpg\" alt></p>\n<p>除了之前说的几个M函数外，还需要用到<code>dftfilt()</code>函数</p>\n<pre><code>function g=dftfilt(f,H)\n%DFTFILT Performs frequency domain filtering.\n%   G=DFTFILT(F,H) filters F in the frequency domain using the\n%   filter transfer function H. The output, G, is the filtered\n%   image, which has the same size as F. DFTFILT automatically pads\n%   F to be the same size as H. Function PADDEDSIZE can be used\n%   to determine an appropriate size for H.\n%\n%   DFTFILT assumes that F is real and that H is a real, uncentered,\n%   circularly-symmetric filter function.\n\n%Obtain the FFT of the padded input.\nF=fft2(f,size(H,1),size(H,2));\n\n%Perform filtering.\ng=real(ifft2(H.*F));\n\n%Crop to original size.\ng=g(1:size(f,1),1:size(f,2));</code></pre><h4 id=\"2-Butterworth滤波\"><a href=\"#2-Butterworth滤波\" class=\"headerlink\" title=\"2. Butterworth滤波\"></a>2. Butterworth滤波</h4><p>该函数输入为灰度图像，自由设置截止频率$D_0$和BLPF的阶数n，输出为滤波后的图像(已归一化到[0,255])</p>\n<pre><code>function [image_out] = Bfilter(image_in, D0, N)\n% Butterworth滤波器，在频率域进行滤波\n% 输入为需要进行滤波的灰度图像，Butterworth滤波器的截止频率D0，阶数N\n% 输出为滤波之后的灰度图像\n\n[m, n] = size(image_in);\nP = 2 * m;\nQ = 2 * n;\n\nfp = zeros(P, Q);\n%对图像填充0,并且乘以(-1)^(x+y) 以移到变换中心\nfor i = 1 : m\n    for j = 1 : n\n        fp(i, j) = double(image_in(i, j)) * (-1)^(i+j);\n    end\nend\n% 对填充后的图像进行傅里叶变换\nF1 = fft2(fp);\n\n% 生成Butterworth滤波函数，中心在(m+1,n+1)\nBw = zeros(P, Q);\na = D0^(2 * N);\nfor u = 1 : P\n    for v = 1 : Q\n        temp = (u-(m+1.0))^2 + (v-(n+1.0))^2;\n        Bw(u, v) = 1 / (1 + (temp^N) / a);\n    end\nend\n\n%进行滤波\nG = F1 .* Bw;\n\n% 反傅里叶变换\ngp = ifft2(G);\n\n% 处理得到的图像\nimage_out = zeros(m, n, &#39;uint8&#39;);\ngp = real(gp);\ng = zeros(m, n);\nfor i = 1 : m\n    for j = 1 : n\n        g(i, j) = gp(i, j) * (-1)^(i+j);\n\n    end\nend\nmmax = max(g(:));\nmmin = min(g(:));\nrange = mmax-mmin;\nfor i = 1 : m\n    for j = 1 : n\n        image_out(i,j) = uint8(255 * (g(i, j)-mmin) / range);\n    end\nend\nend</code></pre><p>测试BLPF的阶数为2,截止频率分别为10,40,80,150,450</p>\n<pre><code>clear all;\nclose all;\nclc;\n\nimage1 = imread(&#39;2.jpg&#39;);\n\nimage2 = Bfilter(image1, 10, 2);\nimage3 = Bfilter(image1, 40, 2);\nimage4 = Bfilter(image1, 80, 2);\nimage5 = Bfilter(image1, 150, 2);\nimage6 = Bfilter(image1, 450, 2);\n\n% 显示图像\nsubplot(2,3,1), imshow(image1), title(&#39;原图像&#39;);\nsubplot(2,3,2), imshow(image2), title(&#39;D0 = 10, n = 2&#39;);\nsubplot(2,3,3), imshow(image3), title(&#39;D0 = 40, n = 2&#39;);\nsubplot(2,3,4), imshow(image4), title(&#39;D0 = 80, n = 2&#39;);\nsubplot(2,3,5), imshow(image5), title(&#39;D0 = 150, n = 2&#39;);\nsubplot(2,3,6), imshow(image6), title(&#39;D0 = 450, n = 2&#39;);</code></pre><p>滤波结果如下:<br><img src=\"https://i.loli.net/2019/07/20/5d32d02f43bc610556.jpg\" alt><br>分析结果:    </p>\n<ol>\n<li>模糊的平滑过渡是截止频率增大的函数</li>\n<li>滤波后输出三副连续的色图，原因是rgb图像的分三次呈现<br>一副彩图是由三色组成,红绿蓝三色，图像读取到matlab后，有三个参数m × n × 3, 代表的是三色叠加，处理之后的图将三色展开分别呈现了，所以才会出现三副连续的色图<br><img src=\"https://i.loli.net/2019/07/20/5d32d80a09a9124012.jpg\" alt></li>\n</ol>\n<p>换成彩色图可以明显看到<br><img src=\"https://i.loli.net/2019/07/20/5d32d80a3073491464.jpg\" alt></p>\n"},{"title":"Day04","date":"2019-07-18T01:38:41.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n## 频域滤波\n1. 对图像平滑的低通滤波\n2. 对图像锐化的高通滤波\n3. 去除周期的选择性滤波\n\n## 二维傅里叶变换\n- 二维傅里叶变换:\n$$ F(u,v)=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)e^{-j2\\pi(ux + vy)}\\,\\mathrm{d}x \\mathrm{d}y $$\n\n- 二维傅里叶逆变换：\n$$ f(x,y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} F(u,v)e^{j2\\pi(ux + vy)}\\,dxdy $$\n\n## 二维离散傅里叶变换\n\nf(x,y)代表一幅大小为M×N的图像，其中x=0,1,......,M-1,y=0,1,.....,N-1,DFT如下\n\n$$ F(u,v)=\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} f(x,y)e^{-j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$\n\nIDFT：\n\n$$ f(x,y)=\\frac{1}{MN}\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} F(u,v)e^{j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$\n\n这里的F(u,v)被称为展开的傅里叶级数\n\n频域原点出的变换的值F(0,0)称为傅里叶变换的直流(dc)分量，F(0,0)等于f(0,0)平均值的MN倍。要注意的是在MATLAB中索引是从1开始的而不是从0开始的\n\n## MATLAB实现对图像的Fourier变换和逆变换\n+ Fourier变换，f为原图像\n```\n>> F = fft2(f);\n```\n+ Fourier谱\n```\n>> S = abs(F);\n```\n该函数计算的是数组中每个元素的幅值( $ \\sqrt{r^2+i^2} $ )\n可以在这里观察到4个角的亮点，这就是周期特性的结果，不便观察\n+ 将交换的原点移动到频域矩形的中心\n```\n>> Fc = fftshift(F)\n```\n频谱范围大，不边观察\n+ 取模，缩放\n```\nS2 = log(1 + abs(Fc));\n```\n+ Fourier逆变换\n```\n>> f = ifft2(F);\n```\n下面是完整代码\n```\nimg=imread('moon.jpg');\nsubplot(2,2,1);\n    imshow(img);\n    title('原图');\n    \nf=rgb2gray(img);    %对于RGB图像必须做的一步，也可以用im2double函数\nF=fft2(f);          %Fourier变换\nF1=log(abs(F)+1);   %取模,缩放\nsubplot(2,2,2);\n    imshow(F1,[]);\n    title('傅里叶变换频谱图');\n    \nFs=fftshift(F);      %将频谱图中零频率成分移动至频谱图中心\nS=log(abs(Fs)+1);    %取模并进行缩放\nsubplot(2,2,3);\n    imshow(S,[]);\n    title('频移后的频谱图');\n    \nfr=real(ifft2(ifftshift(Fs)));  %频率域反变换到空间域，并取实部\nret=im2uint8(mat2gray(fr));    %更改图像类型\nsubplot(2,2,4);\n    imshow(ret);\n    title('逆傅里叶变换');\n```\n结果\n![](https://i.loli.net/2019/07/18/5d3043778b4e114553.jpg)\n如果使用`>> f = im2double(img)`进行处理，则会出现以下结果\n![](https://i.loli.net/2019/07/18/5d304377bcc9554917.jpg)\n\n-分析    \n1. 图像Fourier变换之后立即imshow会报错\n![](https://i.loli.net/2019/07/18/5d3043779bef722309.jpg)\n这是因为经过fourier变换之后的图像矩阵为复数矩阵，包含实部和虚部，此时进行`abs(f)`取复数矩阵的模，再显示。\n2. `rgb2gray()`和`im2double()`的使用\n这一点要特别注意，对于RGB图像，`imread()`是已三维矩阵的形式来存储的，要先进行类型转换，否则会出现空白    \n3. `rgb2gray()`转换为灰度图像,得到的图像呈灰色基调，见‘结果’\n4. `im2double()`转换成双精度图像，得到的图像呈白色基调，见‘结果’\n其他图像处理结果\n![](https://i.loli.net/2019/07/18/5d304377bd0c676784.jpg)\n\n![](https://i.loli.net/2019/07/18/5d304377b0b2610307.jpg)\n可以看到Fourier逆变换处理之后的图片为原图的灰度图片。\n## 对图像Fourier变换的意义分析\n\n对于一个图像，其频率是表征图像中灰度变化剧烈程度的指标，是灰度在平面空间的梯度。设f为一个能量有限的模拟信号，其傅里叶变换代表f的频谱。从纯粹的数学意义上来看，Fourier变换是将一个函数转换成一系列的周期函数来进行处理的。从物理角度来看，Fourier变换是将图像从空间域转换到频率域，逆变换是将图像从频率域转换到空间域。也就是说，Fourier变换是将图像的灰度分布函数变换成图像的频率分布函数。==这里要注意是灰度分布函数==,下面还会说到。\n\nFourie逆变换是将图像的频率分布函数转换成灰度分布函数(原始图像的灰度分布函数),图像的概念前边说过，用一个二维矩阵来表示空间上的各点，z=f(x,y)，但空间是三维的，因此空间上的物体在另一个维度上的关系必须由梯度来表示。\n\nFourier频谱图上的明暗点，意义是指图像上的某一点与邻域点差异的强弱，即梯度的大小。\n\n对频谱移频到原点之后，可以看出图像的频率分布是以原点为圆心，对称分布的.\n","source":"_posts/Day04.md","raw":"---\ntitle: Day04\ndate: 2019-07-18 09:38:41\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n## 频域滤波\n1. 对图像平滑的低通滤波\n2. 对图像锐化的高通滤波\n3. 去除周期的选择性滤波\n\n## 二维傅里叶变换\n- 二维傅里叶变换:\n$$ F(u,v)=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)e^{-j2\\pi(ux + vy)}\\,\\mathrm{d}x \\mathrm{d}y $$\n\n- 二维傅里叶逆变换：\n$$ f(x,y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} F(u,v)e^{j2\\pi(ux + vy)}\\,dxdy $$\n\n## 二维离散傅里叶变换\n\nf(x,y)代表一幅大小为M×N的图像，其中x=0,1,......,M-1,y=0,1,.....,N-1,DFT如下\n\n$$ F(u,v)=\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} f(x,y)e^{-j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$\n\nIDFT：\n\n$$ f(x,y)=\\frac{1}{MN}\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} F(u,v)e^{j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$\n\n这里的F(u,v)被称为展开的傅里叶级数\n\n频域原点出的变换的值F(0,0)称为傅里叶变换的直流(dc)分量，F(0,0)等于f(0,0)平均值的MN倍。要注意的是在MATLAB中索引是从1开始的而不是从0开始的\n\n## MATLAB实现对图像的Fourier变换和逆变换\n+ Fourier变换，f为原图像\n```\n>> F = fft2(f);\n```\n+ Fourier谱\n```\n>> S = abs(F);\n```\n该函数计算的是数组中每个元素的幅值( $ \\sqrt{r^2+i^2} $ )\n可以在这里观察到4个角的亮点，这就是周期特性的结果，不便观察\n+ 将交换的原点移动到频域矩形的中心\n```\n>> Fc = fftshift(F)\n```\n频谱范围大，不边观察\n+ 取模，缩放\n```\nS2 = log(1 + abs(Fc));\n```\n+ Fourier逆变换\n```\n>> f = ifft2(F);\n```\n下面是完整代码\n```\nimg=imread('moon.jpg');\nsubplot(2,2,1);\n    imshow(img);\n    title('原图');\n    \nf=rgb2gray(img);    %对于RGB图像必须做的一步，也可以用im2double函数\nF=fft2(f);          %Fourier变换\nF1=log(abs(F)+1);   %取模,缩放\nsubplot(2,2,2);\n    imshow(F1,[]);\n    title('傅里叶变换频谱图');\n    \nFs=fftshift(F);      %将频谱图中零频率成分移动至频谱图中心\nS=log(abs(Fs)+1);    %取模并进行缩放\nsubplot(2,2,3);\n    imshow(S,[]);\n    title('频移后的频谱图');\n    \nfr=real(ifft2(ifftshift(Fs)));  %频率域反变换到空间域，并取实部\nret=im2uint8(mat2gray(fr));    %更改图像类型\nsubplot(2,2,4);\n    imshow(ret);\n    title('逆傅里叶变换');\n```\n结果\n![](https://i.loli.net/2019/07/18/5d3043778b4e114553.jpg)\n如果使用`>> f = im2double(img)`进行处理，则会出现以下结果\n![](https://i.loli.net/2019/07/18/5d304377bcc9554917.jpg)\n\n-分析    \n1. 图像Fourier变换之后立即imshow会报错\n![](https://i.loli.net/2019/07/18/5d3043779bef722309.jpg)\n这是因为经过fourier变换之后的图像矩阵为复数矩阵，包含实部和虚部，此时进行`abs(f)`取复数矩阵的模，再显示。\n2. `rgb2gray()`和`im2double()`的使用\n这一点要特别注意，对于RGB图像，`imread()`是已三维矩阵的形式来存储的，要先进行类型转换，否则会出现空白    \n3. `rgb2gray()`转换为灰度图像,得到的图像呈灰色基调，见‘结果’\n4. `im2double()`转换成双精度图像，得到的图像呈白色基调，见‘结果’\n其他图像处理结果\n![](https://i.loli.net/2019/07/18/5d304377bd0c676784.jpg)\n\n![](https://i.loli.net/2019/07/18/5d304377b0b2610307.jpg)\n可以看到Fourier逆变换处理之后的图片为原图的灰度图片。\n## 对图像Fourier变换的意义分析\n\n对于一个图像，其频率是表征图像中灰度变化剧烈程度的指标，是灰度在平面空间的梯度。设f为一个能量有限的模拟信号，其傅里叶变换代表f的频谱。从纯粹的数学意义上来看，Fourier变换是将一个函数转换成一系列的周期函数来进行处理的。从物理角度来看，Fourier变换是将图像从空间域转换到频率域，逆变换是将图像从频率域转换到空间域。也就是说，Fourier变换是将图像的灰度分布函数变换成图像的频率分布函数。==这里要注意是灰度分布函数==,下面还会说到。\n\nFourie逆变换是将图像的频率分布函数转换成灰度分布函数(原始图像的灰度分布函数),图像的概念前边说过，用一个二维矩阵来表示空间上的各点，z=f(x,y)，但空间是三维的，因此空间上的物体在另一个维度上的关系必须由梯度来表示。\n\nFourier频谱图上的明暗点，意义是指图像上的某一点与邻域点差异的强弱，即梯度的大小。\n\n对频谱移频到原点之后，可以看出图像的频率分布是以原点为圆心，对称分布的.\n","slug":"Day04","published":1,"updated":"2019-08-10T10:47:33.786Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lsy0006e5g6blrfkulr","content":"<h2 id=\"频域滤波\"><a href=\"#频域滤波\" class=\"headerlink\" title=\"频域滤波\"></a>频域滤波</h2><ol>\n<li>对图像平滑的低通滤波</li>\n<li>对图像锐化的高通滤波</li>\n<li>去除周期的选择性滤波</li>\n</ol>\n<h2 id=\"二维傅里叶变换\"><a href=\"#二维傅里叶变换\" class=\"headerlink\" title=\"二维傅里叶变换\"></a>二维傅里叶变换</h2><ul>\n<li><p>二维傅里叶变换:<br>$$ F(u,v)=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)e^{-j2\\pi(ux + vy)}\\,\\mathrm{d}x \\mathrm{d}y $$</p>\n</li>\n<li><p>二维傅里叶逆变换：<br>$$ f(x,y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} F(u,v)e^{j2\\pi(ux + vy)}\\,dxdy $$</p>\n</li>\n</ul>\n<h2 id=\"二维离散傅里叶变换\"><a href=\"#二维离散傅里叶变换\" class=\"headerlink\" title=\"二维离散傅里叶变换\"></a>二维离散傅里叶变换</h2><p>f(x,y)代表一幅大小为M×N的图像，其中x=0,1,……,M-1,y=0,1,…..,N-1,DFT如下</p>\n<p>$$ F(u,v)=\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} f(x,y)e^{-j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$</p>\n<p>IDFT：</p>\n<p>$$ f(x,y)=\\frac{1}{MN}\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} F(u,v)e^{j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$</p>\n<p>这里的F(u,v)被称为展开的傅里叶级数</p>\n<p>频域原点出的变换的值F(0,0)称为傅里叶变换的直流(dc)分量，F(0,0)等于f(0,0)平均值的MN倍。要注意的是在MATLAB中索引是从1开始的而不是从0开始的</p>\n<h2 id=\"MATLAB实现对图像的Fourier变换和逆变换\"><a href=\"#MATLAB实现对图像的Fourier变换和逆变换\" class=\"headerlink\" title=\"MATLAB实现对图像的Fourier变换和逆变换\"></a>MATLAB实现对图像的Fourier变换和逆变换</h2><ul>\n<li>Fourier变换，f为原图像<pre><code>&gt;&gt; F = fft2(f);</code></pre></li>\n<li>Fourier谱<pre><code>&gt;&gt; S = abs(F);</code></pre>该函数计算的是数组中每个元素的幅值( $ \\sqrt{r^2+i^2} $ )<br>可以在这里观察到4个角的亮点，这就是周期特性的结果，不便观察</li>\n<li>将交换的原点移动到频域矩形的中心<pre><code>&gt;&gt; Fc = fftshift(F)</code></pre>频谱范围大，不边观察</li>\n<li>取模，缩放<pre><code>S2 = log(1 + abs(Fc));</code></pre></li>\n<li>Fourier逆变换<pre><code>&gt;&gt; f = ifft2(F);</code></pre>下面是完整代码<pre><code>img=imread(&#39;moon.jpg&#39;);\nsubplot(2,2,1);\n  imshow(img);\n  title(&#39;原图&#39;);\n</code></pre></li>\n</ul>\n<p>f=rgb2gray(img);    %对于RGB图像必须做的一步，也可以用im2double函数<br>F=fft2(f);          %Fourier变换<br>F1=log(abs(F)+1);   %取模,缩放<br>subplot(2,2,2);<br>    imshow(F1,[]);<br>    title(‘傅里叶变换频谱图’);</p>\n<p>Fs=fftshift(F);      %将频谱图中零频率成分移动至频谱图中心<br>S=log(abs(Fs)+1);    %取模并进行缩放<br>subplot(2,2,3);<br>    imshow(S,[]);<br>    title(‘频移后的频谱图’);</p>\n<p>fr=real(ifft2(ifftshift(Fs)));  %频率域反变换到空间域，并取实部<br>ret=im2uint8(mat2gray(fr));    %更改图像类型<br>subplot(2,2,4);<br>    imshow(ret);<br>    title(‘逆傅里叶变换’);</p>\n<pre><code>结果\n![](https://i.loli.net/2019/07/18/5d3043778b4e114553.jpg)\n如果使用`&gt;&gt; f = im2double(img)`进行处理，则会出现以下结果\n![](https://i.loli.net/2019/07/18/5d304377bcc9554917.jpg)\n\n-分析    \n1. 图像Fourier变换之后立即imshow会报错\n![](https://i.loli.net/2019/07/18/5d3043779bef722309.jpg)\n这是因为经过fourier变换之后的图像矩阵为复数矩阵，包含实部和虚部，此时进行`abs(f)`取复数矩阵的模，再显示。\n2. `rgb2gray()`和`im2double()`的使用\n这一点要特别注意，对于RGB图像，`imread()`是已三维矩阵的形式来存储的，要先进行类型转换，否则会出现空白    \n3. `rgb2gray()`转换为灰度图像,得到的图像呈灰色基调，见‘结果’\n4. `im2double()`转换成双精度图像，得到的图像呈白色基调，见‘结果’\n其他图像处理结果\n![](https://i.loli.net/2019/07/18/5d304377bd0c676784.jpg)\n\n![](https://i.loli.net/2019/07/18/5d304377b0b2610307.jpg)\n可以看到Fourier逆变换处理之后的图片为原图的灰度图片。\n## 对图像Fourier变换的意义分析\n\n对于一个图像，其频率是表征图像中灰度变化剧烈程度的指标，是灰度在平面空间的梯度。设f为一个能量有限的模拟信号，其傅里叶变换代表f的频谱。从纯粹的数学意义上来看，Fourier变换是将一个函数转换成一系列的周期函数来进行处理的。从物理角度来看，Fourier变换是将图像从空间域转换到频率域，逆变换是将图像从频率域转换到空间域。也就是说，Fourier变换是将图像的灰度分布函数变换成图像的频率分布函数。==这里要注意是灰度分布函数==,下面还会说到。\n\nFourie逆变换是将图像的频率分布函数转换成灰度分布函数(原始图像的灰度分布函数),图像的概念前边说过，用一个二维矩阵来表示空间上的各点，z=f(x,y)，但空间是三维的，因此空间上的物体在另一个维度上的关系必须由梯度来表示。\n\nFourier频谱图上的明暗点，意义是指图像上的某一点与邻域点差异的强弱，即梯度的大小。\n\n对频谱移频到原点之后，可以看出图像的频率分布是以原点为圆心，对称分布的.</code></pre>","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"频域滤波\"><a href=\"#频域滤波\" class=\"headerlink\" title=\"频域滤波\"></a>频域滤波</h2><ol>\n<li>对图像平滑的低通滤波</li>\n<li>对图像锐化的高通滤波</li>\n<li>去除周期的选择性滤波</li>\n</ol>\n<h2 id=\"二维傅里叶变换\"><a href=\"#二维傅里叶变换\" class=\"headerlink\" title=\"二维傅里叶变换\"></a>二维傅里叶变换</h2><ul>\n<li><p>二维傅里叶变换:<br>$$ F(u,v)=\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)e^{-j2\\pi(ux + vy)}\\,\\mathrm{d}x \\mathrm{d}y $$</p>\n</li>\n<li><p>二维傅里叶逆变换：<br>$$ f(x,y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} F(u,v)e^{j2\\pi(ux + vy)}\\,dxdy $$</p>\n</li>\n</ul>\n<h2 id=\"二维离散傅里叶变换\"><a href=\"#二维离散傅里叶变换\" class=\"headerlink\" title=\"二维离散傅里叶变换\"></a>二维离散傅里叶变换</h2><p>f(x,y)代表一幅大小为M×N的图像，其中x=0,1,……,M-1,y=0,1,…..,N-1,DFT如下</p>\n<p>$$ F(u,v)=\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} f(x,y)e^{-j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$</p>\n<p>IDFT：</p>\n<p>$$ f(x,y)=\\frac{1}{MN}\\int_{x=0}^{M-1} \\int_{y=0}^{N-1} F(u,v)e^{j2\\pi(\\frac{ux}{M}+\\frac{vy}{N})}\\,\\mathrm{d}x \\mathrm{d}y $$</p>\n<p>这里的F(u,v)被称为展开的傅里叶级数</p>\n<p>频域原点出的变换的值F(0,0)称为傅里叶变换的直流(dc)分量，F(0,0)等于f(0,0)平均值的MN倍。要注意的是在MATLAB中索引是从1开始的而不是从0开始的</p>\n<h2 id=\"MATLAB实现对图像的Fourier变换和逆变换\"><a href=\"#MATLAB实现对图像的Fourier变换和逆变换\" class=\"headerlink\" title=\"MATLAB实现对图像的Fourier变换和逆变换\"></a>MATLAB实现对图像的Fourier变换和逆变换</h2><ul>\n<li>Fourier变换，f为原图像<pre><code>&gt;&gt; F = fft2(f);</code></pre></li>\n<li>Fourier谱<pre><code>&gt;&gt; S = abs(F);</code></pre>该函数计算的是数组中每个元素的幅值( $ \\sqrt{r^2+i^2} $ )<br>可以在这里观察到4个角的亮点，这就是周期特性的结果，不便观察</li>\n<li>将交换的原点移动到频域矩形的中心<pre><code>&gt;&gt; Fc = fftshift(F)</code></pre>频谱范围大，不边观察</li>\n<li>取模，缩放<pre><code>S2 = log(1 + abs(Fc));</code></pre></li>\n<li>Fourier逆变换<pre><code>&gt;&gt; f = ifft2(F);</code></pre>下面是完整代码<pre><code>img=imread(&#39;moon.jpg&#39;);\nsubplot(2,2,1);\n  imshow(img);\n  title(&#39;原图&#39;);\n</code></pre></li>\n</ul>\n<p>f=rgb2gray(img);    %对于RGB图像必须做的一步，也可以用im2double函数<br>F=fft2(f);          %Fourier变换<br>F1=log(abs(F)+1);   %取模,缩放<br>subplot(2,2,2);<br>    imshow(F1,[]);<br>    title(‘傅里叶变换频谱图’);</p>\n<p>Fs=fftshift(F);      %将频谱图中零频率成分移动至频谱图中心<br>S=log(abs(Fs)+1);    %取模并进行缩放<br>subplot(2,2,3);<br>    imshow(S,[]);<br>    title(‘频移后的频谱图’);</p>\n<p>fr=real(ifft2(ifftshift(Fs)));  %频率域反变换到空间域，并取实部<br>ret=im2uint8(mat2gray(fr));    %更改图像类型<br>subplot(2,2,4);<br>    imshow(ret);<br>    title(‘逆傅里叶变换’);</p>\n<pre><code>结果\n![](https://i.loli.net/2019/07/18/5d3043778b4e114553.jpg)\n如果使用`&gt;&gt; f = im2double(img)`进行处理，则会出现以下结果\n![](https://i.loli.net/2019/07/18/5d304377bcc9554917.jpg)\n\n-分析    \n1. 图像Fourier变换之后立即imshow会报错\n![](https://i.loli.net/2019/07/18/5d3043779bef722309.jpg)\n这是因为经过fourier变换之后的图像矩阵为复数矩阵，包含实部和虚部，此时进行`abs(f)`取复数矩阵的模，再显示。\n2. `rgb2gray()`和`im2double()`的使用\n这一点要特别注意，对于RGB图像，`imread()`是已三维矩阵的形式来存储的，要先进行类型转换，否则会出现空白    \n3. `rgb2gray()`转换为灰度图像,得到的图像呈灰色基调，见‘结果’\n4. `im2double()`转换成双精度图像，得到的图像呈白色基调，见‘结果’\n其他图像处理结果\n![](https://i.loli.net/2019/07/18/5d304377bd0c676784.jpg)\n\n![](https://i.loli.net/2019/07/18/5d304377b0b2610307.jpg)\n可以看到Fourier逆变换处理之后的图片为原图的灰度图片。\n## 对图像Fourier变换的意义分析\n\n对于一个图像，其频率是表征图像中灰度变化剧烈程度的指标，是灰度在平面空间的梯度。设f为一个能量有限的模拟信号，其傅里叶变换代表f的频谱。从纯粹的数学意义上来看，Fourier变换是将一个函数转换成一系列的周期函数来进行处理的。从物理角度来看，Fourier变换是将图像从空间域转换到频率域，逆变换是将图像从频率域转换到空间域。也就是说，Fourier变换是将图像的灰度分布函数变换成图像的频率分布函数。==这里要注意是灰度分布函数==,下面还会说到。\n\nFourie逆变换是将图像的频率分布函数转换成灰度分布函数(原始图像的灰度分布函数),图像的概念前边说过，用一个二维矩阵来表示空间上的各点，z=f(x,y)，但空间是三维的，因此空间上的物体在另一个维度上的关系必须由梯度来表示。\n\nFourier频谱图上的明暗点，意义是指图像上的某一点与邻域点差异的强弱，即梯度的大小。\n\n对频谱移频到原点之后，可以看出图像的频率分布是以原点为圆心，对称分布的.</code></pre>"},{"title":"Day05","date":"2019-07-19T06:03:12.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"## 使用频率域滤波器平滑图像\n----\n \n### 理想低通滤波器\n\n在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为\n$$y=\\begin{cases}\n1,\\quad D(x,y)\\leq 0\\\\\n0, \\quad D(x,y) > 0\n\\end{cases}$$\n$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即\n$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$\n过渡点成为**截止频率**\n### 在MATLAB中DFT滤波的步骤:\n1. 用函数`tofloat`把输入图像转换成浮点图像\n```\n>> [f, revertclass] = tofloat(f);\n```\n2. 用函数`paddedsize`来获得填充参数\n```\n>> PQ = paddedsize(size(f));\n```\n3. 得到有填充的Fourier变换\n```\n>> F = fft2(f,PQ(1), PQ(2));\n```\n4. 生成大小为PQ(1)×PQ(2)的滤波函数H,函数类型要满足如下图所示,\n![](https://i.loli.net/2019/07/19/5d318dcf343b438405.jpg)    \n如果是类似这样的\n![](https://i.loli.net/2019/07/19/5d318dcf4915275796.jpg)    \n```\n>> H = lpfilter('gaussian',PQ(1),PQ(2),2*sig);\n```\n在使用滤波器之前，要先`H = fftshift(H)`\n5. 用滤波器乘以FFT变换\n```\n>> G = H .* F;\n```\n6. 获得G的逆Fourier变换\n```\n>> g = ifft2(G);\n```\n7. 修剪左上部矩形为原始大小\n```\n>> g = g(1:size(f, 1), 1:size(f, 2));\n```\n8. 把滤波后的图像变换为输入图像的类\n```\n>> g = revertclass(g);\n```\n\n完整代码\n```\nf = imread('1.jpg');\n\nf = rgb2gray(f);\n\n%未填充的滤波\n\n[M,N] = size(f);\n\n[f, revertclass] = tofloat(f);\n\nF = fft2(f);\n\nsig = 10;\n\nH = lpfilter('gaussian', M, N, sig);\n\nG = H.*F;\n\ng = ifft2(G);\n\ng = revertclass(g);\n\nfigure(1);\n\nsubplot(1,2,1);\n\nimshow(g)\n\ntitle('未填充的滤波');\n\n%已填充的滤波\n\nPQ = paddedsize(size(f));\n\nFp = fft2(f,PQ(1),PQ(2));\n\nHp = lpfilter('gaussian',PQ(1),PQ(2),2*sig);\n\nGp = Hp.*Fp;\n\ngp = ifft2(Gp);\n\ngpc = gp(1:size(f,1),1:size(f,2));\n\ngpc = revertclass(gpc);\n\nsubplot(1,2,2);\n\nimshow(gpc);\n\ntitle('已填充的滤波');\n```\n这里展示了不填充滤波和填充滤波的两种情况，结果\n![](https://i.loli.net/2019/07/19/5d318dcf1e88071166.jpg)\n可以观察到未填充滤波处理后图像的垂直边缘未模糊\n\n涉及到的函数    \n- paddedsize函数\n```\nfunction PQ = paddedsize(AB, CD, PARAM)\n\nif nargin == 1\n\nPQ = 2*AB;\n\nelseif nargin == 2 & ~ischar(CD) %如果CD不为字符串\n\nPQ = AB + CD -1;\n\nPQ = 2 *ceil(PQ / 2);\n\nelseif nargin == 2 %如果CD处为字符串\n\nm = max(AB);\n\nP = 2^nextpow2(2*m); %取2的整数次幂\n\nPQ = [P, P];\n\nelseif nargin == 3\n\nm = max([AB CD]);\n\nP = 2^nextpow2(2*m);\n\nPQ = [P, P];\n\nelse\n\nerror('wrong number of inputs.')\n\nend\n```\n- lpfilter函数\n```\nfunction [ H, D ] = lpfilter( type,M,N,D0,n )\n\n%LPFILTER creates the transfer function of a lowpass filter.\n\n%   Detailed explanation goes here\n\n\n\n%use function dftuv to set up the meshgrid arrays needed for computing\n\n%the required distances.\n\n[U, V] = dftuv(M,N);\n\n\n\n%compute the distances D(U,V)\n\nD = sqrt(U.^2 + V.^2);\n\n\n\n%begin filter computations\n\nswitch type\n\n    case 'ideal'\n\n        H = double(D <= D0);\n\n    case 'btw'\n\n        if nargin == 4\n\n            n = 1;\n\n        end\n\n        H = 1./(1+(D./D0).^(2*n));\n\n    case 'gaussian'\n\n        H = exp(-(D.^2)./(2*(D0^2)));\n\n    otherwise\n\n        error('Unkown filter type');\nend\n```\n- dftuv函数\n```\nfunction [ U,V ] = dftuv( M, N )\n\n%DFTUV 实现频域滤波器的网格函数\n\n%   Detailed explanation goes here\n\nu = 0:(M - 1);\n\nv = 0:(N - 1);\n\nidx = find(u > M/2); %找大于M/2的数据\n\nu(idx) = u(idx) - M; %将大于M/2的数据减去M\n\nidy = find(v > N/2);\n\nv(idy) = v(idy) - N;\n\n[V, U] = meshgrid(v, u);\n```\n### 总结：\n1. 图像平滑之后，变得更柔和，但也会更模糊    \n2. 会出现的问题:图像的边缘部分往往也处于高频，会被滤除\n","source":"_posts/Day05.md","raw":"---\ntitle: Day05\ndate: 2019-07-19 14:03:12\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n## 使用频率域滤波器平滑图像\n----\n \n### 理想低通滤波器\n\n在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为\n$$y=\\begin{cases}\n1,\\quad D(x,y)\\leq 0\\\\\n0, \\quad D(x,y) > 0\n\\end{cases}$$\n$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即\n$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$\n过渡点成为**截止频率**\n### 在MATLAB中DFT滤波的步骤:\n1. 用函数`tofloat`把输入图像转换成浮点图像\n```\n>> [f, revertclass] = tofloat(f);\n```\n2. 用函数`paddedsize`来获得填充参数\n```\n>> PQ = paddedsize(size(f));\n```\n3. 得到有填充的Fourier变换\n```\n>> F = fft2(f,PQ(1), PQ(2));\n```\n4. 生成大小为PQ(1)×PQ(2)的滤波函数H,函数类型要满足如下图所示,\n![](https://i.loli.net/2019/07/19/5d318dcf343b438405.jpg)    \n如果是类似这样的\n![](https://i.loli.net/2019/07/19/5d318dcf4915275796.jpg)    \n```\n>> H = lpfilter('gaussian',PQ(1),PQ(2),2*sig);\n```\n在使用滤波器之前，要先`H = fftshift(H)`\n5. 用滤波器乘以FFT变换\n```\n>> G = H .* F;\n```\n6. 获得G的逆Fourier变换\n```\n>> g = ifft2(G);\n```\n7. 修剪左上部矩形为原始大小\n```\n>> g = g(1:size(f, 1), 1:size(f, 2));\n```\n8. 把滤波后的图像变换为输入图像的类\n```\n>> g = revertclass(g);\n```\n\n完整代码\n```\nf = imread('1.jpg');\n\nf = rgb2gray(f);\n\n%未填充的滤波\n\n[M,N] = size(f);\n\n[f, revertclass] = tofloat(f);\n\nF = fft2(f);\n\nsig = 10;\n\nH = lpfilter('gaussian', M, N, sig);\n\nG = H.*F;\n\ng = ifft2(G);\n\ng = revertclass(g);\n\nfigure(1);\n\nsubplot(1,2,1);\n\nimshow(g)\n\ntitle('未填充的滤波');\n\n%已填充的滤波\n\nPQ = paddedsize(size(f));\n\nFp = fft2(f,PQ(1),PQ(2));\n\nHp = lpfilter('gaussian',PQ(1),PQ(2),2*sig);\n\nGp = Hp.*Fp;\n\ngp = ifft2(Gp);\n\ngpc = gp(1:size(f,1),1:size(f,2));\n\ngpc = revertclass(gpc);\n\nsubplot(1,2,2);\n\nimshow(gpc);\n\ntitle('已填充的滤波');\n```\n这里展示了不填充滤波和填充滤波的两种情况，结果\n![](https://i.loli.net/2019/07/19/5d318dcf1e88071166.jpg)\n可以观察到未填充滤波处理后图像的垂直边缘未模糊\n\n涉及到的函数    \n- paddedsize函数\n```\nfunction PQ = paddedsize(AB, CD, PARAM)\n\nif nargin == 1\n\nPQ = 2*AB;\n\nelseif nargin == 2 & ~ischar(CD) %如果CD不为字符串\n\nPQ = AB + CD -1;\n\nPQ = 2 *ceil(PQ / 2);\n\nelseif nargin == 2 %如果CD处为字符串\n\nm = max(AB);\n\nP = 2^nextpow2(2*m); %取2的整数次幂\n\nPQ = [P, P];\n\nelseif nargin == 3\n\nm = max([AB CD]);\n\nP = 2^nextpow2(2*m);\n\nPQ = [P, P];\n\nelse\n\nerror('wrong number of inputs.')\n\nend\n```\n- lpfilter函数\n```\nfunction [ H, D ] = lpfilter( type,M,N,D0,n )\n\n%LPFILTER creates the transfer function of a lowpass filter.\n\n%   Detailed explanation goes here\n\n\n\n%use function dftuv to set up the meshgrid arrays needed for computing\n\n%the required distances.\n\n[U, V] = dftuv(M,N);\n\n\n\n%compute the distances D(U,V)\n\nD = sqrt(U.^2 + V.^2);\n\n\n\n%begin filter computations\n\nswitch type\n\n    case 'ideal'\n\n        H = double(D <= D0);\n\n    case 'btw'\n\n        if nargin == 4\n\n            n = 1;\n\n        end\n\n        H = 1./(1+(D./D0).^(2*n));\n\n    case 'gaussian'\n\n        H = exp(-(D.^2)./(2*(D0^2)));\n\n    otherwise\n\n        error('Unkown filter type');\nend\n```\n- dftuv函数\n```\nfunction [ U,V ] = dftuv( M, N )\n\n%DFTUV 实现频域滤波器的网格函数\n\n%   Detailed explanation goes here\n\nu = 0:(M - 1);\n\nv = 0:(N - 1);\n\nidx = find(u > M/2); %找大于M/2的数据\n\nu(idx) = u(idx) - M; %将大于M/2的数据减去M\n\nidy = find(v > N/2);\n\nv(idy) = v(idy) - N;\n\n[V, U] = meshgrid(v, u);\n```\n### 总结：\n1. 图像平滑之后，变得更柔和，但也会更模糊    \n2. 会出现的问题:图像的边缘部分往往也处于高频，会被滤除\n","slug":"Day05","published":1,"updated":"2019-08-10T10:47:33.786Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lsz0007e5g6i3228eqs","content":"<h2 id=\"使用频率域滤波器平滑图像\"><a href=\"#使用频率域滤波器平滑图像\" class=\"headerlink\" title=\"使用频率域滤波器平滑图像\"></a>使用频率域滤波器平滑图像</h2><hr>\n<h3 id=\"理想低通滤波器\"><a href=\"#理想低通滤波器\" class=\"headerlink\" title=\"理想低通滤波器\"></a>理想低通滤波器</h3><p>在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为<br>$$y=\\begin{cases}<br>1,\\quad D(x,y)\\leq 0\\<br>0, \\quad D(x,y) &gt; 0<br>\\end{cases}$$<br>$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即<br>$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$<br>过渡点成为<strong>截止频率</strong></p>\n<h3 id=\"在MATLAB中DFT滤波的步骤\"><a href=\"#在MATLAB中DFT滤波的步骤\" class=\"headerlink\" title=\"在MATLAB中DFT滤波的步骤:\"></a>在MATLAB中DFT滤波的步骤:</h3><ol>\n<li>用函数<code>tofloat</code>把输入图像转换成浮点图像<pre><code>&gt;&gt; [f, revertclass] = tofloat(f);</code></pre></li>\n<li>用函数<code>paddedsize</code>来获得填充参数<pre><code>&gt;&gt; PQ = paddedsize(size(f));</code></pre></li>\n<li>得到有填充的Fourier变换<pre><code>&gt;&gt; F = fft2(f,PQ(1), PQ(2));</code></pre></li>\n<li>生成大小为PQ(1)×PQ(2)的滤波函数H,函数类型要满足如下图所示,<br><img src=\"https://i.loli.net/2019/07/19/5d318dcf343b438405.jpg\" alt><br>如果是类似这样的<br><img src=\"https://i.loli.net/2019/07/19/5d318dcf4915275796.jpg\" alt>    <pre><code>&gt;&gt; H = lpfilter(&#39;gaussian&#39;,PQ(1),PQ(2),2*sig);</code></pre>在使用滤波器之前，要先<code>H = fftshift(H)</code></li>\n<li>用滤波器乘以FFT变换<pre><code>&gt;&gt; G = H .* F;</code></pre></li>\n<li>获得G的逆Fourier变换<pre><code>&gt;&gt; g = ifft2(G);</code></pre></li>\n<li>修剪左上部矩形为原始大小<pre><code>&gt;&gt; g = g(1:size(f, 1), 1:size(f, 2));</code></pre></li>\n<li>把滤波后的图像变换为输入图像的类<pre><code>&gt;&gt; g = revertclass(g);</code></pre></li>\n</ol>\n<p>完整代码</p>\n<pre><code>f = imread(&#39;1.jpg&#39;);\n\nf = rgb2gray(f);\n\n%未填充的滤波\n\n[M,N] = size(f);\n\n[f, revertclass] = tofloat(f);\n\nF = fft2(f);\n\nsig = 10;\n\nH = lpfilter(&#39;gaussian&#39;, M, N, sig);\n\nG = H.*F;\n\ng = ifft2(G);\n\ng = revertclass(g);\n\nfigure(1);\n\nsubplot(1,2,1);\n\nimshow(g)\n\ntitle(&#39;未填充的滤波&#39;);\n\n%已填充的滤波\n\nPQ = paddedsize(size(f));\n\nFp = fft2(f,PQ(1),PQ(2));\n\nHp = lpfilter(&#39;gaussian&#39;,PQ(1),PQ(2),2*sig);\n\nGp = Hp.*Fp;\n\ngp = ifft2(Gp);\n\ngpc = gp(1:size(f,1),1:size(f,2));\n\ngpc = revertclass(gpc);\n\nsubplot(1,2,2);\n\nimshow(gpc);\n\ntitle(&#39;已填充的滤波&#39;);</code></pre><p>这里展示了不填充滤波和填充滤波的两种情况，结果<br><img src=\"https://i.loli.net/2019/07/19/5d318dcf1e88071166.jpg\" alt><br>可以观察到未填充滤波处理后图像的垂直边缘未模糊</p>\n<p>涉及到的函数    </p>\n<ul>\n<li>paddedsize函数<pre><code>function PQ = paddedsize(AB, CD, PARAM)\n</code></pre></li>\n</ul>\n<p>if nargin == 1</p>\n<p>PQ = 2*AB;</p>\n<p>elseif nargin == 2 &amp; ~ischar(CD) %如果CD不为字符串</p>\n<p>PQ = AB + CD -1;</p>\n<p>PQ = 2 *ceil(PQ / 2);</p>\n<p>elseif nargin == 2 %如果CD处为字符串</p>\n<p>m = max(AB);</p>\n<p>P = 2^nextpow2(2*m); %取2的整数次幂</p>\n<p>PQ = [P, P];</p>\n<p>elseif nargin == 3</p>\n<p>m = max([AB CD]);</p>\n<p>P = 2^nextpow2(2*m);</p>\n<p>PQ = [P, P];</p>\n<p>else</p>\n<p>error(‘wrong number of inputs.’)</p>\n<p>end</p>\n<pre><code>- lpfilter函数</code></pre><p>function [ H, D ] = lpfilter( type,M,N,D0,n )</p>\n<p>%LPFILTER creates the transfer function of a lowpass filter.</p>\n<p>%   Detailed explanation goes here</p>\n<p>%use function dftuv to set up the meshgrid arrays needed for computing</p>\n<p>%the required distances.</p>\n<p>[U, V] = dftuv(M,N);</p>\n<p>%compute the distances D(U,V)</p>\n<p>D = sqrt(U.^2 + V.^2);</p>\n<p>%begin filter computations</p>\n<p>switch type</p>\n<pre><code>case &#39;ideal&#39;\n\n    H = double(D &lt;= D0);\n\ncase &#39;btw&#39;\n\n    if nargin == 4\n\n        n = 1;\n\n    end\n\n    H = 1./(1+(D./D0).^(2*n));\n\ncase &#39;gaussian&#39;\n\n    H = exp(-(D.^2)./(2*(D0^2)));\n\notherwise\n\n    error(&#39;Unkown filter type&#39;);</code></pre><p>end</p>\n<pre><code>- dftuv函数</code></pre><p>function [ U,V ] = dftuv( M, N )</p>\n<p>%DFTUV 实现频域滤波器的网格函数</p>\n<p>%   Detailed explanation goes here</p>\n<p>u = 0:(M - 1);</p>\n<p>v = 0:(N - 1);</p>\n<p>idx = find(u &gt; M/2); %找大于M/2的数据</p>\n<p>u(idx) = u(idx) - M; %将大于M/2的数据减去M</p>\n<p>idy = find(v &gt; N/2);</p>\n<p>v(idy) = v(idy) - N;</p>\n<p>[V, U] = meshgrid(v, u);</p>\n<pre><code>### 总结：\n1. 图像平滑之后，变得更柔和，但也会更模糊    \n2. 会出现的问题:图像的边缘部分往往也处于高频，会被滤除</code></pre>","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"使用频率域滤波器平滑图像\"><a href=\"#使用频率域滤波器平滑图像\" class=\"headerlink\" title=\"使用频率域滤波器平滑图像\"></a>使用频率域滤波器平滑图像</h2><hr>\n<h3 id=\"理想低通滤波器\"><a href=\"#理想低通滤波器\" class=\"headerlink\" title=\"理想低通滤波器\"></a>理想低通滤波器</h3><p>在以原点为圆心，以$D_0$为半径的圆内无衰减通过所有频率，而在圆外切断所有频率的二维低通滤波器，称为理想低通滤波器(ILPF)，定义为<br>$$y=\\begin{cases}<br>1,\\quad D(x,y)\\leq 0\\<br>0, \\quad D(x,y) &gt; 0<br>\\end{cases}$$<br>$D_0$是一个常数，D(u,v)是频率域中心点(u,v)与频率矩形中心的距离，即<br>$$ D(u,v)=\\lbrack{(u-\\frac{P}{2})^2+(v-\\frac{Q}{2})^2}\\rbrack^\\frac{1}{2} $$<br>过渡点成为<strong>截止频率</strong></p>\n<h3 id=\"在MATLAB中DFT滤波的步骤\"><a href=\"#在MATLAB中DFT滤波的步骤\" class=\"headerlink\" title=\"在MATLAB中DFT滤波的步骤:\"></a>在MATLAB中DFT滤波的步骤:</h3><ol>\n<li>用函数<code>tofloat</code>把输入图像转换成浮点图像<pre><code>&gt;&gt; [f, revertclass] = tofloat(f);</code></pre></li>\n<li>用函数<code>paddedsize</code>来获得填充参数<pre><code>&gt;&gt; PQ = paddedsize(size(f));</code></pre></li>\n<li>得到有填充的Fourier变换<pre><code>&gt;&gt; F = fft2(f,PQ(1), PQ(2));</code></pre></li>\n<li>生成大小为PQ(1)×PQ(2)的滤波函数H,函数类型要满足如下图所示,<br><img src=\"https://i.loli.net/2019/07/19/5d318dcf343b438405.jpg\" alt><br>如果是类似这样的<br><img src=\"https://i.loli.net/2019/07/19/5d318dcf4915275796.jpg\" alt>    <pre><code>&gt;&gt; H = lpfilter(&#39;gaussian&#39;,PQ(1),PQ(2),2*sig);</code></pre>在使用滤波器之前，要先<code>H = fftshift(H)</code></li>\n<li>用滤波器乘以FFT变换<pre><code>&gt;&gt; G = H .* F;</code></pre></li>\n<li>获得G的逆Fourier变换<pre><code>&gt;&gt; g = ifft2(G);</code></pre></li>\n<li>修剪左上部矩形为原始大小<pre><code>&gt;&gt; g = g(1:size(f, 1), 1:size(f, 2));</code></pre></li>\n<li>把滤波后的图像变换为输入图像的类<pre><code>&gt;&gt; g = revertclass(g);</code></pre></li>\n</ol>\n<p>完整代码</p>\n<pre><code>f = imread(&#39;1.jpg&#39;);\n\nf = rgb2gray(f);\n\n%未填充的滤波\n\n[M,N] = size(f);\n\n[f, revertclass] = tofloat(f);\n\nF = fft2(f);\n\nsig = 10;\n\nH = lpfilter(&#39;gaussian&#39;, M, N, sig);\n\nG = H.*F;\n\ng = ifft2(G);\n\ng = revertclass(g);\n\nfigure(1);\n\nsubplot(1,2,1);\n\nimshow(g)\n\ntitle(&#39;未填充的滤波&#39;);\n\n%已填充的滤波\n\nPQ = paddedsize(size(f));\n\nFp = fft2(f,PQ(1),PQ(2));\n\nHp = lpfilter(&#39;gaussian&#39;,PQ(1),PQ(2),2*sig);\n\nGp = Hp.*Fp;\n\ngp = ifft2(Gp);\n\ngpc = gp(1:size(f,1),1:size(f,2));\n\ngpc = revertclass(gpc);\n\nsubplot(1,2,2);\n\nimshow(gpc);\n\ntitle(&#39;已填充的滤波&#39;);</code></pre><p>这里展示了不填充滤波和填充滤波的两种情况，结果<br><img src=\"https://i.loli.net/2019/07/19/5d318dcf1e88071166.jpg\" alt><br>可以观察到未填充滤波处理后图像的垂直边缘未模糊</p>\n<p>涉及到的函数    </p>\n<ul>\n<li>paddedsize函数<pre><code>function PQ = paddedsize(AB, CD, PARAM)\n</code></pre></li>\n</ul>\n<p>if nargin == 1</p>\n<p>PQ = 2*AB;</p>\n<p>elseif nargin == 2 &amp; ~ischar(CD) %如果CD不为字符串</p>\n<p>PQ = AB + CD -1;</p>\n<p>PQ = 2 *ceil(PQ / 2);</p>\n<p>elseif nargin == 2 %如果CD处为字符串</p>\n<p>m = max(AB);</p>\n<p>P = 2^nextpow2(2*m); %取2的整数次幂</p>\n<p>PQ = [P, P];</p>\n<p>elseif nargin == 3</p>\n<p>m = max([AB CD]);</p>\n<p>P = 2^nextpow2(2*m);</p>\n<p>PQ = [P, P];</p>\n<p>else</p>\n<p>error(‘wrong number of inputs.’)</p>\n<p>end</p>\n<pre><code>- lpfilter函数</code></pre><p>function [ H, D ] = lpfilter( type,M,N,D0,n )</p>\n<p>%LPFILTER creates the transfer function of a lowpass filter.</p>\n<p>%   Detailed explanation goes here</p>\n<p>%use function dftuv to set up the meshgrid arrays needed for computing</p>\n<p>%the required distances.</p>\n<p>[U, V] = dftuv(M,N);</p>\n<p>%compute the distances D(U,V)</p>\n<p>D = sqrt(U.^2 + V.^2);</p>\n<p>%begin filter computations</p>\n<p>switch type</p>\n<pre><code>case &#39;ideal&#39;\n\n    H = double(D &lt;= D0);\n\ncase &#39;btw&#39;\n\n    if nargin == 4\n\n        n = 1;\n\n    end\n\n    H = 1./(1+(D./D0).^(2*n));\n\ncase &#39;gaussian&#39;\n\n    H = exp(-(D.^2)./(2*(D0^2)));\n\notherwise\n\n    error(&#39;Unkown filter type&#39;);</code></pre><p>end</p>\n<pre><code>- dftuv函数</code></pre><p>function [ U,V ] = dftuv( M, N )</p>\n<p>%DFTUV 实现频域滤波器的网格函数</p>\n<p>%   Detailed explanation goes here</p>\n<p>u = 0:(M - 1);</p>\n<p>v = 0:(N - 1);</p>\n<p>idx = find(u &gt; M/2); %找大于M/2的数据</p>\n<p>u(idx) = u(idx) - M; %将大于M/2的数据减去M</p>\n<p>idy = find(v &gt; N/2);</p>\n<p>v(idy) = v(idy) - N;</p>\n<p>[V, U] = meshgrid(v, u);</p>\n<pre><code>### 总结：\n1. 图像平滑之后，变得更柔和，但也会更模糊    \n2. 会出现的问题:图像的边缘部分往往也处于高频，会被滤除</code></pre>"},{"title":"Day03","date":"2019-07-17T05:04:09.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n## 标准的空间滤波器\n\n### 线性空间滤波器\n- 可以使用fspecial实现，生成滤波器w\n\n    ```matlab\n    w = fspecial('type', parameters)\n\n    ```\n\n    'type'表示滤波器的类型，'parameters'进一步定义指定的滤波器\n    应用参数如下：\n    ![](https://i.loli.net/2019/07/17/5d2eba0f5055d41026.jpg)\n    ![](https://i.loli.net/2019/07/17/5d2ec9491164776894.jpg)\n- Laplace滤波器的实现\n    + 原理：    \n    图像f(x,y)的laplace算子：\n    ![](https://i.loli.net/2019/07/17/5d2ec90e6a75162149.jpg)\n    Laplace算子增强公式：\n    $$g(x,y) = f(x,y)+c[\\triangledown ^2 f(x,y)]$$\n    注意：如果模板的中心系数为正，c为1;如果为负，c为0.\n\n    ```matlab\n    fspecial('laplacian', alpha)\n    ```\n\n    可以实现更为一般的laplace模板\n\n    - 下面是用laplace滤波器增强图像的例子：\n    首先设置滤波器\n\n    ```matlab\n    >> w = fspecial('laplacian', 0);\n    ```\n\n    ![](https://i.loli.net/2019/07/17/5d2ed6fcca83142276.jpg)\n\n    输入的图像为unit8类，\n\n    ```matlab\n    >> g1 = imfilter(f, w, 'replicate');\n    >> imshow(g1);\n    ```\n\n    得到结果，但存在问题，所有像素都是正的。原因：滤波器的中心参数为负值，为了解决这一问题，可以在滤波前将f转换为浮点数\n\n    ```matlab\n    >> ff = tofloat(f);\n    >> g2 = imfilter(ff, w, 'replicate');\n    >> imshow(g2);\n    ```\n\n    这里tofloat为M-IPT函数，实现代码如下：\n\n    ```matlab\n    function [out,revertclass] = tofloat(inputimage)\n    %Copy the book of Gonzales\n    identify = @(x) x;\n    tosingle = @im2single;\n    table = {'uint8',tosingle,@im2uint8\n    'uint16',tosingle,@im2uint16\n    'logical',tosingle,@logical\n    'double',identify,identify\n    'single',identify,identify};\n    classIndex = find(strcmp(class(inputimage),table(:,1)));\n    if isempty(classIndex)\n    error('不支持的图像类型');\n    end\n    out = table{classIndex,2}(inputimage);\n    revertclass = table{classIndex,3};\n    ```\n\n    导入workspace即可\n\n    最后用原始图像减去laplace图像来恢复失去的灰度层次(因为中心参数为负值)\n\n    ```matlab\n    >> g = ff - g2;\n    imshow(g);\n    ```\n\n    可以看到结果比原图象要清晰\n![](https://i.loli.net/2019/07/17/5d2ed69eaa47174206.jpg)\n### 非线性空间滤波器\n\n- 函数ordfilt2计算统计排序(order-statistic filter)滤波器(也叫做rank filter,即排序滤波器)\n语法为：\n\n```matlab\ng = ordfilt2(f, order, domain)\n```\n\n用邻域集合中的第order个元素去替换f中的每个元素的值来生成图像g，domain是由0和1组成的大小为m×n的矩阵，规定了在计算中使用的邻域中像素点的位置\n- 中值滤波器，最著名的统计排序滤波器，对应第50个百分位，对应奇数的m和n\n\n```matlab\ng = ordfilt2(f, (m*n + 1)/2, ones(m, n));\n\n```\n   - 这里提供了一个专门的二维中值滤波器:\n\n```matlab\ng = medfilt2(f, [m, n], padopt)\n```\n\n\n\n  padopt规定了三个可能的边缘填充选项:\n  1. 'zeros',默认值\n  2. 'symmetric',f按照镜像反射方式对称地沿边缘扩展\n  3. 'indexed'，f属于double类，用1填充;否则用0填充\n  - 中值滤波增强图像:\n  首先给图像添加黑白噪点发生概率为0.2的'椒盐噪声'\n\n    ```matlab\n    >> fn = imnoise(f, 'salt & pepper', 0.2)\n    ```\n\n   对带噪图像进行中值滤波处理\n\n    ```matlab\n    >> gm = medfilt2(fn)\n    ```\n\n   注意，在这里出现了错误，==A应为二维==\n   ![](https://i.loli.net/2019/07/17/5d2ed759e608448713.jpg)\n\n   原因:中值滤波medfilt2,输入的图像应为二维矩阵，实际输入的为imread读取的图像加上噪声，通常是三维RGB图，是三维矩阵\n   解决办法:先用rgb2gray(f)将图像转换为灰度矩阵图像\n\n    ```matlab\n    >> fn2 = rgb2gray(fn);\n    >> gm = medfilt2(fn2);\n    >> imshow(gm);\n    ```\n\n   减弱外圈黑点\n\n    ```matlab\n    >> gms = medfilt2(fn2, 'symmetric');\n    ```\n\n![](https://i.loli.net/2019/07/17/5d2ed7776b71a55041.jpg)\n\n\n","source":"_posts/Day03.md","raw":"---\ntitle: Day03\ndate: 2019-07-17 13:04:09\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n## 标准的空间滤波器\n\n### 线性空间滤波器\n- 可以使用fspecial实现，生成滤波器w\n\n    ```matlab\n    w = fspecial('type', parameters)\n\n    ```\n\n    'type'表示滤波器的类型，'parameters'进一步定义指定的滤波器\n    应用参数如下：\n    ![](https://i.loli.net/2019/07/17/5d2eba0f5055d41026.jpg)\n    ![](https://i.loli.net/2019/07/17/5d2ec9491164776894.jpg)\n- Laplace滤波器的实现\n    + 原理：    \n    图像f(x,y)的laplace算子：\n    ![](https://i.loli.net/2019/07/17/5d2ec90e6a75162149.jpg)\n    Laplace算子增强公式：\n    $$g(x,y) = f(x,y)+c[\\triangledown ^2 f(x,y)]$$\n    注意：如果模板的中心系数为正，c为1;如果为负，c为0.\n\n    ```matlab\n    fspecial('laplacian', alpha)\n    ```\n\n    可以实现更为一般的laplace模板\n\n    - 下面是用laplace滤波器增强图像的例子：\n    首先设置滤波器\n\n    ```matlab\n    >> w = fspecial('laplacian', 0);\n    ```\n\n    ![](https://i.loli.net/2019/07/17/5d2ed6fcca83142276.jpg)\n\n    输入的图像为unit8类，\n\n    ```matlab\n    >> g1 = imfilter(f, w, 'replicate');\n    >> imshow(g1);\n    ```\n\n    得到结果，但存在问题，所有像素都是正的。原因：滤波器的中心参数为负值，为了解决这一问题，可以在滤波前将f转换为浮点数\n\n    ```matlab\n    >> ff = tofloat(f);\n    >> g2 = imfilter(ff, w, 'replicate');\n    >> imshow(g2);\n    ```\n\n    这里tofloat为M-IPT函数，实现代码如下：\n\n    ```matlab\n    function [out,revertclass] = tofloat(inputimage)\n    %Copy the book of Gonzales\n    identify = @(x) x;\n    tosingle = @im2single;\n    table = {'uint8',tosingle,@im2uint8\n    'uint16',tosingle,@im2uint16\n    'logical',tosingle,@logical\n    'double',identify,identify\n    'single',identify,identify};\n    classIndex = find(strcmp(class(inputimage),table(:,1)));\n    if isempty(classIndex)\n    error('不支持的图像类型');\n    end\n    out = table{classIndex,2}(inputimage);\n    revertclass = table{classIndex,3};\n    ```\n\n    导入workspace即可\n\n    最后用原始图像减去laplace图像来恢复失去的灰度层次(因为中心参数为负值)\n\n    ```matlab\n    >> g = ff - g2;\n    imshow(g);\n    ```\n\n    可以看到结果比原图象要清晰\n![](https://i.loli.net/2019/07/17/5d2ed69eaa47174206.jpg)\n### 非线性空间滤波器\n\n- 函数ordfilt2计算统计排序(order-statistic filter)滤波器(也叫做rank filter,即排序滤波器)\n语法为：\n\n```matlab\ng = ordfilt2(f, order, domain)\n```\n\n用邻域集合中的第order个元素去替换f中的每个元素的值来生成图像g，domain是由0和1组成的大小为m×n的矩阵，规定了在计算中使用的邻域中像素点的位置\n- 中值滤波器，最著名的统计排序滤波器，对应第50个百分位，对应奇数的m和n\n\n```matlab\ng = ordfilt2(f, (m*n + 1)/2, ones(m, n));\n\n```\n   - 这里提供了一个专门的二维中值滤波器:\n\n```matlab\ng = medfilt2(f, [m, n], padopt)\n```\n\n\n\n  padopt规定了三个可能的边缘填充选项:\n  1. 'zeros',默认值\n  2. 'symmetric',f按照镜像反射方式对称地沿边缘扩展\n  3. 'indexed'，f属于double类，用1填充;否则用0填充\n  - 中值滤波增强图像:\n  首先给图像添加黑白噪点发生概率为0.2的'椒盐噪声'\n\n    ```matlab\n    >> fn = imnoise(f, 'salt & pepper', 0.2)\n    ```\n\n   对带噪图像进行中值滤波处理\n\n    ```matlab\n    >> gm = medfilt2(fn)\n    ```\n\n   注意，在这里出现了错误，==A应为二维==\n   ![](https://i.loli.net/2019/07/17/5d2ed759e608448713.jpg)\n\n   原因:中值滤波medfilt2,输入的图像应为二维矩阵，实际输入的为imread读取的图像加上噪声，通常是三维RGB图，是三维矩阵\n   解决办法:先用rgb2gray(f)将图像转换为灰度矩阵图像\n\n    ```matlab\n    >> fn2 = rgb2gray(fn);\n    >> gm = medfilt2(fn2);\n    >> imshow(gm);\n    ```\n\n   减弱外圈黑点\n\n    ```matlab\n    >> gms = medfilt2(fn2, 'symmetric');\n    ```\n\n![](https://i.loli.net/2019/07/17/5d2ed7776b71a55041.jpg)\n\n\n","slug":"Day03","published":1,"updated":"2019-08-10T10:47:33.786Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lt2000ae5g67png8b0i","content":"<h2 id=\"标准的空间滤波器\"><a href=\"#标准的空间滤波器\" class=\"headerlink\" title=\"标准的空间滤波器\"></a>标准的空间滤波器</h2><h3 id=\"线性空间滤波器\"><a href=\"#线性空间滤波器\" class=\"headerlink\" title=\"线性空间滤波器\"></a>线性空间滤波器</h3><ul>\n<li><p>可以使用fspecial实现，生成滤波器w</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\">  w <span class=\"token operator\">=</span> <span class=\"token function\">fspecial</span><span class=\"token punctuation\">(</span><span class=\"token string\">'type'</span><span class=\"token punctuation\">,</span> parameters<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>  ‘type’表示滤波器的类型，’parameters’进一步定义指定的滤波器<br>  应用参数如下：<br>  <img src=\"https://i.loli.net/2019/07/17/5d2eba0f5055d41026.jpg\" alt><br>  <img src=\"https://i.loli.net/2019/07/17/5d2ec9491164776894.jpg\" alt></p>\n</li>\n<li><p>Laplace滤波器的实现</p>\n<ul>\n<li><p>原理：<br>图像f(x,y)的laplace算子：<br><img src=\"https://i.loli.net/2019/07/17/5d2ec90e6a75162149.jpg\" alt><br>Laplace算子增强公式：<br>$$g(x,y) = f(x,y)+c[\\triangledown ^2 f(x,y)]$$<br>注意：如果模板的中心系数为正，c为1;如果为负，c为0.</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token function\">fspecial</span><span class=\"token punctuation\">(</span><span class=\"token string\">'laplacian'</span><span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">)</span></code></pre>\n<p>可以实现更为一般的laplace模板</p>\n</li>\n</ul>\n<ul>\n<li><p>下面是用laplace滤波器增强图像的例子：<br>首先设置滤波器</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> w <span class=\"token operator\">=</span> <span class=\"token function\">fspecial</span><span class=\"token punctuation\">(</span><span class=\"token string\">'laplacian'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p><img src=\"https://i.loli.net/2019/07/17/5d2ed6fcca83142276.jpg\" alt></p>\n<p>输入的图像为unit8类，</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> g1 <span class=\"token operator\">=</span> <span class=\"token function\">imfilter</span><span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> <span class=\"token string\">'replicate'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token operator\">></span><span class=\"token operator\">></span> <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span>g1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>得到结果，但存在问题，所有像素都是正的。原因：滤波器的中心参数为负值，为了解决这一问题，可以在滤波前将f转换为浮点数</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> ff <span class=\"token operator\">=</span> <span class=\"token function\">tofloat</span><span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token operator\">></span><span class=\"token operator\">></span> g2 <span class=\"token operator\">=</span> <span class=\"token function\">imfilter</span><span class=\"token punctuation\">(</span>ff<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">,</span> <span class=\"token string\">'replicate'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token operator\">></span><span class=\"token operator\">></span> <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span>g2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>这里tofloat为M-IPT函数，实现代码如下：</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token keyword\">function</span> <span class=\"token punctuation\">[</span>out<span class=\"token punctuation\">,</span>revertclass<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token function\">tofloat</span><span class=\"token punctuation\">(</span>inputimage<span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\">%Copy the book of Gonzales</span>\nidentify <span class=\"token operator\">=</span> <span class=\"token operator\">@</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> x<span class=\"token punctuation\">;</span>\ntosingle <span class=\"token operator\">=</span> <span class=\"token operator\">@</span>im2single<span class=\"token punctuation\">;</span>\ntable <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'uint8'</span><span class=\"token punctuation\">,</span>tosingle<span class=\"token punctuation\">,</span><span class=\"token operator\">@</span>im2uint8\n<span class=\"token string\">'uint16'</span><span class=\"token punctuation\">,</span>tosingle<span class=\"token punctuation\">,</span><span class=\"token operator\">@</span>im2uint16\n<span class=\"token string\">'logical'</span><span class=\"token punctuation\">,</span>tosingle<span class=\"token punctuation\">,</span><span class=\"token operator\">@</span>logical\n<span class=\"token string\">'double'</span><span class=\"token punctuation\">,</span>identify<span class=\"token punctuation\">,</span>identify\n<span class=\"token string\">'single'</span><span class=\"token punctuation\">,</span>identify<span class=\"token punctuation\">,</span>identify<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\nclassIndex <span class=\"token operator\">=</span> <span class=\"token function\">find</span><span class=\"token punctuation\">(</span><span class=\"token function\">strcmp</span><span class=\"token punctuation\">(</span><span class=\"token function\">class</span><span class=\"token punctuation\">(</span>inputimage<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token function\">table</span><span class=\"token punctuation\">(</span><span class=\"token operator\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">if</span> <span class=\"token function\">isempty</span><span class=\"token punctuation\">(</span>classIndex<span class=\"token punctuation\">)</span>\n<span class=\"token function\">error</span><span class=\"token punctuation\">(</span><span class=\"token string\">'不支持的图像类型'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">end</span>\nout <span class=\"token operator\">=</span> table<span class=\"token punctuation\">{</span>classIndex<span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">(</span>inputimage<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nrevertclass <span class=\"token operator\">=</span> table<span class=\"token punctuation\">{</span>classIndex<span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span></code></pre>\n<p>导入workspace即可</p>\n<p>最后用原始图像减去laplace图像来恢复失去的灰度层次(因为中心参数为负值)</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> g <span class=\"token operator\">=</span> ff <span class=\"token operator\">-</span> g2<span class=\"token punctuation\">;</span>\n<span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span>g<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>可以看到结果比原图象要清晰<br><img src=\"https://i.loli.net/2019/07/17/5d2ed69eaa47174206.jpg\" alt></p>\n<h3 id=\"非线性空间滤波器\"><a href=\"#非线性空间滤波器\" class=\"headerlink\" title=\"非线性空间滤波器\"></a>非线性空间滤波器</h3></li>\n</ul>\n</li>\n<li><p>函数ordfilt2计算统计排序(order-statistic filter)滤波器(也叫做rank filter,即排序滤波器)<br>语法为：</p>\n</li>\n</ul>\n<pre class=\" language-matlab\"><code class=\"language-matlab\">g <span class=\"token operator\">=</span> <span class=\"token function\">ordfilt2</span><span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">,</span> order<span class=\"token punctuation\">,</span> domain<span class=\"token punctuation\">)</span></code></pre>\n<p>用邻域集合中的第order个元素去替换f中的每个元素的值来生成图像g，domain是由0和1组成的大小为m×n的矩阵，规定了在计算中使用的邻域中像素点的位置</p>\n<ul>\n<li>中值滤波器，最著名的统计排序滤波器，对应第50个百分位，对应奇数的m和n</li>\n</ul>\n<pre class=\" language-matlab\"><code class=\"language-matlab\">g <span class=\"token operator\">=</span> <span class=\"token function\">ordfilt2</span><span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>m<span class=\"token operator\">*</span>n <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token function\">ones</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<ul>\n<li>这里提供了一个专门的二维中值滤波器:</li>\n</ul>\n<pre class=\" language-matlab\"><code class=\"language-matlab\">g <span class=\"token operator\">=</span> <span class=\"token function\">medfilt2</span><span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> padopt<span class=\"token punctuation\">)</span></code></pre>\n<p>  padopt规定了三个可能的边缘填充选项:</p>\n<ol>\n<li>‘zeros’,默认值</li>\n<li>‘symmetric’,f按照镜像反射方式对称地沿边缘扩展</li>\n<li>‘indexed’，f属于double类，用1填充;否则用0填充</li>\n</ol>\n<ul>\n<li><p>中值滤波增强图像:<br>首先给图像添加黑白噪点发生概率为0.2的’椒盐噪声’</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> fn <span class=\"token operator\">=</span> <span class=\"token function\">imnoise</span><span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">,</span> <span class=\"token string\">'salt &amp; pepper'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span></code></pre>\n<p>对带噪图像进行中值滤波处理</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> gm <span class=\"token operator\">=</span> <span class=\"token function\">medfilt2</span><span class=\"token punctuation\">(</span>fn<span class=\"token punctuation\">)</span></code></pre>\n<p>注意，在这里出现了错误，==A应为二维==<br><img src=\"https://i.loli.net/2019/07/17/5d2ed759e608448713.jpg\" alt></p>\n<p>原因:中值滤波medfilt2,输入的图像应为二维矩阵，实际输入的为imread读取的图像加上噪声，通常是三维RGB图，是三维矩阵<br>解决办法:先用rgb2gray(f)将图像转换为灰度矩阵图像</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> fn2 <span class=\"token operator\">=</span> <span class=\"token function\">rgb2gray</span><span class=\"token punctuation\">(</span>fn<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token operator\">></span><span class=\"token operator\">></span> gm <span class=\"token operator\">=</span> <span class=\"token function\">medfilt2</span><span class=\"token punctuation\">(</span>fn2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token operator\">></span><span class=\"token operator\">></span> <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span>gm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>减弱外圈黑点</p>\n<pre class=\" language-matlab\"><code class=\"language-matlab\"><span class=\"token operator\">></span><span class=\"token operator\">></span> gms <span class=\"token operator\">=</span> <span class=\"token function\">medfilt2</span><span class=\"token punctuation\">(</span>fn2<span class=\"token punctuation\">,</span> <span class=\"token string\">'symmetric'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n</li>\n</ul>\n<p><img src=\"https://i.loli.net/2019/07/17/5d2ed7776b71a55041.jpg\" alt></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"标准的空间滤波器\"><a href=\"#标准的空间滤波器\" class=\"headerlink\" title=\"标准的空间滤波器\"></a>标准的空间滤波器</h2><h3 id=\"线性空间滤波器\"><a href=\"#线性空间滤波器\" class=\"headerlink\" title=\"线性空间滤波器\"></a>线性空间滤波器</h3><ul>\n<li><p>可以使用fspecial实现，生成滤波器w</p>\n<pre><code class=\"matlab\">  w = fspecial(&#39;type&#39;, parameters)\n</code></pre>\n<p>  ‘type’表示滤波器的类型，’parameters’进一步定义指定的滤波器<br>  应用参数如下：<br>  <img src=\"https://i.loli.net/2019/07/17/5d2eba0f5055d41026.jpg\" alt><br>  <img src=\"https://i.loli.net/2019/07/17/5d2ec9491164776894.jpg\" alt></p>\n</li>\n<li><p>Laplace滤波器的实现</p>\n<ul>\n<li><p>原理：<br>图像f(x,y)的laplace算子：<br><img src=\"https://i.loli.net/2019/07/17/5d2ec90e6a75162149.jpg\" alt><br>Laplace算子增强公式：<br>$$g(x,y) = f(x,y)+c[\\triangledown ^2 f(x,y)]$$<br>注意：如果模板的中心系数为正，c为1;如果为负，c为0.</p>\n<pre><code class=\"matlab\">fspecial(&#39;laplacian&#39;, alpha)</code></pre>\n<p>可以实现更为一般的laplace模板</p>\n</li>\n</ul>\n<ul>\n<li><p>下面是用laplace滤波器增强图像的例子：<br>首先设置滤波器</p>\n<pre><code class=\"matlab\">&gt;&gt; w = fspecial(&#39;laplacian&#39;, 0);</code></pre>\n<p><img src=\"https://i.loli.net/2019/07/17/5d2ed6fcca83142276.jpg\" alt></p>\n<p>输入的图像为unit8类，</p>\n<pre><code class=\"matlab\">&gt;&gt; g1 = imfilter(f, w, &#39;replicate&#39;);\n&gt;&gt; imshow(g1);</code></pre>\n<p>得到结果，但存在问题，所有像素都是正的。原因：滤波器的中心参数为负值，为了解决这一问题，可以在滤波前将f转换为浮点数</p>\n<pre><code class=\"matlab\">&gt;&gt; ff = tofloat(f);\n&gt;&gt; g2 = imfilter(ff, w, &#39;replicate&#39;);\n&gt;&gt; imshow(g2);</code></pre>\n<p>这里tofloat为M-IPT函数，实现代码如下：</p>\n<pre><code class=\"matlab\">function [out,revertclass] = tofloat(inputimage)\n%Copy the book of Gonzales\nidentify = @(x) x;\ntosingle = @im2single;\ntable = {&#39;uint8&#39;,tosingle,@im2uint8\n&#39;uint16&#39;,tosingle,@im2uint16\n&#39;logical&#39;,tosingle,@logical\n&#39;double&#39;,identify,identify\n&#39;single&#39;,identify,identify};\nclassIndex = find(strcmp(class(inputimage),table(:,1)));\nif isempty(classIndex)\nerror(&#39;不支持的图像类型&#39;);\nend\nout = table{classIndex,2}(inputimage);\nrevertclass = table{classIndex,3};</code></pre>\n<p>导入workspace即可</p>\n<p>最后用原始图像减去laplace图像来恢复失去的灰度层次(因为中心参数为负值)</p>\n<pre><code class=\"matlab\">&gt;&gt; g = ff - g2;\nimshow(g);</code></pre>\n<p>可以看到结果比原图象要清晰<br><img src=\"https://i.loli.net/2019/07/17/5d2ed69eaa47174206.jpg\" alt></p>\n<h3 id=\"非线性空间滤波器\"><a href=\"#非线性空间滤波器\" class=\"headerlink\" title=\"非线性空间滤波器\"></a>非线性空间滤波器</h3></li>\n</ul>\n</li>\n<li><p>函数ordfilt2计算统计排序(order-statistic filter)滤波器(也叫做rank filter,即排序滤波器)<br>语法为：</p>\n</li>\n</ul>\n<pre><code class=\"matlab\">g = ordfilt2(f, order, domain)</code></pre>\n<p>用邻域集合中的第order个元素去替换f中的每个元素的值来生成图像g，domain是由0和1组成的大小为m×n的矩阵，规定了在计算中使用的邻域中像素点的位置</p>\n<ul>\n<li>中值滤波器，最著名的统计排序滤波器，对应第50个百分位，对应奇数的m和n</li>\n</ul>\n<pre><code class=\"matlab\">g = ordfilt2(f, (m*n + 1)/2, ones(m, n));\n</code></pre>\n<ul>\n<li>这里提供了一个专门的二维中值滤波器:</li>\n</ul>\n<pre><code class=\"matlab\">g = medfilt2(f, [m, n], padopt)</code></pre>\n<p>  padopt规定了三个可能的边缘填充选项:</p>\n<ol>\n<li>‘zeros’,默认值</li>\n<li>‘symmetric’,f按照镜像反射方式对称地沿边缘扩展</li>\n<li>‘indexed’，f属于double类，用1填充;否则用0填充</li>\n</ol>\n<ul>\n<li><p>中值滤波增强图像:<br>首先给图像添加黑白噪点发生概率为0.2的’椒盐噪声’</p>\n<pre><code class=\"matlab\">&gt;&gt; fn = imnoise(f, &#39;salt &amp; pepper&#39;, 0.2)</code></pre>\n<p>对带噪图像进行中值滤波处理</p>\n<pre><code class=\"matlab\">&gt;&gt; gm = medfilt2(fn)</code></pre>\n<p>注意，在这里出现了错误，==A应为二维==<br><img src=\"https://i.loli.net/2019/07/17/5d2ed759e608448713.jpg\" alt></p>\n<p>原因:中值滤波medfilt2,输入的图像应为二维矩阵，实际输入的为imread读取的图像加上噪声，通常是三维RGB图，是三维矩阵<br>解决办法:先用rgb2gray(f)将图像转换为灰度矩阵图像</p>\n<pre><code class=\"matlab\">&gt;&gt; fn2 = rgb2gray(fn);\n&gt;&gt; gm = medfilt2(fn2);\n&gt;&gt; imshow(gm);</code></pre>\n<p>减弱外圈黑点</p>\n<pre><code class=\"matlab\">&gt;&gt; gms = medfilt2(fn2, &#39;symmetric&#39;);</code></pre>\n</li>\n</ul>\n<p><img src=\"https://i.loli.net/2019/07/17/5d2ed7776b71a55041.jpg\" alt></p>\n"},{"title":"Day08","date":"2019-07-22T05:48:33.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"# 形态学图像处理\n从这里开始过渡，从输入输出都是图像，过渡到图像分析方法，输出以某种方法来描述图像的内容。\n## 集合理论基础\n令Z为整数集合，用于产生的数字图像的抽样处理可以看做是把xy平面分割成网格状，其中每个网格的**中心坐标**是来自笛卡尔积$Z^2$中的一对元素。在集合理论中，如果(x,y)是来自$Z^2$的整数,f是分配给每个不同坐标的对(x,y)的亮度值的映射，那么函数f(x,y)被成为数字图像。如果亮度值也为整数，那么这幅图像就变成了二维图像。   \n集合的基本操作:$\\in$,$\\notin$,$\\cup$,$\\cap$,+,-.除了这些基本操作，形态学操作还需要两个算子，他们特别针对元素均为像素坐标的集合\n1. 集合的反射$\\hat{B}$\n$$ \\hat{B} = \\{w|w=-b,b\\in B\\}$$\n2. 点z=($z_1$,$z_2$)集合的平移${(A)}_z$\n$$ (A)_z = \\{c|c=a+z,a\\in A\\}$$\n### 二值图像、集合及逻辑算子\n形态学理论把二值图像看成是前景(1值)像素的集合,集合的元素属于$Z^2$如果A和B都是二值图像，那么$C=A\\cup B$也是二值图像\n$$C(x,y)=\\begin{cases}\n1,\\quad A(x,y)或B(x,y)为1,或者两者均为1\\\\\n0 \\quad 其他\n\\end{cases}\n$$\n### 在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\n\n| 集合运算  | 二值图像的MATLAb语句 | 名称 |\n| -----     | :--------:           | ---  |\n| $A\\cap B$ | A & B                | 与   |\n| $A\\cup B$ | A $\\rvert$ B         | 或   |\n| $A^c$     | ~B                   | 非   |\n| $A-B$     | A &~ B               | 差   |\n\n## 腐蚀和膨胀\n### 膨胀\n膨胀是使图像中的目标\"生长\"或\"变粗\"的操作。程度由一种被称为**结构元**的形状来控制\nA被B膨胀，表示为$A \\oplus B$,作为集合操作\n$$ A\\oplus B=\\{ z|\\hat{B}_z\\cap A\\not= \\emptyset\\}$$\n约定: $A \\oplus B$ 的第一个操作数是图像，第二个操作数是结构元，结构元通常比图像小的多。\n![](https://i.loli.net/2019/07/22/5d35670a79cd611294.jpg)\n  - 工具箱函数imdilate(A, B)来执行膨胀\n```\nf = imread('1111.jpg');\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nD = imdilate(f, B);\nsubplot(1,2,1),imshow(f);\ntitle('原图')\nsubplot(1,2,2),imshow(D);\ntitle('膨胀后的图')\n```\n![](https://i.loli.net/2019/07/22/5d3564132fa1741100.jpg)\n### 腐蚀\n腐蚀\"收缩\"或\"细化\"二值图像中的物体。像膨胀一样，收缩的方法和程度由结构元控制。\nA被B腐蚀表示为$A\\ominus B$,定义为:\n$$ A\\ominus B = \\{z| (B)_z\\subseteq A\\} = \\{z| (B)_z\\cap A^c = \\emptyset\\}$$\n![](https://i.loli.net/2019/07/23/5d36cefa2813d95731.jpg)\n\n工具箱函数imerode(A,B)来执腐蚀\n```\nf = imread('tig.jpg');\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nR = imerode(f, B);\nsubplot(1,2,1),imshow(f);\ntitle('原图')\nsubplot(1,2,2),imshow(R);\ntitle('腐蚀后的图')\n```\n![](https://i.loli.net/2019/07/22/5d356b5f7eed962952.jpg)\n### 结构元\nstrel函数，用来构造各种大小和形状的结构元\n```\nse = strel(shape, parameters);\n```\nshape是希望形状的字符串，parameters是描述形状信息的参数列表\n![](https://i.loli.net/2019/07/22/5d35670a85b4f22579.jpg)\n![](https://i.loli.net/2019/07/22/5d35670a63e2817742.jpg)\n注意生成的se含有两项\n1. se.Neighborhood:[ ×  logical ]\n2. se.Demensionality: 2\n\n\n\n\n","source":"_posts/Day08.md","raw":"---\ntitle: Day08\ndate: 2019-07-22 13:48:33\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n# 形态学图像处理\n从这里开始过渡，从输入输出都是图像，过渡到图像分析方法，输出以某种方法来描述图像的内容。\n## 集合理论基础\n令Z为整数集合，用于产生的数字图像的抽样处理可以看做是把xy平面分割成网格状，其中每个网格的**中心坐标**是来自笛卡尔积$Z^2$中的一对元素。在集合理论中，如果(x,y)是来自$Z^2$的整数,f是分配给每个不同坐标的对(x,y)的亮度值的映射，那么函数f(x,y)被成为数字图像。如果亮度值也为整数，那么这幅图像就变成了二维图像。   \n集合的基本操作:$\\in$,$\\notin$,$\\cup$,$\\cap$,+,-.除了这些基本操作，形态学操作还需要两个算子，他们特别针对元素均为像素坐标的集合\n1. 集合的反射$\\hat{B}$\n$$ \\hat{B} = \\{w|w=-b,b\\in B\\}$$\n2. 点z=($z_1$,$z_2$)集合的平移${(A)}_z$\n$$ (A)_z = \\{c|c=a+z,a\\in A\\}$$\n### 二值图像、集合及逻辑算子\n形态学理论把二值图像看成是前景(1值)像素的集合,集合的元素属于$Z^2$如果A和B都是二值图像，那么$C=A\\cup B$也是二值图像\n$$C(x,y)=\\begin{cases}\n1,\\quad A(x,y)或B(x,y)为1,或者两者均为1\\\\\n0 \\quad 其他\n\\end{cases}\n$$\n### 在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\n\n| 集合运算  | 二值图像的MATLAb语句 | 名称 |\n| -----     | :--------:           | ---  |\n| $A\\cap B$ | A & B                | 与   |\n| $A\\cup B$ | A $\\rvert$ B         | 或   |\n| $A^c$     | ~B                   | 非   |\n| $A-B$     | A &~ B               | 差   |\n\n## 腐蚀和膨胀\n### 膨胀\n膨胀是使图像中的目标\"生长\"或\"变粗\"的操作。程度由一种被称为**结构元**的形状来控制\nA被B膨胀，表示为$A \\oplus B$,作为集合操作\n$$ A\\oplus B=\\{ z|\\hat{B}_z\\cap A\\not= \\emptyset\\}$$\n约定: $A \\oplus B$ 的第一个操作数是图像，第二个操作数是结构元，结构元通常比图像小的多。\n![](https://i.loli.net/2019/07/22/5d35670a79cd611294.jpg)\n  - 工具箱函数imdilate(A, B)来执行膨胀\n```\nf = imread('1111.jpg');\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nD = imdilate(f, B);\nsubplot(1,2,1),imshow(f);\ntitle('原图')\nsubplot(1,2,2),imshow(D);\ntitle('膨胀后的图')\n```\n![](https://i.loli.net/2019/07/22/5d3564132fa1741100.jpg)\n### 腐蚀\n腐蚀\"收缩\"或\"细化\"二值图像中的物体。像膨胀一样，收缩的方法和程度由结构元控制。\nA被B腐蚀表示为$A\\ominus B$,定义为:\n$$ A\\ominus B = \\{z| (B)_z\\subseteq A\\} = \\{z| (B)_z\\cap A^c = \\emptyset\\}$$\n![](https://i.loli.net/2019/07/23/5d36cefa2813d95731.jpg)\n\n工具箱函数imerode(A,B)来执腐蚀\n```\nf = imread('tig.jpg');\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nR = imerode(f, B);\nsubplot(1,2,1),imshow(f);\ntitle('原图')\nsubplot(1,2,2),imshow(R);\ntitle('腐蚀后的图')\n```\n![](https://i.loli.net/2019/07/22/5d356b5f7eed962952.jpg)\n### 结构元\nstrel函数，用来构造各种大小和形状的结构元\n```\nse = strel(shape, parameters);\n```\nshape是希望形状的字符串，parameters是描述形状信息的参数列表\n![](https://i.loli.net/2019/07/22/5d35670a85b4f22579.jpg)\n![](https://i.loli.net/2019/07/22/5d35670a63e2817742.jpg)\n注意生成的se含有两项\n1. se.Neighborhood:[ ×  logical ]\n2. se.Demensionality: 2\n\n\n\n\n","slug":"Day08","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lt3000ce5g6q3qte1wp","content":"<h1 id=\"形态学图像处理\"><a href=\"#形态学图像处理\" class=\"headerlink\" title=\"形态学图像处理\"></a>形态学图像处理</h1><p>从这里开始过渡，从输入输出都是图像，过渡到图像分析方法，输出以某种方法来描述图像的内容。</p>\n<h2 id=\"集合理论基础\"><a href=\"#集合理论基础\" class=\"headerlink\" title=\"集合理论基础\"></a>集合理论基础</h2><p>令Z为整数集合，用于产生的数字图像的抽样处理可以看做是把xy平面分割成网格状，其中每个网格的<strong>中心坐标</strong>是来自笛卡尔积$Z^2$中的一对元素。在集合理论中，如果(x,y)是来自$Z^2$的整数,f是分配给每个不同坐标的对(x,y)的亮度值的映射，那么函数f(x,y)被成为数字图像。如果亮度值也为整数，那么这幅图像就变成了二维图像。<br>集合的基本操作:$\\in$,$\\notin$,$\\cup$,$\\cap$,+,-.除了这些基本操作，形态学操作还需要两个算子，他们特别针对元素均为像素坐标的集合</p>\n<ol>\n<li>集合的反射$\\hat{B}$<br>$$ \\hat{B} = \\{w|w=-b,b\\in B\\}$$</li>\n<li>点z=($z_1$,$z_2$)集合的平移${(A)}_z$<br>$$ (A)_z = \\{c|c=a+z,a\\in A\\}$$<h3 id=\"二值图像、集合及逻辑算子\"><a href=\"#二值图像、集合及逻辑算子\" class=\"headerlink\" title=\"二值图像、集合及逻辑算子\"></a>二值图像、集合及逻辑算子</h3>形态学理论把二值图像看成是前景(1值)像素的集合,集合的元素属于$Z^2$如果A和B都是二值图像，那么$C=A\\cup B$也是二值图像<br>$$C(x,y)=\\begin{cases}<br>1,\\quad A(x,y)或B(x,y)为1,或者两者均为1\\<br>0 \\quad 其他<br>\\end{cases}<br>$$<h3 id=\"在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\"><a href=\"#在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\" class=\"headerlink\" title=\"在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\"></a>在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算</h3></li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>集合运算</th>\n<th align=\"center\">二值图像的MATLAb语句</th>\n<th>名称</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>$A\\cap B$</td>\n<td align=\"center\">A &amp; B</td>\n<td>与</td>\n</tr>\n<tr>\n<td>$A\\cup B$</td>\n<td align=\"center\">A $\\rvert$ B</td>\n<td>或</td>\n</tr>\n<tr>\n<td>$A^c$</td>\n<td align=\"center\">~B</td>\n<td>非</td>\n</tr>\n<tr>\n<td>$A-B$</td>\n<td align=\"center\">A &amp;~ B</td>\n<td>差</td>\n</tr>\n</tbody></table>\n<h2 id=\"腐蚀和膨胀\"><a href=\"#腐蚀和膨胀\" class=\"headerlink\" title=\"腐蚀和膨胀\"></a>腐蚀和膨胀</h2><h3 id=\"膨胀\"><a href=\"#膨胀\" class=\"headerlink\" title=\"膨胀\"></a>膨胀</h3><p>膨胀是使图像中的目标”生长”或”变粗”的操作。程度由一种被称为<strong>结构元</strong>的形状来控制<br>A被B膨胀，表示为$A \\oplus B$,作为集合操作<br>$$ A\\oplus B=\\{ z|\\hat{B}_z\\cap A\\not= \\emptyset\\}$$<br>约定: $A \\oplus B$ 的第一个操作数是图像，第二个操作数是结构元，结构元通常比图像小的多。<br><img src=\"https://i.loli.net/2019/07/22/5d35670a79cd611294.jpg\" alt></p>\n<ul>\n<li>工具箱函数imdilate(A, B)来执行膨胀<pre><code>f = imread(&#39;1111.jpg&#39;);\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nD = imdilate(f, B);\nsubplot(1,2,1),imshow(f);\ntitle(&#39;原图&#39;)\nsubplot(1,2,2),imshow(D);\ntitle(&#39;膨胀后的图&#39;)</code></pre><img src=\"https://i.loli.net/2019/07/22/5d3564132fa1741100.jpg\" alt><h3 id=\"腐蚀\"><a href=\"#腐蚀\" class=\"headerlink\" title=\"腐蚀\"></a>腐蚀</h3>腐蚀”收缩”或”细化”二值图像中的物体。像膨胀一样，收缩的方法和程度由结构元控制。<br>A被B腐蚀表示为$A\\ominus B$,定义为:<br>$$ A\\ominus B = \\{z| (B)_z\\subseteq A\\} = \\{z| (B)_z\\cap A^c = \\emptyset\\}$$<br><img src=\"https://i.loli.net/2019/07/23/5d36cefa2813d95731.jpg\" alt></li>\n</ul>\n<p>工具箱函数imerode(A,B)来执腐蚀</p>\n<pre><code>f = imread(&#39;tig.jpg&#39;);\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nR = imerode(f, B);\nsubplot(1,2,1),imshow(f);\ntitle(&#39;原图&#39;)\nsubplot(1,2,2),imshow(R);\ntitle(&#39;腐蚀后的图&#39;)</code></pre><p><img src=\"https://i.loli.net/2019/07/22/5d356b5f7eed962952.jpg\" alt></p>\n<h3 id=\"结构元\"><a href=\"#结构元\" class=\"headerlink\" title=\"结构元\"></a>结构元</h3><p>strel函数，用来构造各种大小和形状的结构元</p>\n<pre><code>se = strel(shape, parameters);</code></pre><p>shape是希望形状的字符串，parameters是描述形状信息的参数列表<br><img src=\"https://i.loli.net/2019/07/22/5d35670a85b4f22579.jpg\" alt><br><img src=\"https://i.loli.net/2019/07/22/5d35670a63e2817742.jpg\" alt><br>注意生成的se含有两项</p>\n<ol>\n<li>se.Neighborhood:[ ×  logical ]</li>\n<li>se.Demensionality: 2</li>\n</ol>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"形态学图像处理\"><a href=\"#形态学图像处理\" class=\"headerlink\" title=\"形态学图像处理\"></a>形态学图像处理</h1><p>从这里开始过渡，从输入输出都是图像，过渡到图像分析方法，输出以某种方法来描述图像的内容。</p>\n<h2 id=\"集合理论基础\"><a href=\"#集合理论基础\" class=\"headerlink\" title=\"集合理论基础\"></a>集合理论基础</h2><p>令Z为整数集合，用于产生的数字图像的抽样处理可以看做是把xy平面分割成网格状，其中每个网格的<strong>中心坐标</strong>是来自笛卡尔积$Z^2$中的一对元素。在集合理论中，如果(x,y)是来自$Z^2$的整数,f是分配给每个不同坐标的对(x,y)的亮度值的映射，那么函数f(x,y)被成为数字图像。如果亮度值也为整数，那么这幅图像就变成了二维图像。<br>集合的基本操作:$\\in$,$\\notin$,$\\cup$,$\\cap$,+,-.除了这些基本操作，形态学操作还需要两个算子，他们特别针对元素均为像素坐标的集合</p>\n<ol>\n<li>集合的反射$\\hat{B}$<br>$$ \\hat{B} = \\{w|w=-b,b\\in B\\}$$</li>\n<li>点z=($z_1$,$z_2$)集合的平移${(A)}_z$<br>$$ (A)_z = \\{c|c=a+z,a\\in A\\}$$<h3 id=\"二值图像、集合及逻辑算子\"><a href=\"#二值图像、集合及逻辑算子\" class=\"headerlink\" title=\"二值图像、集合及逻辑算子\"></a>二值图像、集合及逻辑算子</h3>形态学理论把二值图像看成是前景(1值)像素的集合,集合的元素属于$Z^2$如果A和B都是二值图像，那么$C=A\\cup B$也是二值图像<br>$$C(x,y)=\\begin{cases}<br>1,\\quad A(x,y)或B(x,y)为1,或者两者均为1\\<br>0 \\quad 其他<br>\\end{cases}<br>$$<h3 id=\"在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\"><a href=\"#在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\" class=\"headerlink\" title=\"在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算\"></a>在MATLAB中使用逻辑表达式在二值图像上进行逻辑运算</h3></li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>集合运算</th>\n<th align=\"center\">二值图像的MATLAb语句</th>\n<th>名称</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>$A\\cap B$</td>\n<td align=\"center\">A &amp; B</td>\n<td>与</td>\n</tr>\n<tr>\n<td>$A\\cup B$</td>\n<td align=\"center\">A $\\rvert$ B</td>\n<td>或</td>\n</tr>\n<tr>\n<td>$A^c$</td>\n<td align=\"center\">~B</td>\n<td>非</td>\n</tr>\n<tr>\n<td>$A-B$</td>\n<td align=\"center\">A &amp;~ B</td>\n<td>差</td>\n</tr>\n</tbody></table>\n<h2 id=\"腐蚀和膨胀\"><a href=\"#腐蚀和膨胀\" class=\"headerlink\" title=\"腐蚀和膨胀\"></a>腐蚀和膨胀</h2><h3 id=\"膨胀\"><a href=\"#膨胀\" class=\"headerlink\" title=\"膨胀\"></a>膨胀</h3><p>膨胀是使图像中的目标”生长”或”变粗”的操作。程度由一种被称为<strong>结构元</strong>的形状来控制<br>A被B膨胀，表示为$A \\oplus B$,作为集合操作<br>$$ A\\oplus B=\\{ z|\\hat{B}_z\\cap A\\not= \\emptyset\\}$$<br>约定: $A \\oplus B$ 的第一个操作数是图像，第二个操作数是结构元，结构元通常比图像小的多。<br><img src=\"https://i.loli.net/2019/07/22/5d35670a79cd611294.jpg\" alt></p>\n<ul>\n<li>工具箱函数imdilate(A, B)来执行膨胀<pre><code>f = imread(&#39;1111.jpg&#39;);\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nD = imdilate(f, B);\nsubplot(1,2,1),imshow(f);\ntitle(&#39;原图&#39;)\nsubplot(1,2,2),imshow(D);\ntitle(&#39;膨胀后的图&#39;)</code></pre><img src=\"https://i.loli.net/2019/07/22/5d3564132fa1741100.jpg\" alt><h3 id=\"腐蚀\"><a href=\"#腐蚀\" class=\"headerlink\" title=\"腐蚀\"></a>腐蚀</h3>腐蚀”收缩”或”细化”二值图像中的物体。像膨胀一样，收缩的方法和程度由结构元控制。<br>A被B腐蚀表示为$A\\ominus B$,定义为:<br>$$ A\\ominus B = \\{z| (B)_z\\subseteq A\\} = \\{z| (B)_z\\cap A^c = \\emptyset\\}$$<br><img src=\"https://i.loli.net/2019/07/23/5d36cefa2813d95731.jpg\" alt></li>\n</ul>\n<p>工具箱函数imerode(A,B)来执腐蚀</p>\n<pre><code>f = imread(&#39;tig.jpg&#39;);\nB = [0 1 0; 1 1 1; 0 1 0];%自定义结构元\nR = imerode(f, B);\nsubplot(1,2,1),imshow(f);\ntitle(&#39;原图&#39;)\nsubplot(1,2,2),imshow(R);\ntitle(&#39;腐蚀后的图&#39;)</code></pre><p><img src=\"https://i.loli.net/2019/07/22/5d356b5f7eed962952.jpg\" alt></p>\n<h3 id=\"结构元\"><a href=\"#结构元\" class=\"headerlink\" title=\"结构元\"></a>结构元</h3><p>strel函数，用来构造各种大小和形状的结构元</p>\n<pre><code>se = strel(shape, parameters);</code></pre><p>shape是希望形状的字符串，parameters是描述形状信息的参数列表<br><img src=\"https://i.loli.net/2019/07/22/5d35670a85b4f22579.jpg\" alt><br><img src=\"https://i.loli.net/2019/07/22/5d35670a63e2817742.jpg\" alt><br>注意生成的se含有两项</p>\n<ol>\n<li>se.Neighborhood:[ ×  logical ]</li>\n<li>se.Demensionality: 2</li>\n</ol>\n"},{"title":"Day07","date":"2019-07-21T06:47:14.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n## 使用频率域滤波器锐化图像\n---\n### 高通滤波器\n图像的锐化可以在频率与通过高通滤波器来实现\n一个高通滤波器可以由一个低通滤波器来实现:\n$$H_{HP}(u,v)=1-H_{LP}(u,v)$$\n被低通滤波器衰减的频率可以通过高通滤波器\n#### 理想高通滤波器\n二维理想高通滤波器可以定义为\n$$ H(u,v)=\\begin{cases}\n1,\\quad D(u,v)\\leq D_0\\\\\n0,\\quad D(u,v)>D_0\n\\end{cases}\n$$\n![](https://i.loli.net/2019/07/21/5d341bf1c410443073.jpg)\n#### 布特沃斯高通滤波器\n截止频率为$D_0$的n阶布特沃斯高通滤波器(BHPF)的定义为:\n$$ H(u,v)=\\frac{1}{1+[D_0/D(u,v)]^{2n}}$$\n![](https://i.loli.net/2019/07/21/5d341bf1c376281237.jpg)\n#### 高斯高通滤波器\n截止频率处在距频率矩形中心距离为$D_0$的高斯高通滤波器(GHPF)的传递函数如下:\n$$H(u,v)=1-e^{-D^2(u,v)/2D_0^2}$$\n![](https://i.loli.net/2019/07/21/5d341bf1c3f7954220.jpg)\n#### 在MATLAB中使用高通滤波器来锐化图像\n使用高通滤波器来锐化图像，与平滑图像类似，只是将低通滤波器换成了高通滤波器，具体步骤不再赘述\n```\nf = imread('1.jpg');\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(1);\nF = fft2(f, PQ(1), PQ(2));\nH = hpfilter('gaussian',PQ(1), PQ(2), D0);\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure(1)\nsubplot(2,2,1);\nimshow(f,[]);\ntitle('原图像')\nsubplot(2,2,2);\nimshow(fftshift(H));\ntitle('高斯高通滤波器');\nsubplot(2,2,3);\nimshow(log(1 + abs(fftshift(F))), [])\ntitle('滤波后图像谱');\nsubplot(2,2,4);\nimshow(g);\ntitle('滤波后图像');\n```\n同样这里需要的是高通滤波函数hpfilter()\n```\nfunction [H] = hpfilter(type,M,N,D0,n)\n%HPFILTER Computes freq. domain highpass filters\n%\t\tTHIS IS NOT A STANDARD MATLAB FUNCTION\n%\t\tH = hpfilter (type,M,N,D0,n) creates the\n%\t\ttransfer function of a highpass filter, H, of\n%\t\tthe specified type and size MxN. Possible\n%\t\tvalues for type, D0, and n are:\n%\n%\t\t'ideal'\t\t\t\tIdeal highpass filter with\n%\t\t\t\t\t\tcutoff frequency D0. If\n%\t\t\t\t\t\tsupplied, n is ignored.\n%\t\t'btw'\t\t\t\tButterworth highpass filter\n%\t\t\t\t\t\tof order n, and cutoff D0.\n%\t\t'gaussn'\t\t\tGaussian highpass filter with\n%\t\t\t\t\t\tcutoff (standard deviation)D0.\n%\t\t\t\t\t\tIf supplied, n is ignored.\n%\t\tM and N should be even numbers for DFT\n%\t\tfiltering.\n%\n%\t\tClass support: double, uint8, uint16\n%\t\tThe output is of class double\n\n%       The transfer function Hhp of a highpass filter\n%       is 1 - Hlp, where Hlp is the transfer function of\n%       the corresponding lowpass filter.  Thus, we can\n%       use function lpfilter to generate highpass filters\n\n%       If filter is btw, make sure that n is provided\n%       Otherwise, pass n=1 as an arbitrary value to\n%       prevent error message\n\nif nargin == 4\n    n = 1; %default value of n\nend\n\nHlp = lpfilter(type,M,N,D0,n);\nH = 1 - Hlp;\n\n%       End of function\n```\n锐化结果:\n1. IHPF\n![](https://i.loli.net/2019/07/21/5d341eae3a6b123891.jpg)\n2. BHPF\n![](https://i.loli.net/2019/07/21/5d341bf1f13e453488.jpg)\n3. GHPF\n![](https://i.loli.net/2019/07/21/5d341eae4fa8d96779.jpg)\n\n\n","source":"_posts/Day07.md","raw":"---\ntitle: Day07\ndate: 2019-07-21 14:47:14\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n## 使用频率域滤波器锐化图像\n---\n### 高通滤波器\n图像的锐化可以在频率与通过高通滤波器来实现\n一个高通滤波器可以由一个低通滤波器来实现:\n$$H_{HP}(u,v)=1-H_{LP}(u,v)$$\n被低通滤波器衰减的频率可以通过高通滤波器\n#### 理想高通滤波器\n二维理想高通滤波器可以定义为\n$$ H(u,v)=\\begin{cases}\n1,\\quad D(u,v)\\leq D_0\\\\\n0,\\quad D(u,v)>D_0\n\\end{cases}\n$$\n![](https://i.loli.net/2019/07/21/5d341bf1c410443073.jpg)\n#### 布特沃斯高通滤波器\n截止频率为$D_0$的n阶布特沃斯高通滤波器(BHPF)的定义为:\n$$ H(u,v)=\\frac{1}{1+[D_0/D(u,v)]^{2n}}$$\n![](https://i.loli.net/2019/07/21/5d341bf1c376281237.jpg)\n#### 高斯高通滤波器\n截止频率处在距频率矩形中心距离为$D_0$的高斯高通滤波器(GHPF)的传递函数如下:\n$$H(u,v)=1-e^{-D^2(u,v)/2D_0^2}$$\n![](https://i.loli.net/2019/07/21/5d341bf1c3f7954220.jpg)\n#### 在MATLAB中使用高通滤波器来锐化图像\n使用高通滤波器来锐化图像，与平滑图像类似，只是将低通滤波器换成了高通滤波器，具体步骤不再赘述\n```\nf = imread('1.jpg');\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(1);\nF = fft2(f, PQ(1), PQ(2));\nH = hpfilter('gaussian',PQ(1), PQ(2), D0);\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure(1)\nsubplot(2,2,1);\nimshow(f,[]);\ntitle('原图像')\nsubplot(2,2,2);\nimshow(fftshift(H));\ntitle('高斯高通滤波器');\nsubplot(2,2,3);\nimshow(log(1 + abs(fftshift(F))), [])\ntitle('滤波后图像谱');\nsubplot(2,2,4);\nimshow(g);\ntitle('滤波后图像');\n```\n同样这里需要的是高通滤波函数hpfilter()\n```\nfunction [H] = hpfilter(type,M,N,D0,n)\n%HPFILTER Computes freq. domain highpass filters\n%\t\tTHIS IS NOT A STANDARD MATLAB FUNCTION\n%\t\tH = hpfilter (type,M,N,D0,n) creates the\n%\t\ttransfer function of a highpass filter, H, of\n%\t\tthe specified type and size MxN. Possible\n%\t\tvalues for type, D0, and n are:\n%\n%\t\t'ideal'\t\t\t\tIdeal highpass filter with\n%\t\t\t\t\t\tcutoff frequency D0. If\n%\t\t\t\t\t\tsupplied, n is ignored.\n%\t\t'btw'\t\t\t\tButterworth highpass filter\n%\t\t\t\t\t\tof order n, and cutoff D0.\n%\t\t'gaussn'\t\t\tGaussian highpass filter with\n%\t\t\t\t\t\tcutoff (standard deviation)D0.\n%\t\t\t\t\t\tIf supplied, n is ignored.\n%\t\tM and N should be even numbers for DFT\n%\t\tfiltering.\n%\n%\t\tClass support: double, uint8, uint16\n%\t\tThe output is of class double\n\n%       The transfer function Hhp of a highpass filter\n%       is 1 - Hlp, where Hlp is the transfer function of\n%       the corresponding lowpass filter.  Thus, we can\n%       use function lpfilter to generate highpass filters\n\n%       If filter is btw, make sure that n is provided\n%       Otherwise, pass n=1 as an arbitrary value to\n%       prevent error message\n\nif nargin == 4\n    n = 1; %default value of n\nend\n\nHlp = lpfilter(type,M,N,D0,n);\nH = 1 - Hlp;\n\n%       End of function\n```\n锐化结果:\n1. IHPF\n![](https://i.loli.net/2019/07/21/5d341eae3a6b123891.jpg)\n2. BHPF\n![](https://i.loli.net/2019/07/21/5d341bf1f13e453488.jpg)\n3. GHPF\n![](https://i.loli.net/2019/07/21/5d341eae4fa8d96779.jpg)\n\n\n","slug":"Day07","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lt5000fe5g6gbq5ofue","content":"<h2 id=\"使用频率域滤波器锐化图像\"><a href=\"#使用频率域滤波器锐化图像\" class=\"headerlink\" title=\"使用频率域滤波器锐化图像\"></a>使用频率域滤波器锐化图像</h2><hr>\n<h3 id=\"高通滤波器\"><a href=\"#高通滤波器\" class=\"headerlink\" title=\"高通滤波器\"></a>高通滤波器</h3><p>图像的锐化可以在频率与通过高通滤波器来实现<br>一个高通滤波器可以由一个低通滤波器来实现:<br>$$H_{HP}(u,v)=1-H_{LP}(u,v)$$<br>被低通滤波器衰减的频率可以通过高通滤波器</p>\n<h4 id=\"理想高通滤波器\"><a href=\"#理想高通滤波器\" class=\"headerlink\" title=\"理想高通滤波器\"></a>理想高通滤波器</h4><p>二维理想高通滤波器可以定义为<br>$$ H(u,v)=\\begin{cases}<br>1,\\quad D(u,v)\\leq D_0\\<br>0,\\quad D(u,v)&gt;D_0<br>\\end{cases}<br>$$<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1c410443073.jpg\" alt></p>\n<h4 id=\"布特沃斯高通滤波器\"><a href=\"#布特沃斯高通滤波器\" class=\"headerlink\" title=\"布特沃斯高通滤波器\"></a>布特沃斯高通滤波器</h4><p>截止频率为$D_0$的n阶布特沃斯高通滤波器(BHPF)的定义为:<br>$$ H(u,v)=\\frac{1}{1+[D_0/D(u,v)]^{2n}}$$<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1c376281237.jpg\" alt></p>\n<h4 id=\"高斯高通滤波器\"><a href=\"#高斯高通滤波器\" class=\"headerlink\" title=\"高斯高通滤波器\"></a>高斯高通滤波器</h4><p>截止频率处在距频率矩形中心距离为$D_0$的高斯高通滤波器(GHPF)的传递函数如下:<br>$$H(u,v)=1-e^{-D^2(u,v)/2D_0^2}$$<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1c3f7954220.jpg\" alt></p>\n<h4 id=\"在MATLAB中使用高通滤波器来锐化图像\"><a href=\"#在MATLAB中使用高通滤波器来锐化图像\" class=\"headerlink\" title=\"在MATLAB中使用高通滤波器来锐化图像\"></a>在MATLAB中使用高通滤波器来锐化图像</h4><p>使用高通滤波器来锐化图像，与平滑图像类似，只是将低通滤波器换成了高通滤波器，具体步骤不再赘述</p>\n<pre><code>f = imread(&#39;1.jpg&#39;);\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(1);\nF = fft2(f, PQ(1), PQ(2));\nH = hpfilter(&#39;gaussian&#39;,PQ(1), PQ(2), D0);\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure(1)\nsubplot(2,2,1);\nimshow(f,[]);\ntitle(&#39;原图像&#39;)\nsubplot(2,2,2);\nimshow(fftshift(H));\ntitle(&#39;高斯高通滤波器&#39;);\nsubplot(2,2,3);\nimshow(log(1 + abs(fftshift(F))), [])\ntitle(&#39;滤波后图像谱&#39;);\nsubplot(2,2,4);\nimshow(g);\ntitle(&#39;滤波后图像&#39;);</code></pre><p>同样这里需要的是高通滤波函数hpfilter()</p>\n<pre><code>function [H] = hpfilter(type,M,N,D0,n)\n%HPFILTER Computes freq. domain highpass filters\n%        THIS IS NOT A STANDARD MATLAB FUNCTION\n%        H = hpfilter (type,M,N,D0,n) creates the\n%        transfer function of a highpass filter, H, of\n%        the specified type and size MxN. Possible\n%        values for type, D0, and n are:\n%\n%        &#39;ideal&#39;                Ideal highpass filter with\n%                        cutoff frequency D0. If\n%                        supplied, n is ignored.\n%        &#39;btw&#39;                Butterworth highpass filter\n%                        of order n, and cutoff D0.\n%        &#39;gaussn&#39;            Gaussian highpass filter with\n%                        cutoff (standard deviation)D0.\n%                        If supplied, n is ignored.\n%        M and N should be even numbers for DFT\n%        filtering.\n%\n%        Class support: double, uint8, uint16\n%        The output is of class double\n\n%       The transfer function Hhp of a highpass filter\n%       is 1 - Hlp, where Hlp is the transfer function of\n%       the corresponding lowpass filter.  Thus, we can\n%       use function lpfilter to generate highpass filters\n\n%       If filter is btw, make sure that n is provided\n%       Otherwise, pass n=1 as an arbitrary value to\n%       prevent error message\n\nif nargin == 4\n    n = 1; %default value of n\nend\n\nHlp = lpfilter(type,M,N,D0,n);\nH = 1 - Hlp;\n\n%       End of function</code></pre><p>锐化结果:</p>\n<ol>\n<li>IHPF<br><img src=\"https://i.loli.net/2019/07/21/5d341eae3a6b123891.jpg\" alt></li>\n<li>BHPF<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f13e453488.jpg\" alt></li>\n<li>GHPF<br><img src=\"https://i.loli.net/2019/07/21/5d341eae4fa8d96779.jpg\" alt></li>\n</ol>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"使用频率域滤波器锐化图像\"><a href=\"#使用频率域滤波器锐化图像\" class=\"headerlink\" title=\"使用频率域滤波器锐化图像\"></a>使用频率域滤波器锐化图像</h2><hr>\n<h3 id=\"高通滤波器\"><a href=\"#高通滤波器\" class=\"headerlink\" title=\"高通滤波器\"></a>高通滤波器</h3><p>图像的锐化可以在频率与通过高通滤波器来实现<br>一个高通滤波器可以由一个低通滤波器来实现:<br>$$H_{HP}(u,v)=1-H_{LP}(u,v)$$<br>被低通滤波器衰减的频率可以通过高通滤波器</p>\n<h4 id=\"理想高通滤波器\"><a href=\"#理想高通滤波器\" class=\"headerlink\" title=\"理想高通滤波器\"></a>理想高通滤波器</h4><p>二维理想高通滤波器可以定义为<br>$$ H(u,v)=\\begin{cases}<br>1,\\quad D(u,v)\\leq D_0\\<br>0,\\quad D(u,v)&gt;D_0<br>\\end{cases}<br>$$<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1c410443073.jpg\" alt></p>\n<h4 id=\"布特沃斯高通滤波器\"><a href=\"#布特沃斯高通滤波器\" class=\"headerlink\" title=\"布特沃斯高通滤波器\"></a>布特沃斯高通滤波器</h4><p>截止频率为$D_0$的n阶布特沃斯高通滤波器(BHPF)的定义为:<br>$$ H(u,v)=\\frac{1}{1+[D_0/D(u,v)]^{2n}}$$<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1c376281237.jpg\" alt></p>\n<h4 id=\"高斯高通滤波器\"><a href=\"#高斯高通滤波器\" class=\"headerlink\" title=\"高斯高通滤波器\"></a>高斯高通滤波器</h4><p>截止频率处在距频率矩形中心距离为$D_0$的高斯高通滤波器(GHPF)的传递函数如下:<br>$$H(u,v)=1-e^{-D^2(u,v)/2D_0^2}$$<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1c3f7954220.jpg\" alt></p>\n<h4 id=\"在MATLAB中使用高通滤波器来锐化图像\"><a href=\"#在MATLAB中使用高通滤波器来锐化图像\" class=\"headerlink\" title=\"在MATLAB中使用高通滤波器来锐化图像\"></a>在MATLAB中使用高通滤波器来锐化图像</h4><p>使用高通滤波器来锐化图像，与平滑图像类似，只是将低通滤波器换成了高通滤波器，具体步骤不再赘述</p>\n<pre><code>f = imread(&#39;1.jpg&#39;);\nf = rgb2gray(f);\n[f, revertclass] = tofloat(f);\nPQ = paddedsize(size(f));\n[U, V] = dftuv(PQ(1), PQ(2));\nD = hypot(U, V);\nD0 = 0.05*PQ(1);\nF = fft2(f, PQ(1), PQ(2));\nH = hpfilter(&#39;gaussian&#39;,PQ(1), PQ(2), D0);\ng = dftfilt(f, H);\ng = revertclass(g);\nfigure(1)\nsubplot(2,2,1);\nimshow(f,[]);\ntitle(&#39;原图像&#39;)\nsubplot(2,2,2);\nimshow(fftshift(H));\ntitle(&#39;高斯高通滤波器&#39;);\nsubplot(2,2,3);\nimshow(log(1 + abs(fftshift(F))), [])\ntitle(&#39;滤波后图像谱&#39;);\nsubplot(2,2,4);\nimshow(g);\ntitle(&#39;滤波后图像&#39;);</code></pre><p>同样这里需要的是高通滤波函数hpfilter()</p>\n<pre><code>function [H] = hpfilter(type,M,N,D0,n)\n%HPFILTER Computes freq. domain highpass filters\n%        THIS IS NOT A STANDARD MATLAB FUNCTION\n%        H = hpfilter (type,M,N,D0,n) creates the\n%        transfer function of a highpass filter, H, of\n%        the specified type and size MxN. Possible\n%        values for type, D0, and n are:\n%\n%        &#39;ideal&#39;                Ideal highpass filter with\n%                        cutoff frequency D0. If\n%                        supplied, n is ignored.\n%        &#39;btw&#39;                Butterworth highpass filter\n%                        of order n, and cutoff D0.\n%        &#39;gaussn&#39;            Gaussian highpass filter with\n%                        cutoff (standard deviation)D0.\n%                        If supplied, n is ignored.\n%        M and N should be even numbers for DFT\n%        filtering.\n%\n%        Class support: double, uint8, uint16\n%        The output is of class double\n\n%       The transfer function Hhp of a highpass filter\n%       is 1 - Hlp, where Hlp is the transfer function of\n%       the corresponding lowpass filter.  Thus, we can\n%       use function lpfilter to generate highpass filters\n\n%       If filter is btw, make sure that n is provided\n%       Otherwise, pass n=1 as an arbitrary value to\n%       prevent error message\n\nif nargin == 4\n    n = 1; %default value of n\nend\n\nHlp = lpfilter(type,M,N,D0,n);\nH = 1 - Hlp;\n\n%       End of function</code></pre><p>锐化结果:</p>\n<ol>\n<li>IHPF<br><img src=\"https://i.loli.net/2019/07/21/5d341eae3a6b123891.jpg\" alt></li>\n<li>BHPF<br><img src=\"https://i.loli.net/2019/07/21/5d341bf1f13e453488.jpg\" alt></li>\n<li>GHPF<br><img src=\"https://i.loli.net/2019/07/21/5d341eae4fa8d96779.jpg\" alt></li>\n</ol>\n"},{"title":"Day09","date":"2019-07-23T02:02:38.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"# 图像分割\n---\n> 整体等于部分之和    \n>                 -----欧几里德\n\n---\n图像分割把图像细分为它的组成要素或物体，细分的水平取决于要解决的问题。    \n单色分割的分割算法通常是基于图像亮度值的两个基本特征:不连续性和相似性。第一类，方法是基于亮度的突变来分割一幅图像，比如边缘;第二类，主要方法是根据事先定义好的准则把图像分割成相似的区域\n\n## 点、线和边缘检测\n\n### 背景知识\n1. 边缘像素是图像中灰度突变的像素，边缘是连接的边缘像素的集合\n2. 一条线可以视为一条边缘线段，该线段两侧的背景灰度要么远亮于该线像素的灰度，要么远暗于该线像素的灰度。孤立点可视为一条线，只是长度和宽度都是一个像素\n3. 局部变化检测可以用微分(一阶微分和二阶微分)    \n   - 对于一阶导数的任何近似，约定:\n      - 在恒定灰度区域必须为0\n      - 在灰度台阶和或斜坡开始处必须不为0\n      - 在沿灰度斜坡点处也必须不为0\n   - 类似的对于二阶导数的近似\n      - 在恒定灰度区域必须为0\n      - 在灰度台阶或斜坡开始除和结束处必须不为0\n      - 沿灰度斜坡必须为0\n   - 一维函数展开为关于x的泰勒级数,结果差分\n   $$ \\frac{\\partial f}{\\partial x}=f'(x)=f(x+1)-f(x)$$\n    二阶导数\n    $$ \\frac{\\partial ^2 f}{\\partial ^2 x}=f''(x)=f(x+1)+f(x-1)-2f(x)$$\n    - 可以得出结论:\n      - 一阶导数通常在图像中产生较粗的边缘\n      - 二阶导数对精细细节，如细线、孤立点和噪声有较强的响应\n      - 二阶导数在灰度斜坡和灰度台阶过渡处会产生双边缘响应\n      - 二阶导数的符号可用于确定边缘的过程是从亮到暗还是从暗到亮\n    - 计算图像中每个像素位置的一阶导数和二阶导数的可选择方法是空间滤波器。模板在该区域中心点处的响应为\n    $$R = w_1z_1 + w_2z_2 + ... + w_9z_9 = \\sum_{k=1}^{9}w_kz_k$$\n\n$w_1$ | $w_2$ | $w_3$\n:---: | :---: | :---:\n$w_4$ | $w_5$ | $w_6$\n$w_7$ | $w_8$ | $w_9$\n\n这是一个普通的3×3空间滤波器掩模\n\n### 孤立点检测\n- 点的检测应以二阶导数为基础，这意味着使用laplace\n$$\\triangledown ^2f(x,y) = \\frac{\\partial ^2 f}{\\partial x^2} + \\frac{\\partial ^2 f}{\\partial y^2}$$\n偏微分之后可求得laplace为\n$$\\triangledown ^2f(x,y) = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$\n点检测laplace模板\n\n1 | 1 | 1\n:---:  | :---: | :---:\n1 | -8 | 1\n1 | 1 | 1\n\n\n如果在某点处的该模板的响应的绝对值超过了一个指定的阈值，那么就说在模板中心位置(x,y)处的该点已经被检测到。在输出图像中，这样的点被标注为1,所有其他点被标注为0\n$$g(x,y)=\\begin{cases}\n1,\\quad |R(x,y)| \\geqq T\\\\\n0, \\quad 其他\n\\end{cases}\n$$\n- MATLAB实现\n\n```\nf = imread('moon.jpg');\n\nf = rgb2gray(f);\n\nw = [-1 -1 -1; -1 8 -1; -1 -1 -1];\n\ng = abs(imfilter(f, w));\n\nT = max(g(:));\n\ng = g >= T;\n\nfigure(1);\n\nsubplot(1,2,1)\n\nimshow(f)\n\nsubplot(1,2,2)\n\nimshow(g)\n```\n结果：\n![](https://i.loli.net/2019/07/24/5d37b3a82234833730.jpg)\n\n### 线检测\n可以预期，二阶导数将导致更强的响应，并产生比一阶导数更细的线\n\n线检测模板\n- 水平\n\n-1 | -1 | -1\n:---:  | :---: | :---:\n2 | 2 | 2\n-1 | -1 | -1\n\n- +45度\n\n2 -| -1 | -1\n:---:  | :---: | :---:\n-1 | 2  | -1\n-1 | -1 | 2\n\n- 垂直\n\n-1 | 2 | -1\n:---:  | :---: | :---:\n-1 | 2 | -1\n-1 | 2 | -1\n\n- -45度\n\n-1 | -1 | 2\n:---:  | :---: | :---:\n-1 | 2  | -1\n2 | -1 | -1\n\n对于恒定的背景，当线通过模板的中间一行时可能产生更大的响应。    \n每个模板的系数之和为0,这表示在恒定亮度区域内，模板的响应为0.\n- MATLAB实现检测指定方向上的线\n```\nclc\n\nclear\n\n\nf = imread('11111.jpg');\n\n\nf = rgb2gray(f);\n\nfigure(1);\n\nsubplot(2,3,1)\n\nimshow(f);\n\nw = [-1, 2, -1; -1 2 -1; -1 2 -1];\n\n% g = imfilter(tofloat(f),w);\n\ng = imfilter(f,w);\n\nsubplot(2,3,2)\n\nimshow(g, [ ]);\n\ngtop = g(1:120, 1:120);\n\n% gtop = pixeldup(gtop, 4);\n\nsubplot(2,3,3)\n\nimshow(gtop, [ ]);\n\ngbot = g(end - 119:end, end - 119:end);\n\n% gbot = pixeldup(gbot, 4);\n\nsubplot(2,3,4)\n\nimshow(gbot, [ ]);\n\n\ng = abs(g);\n\nsubplot(2,3,5)\n\nimshow(g, [])\n\n\nT = max(g(:));\n\ng = g >= T;\n\nsubplot(2,3,6);\n\nimshow(g)\n\n```\n\n结果:\n![](https://i.loli.net/2019/07/24/5d37b3a815b7125153.jpg)\n可能会用到的M函数pixeldup\n```\nfunction B=pixeldup(A,m,n)%pixeldup用来重复像素的，在水平方向复制m倍，在垂直方向复制n倍，m，n必须为整数，n没有赋值默认为m%检查输入参数个数\nif nargin<2\n\terror('At least two inputs are required.');\n\tend\nif nargin==2\n\tn=m;\n\tend\nu=1:size(A,1);%产生一个向量，其向量中元素的个数为A的行数%复制向量中每个元素m次m=round(m);%防止m为非整数u=u(ones(1,m),:);\nu=u(:);%在垂直方向重复操作\nv=1:size(A,2);\nn=round(n);\nv=v(ones(1,n),:);\nv=v(:);\nB=A(u,v);\n```\n\n**慎用tofloat函数**\n\n\n","source":"_posts/Day09.md","raw":"---\ntitle: Day09\ndate: 2019-07-23 10:02:38\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n# 图像分割\n---\n> 整体等于部分之和    \n>                 -----欧几里德\n\n---\n图像分割把图像细分为它的组成要素或物体，细分的水平取决于要解决的问题。    \n单色分割的分割算法通常是基于图像亮度值的两个基本特征:不连续性和相似性。第一类，方法是基于亮度的突变来分割一幅图像，比如边缘;第二类，主要方法是根据事先定义好的准则把图像分割成相似的区域\n\n## 点、线和边缘检测\n\n### 背景知识\n1. 边缘像素是图像中灰度突变的像素，边缘是连接的边缘像素的集合\n2. 一条线可以视为一条边缘线段，该线段两侧的背景灰度要么远亮于该线像素的灰度，要么远暗于该线像素的灰度。孤立点可视为一条线，只是长度和宽度都是一个像素\n3. 局部变化检测可以用微分(一阶微分和二阶微分)    \n   - 对于一阶导数的任何近似，约定:\n      - 在恒定灰度区域必须为0\n      - 在灰度台阶和或斜坡开始处必须不为0\n      - 在沿灰度斜坡点处也必须不为0\n   - 类似的对于二阶导数的近似\n      - 在恒定灰度区域必须为0\n      - 在灰度台阶或斜坡开始除和结束处必须不为0\n      - 沿灰度斜坡必须为0\n   - 一维函数展开为关于x的泰勒级数,结果差分\n   $$ \\frac{\\partial f}{\\partial x}=f'(x)=f(x+1)-f(x)$$\n    二阶导数\n    $$ \\frac{\\partial ^2 f}{\\partial ^2 x}=f''(x)=f(x+1)+f(x-1)-2f(x)$$\n    - 可以得出结论:\n      - 一阶导数通常在图像中产生较粗的边缘\n      - 二阶导数对精细细节，如细线、孤立点和噪声有较强的响应\n      - 二阶导数在灰度斜坡和灰度台阶过渡处会产生双边缘响应\n      - 二阶导数的符号可用于确定边缘的过程是从亮到暗还是从暗到亮\n    - 计算图像中每个像素位置的一阶导数和二阶导数的可选择方法是空间滤波器。模板在该区域中心点处的响应为\n    $$R = w_1z_1 + w_2z_2 + ... + w_9z_9 = \\sum_{k=1}^{9}w_kz_k$$\n\n$w_1$ | $w_2$ | $w_3$\n:---: | :---: | :---:\n$w_4$ | $w_5$ | $w_6$\n$w_7$ | $w_8$ | $w_9$\n\n这是一个普通的3×3空间滤波器掩模\n\n### 孤立点检测\n- 点的检测应以二阶导数为基础，这意味着使用laplace\n$$\\triangledown ^2f(x,y) = \\frac{\\partial ^2 f}{\\partial x^2} + \\frac{\\partial ^2 f}{\\partial y^2}$$\n偏微分之后可求得laplace为\n$$\\triangledown ^2f(x,y) = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$\n点检测laplace模板\n\n1 | 1 | 1\n:---:  | :---: | :---:\n1 | -8 | 1\n1 | 1 | 1\n\n\n如果在某点处的该模板的响应的绝对值超过了一个指定的阈值，那么就说在模板中心位置(x,y)处的该点已经被检测到。在输出图像中，这样的点被标注为1,所有其他点被标注为0\n$$g(x,y)=\\begin{cases}\n1,\\quad |R(x,y)| \\geqq T\\\\\n0, \\quad 其他\n\\end{cases}\n$$\n- MATLAB实现\n\n```\nf = imread('moon.jpg');\n\nf = rgb2gray(f);\n\nw = [-1 -1 -1; -1 8 -1; -1 -1 -1];\n\ng = abs(imfilter(f, w));\n\nT = max(g(:));\n\ng = g >= T;\n\nfigure(1);\n\nsubplot(1,2,1)\n\nimshow(f)\n\nsubplot(1,2,2)\n\nimshow(g)\n```\n结果：\n![](https://i.loli.net/2019/07/24/5d37b3a82234833730.jpg)\n\n### 线检测\n可以预期，二阶导数将导致更强的响应，并产生比一阶导数更细的线\n\n线检测模板\n- 水平\n\n-1 | -1 | -1\n:---:  | :---: | :---:\n2 | 2 | 2\n-1 | -1 | -1\n\n- +45度\n\n2 -| -1 | -1\n:---:  | :---: | :---:\n-1 | 2  | -1\n-1 | -1 | 2\n\n- 垂直\n\n-1 | 2 | -1\n:---:  | :---: | :---:\n-1 | 2 | -1\n-1 | 2 | -1\n\n- -45度\n\n-1 | -1 | 2\n:---:  | :---: | :---:\n-1 | 2  | -1\n2 | -1 | -1\n\n对于恒定的背景，当线通过模板的中间一行时可能产生更大的响应。    \n每个模板的系数之和为0,这表示在恒定亮度区域内，模板的响应为0.\n- MATLAB实现检测指定方向上的线\n```\nclc\n\nclear\n\n\nf = imread('11111.jpg');\n\n\nf = rgb2gray(f);\n\nfigure(1);\n\nsubplot(2,3,1)\n\nimshow(f);\n\nw = [-1, 2, -1; -1 2 -1; -1 2 -1];\n\n% g = imfilter(tofloat(f),w);\n\ng = imfilter(f,w);\n\nsubplot(2,3,2)\n\nimshow(g, [ ]);\n\ngtop = g(1:120, 1:120);\n\n% gtop = pixeldup(gtop, 4);\n\nsubplot(2,3,3)\n\nimshow(gtop, [ ]);\n\ngbot = g(end - 119:end, end - 119:end);\n\n% gbot = pixeldup(gbot, 4);\n\nsubplot(2,3,4)\n\nimshow(gbot, [ ]);\n\n\ng = abs(g);\n\nsubplot(2,3,5)\n\nimshow(g, [])\n\n\nT = max(g(:));\n\ng = g >= T;\n\nsubplot(2,3,6);\n\nimshow(g)\n\n```\n\n结果:\n![](https://i.loli.net/2019/07/24/5d37b3a815b7125153.jpg)\n可能会用到的M函数pixeldup\n```\nfunction B=pixeldup(A,m,n)%pixeldup用来重复像素的，在水平方向复制m倍，在垂直方向复制n倍，m，n必须为整数，n没有赋值默认为m%检查输入参数个数\nif nargin<2\n\terror('At least two inputs are required.');\n\tend\nif nargin==2\n\tn=m;\n\tend\nu=1:size(A,1);%产生一个向量，其向量中元素的个数为A的行数%复制向量中每个元素m次m=round(m);%防止m为非整数u=u(ones(1,m),:);\nu=u(:);%在垂直方向重复操作\nv=1:size(A,2);\nn=round(n);\nv=v(ones(1,n),:);\nv=v(:);\nB=A(u,v);\n```\n\n**慎用tofloat函数**\n\n\n","slug":"Day09","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lt8000he5g6fkd7eis8","content":"<h1 id=\"图像分割\"><a href=\"#图像分割\" class=\"headerlink\" title=\"图像分割\"></a>图像分割</h1><hr>\n<blockquote>\n<p>整体等于部分之和<br>                —–欧几里德</p>\n</blockquote>\n<hr>\n<p>图像分割把图像细分为它的组成要素或物体，细分的水平取决于要解决的问题。<br>单色分割的分割算法通常是基于图像亮度值的两个基本特征:不连续性和相似性。第一类，方法是基于亮度的突变来分割一幅图像，比如边缘;第二类，主要方法是根据事先定义好的准则把图像分割成相似的区域</p>\n<h2 id=\"点、线和边缘检测\"><a href=\"#点、线和边缘检测\" class=\"headerlink\" title=\"点、线和边缘检测\"></a>点、线和边缘检测</h2><h3 id=\"背景知识\"><a href=\"#背景知识\" class=\"headerlink\" title=\"背景知识\"></a>背景知识</h3><ol>\n<li>边缘像素是图像中灰度突变的像素，边缘是连接的边缘像素的集合</li>\n<li>一条线可以视为一条边缘线段，该线段两侧的背景灰度要么远亮于该线像素的灰度，要么远暗于该线像素的灰度。孤立点可视为一条线，只是长度和宽度都是一个像素</li>\n<li>局部变化检测可以用微分(一阶微分和二阶微分)    <ul>\n<li>对于一阶导数的任何近似，约定:<ul>\n<li>在恒定灰度区域必须为0</li>\n<li>在灰度台阶和或斜坡开始处必须不为0</li>\n<li>在沿灰度斜坡点处也必须不为0</li>\n</ul>\n</li>\n<li>类似的对于二阶导数的近似<ul>\n<li>在恒定灰度区域必须为0</li>\n<li>在灰度台阶或斜坡开始除和结束处必须不为0</li>\n<li>沿灰度斜坡必须为0</li>\n</ul>\n</li>\n<li>一维函数展开为关于x的泰勒级数,结果差分<br>$$ \\frac{\\partial f}{\\partial x}=f’(x)=f(x+1)-f(x)$$<br>二阶导数<br>$$ \\frac{\\partial ^2 f}{\\partial ^2 x}=f’’(x)=f(x+1)+f(x-1)-2f(x)$$<ul>\n<li>可以得出结论:<ul>\n<li>一阶导数通常在图像中产生较粗的边缘</li>\n<li>二阶导数对精细细节，如细线、孤立点和噪声有较强的响应</li>\n<li>二阶导数在灰度斜坡和灰度台阶过渡处会产生双边缘响应</li>\n<li>二阶导数的符号可用于确定边缘的过程是从亮到暗还是从暗到亮</li>\n</ul>\n</li>\n<li>计算图像中每个像素位置的一阶导数和二阶导数的可选择方法是空间滤波器。模板在该区域中心点处的响应为<br>$$R = w_1z_1 + w_2z_2 + … + w_9z_9 = \\sum_{k=1}^{9}w_kz_k$$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th align=\"center\">$w_1$</th>\n<th align=\"center\">$w_2$</th>\n<th align=\"center\">$w_3$</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$w_4$</td>\n<td align=\"center\">$w_5$</td>\n<td align=\"center\">$w_6$</td>\n</tr>\n<tr>\n<td align=\"center\">$w_7$</td>\n<td align=\"center\">$w_8$</td>\n<td align=\"center\">$w_9$</td>\n</tr>\n</tbody></table>\n<p>这是一个普通的3×3空间滤波器掩模</p>\n<h3 id=\"孤立点检测\"><a href=\"#孤立点检测\" class=\"headerlink\" title=\"孤立点检测\"></a>孤立点检测</h3><ul>\n<li>点的检测应以二阶导数为基础，这意味着使用laplace<br>$$\\triangledown ^2f(x,y) = \\frac{\\partial ^2 f}{\\partial x^2} + \\frac{\\partial ^2 f}{\\partial y^2}$$<br>偏微分之后可求得laplace为<br>$$\\triangledown ^2f(x,y) = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$<br>点检测laplace模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">1</th>\n<th align=\"center\">1</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1</td>\n<td align=\"center\">-8</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>如果在某点处的该模板的响应的绝对值超过了一个指定的阈值，那么就说在模板中心位置(x,y)处的该点已经被检测到。在输出图像中，这样的点被标注为1,所有其他点被标注为0<br>$$g(x,y)=\\begin{cases}<br>1,\\quad |R(x,y)| \\geqq T\\<br>0, \\quad 其他<br>\\end{cases}<br>$$</p>\n<ul>\n<li>MATLAB实现</li>\n</ul>\n<pre><code>f = imread(&#39;moon.jpg&#39;);\n\nf = rgb2gray(f);\n\nw = [-1 -1 -1; -1 8 -1; -1 -1 -1];\n\ng = abs(imfilter(f, w));\n\nT = max(g(:));\n\ng = g &gt;= T;\n\nfigure(1);\n\nsubplot(1,2,1)\n\nimshow(f)\n\nsubplot(1,2,2)\n\nimshow(g)</code></pre><p>结果：<br><img src=\"https://i.loli.net/2019/07/24/5d37b3a82234833730.jpg\" alt></p>\n<h3 id=\"线检测\"><a href=\"#线检测\" class=\"headerlink\" title=\"线检测\"></a>线检测</h3><p>可以预期，二阶导数将导致更强的响应，并产生比一阶导数更细的线</p>\n<p>线检测模板</p>\n<ul>\n<li>水平</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">2</td>\n<td align=\"center\">2</td>\n<td align=\"center\">2</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n</tr>\n</tbody></table>\n<ul>\n<li>+45度</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">2 -</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n</tr>\n</tbody></table>\n<ul>\n<li>垂直</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">2</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n</tbody></table>\n<ul>\n<li>-45度</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n<tr>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n</tr>\n</tbody></table>\n<p>对于恒定的背景，当线通过模板的中间一行时可能产生更大的响应。<br>每个模板的系数之和为0,这表示在恒定亮度区域内，模板的响应为0.</p>\n<ul>\n<li>MATLAB实现检测指定方向上的线<pre><code>clc\n</code></pre></li>\n</ul>\n<p>clear</p>\n<p>f = imread(‘11111.jpg’);</p>\n<p>f = rgb2gray(f);</p>\n<p>figure(1);</p>\n<p>subplot(2,3,1)</p>\n<p>imshow(f);</p>\n<p>w = [-1, 2, -1; -1 2 -1; -1 2 -1];</p>\n<p>% g = imfilter(tofloat(f),w);</p>\n<p>g = imfilter(f,w);</p>\n<p>subplot(2,3,2)</p>\n<p>imshow(g, [ ]);</p>\n<p>gtop = g(1:120, 1:120);</p>\n<p>% gtop = pixeldup(gtop, 4);</p>\n<p>subplot(2,3,3)</p>\n<p>imshow(gtop, [ ]);</p>\n<p>gbot = g(end - 119:end, end - 119:end);</p>\n<p>% gbot = pixeldup(gbot, 4);</p>\n<p>subplot(2,3,4)</p>\n<p>imshow(gbot, [ ]);</p>\n<p>g = abs(g);</p>\n<p>subplot(2,3,5)</p>\n<p>imshow(g, [])</p>\n<p>T = max(g(:));</p>\n<p>g = g &gt;= T;</p>\n<p>subplot(2,3,6);</p>\n<p>imshow(g)</p>\n<pre><code>\n结果:\n![](https://i.loli.net/2019/07/24/5d37b3a815b7125153.jpg)\n可能会用到的M函数pixeldup</code></pre><p>function B=pixeldup(A,m,n)%pixeldup用来重复像素的，在水平方向复制m倍，在垂直方向复制n倍，m，n必须为整数，n没有赋值默认为m%检查输入参数个数<br>if nargin&lt;2<br>    error(‘At least two inputs are required.’);<br>    end<br>if nargin==2<br>    n=m;<br>    end<br>u=1:size(A,1);%产生一个向量，其向量中元素的个数为A的行数%复制向量中每个元素m次m=round(m);%防止m为非整数u=u(ones(1,m),:);<br>u=u(:);%在垂直方向重复操作<br>v=1:size(A,2);<br>n=round(n);<br>v=v(ones(1,n),:);<br>v=v(:);<br>B=A(u,v);</p>\n<pre><code>\n**慎用tofloat函数**\n\n</code></pre>","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"图像分割\"><a href=\"#图像分割\" class=\"headerlink\" title=\"图像分割\"></a>图像分割</h1><hr>\n<blockquote>\n<p>整体等于部分之和<br>                —–欧几里德</p>\n</blockquote>\n<hr>\n<p>图像分割把图像细分为它的组成要素或物体，细分的水平取决于要解决的问题。<br>单色分割的分割算法通常是基于图像亮度值的两个基本特征:不连续性和相似性。第一类，方法是基于亮度的突变来分割一幅图像，比如边缘;第二类，主要方法是根据事先定义好的准则把图像分割成相似的区域</p>\n<h2 id=\"点、线和边缘检测\"><a href=\"#点、线和边缘检测\" class=\"headerlink\" title=\"点、线和边缘检测\"></a>点、线和边缘检测</h2><h3 id=\"背景知识\"><a href=\"#背景知识\" class=\"headerlink\" title=\"背景知识\"></a>背景知识</h3><ol>\n<li>边缘像素是图像中灰度突变的像素，边缘是连接的边缘像素的集合</li>\n<li>一条线可以视为一条边缘线段，该线段两侧的背景灰度要么远亮于该线像素的灰度，要么远暗于该线像素的灰度。孤立点可视为一条线，只是长度和宽度都是一个像素</li>\n<li>局部变化检测可以用微分(一阶微分和二阶微分)    <ul>\n<li>对于一阶导数的任何近似，约定:<ul>\n<li>在恒定灰度区域必须为0</li>\n<li>在灰度台阶和或斜坡开始处必须不为0</li>\n<li>在沿灰度斜坡点处也必须不为0</li>\n</ul>\n</li>\n<li>类似的对于二阶导数的近似<ul>\n<li>在恒定灰度区域必须为0</li>\n<li>在灰度台阶或斜坡开始除和结束处必须不为0</li>\n<li>沿灰度斜坡必须为0</li>\n</ul>\n</li>\n<li>一维函数展开为关于x的泰勒级数,结果差分<br>$$ \\frac{\\partial f}{\\partial x}=f’(x)=f(x+1)-f(x)$$<br>二阶导数<br>$$ \\frac{\\partial ^2 f}{\\partial ^2 x}=f’’(x)=f(x+1)+f(x-1)-2f(x)$$<ul>\n<li>可以得出结论:<ul>\n<li>一阶导数通常在图像中产生较粗的边缘</li>\n<li>二阶导数对精细细节，如细线、孤立点和噪声有较强的响应</li>\n<li>二阶导数在灰度斜坡和灰度台阶过渡处会产生双边缘响应</li>\n<li>二阶导数的符号可用于确定边缘的过程是从亮到暗还是从暗到亮</li>\n</ul>\n</li>\n<li>计算图像中每个像素位置的一阶导数和二阶导数的可选择方法是空间滤波器。模板在该区域中心点处的响应为<br>$$R = w_1z_1 + w_2z_2 + … + w_9z_9 = \\sum_{k=1}^{9}w_kz_k$$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th align=\"center\">$w_1$</th>\n<th align=\"center\">$w_2$</th>\n<th align=\"center\">$w_3$</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$w_4$</td>\n<td align=\"center\">$w_5$</td>\n<td align=\"center\">$w_6$</td>\n</tr>\n<tr>\n<td align=\"center\">$w_7$</td>\n<td align=\"center\">$w_8$</td>\n<td align=\"center\">$w_9$</td>\n</tr>\n</tbody></table>\n<p>这是一个普通的3×3空间滤波器掩模</p>\n<h3 id=\"孤立点检测\"><a href=\"#孤立点检测\" class=\"headerlink\" title=\"孤立点检测\"></a>孤立点检测</h3><ul>\n<li>点的检测应以二阶导数为基础，这意味着使用laplace<br>$$\\triangledown ^2f(x,y) = \\frac{\\partial ^2 f}{\\partial x^2} + \\frac{\\partial ^2 f}{\\partial y^2}$$<br>偏微分之后可求得laplace为<br>$$\\triangledown ^2f(x,y) = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$<br>点检测laplace模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">1</th>\n<th align=\"center\">1</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1</td>\n<td align=\"center\">-8</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>如果在某点处的该模板的响应的绝对值超过了一个指定的阈值，那么就说在模板中心位置(x,y)处的该点已经被检测到。在输出图像中，这样的点被标注为1,所有其他点被标注为0<br>$$g(x,y)=\\begin{cases}<br>1,\\quad |R(x,y)| \\geqq T\\<br>0, \\quad 其他<br>\\end{cases}<br>$$</p>\n<ul>\n<li>MATLAB实现</li>\n</ul>\n<pre><code>f = imread(&#39;moon.jpg&#39;);\n\nf = rgb2gray(f);\n\nw = [-1 -1 -1; -1 8 -1; -1 -1 -1];\n\ng = abs(imfilter(f, w));\n\nT = max(g(:));\n\ng = g &gt;= T;\n\nfigure(1);\n\nsubplot(1,2,1)\n\nimshow(f)\n\nsubplot(1,2,2)\n\nimshow(g)</code></pre><p>结果：<br><img src=\"https://i.loli.net/2019/07/24/5d37b3a82234833730.jpg\" alt></p>\n<h3 id=\"线检测\"><a href=\"#线检测\" class=\"headerlink\" title=\"线检测\"></a>线检测</h3><p>可以预期，二阶导数将导致更强的响应，并产生比一阶导数更细的线</p>\n<p>线检测模板</p>\n<ul>\n<li>水平</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">2</td>\n<td align=\"center\">2</td>\n<td align=\"center\">2</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n</tr>\n</tbody></table>\n<ul>\n<li>+45度</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">2 -</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n</tr>\n</tbody></table>\n<ul>\n<li>垂直</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">2</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n</tbody></table>\n<ul>\n<li>-45度</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">2</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n</tr>\n<tr>\n<td align=\"center\">2</td>\n<td align=\"center\">-1</td>\n<td align=\"center\">-1</td>\n</tr>\n</tbody></table>\n<p>对于恒定的背景，当线通过模板的中间一行时可能产生更大的响应。<br>每个模板的系数之和为0,这表示在恒定亮度区域内，模板的响应为0.</p>\n<ul>\n<li>MATLAB实现检测指定方向上的线<pre><code>clc\n</code></pre></li>\n</ul>\n<p>clear</p>\n<p>f = imread(‘11111.jpg’);</p>\n<p>f = rgb2gray(f);</p>\n<p>figure(1);</p>\n<p>subplot(2,3,1)</p>\n<p>imshow(f);</p>\n<p>w = [-1, 2, -1; -1 2 -1; -1 2 -1];</p>\n<p>% g = imfilter(tofloat(f),w);</p>\n<p>g = imfilter(f,w);</p>\n<p>subplot(2,3,2)</p>\n<p>imshow(g, [ ]);</p>\n<p>gtop = g(1:120, 1:120);</p>\n<p>% gtop = pixeldup(gtop, 4);</p>\n<p>subplot(2,3,3)</p>\n<p>imshow(gtop, [ ]);</p>\n<p>gbot = g(end - 119:end, end - 119:end);</p>\n<p>% gbot = pixeldup(gbot, 4);</p>\n<p>subplot(2,3,4)</p>\n<p>imshow(gbot, [ ]);</p>\n<p>g = abs(g);</p>\n<p>subplot(2,3,5)</p>\n<p>imshow(g, [])</p>\n<p>T = max(g(:));</p>\n<p>g = g &gt;= T;</p>\n<p>subplot(2,3,6);</p>\n<p>imshow(g)</p>\n<pre><code>\n结果:\n![](https://i.loli.net/2019/07/24/5d37b3a815b7125153.jpg)\n可能会用到的M函数pixeldup</code></pre><p>function B=pixeldup(A,m,n)%pixeldup用来重复像素的，在水平方向复制m倍，在垂直方向复制n倍，m，n必须为整数，n没有赋值默认为m%检查输入参数个数<br>if nargin&lt;2<br>    error(‘At least two inputs are required.’);<br>    end<br>if nargin==2<br>    n=m;<br>    end<br>u=1:size(A,1);%产生一个向量，其向量中元素的个数为A的行数%复制向量中每个元素m次m=round(m);%防止m为非整数u=u(ones(1,m),:);<br>u=u(:);%在垂直方向重复操作<br>v=1:size(A,2);<br>n=round(n);<br>v=v(ones(1,n),:);<br>v=v(:);<br>B=A(u,v);</p>\n<pre><code>\n**慎用tofloat函数**\n\n</code></pre>"},{"title":"Day11","date":"2019-07-25T10:29:59.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# 配了一天的环境，还没有装好，卒！\n","source":"_posts/Day11.md","raw":"---\ntitle: Day11\ndate: 2019-07-25 18:29:59\ntags:\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# 配了一天的环境，还没有装好，卒！\n","slug":"Day11","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lta000je5g6ja5acbfr","content":"<h1 id=\"配了一天的环境，还没有装好，卒！\"><a href=\"#配了一天的环境，还没有装好，卒！\" class=\"headerlink\" title=\"配了一天的环境，还没有装好，卒！\"></a>配了一天的环境，还没有装好，卒！</h1>","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"配了一天的环境，还没有装好，卒！\"><a href=\"#配了一天的环境，还没有装好，卒！\" class=\"headerlink\" title=\"配了一天的环境，还没有装好，卒！\"></a>配了一天的环境，还没有装好，卒！</h1>"},{"title":"Day13","date":"2019-07-27T10:48:06.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# 边缘检测之梯度详解\n\n梯度的概念和性质在边缘检测中比较重要，所以我又仔细看了一下相关知识点，总结一下。\n\n## 梯度概念\n梯度是一个可以确定图像f的(x,y)位置处的边缘方向和强度的工具，用 $\\triangledown f$来表示，用 **向量**来定义\n\n$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$\n\n## 梯度性质\n\n1. 梯度向量大小。    \n$\\triangledown f$的大小为M(x,y)\n$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{\n1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$\n这是梯度向量方向变化率的值。其中$g_x$,$g_y$和M(x,y)都是和原图像大小相同的图像。称M(x,y)为梯度图像。\n\n2. 梯度向量的方向\n$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$\n同理，　$\\alpha(x,y)$也是由$g_x$和$g_y$阵列创建的尺寸相同的图像。    \n任意点(x,y)处的一个边缘的方向与该点处梯度向量的方向$\\alpha(x,y)$正交。  \n梯度向量有时也称为边缘法线\n\n3. 梯度指出f在(x,y)处的最大变化率的方向\n\n## 梯度算子\n### 一维模板\n\n$$g_x = \\frac{\\partial f(x,y)}{\\partial x} = f(x+1,y) - f(x,y)$$\n和\n$$g_y = \\frac{\\partial f(x,y)}{\\partial y} = f(x,y+1)-f(x,y)$$\n\n### 二维模板\n\n罗伯特交叉梯度算子(Roberts),ROberts算子以求对角像素之差为基础:\n$$g_x = \\frac{\\partial f}{\\partial x} = (z_9 - z_5)$$\n和\n$$g_y = \\frac{\\partial f}{\\partial y} = (z_8 - z_6)$$\n\n### 3×3模板\n\n#### Prewitt算子\n$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$\n和\n$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$\n\n#### Sobel算子\n\n$$g_x = (z_7 + 2z_8 + z_9)-(z_1 +2 z_2 + z_3)$$\n和\n$$g_y = (z_3 + 2z_6 + z_9) - (z_1 +2 z_4 + z_7)$$\n\n在中心位置处使用2可以平滑图像\n\n注意:所有模板中的系数之和为0，这意味着恒定灰度的响应为0.\n","source":"_posts/Day13.md","raw":"---\ntitle: Day13\ndate: 2019-07-27 18:48:06\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# 边缘检测之梯度详解\n\n梯度的概念和性质在边缘检测中比较重要，所以我又仔细看了一下相关知识点，总结一下。\n\n## 梯度概念\n梯度是一个可以确定图像f的(x,y)位置处的边缘方向和强度的工具，用 $\\triangledown f$来表示，用 **向量**来定义\n\n$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$\n\n## 梯度性质\n\n1. 梯度向量大小。    \n$\\triangledown f$的大小为M(x,y)\n$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{\n1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$\n这是梯度向量方向变化率的值。其中$g_x$,$g_y$和M(x,y)都是和原图像大小相同的图像。称M(x,y)为梯度图像。\n\n2. 梯度向量的方向\n$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$\n同理，　$\\alpha(x,y)$也是由$g_x$和$g_y$阵列创建的尺寸相同的图像。    \n任意点(x,y)处的一个边缘的方向与该点处梯度向量的方向$\\alpha(x,y)$正交。  \n梯度向量有时也称为边缘法线\n\n3. 梯度指出f在(x,y)处的最大变化率的方向\n\n## 梯度算子\n### 一维模板\n\n$$g_x = \\frac{\\partial f(x,y)}{\\partial x} = f(x+1,y) - f(x,y)$$\n和\n$$g_y = \\frac{\\partial f(x,y)}{\\partial y} = f(x,y+1)-f(x,y)$$\n\n### 二维模板\n\n罗伯特交叉梯度算子(Roberts),ROberts算子以求对角像素之差为基础:\n$$g_x = \\frac{\\partial f}{\\partial x} = (z_9 - z_5)$$\n和\n$$g_y = \\frac{\\partial f}{\\partial y} = (z_8 - z_6)$$\n\n### 3×3模板\n\n#### Prewitt算子\n$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$\n和\n$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$\n\n#### Sobel算子\n\n$$g_x = (z_7 + 2z_8 + z_9)-(z_1 +2 z_2 + z_3)$$\n和\n$$g_y = (z_3 + 2z_6 + z_9) - (z_1 +2 z_4 + z_7)$$\n\n在中心位置处使用2可以平滑图像\n\n注意:所有模板中的系数之和为0，这意味着恒定灰度的响应为0.\n","slug":"Day13","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltb000le5g6b0n06up0","content":"<h1 id=\"边缘检测之梯度详解\"><a href=\"#边缘检测之梯度详解\" class=\"headerlink\" title=\"边缘检测之梯度详解\"></a>边缘检测之梯度详解</h1><p>梯度的概念和性质在边缘检测中比较重要，所以我又仔细看了一下相关知识点，总结一下。</p>\n<h2 id=\"梯度概念\"><a href=\"#梯度概念\" class=\"headerlink\" title=\"梯度概念\"></a>梯度概念</h2><p>梯度是一个可以确定图像f的(x,y)位置处的边缘方向和强度的工具，用 $\\triangledown f$来表示，用 <strong>向量</strong>来定义</p>\n<p>$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$</p>\n<h2 id=\"梯度性质\"><a href=\"#梯度性质\" class=\"headerlink\" title=\"梯度性质\"></a>梯度性质</h2><ol>\n<li><p>梯度向量大小。<br>$\\triangledown f$的大小为M(x,y)<br>$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{<br>1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$<br>这是梯度向量方向变化率的值。其中$g_x$,$g_y$和M(x,y)都是和原图像大小相同的图像。称M(x,y)为梯度图像。</p>\n</li>\n<li><p>梯度向量的方向<br>$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$<br>同理，　$\\alpha(x,y)$也是由$g_x$和$g_y$阵列创建的尺寸相同的图像。<br>任意点(x,y)处的一个边缘的方向与该点处梯度向量的方向$\\alpha(x,y)$正交。<br>梯度向量有时也称为边缘法线</p>\n</li>\n<li><p>梯度指出f在(x,y)处的最大变化率的方向</p>\n</li>\n</ol>\n<h2 id=\"梯度算子\"><a href=\"#梯度算子\" class=\"headerlink\" title=\"梯度算子\"></a>梯度算子</h2><h3 id=\"一维模板\"><a href=\"#一维模板\" class=\"headerlink\" title=\"一维模板\"></a>一维模板</h3><p>$$g_x = \\frac{\\partial f(x,y)}{\\partial x} = f(x+1,y) - f(x,y)$$<br>和<br>$$g_y = \\frac{\\partial f(x,y)}{\\partial y} = f(x,y+1)-f(x,y)$$</p>\n<h3 id=\"二维模板\"><a href=\"#二维模板\" class=\"headerlink\" title=\"二维模板\"></a>二维模板</h3><p>罗伯特交叉梯度算子(Roberts),ROberts算子以求对角像素之差为基础:<br>$$g_x = \\frac{\\partial f}{\\partial x} = (z_9 - z_5)$$<br>和<br>$$g_y = \\frac{\\partial f}{\\partial y} = (z_8 - z_6)$$</p>\n<h3 id=\"3×3模板\"><a href=\"#3×3模板\" class=\"headerlink\" title=\"3×3模板\"></a>3×3模板</h3><h4 id=\"Prewitt算子\"><a href=\"#Prewitt算子\" class=\"headerlink\" title=\"Prewitt算子\"></a>Prewitt算子</h4><p>$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$<br>和<br>$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$</p>\n<h4 id=\"Sobel算子\"><a href=\"#Sobel算子\" class=\"headerlink\" title=\"Sobel算子\"></a>Sobel算子</h4><p>$$g_x = (z_7 + 2z_8 + z_9)-(z_1 +2 z_2 + z_3)$$<br>和<br>$$g_y = (z_3 + 2z_6 + z_9) - (z_1 +2 z_4 + z_7)$$</p>\n<p>在中心位置处使用2可以平滑图像</p>\n<p>注意:所有模板中的系数之和为0，这意味着恒定灰度的响应为0.</p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"边缘检测之梯度详解\"><a href=\"#边缘检测之梯度详解\" class=\"headerlink\" title=\"边缘检测之梯度详解\"></a>边缘检测之梯度详解</h1><p>梯度的概念和性质在边缘检测中比较重要，所以我又仔细看了一下相关知识点，总结一下。</p>\n<h2 id=\"梯度概念\"><a href=\"#梯度概念\" class=\"headerlink\" title=\"梯度概念\"></a>梯度概念</h2><p>梯度是一个可以确定图像f的(x,y)位置处的边缘方向和强度的工具，用 $\\triangledown f$来表示，用 <strong>向量</strong>来定义</p>\n<p>$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$</p>\n<h2 id=\"梯度性质\"><a href=\"#梯度性质\" class=\"headerlink\" title=\"梯度性质\"></a>梯度性质</h2><ol>\n<li><p>梯度向量大小。<br>$\\triangledown f$的大小为M(x,y)<br>$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{<br>1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$<br>这是梯度向量方向变化率的值。其中$g_x$,$g_y$和M(x,y)都是和原图像大小相同的图像。称M(x,y)为梯度图像。</p>\n</li>\n<li><p>梯度向量的方向<br>$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$<br>同理，　$\\alpha(x,y)$也是由$g_x$和$g_y$阵列创建的尺寸相同的图像。<br>任意点(x,y)处的一个边缘的方向与该点处梯度向量的方向$\\alpha(x,y)$正交。<br>梯度向量有时也称为边缘法线</p>\n</li>\n<li><p>梯度指出f在(x,y)处的最大变化率的方向</p>\n</li>\n</ol>\n<h2 id=\"梯度算子\"><a href=\"#梯度算子\" class=\"headerlink\" title=\"梯度算子\"></a>梯度算子</h2><h3 id=\"一维模板\"><a href=\"#一维模板\" class=\"headerlink\" title=\"一维模板\"></a>一维模板</h3><p>$$g_x = \\frac{\\partial f(x,y)}{\\partial x} = f(x+1,y) - f(x,y)$$<br>和<br>$$g_y = \\frac{\\partial f(x,y)}{\\partial y} = f(x,y+1)-f(x,y)$$</p>\n<h3 id=\"二维模板\"><a href=\"#二维模板\" class=\"headerlink\" title=\"二维模板\"></a>二维模板</h3><p>罗伯特交叉梯度算子(Roberts),ROberts算子以求对角像素之差为基础:<br>$$g_x = \\frac{\\partial f}{\\partial x} = (z_9 - z_5)$$<br>和<br>$$g_y = \\frac{\\partial f}{\\partial y} = (z_8 - z_6)$$</p>\n<h3 id=\"3×3模板\"><a href=\"#3×3模板\" class=\"headerlink\" title=\"3×3模板\"></a>3×3模板</h3><h4 id=\"Prewitt算子\"><a href=\"#Prewitt算子\" class=\"headerlink\" title=\"Prewitt算子\"></a>Prewitt算子</h4><p>$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$<br>和<br>$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$</p>\n<h4 id=\"Sobel算子\"><a href=\"#Sobel算子\" class=\"headerlink\" title=\"Sobel算子\"></a>Sobel算子</h4><p>$$g_x = (z_7 + 2z_8 + z_9)-(z_1 +2 z_2 + z_3)$$<br>和<br>$$g_y = (z_3 + 2z_6 + z_9) - (z_1 +2 z_4 + z_7)$$</p>\n<p>在中心位置处使用2可以平滑图像</p>\n<p>注意:所有模板中的系数之和为0，这意味着恒定灰度的响应为0.</p>\n"},{"title":"Day12","date":"2019-07-25T16:06:26.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# 基于霍夫变换的圆形检测\n\n## 霍夫变换的原理\n\n\nHough 变换就是利用图像全局特征将边缘像素连接起来组成区域封闭边界，它将图像空间转换到参数空间，在参数空间对点进行描述，达到检测图像边缘的目的。该方法把所有可能落在边缘上的点进行统计计算，根据对数据的统计结果确定属于边缘的程度。Hough 变换的实质就是对图像进行坐标变换，把平面坐标变换为参数坐标，使变换的结果更易识别和检测。\n\n---\n\n### 对霍夫变换圆形检测的原理的理解:\n已知圆的一般方程为:\n$$(x-a)^2 + (y-b)^2 = r^2 $$\n其中(a,b)代表圆心，r是圆的半径    \n依旧是把图像空间转换成参数空间，这里是将X-Y平面转化成a-b-r参数空间，则在图像空间中的一个过(x,y)点的圆，对应参数空间中高度变化的三维锥面。\n![](https://i.loli.net/2019/07/26/5d3ab8c50fc2a28962.jpg)\n同理，过图像空间的任意一点的圆都对应于参数空间的一个三维锥面，因此，过图像空间上同一圆的点，对应的参数空间中的三维锥面，在r平面必然相交于一点(a,b,r)，这样通过这一点就可以得到一个圆的参数。\n![](https://i.loli.net/2019/07/26/5d3ab8c4d635d79647.jpg)\n这里霍夫变换的圆检测就是在这三个参数组成的三维空间内进行的    \n换一种理解思路:在笛卡尔坐标下的圆的方程已给出，在极坐标系下，假设圆心为$(x_0,y_0)$,圆上的点可以表示为:\n$$x = x_0 + rcos\\theta, y = y_0 + rsin\\theta$$\n对于一个圆，假如中心像素点$(x_0,y_0)$，半径r已知，那么旋转360°，圆上的所有点就可以求得。同样，假如圆上的所有点，半径r已知，旋转360°，则会得到一个累加的极值点，那么这个点就是圆心了。\n\n---\n\n理论上霍夫变换可以检测任何形状，但复杂的形状需要的参数就多，霍夫空间的维数就多，因此在程序实现上所需的内存空间以及运行效率上都不利于把标准霍夫变换应用于实际复杂图形的检测中。所以一些改进的霍夫变换就相继提出，它们的基本原理就是尽可能减小霍夫空间的维数。\n\n在OpenCV中，HoughCircles函数实现了圆形检测，它使用的算法也是改进的霍夫变换——2-1霍夫变换（21HT）。也就是把霍夫变换分为两个阶段，从而减小了霍夫空间的维数。第一阶段用于检测圆心，第二阶段从圆心推导出圆半径。    \n检测圆心的原理是圆心是它所在圆周所有法线的交汇处，因此只要找到这个交点，即可确定圆心，该方法所用的霍夫空间与图像空间的性质相同，因此它仅仅是二维空间。检测圆半径的方法是从圆心到圆周上的任意一点的距离（即半径）是相同，只要确定一个阈值，只要相同距离的数量大于该阈值，我们就认为该距离就是该圆心所对应的圆半径，该方法只需要计算半径直方图，不使用霍夫空间。圆和半径知道了，圆自然就能求得。\n\n21HT的具体步骤:\n第一阶段：检测圆心\n\n1.1、对输入图像边缘检测；\n\n1.2、计算图形的梯度，并确定圆周线，其中圆周的梯度就是它的法线；\n\n1.3、在二维霍夫空间内，绘出所有图形的梯度直线，某坐标点上累加和的值越大，说明在该点上直线相交的次数越多，也就是越有可能是圆心；\n\n1.4、在霍夫空间的4邻域内进行非最大值抑制；\n\n1.5、设定一个阈值，霍夫空间内累加和大于该阈值的点就对应于圆心。\n\n第二阶段：检测圆半径\n\n2.1、计算某一个圆心到所有圆周线的距离，这些距离中就有该圆心所对应的圆的半径的值，这些半径值当然是相等的，并且这些圆半径的数量要远远大于其他距离值相等的数量；\n\n2.2、设定两个阈值，定义为最大半径和最小半径，保留距离在这两个半径之间的值，这意味着我们检测的圆不能太大，也不能太小；\n\n2.3、对保留下来的距离进行排序；\n\n2.4、找到距离相同的那些值，并计算相同值的数量；\n\n2.5、设定一个阈值，只有相同值的数量大于该阈值，才认为该值是该圆心对应的圆半径；\n\n2.6、对每一个圆心，完成上面的2.1～2.5步骤，得到所有的圆半径。\n\nHoughCircles函数的原型为：    \nvoid HoughCircles(InputArray image,OutputArray circles, int method, double dp, double minDist, double param1=100, double param2=100, int minRadius=0,int maxRadius=0 )    \nimage为输入图像，要求是灰度图像    \ncircles为输出圆向量，每个向量包括三个浮点型的元素——圆心横坐标，圆心纵坐标和圆半径    \nmethod为使用霍夫变换圆检测的算法，Opencv2.4.9只实现了2-1霍夫变换，它的参数是CV_HOUGH_GRADIENT    \ndp为第一阶段所使用的霍夫空间的分辨率，dp=1时表示霍夫空间与输入图像空间的大小一致，dp=2时霍夫空间是输入图像空间的一半，以此类推    \nminDist为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心    \nparam1为边缘检测时使用Canny算子的高阈值    \nparam2为步骤1.5和步骤2.5中所共有的阈值    \nminRadius和maxRadius为所检测到的圆半径的最小值和最大值\n\n### 霍夫变换椭圆检测的实现\n\n运行环境: vs2017 + Opencv3.4\n由于HoughCircles函数是调用Canny函数进行边缘检测，OpenCV的Canny函数不包括平滑滤波，所以先对原图进行滤波处理，在这里使用的是高斯模糊\n```\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include <iostream>\nusing namespace cv;\nusing namespace std;\n \nint main( int argc, char** argv )\n{\n \tMat src, gray;\n\tsrc=imread(\"coins.jpg\");\n\tif( !src.data )  \n\t\treturn -1;  \n\t\n\tcvtColor( src, gray, CV_BGR2GRAY );\n    //高斯模糊平滑\n\tGaussianBlur( gray, gray, Size(9, 9), 2, 2 );\n \n    vector<Vec3f> circles;\n    //霍夫变换\n    HoughCircles( gray, circles, CV_HOUGH_GRADIENT, 1, gray.rows/20, 100, 60, 0, 0 );\n \n    //在原图中画出圆心和圆\n    for( size_t i = 0; i < circles.size(); i++ )\n    {\n        //提取出圆心坐标\n        Point center(cvRound(circles[i][0]), cvRound(circles[i][1]));\n        //提取出圆半径\n        int radius = cvRound(circles[i][2]);\n        //圆心\n        circle( src, center, 3, Scalar(0,255,0), -1, 8, 0 );\n        //圆\n        circle( src, center, radius, Scalar(0,0,255), 3, 8, 0 );\n   }\n \n    imshow( \"霍夫变换检测圆图\", src );\n \n    waitKey(0);\n    return 0;\n}\n```\n结果:\n![](https://i.loli.net/2019/07/26/5d3abf54a4c3b88169.jpg)\n\n","source":"_posts/Day12.md","raw":"---\ntitle: Day12\ndate: 2019-07-26 00:06:26\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# 基于霍夫变换的圆形检测\n\n## 霍夫变换的原理\n\n\nHough 变换就是利用图像全局特征将边缘像素连接起来组成区域封闭边界，它将图像空间转换到参数空间，在参数空间对点进行描述，达到检测图像边缘的目的。该方法把所有可能落在边缘上的点进行统计计算，根据对数据的统计结果确定属于边缘的程度。Hough 变换的实质就是对图像进行坐标变换，把平面坐标变换为参数坐标，使变换的结果更易识别和检测。\n\n---\n\n### 对霍夫变换圆形检测的原理的理解:\n已知圆的一般方程为:\n$$(x-a)^2 + (y-b)^2 = r^2 $$\n其中(a,b)代表圆心，r是圆的半径    \n依旧是把图像空间转换成参数空间，这里是将X-Y平面转化成a-b-r参数空间，则在图像空间中的一个过(x,y)点的圆，对应参数空间中高度变化的三维锥面。\n![](https://i.loli.net/2019/07/26/5d3ab8c50fc2a28962.jpg)\n同理，过图像空间的任意一点的圆都对应于参数空间的一个三维锥面，因此，过图像空间上同一圆的点，对应的参数空间中的三维锥面，在r平面必然相交于一点(a,b,r)，这样通过这一点就可以得到一个圆的参数。\n![](https://i.loli.net/2019/07/26/5d3ab8c4d635d79647.jpg)\n这里霍夫变换的圆检测就是在这三个参数组成的三维空间内进行的    \n换一种理解思路:在笛卡尔坐标下的圆的方程已给出，在极坐标系下，假设圆心为$(x_0,y_0)$,圆上的点可以表示为:\n$$x = x_0 + rcos\\theta, y = y_0 + rsin\\theta$$\n对于一个圆，假如中心像素点$(x_0,y_0)$，半径r已知，那么旋转360°，圆上的所有点就可以求得。同样，假如圆上的所有点，半径r已知，旋转360°，则会得到一个累加的极值点，那么这个点就是圆心了。\n\n---\n\n理论上霍夫变换可以检测任何形状，但复杂的形状需要的参数就多，霍夫空间的维数就多，因此在程序实现上所需的内存空间以及运行效率上都不利于把标准霍夫变换应用于实际复杂图形的检测中。所以一些改进的霍夫变换就相继提出，它们的基本原理就是尽可能减小霍夫空间的维数。\n\n在OpenCV中，HoughCircles函数实现了圆形检测，它使用的算法也是改进的霍夫变换——2-1霍夫变换（21HT）。也就是把霍夫变换分为两个阶段，从而减小了霍夫空间的维数。第一阶段用于检测圆心，第二阶段从圆心推导出圆半径。    \n检测圆心的原理是圆心是它所在圆周所有法线的交汇处，因此只要找到这个交点，即可确定圆心，该方法所用的霍夫空间与图像空间的性质相同，因此它仅仅是二维空间。检测圆半径的方法是从圆心到圆周上的任意一点的距离（即半径）是相同，只要确定一个阈值，只要相同距离的数量大于该阈值，我们就认为该距离就是该圆心所对应的圆半径，该方法只需要计算半径直方图，不使用霍夫空间。圆和半径知道了，圆自然就能求得。\n\n21HT的具体步骤:\n第一阶段：检测圆心\n\n1.1、对输入图像边缘检测；\n\n1.2、计算图形的梯度，并确定圆周线，其中圆周的梯度就是它的法线；\n\n1.3、在二维霍夫空间内，绘出所有图形的梯度直线，某坐标点上累加和的值越大，说明在该点上直线相交的次数越多，也就是越有可能是圆心；\n\n1.4、在霍夫空间的4邻域内进行非最大值抑制；\n\n1.5、设定一个阈值，霍夫空间内累加和大于该阈值的点就对应于圆心。\n\n第二阶段：检测圆半径\n\n2.1、计算某一个圆心到所有圆周线的距离，这些距离中就有该圆心所对应的圆的半径的值，这些半径值当然是相等的，并且这些圆半径的数量要远远大于其他距离值相等的数量；\n\n2.2、设定两个阈值，定义为最大半径和最小半径，保留距离在这两个半径之间的值，这意味着我们检测的圆不能太大，也不能太小；\n\n2.3、对保留下来的距离进行排序；\n\n2.4、找到距离相同的那些值，并计算相同值的数量；\n\n2.5、设定一个阈值，只有相同值的数量大于该阈值，才认为该值是该圆心对应的圆半径；\n\n2.6、对每一个圆心，完成上面的2.1～2.5步骤，得到所有的圆半径。\n\nHoughCircles函数的原型为：    \nvoid HoughCircles(InputArray image,OutputArray circles, int method, double dp, double minDist, double param1=100, double param2=100, int minRadius=0,int maxRadius=0 )    \nimage为输入图像，要求是灰度图像    \ncircles为输出圆向量，每个向量包括三个浮点型的元素——圆心横坐标，圆心纵坐标和圆半径    \nmethod为使用霍夫变换圆检测的算法，Opencv2.4.9只实现了2-1霍夫变换，它的参数是CV_HOUGH_GRADIENT    \ndp为第一阶段所使用的霍夫空间的分辨率，dp=1时表示霍夫空间与输入图像空间的大小一致，dp=2时霍夫空间是输入图像空间的一半，以此类推    \nminDist为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心    \nparam1为边缘检测时使用Canny算子的高阈值    \nparam2为步骤1.5和步骤2.5中所共有的阈值    \nminRadius和maxRadius为所检测到的圆半径的最小值和最大值\n\n### 霍夫变换椭圆检测的实现\n\n运行环境: vs2017 + Opencv3.4\n由于HoughCircles函数是调用Canny函数进行边缘检测，OpenCV的Canny函数不包括平滑滤波，所以先对原图进行滤波处理，在这里使用的是高斯模糊\n```\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include <iostream>\nusing namespace cv;\nusing namespace std;\n \nint main( int argc, char** argv )\n{\n \tMat src, gray;\n\tsrc=imread(\"coins.jpg\");\n\tif( !src.data )  \n\t\treturn -1;  \n\t\n\tcvtColor( src, gray, CV_BGR2GRAY );\n    //高斯模糊平滑\n\tGaussianBlur( gray, gray, Size(9, 9), 2, 2 );\n \n    vector<Vec3f> circles;\n    //霍夫变换\n    HoughCircles( gray, circles, CV_HOUGH_GRADIENT, 1, gray.rows/20, 100, 60, 0, 0 );\n \n    //在原图中画出圆心和圆\n    for( size_t i = 0; i < circles.size(); i++ )\n    {\n        //提取出圆心坐标\n        Point center(cvRound(circles[i][0]), cvRound(circles[i][1]));\n        //提取出圆半径\n        int radius = cvRound(circles[i][2]);\n        //圆心\n        circle( src, center, 3, Scalar(0,255,0), -1, 8, 0 );\n        //圆\n        circle( src, center, radius, Scalar(0,0,255), 3, 8, 0 );\n   }\n \n    imshow( \"霍夫变换检测圆图\", src );\n \n    waitKey(0);\n    return 0;\n}\n```\n结果:\n![](https://i.loli.net/2019/07/26/5d3abf54a4c3b88169.jpg)\n\n","slug":"Day12","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltc000ne5g61a05847j","content":"<h1 id=\"基于霍夫变换的圆形检测\"><a href=\"#基于霍夫变换的圆形检测\" class=\"headerlink\" title=\"基于霍夫变换的圆形检测\"></a>基于霍夫变换的圆形检测</h1><h2 id=\"霍夫变换的原理\"><a href=\"#霍夫变换的原理\" class=\"headerlink\" title=\"霍夫变换的原理\"></a>霍夫变换的原理</h2><p>Hough 变换就是利用图像全局特征将边缘像素连接起来组成区域封闭边界，它将图像空间转换到参数空间，在参数空间对点进行描述，达到检测图像边缘的目的。该方法把所有可能落在边缘上的点进行统计计算，根据对数据的统计结果确定属于边缘的程度。Hough 变换的实质就是对图像进行坐标变换，把平面坐标变换为参数坐标，使变换的结果更易识别和检测。</p>\n<hr>\n<h3 id=\"对霍夫变换圆形检测的原理的理解\"><a href=\"#对霍夫变换圆形检测的原理的理解\" class=\"headerlink\" title=\"对霍夫变换圆形检测的原理的理解:\"></a>对霍夫变换圆形检测的原理的理解:</h3><p>已知圆的一般方程为:<br>$$(x-a)^2 + (y-b)^2 = r^2 $$<br>其中(a,b)代表圆心，r是圆的半径<br>依旧是把图像空间转换成参数空间，这里是将X-Y平面转化成a-b-r参数空间，则在图像空间中的一个过(x,y)点的圆，对应参数空间中高度变化的三维锥面。<br><img src=\"https://i.loli.net/2019/07/26/5d3ab8c50fc2a28962.jpg\" alt><br>同理，过图像空间的任意一点的圆都对应于参数空间的一个三维锥面，因此，过图像空间上同一圆的点，对应的参数空间中的三维锥面，在r平面必然相交于一点(a,b,r)，这样通过这一点就可以得到一个圆的参数。<br><img src=\"https://i.loli.net/2019/07/26/5d3ab8c4d635d79647.jpg\" alt><br>这里霍夫变换的圆检测就是在这三个参数组成的三维空间内进行的<br>换一种理解思路:在笛卡尔坐标下的圆的方程已给出，在极坐标系下，假设圆心为$(x_0,y_0)$,圆上的点可以表示为:<br>$$x = x_0 + rcos\\theta, y = y_0 + rsin\\theta$$<br>对于一个圆，假如中心像素点$(x_0,y_0)$，半径r已知，那么旋转360°，圆上的所有点就可以求得。同样，假如圆上的所有点，半径r已知，旋转360°，则会得到一个累加的极值点，那么这个点就是圆心了。</p>\n<hr>\n<p>理论上霍夫变换可以检测任何形状，但复杂的形状需要的参数就多，霍夫空间的维数就多，因此在程序实现上所需的内存空间以及运行效率上都不利于把标准霍夫变换应用于实际复杂图形的检测中。所以一些改进的霍夫变换就相继提出，它们的基本原理就是尽可能减小霍夫空间的维数。</p>\n<p>在OpenCV中，HoughCircles函数实现了圆形检测，它使用的算法也是改进的霍夫变换——2-1霍夫变换（21HT）。也就是把霍夫变换分为两个阶段，从而减小了霍夫空间的维数。第一阶段用于检测圆心，第二阶段从圆心推导出圆半径。<br>检测圆心的原理是圆心是它所在圆周所有法线的交汇处，因此只要找到这个交点，即可确定圆心，该方法所用的霍夫空间与图像空间的性质相同，因此它仅仅是二维空间。检测圆半径的方法是从圆心到圆周上的任意一点的距离（即半径）是相同，只要确定一个阈值，只要相同距离的数量大于该阈值，我们就认为该距离就是该圆心所对应的圆半径，该方法只需要计算半径直方图，不使用霍夫空间。圆和半径知道了，圆自然就能求得。</p>\n<p>21HT的具体步骤:<br>第一阶段：检测圆心</p>\n<p>1.1、对输入图像边缘检测；</p>\n<p>1.2、计算图形的梯度，并确定圆周线，其中圆周的梯度就是它的法线；</p>\n<p>1.3、在二维霍夫空间内，绘出所有图形的梯度直线，某坐标点上累加和的值越大，说明在该点上直线相交的次数越多，也就是越有可能是圆心；</p>\n<p>1.4、在霍夫空间的4邻域内进行非最大值抑制；</p>\n<p>1.5、设定一个阈值，霍夫空间内累加和大于该阈值的点就对应于圆心。</p>\n<p>第二阶段：检测圆半径</p>\n<p>2.1、计算某一个圆心到所有圆周线的距离，这些距离中就有该圆心所对应的圆的半径的值，这些半径值当然是相等的，并且这些圆半径的数量要远远大于其他距离值相等的数量；</p>\n<p>2.2、设定两个阈值，定义为最大半径和最小半径，保留距离在这两个半径之间的值，这意味着我们检测的圆不能太大，也不能太小；</p>\n<p>2.3、对保留下来的距离进行排序；</p>\n<p>2.4、找到距离相同的那些值，并计算相同值的数量；</p>\n<p>2.5、设定一个阈值，只有相同值的数量大于该阈值，才认为该值是该圆心对应的圆半径；</p>\n<p>2.6、对每一个圆心，完成上面的2.1～2.5步骤，得到所有的圆半径。</p>\n<p>HoughCircles函数的原型为：<br>void HoughCircles(InputArray image,OutputArray circles, int method, double dp, double minDist, double param1=100, double param2=100, int minRadius=0,int maxRadius=0 )<br>image为输入图像，要求是灰度图像<br>circles为输出圆向量，每个向量包括三个浮点型的元素——圆心横坐标，圆心纵坐标和圆半径<br>method为使用霍夫变换圆检测的算法，Opencv2.4.9只实现了2-1霍夫变换，它的参数是CV_HOUGH_GRADIENT<br>dp为第一阶段所使用的霍夫空间的分辨率，dp=1时表示霍夫空间与输入图像空间的大小一致，dp=2时霍夫空间是输入图像空间的一半，以此类推<br>minDist为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心<br>param1为边缘检测时使用Canny算子的高阈值<br>param2为步骤1.5和步骤2.5中所共有的阈值<br>minRadius和maxRadius为所检测到的圆半径的最小值和最大值</p>\n<h3 id=\"霍夫变换椭圆检测的实现\"><a href=\"#霍夫变换椭圆检测的实现\" class=\"headerlink\" title=\"霍夫变换椭圆检测的实现\"></a>霍夫变换椭圆检测的实现</h3><p>运行环境: vs2017 + Opencv3.4<br>由于HoughCircles函数是调用Canny函数进行边缘检测，OpenCV的Canny函数不包括平滑滤波，所以先对原图进行滤波处理，在这里使用的是高斯模糊</p>\n<pre><code>#include &quot;opencv2/core/core.hpp&quot;\n#include &quot;opencv2/highgui/highgui.hpp&quot;\n#include &quot;opencv2/imgproc/imgproc.hpp&quot;\n#include &lt;iostream&gt;\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n     Mat src, gray;\n    src=imread(&quot;coins.jpg&quot;);\n    if( !src.data )  \n        return -1;  \n\n    cvtColor( src, gray, CV_BGR2GRAY );\n    //高斯模糊平滑\n    GaussianBlur( gray, gray, Size(9, 9), 2, 2 );\n\n    vector&lt;Vec3f&gt; circles;\n    //霍夫变换\n    HoughCircles( gray, circles, CV_HOUGH_GRADIENT, 1, gray.rows/20, 100, 60, 0, 0 );\n\n    //在原图中画出圆心和圆\n    for( size_t i = 0; i &lt; circles.size(); i++ )\n    {\n        //提取出圆心坐标\n        Point center(cvRound(circles[i][0]), cvRound(circles[i][1]));\n        //提取出圆半径\n        int radius = cvRound(circles[i][2]);\n        //圆心\n        circle( src, center, 3, Scalar(0,255,0), -1, 8, 0 );\n        //圆\n        circle( src, center, radius, Scalar(0,0,255), 3, 8, 0 );\n   }\n\n    imshow( &quot;霍夫变换检测圆图&quot;, src );\n\n    waitKey(0);\n    return 0;\n}</code></pre><p>结果:<br><img src=\"https://i.loli.net/2019/07/26/5d3abf54a4c3b88169.jpg\" alt></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"基于霍夫变换的圆形检测\"><a href=\"#基于霍夫变换的圆形检测\" class=\"headerlink\" title=\"基于霍夫变换的圆形检测\"></a>基于霍夫变换的圆形检测</h1><h2 id=\"霍夫变换的原理\"><a href=\"#霍夫变换的原理\" class=\"headerlink\" title=\"霍夫变换的原理\"></a>霍夫变换的原理</h2><p>Hough 变换就是利用图像全局特征将边缘像素连接起来组成区域封闭边界，它将图像空间转换到参数空间，在参数空间对点进行描述，达到检测图像边缘的目的。该方法把所有可能落在边缘上的点进行统计计算，根据对数据的统计结果确定属于边缘的程度。Hough 变换的实质就是对图像进行坐标变换，把平面坐标变换为参数坐标，使变换的结果更易识别和检测。</p>\n<hr>\n<h3 id=\"对霍夫变换圆形检测的原理的理解\"><a href=\"#对霍夫变换圆形检测的原理的理解\" class=\"headerlink\" title=\"对霍夫变换圆形检测的原理的理解:\"></a>对霍夫变换圆形检测的原理的理解:</h3><p>已知圆的一般方程为:<br>$$(x-a)^2 + (y-b)^2 = r^2 $$<br>其中(a,b)代表圆心，r是圆的半径<br>依旧是把图像空间转换成参数空间，这里是将X-Y平面转化成a-b-r参数空间，则在图像空间中的一个过(x,y)点的圆，对应参数空间中高度变化的三维锥面。<br><img src=\"https://i.loli.net/2019/07/26/5d3ab8c50fc2a28962.jpg\" alt><br>同理，过图像空间的任意一点的圆都对应于参数空间的一个三维锥面，因此，过图像空间上同一圆的点，对应的参数空间中的三维锥面，在r平面必然相交于一点(a,b,r)，这样通过这一点就可以得到一个圆的参数。<br><img src=\"https://i.loli.net/2019/07/26/5d3ab8c4d635d79647.jpg\" alt><br>这里霍夫变换的圆检测就是在这三个参数组成的三维空间内进行的<br>换一种理解思路:在笛卡尔坐标下的圆的方程已给出，在极坐标系下，假设圆心为$(x_0,y_0)$,圆上的点可以表示为:<br>$$x = x_0 + rcos\\theta, y = y_0 + rsin\\theta$$<br>对于一个圆，假如中心像素点$(x_0,y_0)$，半径r已知，那么旋转360°，圆上的所有点就可以求得。同样，假如圆上的所有点，半径r已知，旋转360°，则会得到一个累加的极值点，那么这个点就是圆心了。</p>\n<hr>\n<p>理论上霍夫变换可以检测任何形状，但复杂的形状需要的参数就多，霍夫空间的维数就多，因此在程序实现上所需的内存空间以及运行效率上都不利于把标准霍夫变换应用于实际复杂图形的检测中。所以一些改进的霍夫变换就相继提出，它们的基本原理就是尽可能减小霍夫空间的维数。</p>\n<p>在OpenCV中，HoughCircles函数实现了圆形检测，它使用的算法也是改进的霍夫变换——2-1霍夫变换（21HT）。也就是把霍夫变换分为两个阶段，从而减小了霍夫空间的维数。第一阶段用于检测圆心，第二阶段从圆心推导出圆半径。<br>检测圆心的原理是圆心是它所在圆周所有法线的交汇处，因此只要找到这个交点，即可确定圆心，该方法所用的霍夫空间与图像空间的性质相同，因此它仅仅是二维空间。检测圆半径的方法是从圆心到圆周上的任意一点的距离（即半径）是相同，只要确定一个阈值，只要相同距离的数量大于该阈值，我们就认为该距离就是该圆心所对应的圆半径，该方法只需要计算半径直方图，不使用霍夫空间。圆和半径知道了，圆自然就能求得。</p>\n<p>21HT的具体步骤:<br>第一阶段：检测圆心</p>\n<p>1.1、对输入图像边缘检测；</p>\n<p>1.2、计算图形的梯度，并确定圆周线，其中圆周的梯度就是它的法线；</p>\n<p>1.3、在二维霍夫空间内，绘出所有图形的梯度直线，某坐标点上累加和的值越大，说明在该点上直线相交的次数越多，也就是越有可能是圆心；</p>\n<p>1.4、在霍夫空间的4邻域内进行非最大值抑制；</p>\n<p>1.5、设定一个阈值，霍夫空间内累加和大于该阈值的点就对应于圆心。</p>\n<p>第二阶段：检测圆半径</p>\n<p>2.1、计算某一个圆心到所有圆周线的距离，这些距离中就有该圆心所对应的圆的半径的值，这些半径值当然是相等的，并且这些圆半径的数量要远远大于其他距离值相等的数量；</p>\n<p>2.2、设定两个阈值，定义为最大半径和最小半径，保留距离在这两个半径之间的值，这意味着我们检测的圆不能太大，也不能太小；</p>\n<p>2.3、对保留下来的距离进行排序；</p>\n<p>2.4、找到距离相同的那些值，并计算相同值的数量；</p>\n<p>2.5、设定一个阈值，只有相同值的数量大于该阈值，才认为该值是该圆心对应的圆半径；</p>\n<p>2.6、对每一个圆心，完成上面的2.1～2.5步骤，得到所有的圆半径。</p>\n<p>HoughCircles函数的原型为：<br>void HoughCircles(InputArray image,OutputArray circles, int method, double dp, double minDist, double param1=100, double param2=100, int minRadius=0,int maxRadius=0 )<br>image为输入图像，要求是灰度图像<br>circles为输出圆向量，每个向量包括三个浮点型的元素——圆心横坐标，圆心纵坐标和圆半径<br>method为使用霍夫变换圆检测的算法，Opencv2.4.9只实现了2-1霍夫变换，它的参数是CV_HOUGH_GRADIENT<br>dp为第一阶段所使用的霍夫空间的分辨率，dp=1时表示霍夫空间与输入图像空间的大小一致，dp=2时霍夫空间是输入图像空间的一半，以此类推<br>minDist为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心<br>param1为边缘检测时使用Canny算子的高阈值<br>param2为步骤1.5和步骤2.5中所共有的阈值<br>minRadius和maxRadius为所检测到的圆半径的最小值和最大值</p>\n<h3 id=\"霍夫变换椭圆检测的实现\"><a href=\"#霍夫变换椭圆检测的实现\" class=\"headerlink\" title=\"霍夫变换椭圆检测的实现\"></a>霍夫变换椭圆检测的实现</h3><p>运行环境: vs2017 + Opencv3.4<br>由于HoughCircles函数是调用Canny函数进行边缘检测，OpenCV的Canny函数不包括平滑滤波，所以先对原图进行滤波处理，在这里使用的是高斯模糊</p>\n<pre><code>#include &quot;opencv2/core/core.hpp&quot;\n#include &quot;opencv2/highgui/highgui.hpp&quot;\n#include &quot;opencv2/imgproc/imgproc.hpp&quot;\n#include &lt;iostream&gt;\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n     Mat src, gray;\n    src=imread(&quot;coins.jpg&quot;);\n    if( !src.data )  \n        return -1;  \n\n    cvtColor( src, gray, CV_BGR2GRAY );\n    //高斯模糊平滑\n    GaussianBlur( gray, gray, Size(9, 9), 2, 2 );\n\n    vector&lt;Vec3f&gt; circles;\n    //霍夫变换\n    HoughCircles( gray, circles, CV_HOUGH_GRADIENT, 1, gray.rows/20, 100, 60, 0, 0 );\n\n    //在原图中画出圆心和圆\n    for( size_t i = 0; i &lt; circles.size(); i++ )\n    {\n        //提取出圆心坐标\n        Point center(cvRound(circles[i][0]), cvRound(circles[i][1]));\n        //提取出圆半径\n        int radius = cvRound(circles[i][2]);\n        //圆心\n        circle( src, center, 3, Scalar(0,255,0), -1, 8, 0 );\n        //圆\n        circle( src, center, radius, Scalar(0,0,255), 3, 8, 0 );\n   }\n\n    imshow( &quot;霍夫变换检测圆图&quot;, src );\n\n    waitKey(0);\n    return 0;\n}</code></pre><p>结果:<br><img src=\"https://i.loli.net/2019/07/26/5d3abf54a4c3b88169.jpg\" alt></p>\n"},{"title":"Day14","date":"2019-07-27T17:51:51.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# High-quality-ellipse-detection\n\n高精度椭圆检测    \n参考[High-quality-ellipse-detection](https://github.com/AlanLuSun/High-quality-ellipse-detection)\n\n关于椭圆检测的部分，实在是看不懂，我只做了得到椭圆参数绘制椭圆的部分\n\n## OpenCV椭圆绘制\n\n### ellipse函数\n\n语法\n\n```\nvoid cvEllipse( CvArr* img, CvPoint center, CvSize axes, double angle,\n                double start_angle, double end_angle, CvScalar color,\n                int thickness=1, int line_type=8, int shift=0 );\n```\n参数:    \nimg:图像。    \ncenter:椭圆圆心坐标。    \naxes:轴的长度。    \nangle:偏转的角度。    \nstart_angle:圆弧起始角的角度。    \nend_angle:圆弧终结角的角度。    \ncolor:线条的颜色。    \nthickness:线条的粗细程度。    \nline_type:线条的类型,见CVLINE的描述。    \nshift:圆心坐标点和数轴的精度。    \n\nC++代码实现\n```C++\n#include<opencv2/opencv.hpp>#include<opencv2/core/core.hpp> // 核心组件\n#include<opencv2/highgui/highgui.hpp>  // GUI\n#include<opencv2/imgproc/imgproc.hpp>  // 图像处理\nusing namespace cv;\nusing namespace std;\n// 定义存储椭圆参数的数据结构\nstruct Ellipse {\n\tint x0, y0, a, b;\n\tdouble alpha;\n};\nint drawEllipse(Ellipse ellipses_para, Mat im);\nint drawEllipse(Ellipse ellipses_para, Mat im) {\n// Draw Ellipse after detection\n//x0 - x coordinate of the center of the ellipse\n//y0 - y coordinate of the center of the ellipse\n//a - length of semimajor axis\n//b - length of semiminor axis\n//alpha - angle of orientation of semimajor axis\n\tif (im.empty()) {\n\t\tprintf(\"imread error!\");\n\t\treturn -1;\n\t}\n\tint x0, y0, a, b;\n\tdouble alpha;\n\tint thickness = 3;\n\tint lineType = 8;\n\tx0 = ellipses_para.x0;\n\ty0 = ellipses_para.y0;\n\ta = ellipses_para.a;\n\tb = ellipses_para.b;\n\talpha = ellipses_para.alpha;\n\tellipse(im, Point(x0, y0), Size(a, b), alpha, 0, 360, Scalar(255, 255, 0), thickness, lineType);\n\timshow(\"原图\", im);\n\twaitKey();}\nint main() {\n\tEllipse ellipses_para;\n\tMat im = imread(\"11.bmp\");\n\t/*test\n        ellipses_para.x0 = 100;\n\tellipses_para.y0 = 100;\n\tellipses_para.a = 90;\n\tellipses_para.b = 60;\n\tellipses_para.alpha = 80.0;*/\n\tdrawEllipse(ellipses_para, im);\n\treturn 0;\n}\n\n```\n\n\n","source":"_posts/Day14.md","raw":"---\ntitle: Day14\ndate: 2019-07-28 01:51:51\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# High-quality-ellipse-detection\n\n高精度椭圆检测    \n参考[High-quality-ellipse-detection](https://github.com/AlanLuSun/High-quality-ellipse-detection)\n\n关于椭圆检测的部分，实在是看不懂，我只做了得到椭圆参数绘制椭圆的部分\n\n## OpenCV椭圆绘制\n\n### ellipse函数\n\n语法\n\n```\nvoid cvEllipse( CvArr* img, CvPoint center, CvSize axes, double angle,\n                double start_angle, double end_angle, CvScalar color,\n                int thickness=1, int line_type=8, int shift=0 );\n```\n参数:    \nimg:图像。    \ncenter:椭圆圆心坐标。    \naxes:轴的长度。    \nangle:偏转的角度。    \nstart_angle:圆弧起始角的角度。    \nend_angle:圆弧终结角的角度。    \ncolor:线条的颜色。    \nthickness:线条的粗细程度。    \nline_type:线条的类型,见CVLINE的描述。    \nshift:圆心坐标点和数轴的精度。    \n\nC++代码实现\n```C++\n#include<opencv2/opencv.hpp>#include<opencv2/core/core.hpp> // 核心组件\n#include<opencv2/highgui/highgui.hpp>  // GUI\n#include<opencv2/imgproc/imgproc.hpp>  // 图像处理\nusing namespace cv;\nusing namespace std;\n// 定义存储椭圆参数的数据结构\nstruct Ellipse {\n\tint x0, y0, a, b;\n\tdouble alpha;\n};\nint drawEllipse(Ellipse ellipses_para, Mat im);\nint drawEllipse(Ellipse ellipses_para, Mat im) {\n// Draw Ellipse after detection\n//x0 - x coordinate of the center of the ellipse\n//y0 - y coordinate of the center of the ellipse\n//a - length of semimajor axis\n//b - length of semiminor axis\n//alpha - angle of orientation of semimajor axis\n\tif (im.empty()) {\n\t\tprintf(\"imread error!\");\n\t\treturn -1;\n\t}\n\tint x0, y0, a, b;\n\tdouble alpha;\n\tint thickness = 3;\n\tint lineType = 8;\n\tx0 = ellipses_para.x0;\n\ty0 = ellipses_para.y0;\n\ta = ellipses_para.a;\n\tb = ellipses_para.b;\n\talpha = ellipses_para.alpha;\n\tellipse(im, Point(x0, y0), Size(a, b), alpha, 0, 360, Scalar(255, 255, 0), thickness, lineType);\n\timshow(\"原图\", im);\n\twaitKey();}\nint main() {\n\tEllipse ellipses_para;\n\tMat im = imread(\"11.bmp\");\n\t/*test\n        ellipses_para.x0 = 100;\n\tellipses_para.y0 = 100;\n\tellipses_para.a = 90;\n\tellipses_para.b = 60;\n\tellipses_para.alpha = 80.0;*/\n\tdrawEllipse(ellipses_para, im);\n\treturn 0;\n}\n\n```\n\n\n","slug":"Day14","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltd000pe5g67w5w6u9n","content":"<h1 id=\"High-quality-ellipse-detection\"><a href=\"#High-quality-ellipse-detection\" class=\"headerlink\" title=\"High-quality-ellipse-detection\"></a>High-quality-ellipse-detection</h1><p>高精度椭圆检测<br>参考<a href=\"https://github.com/AlanLuSun/High-quality-ellipse-detection\" target=\"_blank\" rel=\"noopener\">High-quality-ellipse-detection</a></p>\n<p>关于椭圆检测的部分，实在是看不懂，我只做了得到椭圆参数绘制椭圆的部分</p>\n<h2 id=\"OpenCV椭圆绘制\"><a href=\"#OpenCV椭圆绘制\" class=\"headerlink\" title=\"OpenCV椭圆绘制\"></a>OpenCV椭圆绘制</h2><h3 id=\"ellipse函数\"><a href=\"#ellipse函数\" class=\"headerlink\" title=\"ellipse函数\"></a>ellipse函数</h3><p>语法</p>\n<pre><code>void cvEllipse( CvArr* img, CvPoint center, CvSize axes, double angle,\n                double start_angle, double end_angle, CvScalar color,\n                int thickness=1, int line_type=8, int shift=0 );</code></pre><p>参数:<br>img:图像。<br>center:椭圆圆心坐标。<br>axes:轴的长度。<br>angle:偏转的角度。<br>start_angle:圆弧起始角的角度。<br>end_angle:圆弧终结角的角度。<br>color:线条的颜色。<br>thickness:线条的粗细程度。<br>line_type:线条的类型,见CVLINE的描述。<br>shift:圆心坐标点和数轴的精度。    </p>\n<p>C++代码实现</p>\n<pre class=\" language-C++\"><code class=\"language-C++\">#include<opencv2/opencv.hpp>#include<opencv2/core/core.hpp> // 核心组件\n#include<opencv2/highgui/highgui.hpp>  // GUI\n#include<opencv2/imgproc/imgproc.hpp>  // 图像处理\nusing namespace cv;\nusing namespace std;\n// 定义存储椭圆参数的数据结构\nstruct Ellipse {\n    int x0, y0, a, b;\n    double alpha;\n};\nint drawEllipse(Ellipse ellipses_para, Mat im);\nint drawEllipse(Ellipse ellipses_para, Mat im) {\n// Draw Ellipse after detection\n//x0 - x coordinate of the center of the ellipse\n//y0 - y coordinate of the center of the ellipse\n//a - length of semimajor axis\n//b - length of semiminor axis\n//alpha - angle of orientation of semimajor axis\n    if (im.empty()) {\n        printf(\"imread error!\");\n        return -1;\n    }\n    int x0, y0, a, b;\n    double alpha;\n    int thickness = 3;\n    int lineType = 8;\n    x0 = ellipses_para.x0;\n    y0 = ellipses_para.y0;\n    a = ellipses_para.a;\n    b = ellipses_para.b;\n    alpha = ellipses_para.alpha;\n    ellipse(im, Point(x0, y0), Size(a, b), alpha, 0, 360, Scalar(255, 255, 0), thickness, lineType);\n    imshow(\"原图\", im);\n    waitKey();}\nint main() {\n    Ellipse ellipses_para;\n    Mat im = imread(\"11.bmp\");\n    /*test\n        ellipses_para.x0 = 100;\n    ellipses_para.y0 = 100;\n    ellipses_para.a = 90;\n    ellipses_para.b = 60;\n    ellipses_para.alpha = 80.0;*/\n    drawEllipse(ellipses_para, im);\n    return 0;\n}\n</code></pre>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"High-quality-ellipse-detection\"><a href=\"#High-quality-ellipse-detection\" class=\"headerlink\" title=\"High-quality-ellipse-detection\"></a>High-quality-ellipse-detection</h1><p>高精度椭圆检测<br>参考<a href=\"https://github.com/AlanLuSun/High-quality-ellipse-detection\" target=\"_blank\" rel=\"noopener\">High-quality-ellipse-detection</a></p>\n<p>关于椭圆检测的部分，实在是看不懂，我只做了得到椭圆参数绘制椭圆的部分</p>\n<h2 id=\"OpenCV椭圆绘制\"><a href=\"#OpenCV椭圆绘制\" class=\"headerlink\" title=\"OpenCV椭圆绘制\"></a>OpenCV椭圆绘制</h2><h3 id=\"ellipse函数\"><a href=\"#ellipse函数\" class=\"headerlink\" title=\"ellipse函数\"></a>ellipse函数</h3><p>语法</p>\n<pre><code>void cvEllipse( CvArr* img, CvPoint center, CvSize axes, double angle,\n                double start_angle, double end_angle, CvScalar color,\n                int thickness=1, int line_type=8, int shift=0 );</code></pre><p>参数:<br>img:图像。<br>center:椭圆圆心坐标。<br>axes:轴的长度。<br>angle:偏转的角度。<br>start_angle:圆弧起始角的角度。<br>end_angle:圆弧终结角的角度。<br>color:线条的颜色。<br>thickness:线条的粗细程度。<br>line_type:线条的类型,见CVLINE的描述。<br>shift:圆心坐标点和数轴的精度。    </p>\n<p>C++代码实现</p>\n<pre><code class=\"C++\">#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/core/core.hpp&gt; // 核心组件\n#include&lt;opencv2/highgui/highgui.hpp&gt;  // GUI\n#include&lt;opencv2/imgproc/imgproc.hpp&gt;  // 图像处理\nusing namespace cv;\nusing namespace std;\n// 定义存储椭圆参数的数据结构\nstruct Ellipse {\n    int x0, y0, a, b;\n    double alpha;\n};\nint drawEllipse(Ellipse ellipses_para, Mat im);\nint drawEllipse(Ellipse ellipses_para, Mat im) {\n// Draw Ellipse after detection\n//x0 - x coordinate of the center of the ellipse\n//y0 - y coordinate of the center of the ellipse\n//a - length of semimajor axis\n//b - length of semiminor axis\n//alpha - angle of orientation of semimajor axis\n    if (im.empty()) {\n        printf(&quot;imread error!&quot;);\n        return -1;\n    }\n    int x0, y0, a, b;\n    double alpha;\n    int thickness = 3;\n    int lineType = 8;\n    x0 = ellipses_para.x0;\n    y0 = ellipses_para.y0;\n    a = ellipses_para.a;\n    b = ellipses_para.b;\n    alpha = ellipses_para.alpha;\n    ellipse(im, Point(x0, y0), Size(a, b), alpha, 0, 360, Scalar(255, 255, 0), thickness, lineType);\n    imshow(&quot;原图&quot;, im);\n    waitKey();}\nint main() {\n    Ellipse ellipses_para;\n    Mat im = imread(&quot;11.bmp&quot;);\n    /*test\n        ellipses_para.x0 = 100;\n    ellipses_para.y0 = 100;\n    ellipses_para.a = 90;\n    ellipses_para.b = 60;\n    ellipses_para.alpha = 80.0;*/\n    drawEllipse(ellipses_para, im);\n    return 0;\n}\n</code></pre>\n"},{"title":"Day16","date":"2019-07-30T02:04:11.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# 装环境，转战Ubuntu\n\n有空写教程\n![](https://i.loli.net/2019/07/31/5d41343d2fc3746297.png)\n\n\n\n","source":"_posts/Day16.md","raw":"---\ntitle: Day16\ndate: 2019-07-30 10:04:11\ntags: 实习\ncategories:\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# 装环境，转战Ubuntu\n\n有空写教程\n![](https://i.loli.net/2019/07/31/5d41343d2fc3746297.png)\n\n\n\n","slug":"Day16","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lte000re5g61q774frn","content":"<h1 id=\"装环境，转战Ubuntu\"><a href=\"#装环境，转战Ubuntu\" class=\"headerlink\" title=\"装环境，转战Ubuntu\"></a>装环境，转战Ubuntu</h1><p>有空写教程<br><img src=\"https://i.loli.net/2019/07/31/5d41343d2fc3746297.png\" alt></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"装环境，转战Ubuntu\"><a href=\"#装环境，转战Ubuntu\" class=\"headerlink\" title=\"装环境，转战Ubuntu\"></a>装环境，转战Ubuntu</h1><p>有空写教程<br><img src=\"https://i.loli.net/2019/07/31/5d41343d2fc3746297.png\" alt></p>\n"},{"title":"Day15","date":"2019-07-29T15:49:49.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# High-quality-ellipse-detection\n\n[High-quality-ellipse-detection　Github传送门](https://github.com/AlanLuSun/High-quality-ellipse-detection)\n\n个人环境:Matlab 2019a、VS2017、Opencv3.4.4，64位Windows操作系统\n\n## OpenCV环境配置请看这篇\n[OpenCV入坑指南:环境搭建篇](https://kevinnnm.github.io/2019/07/25/OpenCV%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%AF%87/)\n## MatLab和C++混合编程环境配置\n\nMatlab的安装这里不再说    \n1. 在命令行里输入 `mex -setup`，选择vs就行了\n2. 执行 `mex -setup C++`完成配置\n![](https://i.loli.net/2019/07/29/5d3ea6561215b10575.png)\n![](https://i.loli.net/2019/07/29/5d3eaa19b300f42041.png)\n\n## 下载Github文件\n\ndownload Zip即可\n\n\n## 导入依赖文件\n\n将 **D:\\OpenCV\\opencv\\build\\x64\\vc15\\lib**下的 **opencv_world344.lib**文件复制到你的Matlab安装路径下的 **microsoft**文件夹下,我的是 **D:\\MATLAB\\R2019a\\extern\\lib\\win64\\microsoft**\n\n![](https://i.loli.net/2019/07/29/5d3ea6564f0b271051.png)\n![](https://i.loli.net/2019/07/29/5d3ea6564ed8016435.png)\n## 在Matlab中导入文件\n\n## 在命令行执行以下命令\n\n注意作者的命令为:\n\n```\nmex generateEllipseCandidates.cpp -IF:\\OpenCV\\opencv2.4.9\\build\\include -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv2 -LF:\\OpenCV\\opencv2.4.9\\build\\x64\\vc11\\lib -IF:\\Matlab\\settlein\\extern\\include -LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib\n```\n把OpenCV和Matlab的相关文件的路径改成你的安装路径    \n我这里版本号为OpenCV3.4.4,安装路径如下,\n![](https://i.loli.net/2019/07/29/5d3ea6561fbd474647.png)\n故修改为`D:\\OpenCV\\opencv\\build...`,    \n由于OpenCV3.4.4只有 **opencv_world344.lib** 这一个lib文件，故将 `LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib`　修改为 `LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib`\n\n完整的命令为:\n```\nmex generateEllipseCandidates.cpp -ID:\\OpenCV\\opencv\\build\\include \n-ID:\\OpenCV\\opencv\\build\\include\\opencv -ID:\\OpenCV\\opencv\\build\\include\\opencv2 \n-LD:\\OpenCV\\opencv\\build\\x64\\vc15\\lib \n-ID:\\Matlab\\R2019a\\include -LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib\n\n```\n![](https://i.loli.net/2019/07/29/5d3ea65639bdf67747.png)\n编译成功之后生成`generateEllipseCandidates.mexw64`文件\n![](https://i.loli.net/2019/07/29/5d3ea6564e0c183020.png)\n之后再运行`LCS_ellipse.m`\n![7.png](https://i.loli.net/2019/07/29/5d3ea657cb9e659639.png)\n\n##　报错解决办法\n1. 如图\n![](https://i.loli.net/2019/07/29/5d3eabf1c942443319.png)\n在.cpp文件中添加\n```C++\nusing namespace std\n```\n2. 如图\n\n![](https://i.loli.net/2019/07/29/5d3eabf1d457769964.png)\n缺少lib文件，检查一下是不是配置出错了\n","source":"_posts/Day15.md","raw":"---\ntitle: Day15\ndate: 2019-07-29 23:49:49\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# High-quality-ellipse-detection\n\n[High-quality-ellipse-detection　Github传送门](https://github.com/AlanLuSun/High-quality-ellipse-detection)\n\n个人环境:Matlab 2019a、VS2017、Opencv3.4.4，64位Windows操作系统\n\n## OpenCV环境配置请看这篇\n[OpenCV入坑指南:环境搭建篇](https://kevinnnm.github.io/2019/07/25/OpenCV%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%AF%87/)\n## MatLab和C++混合编程环境配置\n\nMatlab的安装这里不再说    \n1. 在命令行里输入 `mex -setup`，选择vs就行了\n2. 执行 `mex -setup C++`完成配置\n![](https://i.loli.net/2019/07/29/5d3ea6561215b10575.png)\n![](https://i.loli.net/2019/07/29/5d3eaa19b300f42041.png)\n\n## 下载Github文件\n\ndownload Zip即可\n\n\n## 导入依赖文件\n\n将 **D:\\OpenCV\\opencv\\build\\x64\\vc15\\lib**下的 **opencv_world344.lib**文件复制到你的Matlab安装路径下的 **microsoft**文件夹下,我的是 **D:\\MATLAB\\R2019a\\extern\\lib\\win64\\microsoft**\n\n![](https://i.loli.net/2019/07/29/5d3ea6564f0b271051.png)\n![](https://i.loli.net/2019/07/29/5d3ea6564ed8016435.png)\n## 在Matlab中导入文件\n\n## 在命令行执行以下命令\n\n注意作者的命令为:\n\n```\nmex generateEllipseCandidates.cpp -IF:\\OpenCV\\opencv2.4.9\\build\\include -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv2 -LF:\\OpenCV\\opencv2.4.9\\build\\x64\\vc11\\lib -IF:\\Matlab\\settlein\\extern\\include -LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib\n```\n把OpenCV和Matlab的相关文件的路径改成你的安装路径    \n我这里版本号为OpenCV3.4.4,安装路径如下,\n![](https://i.loli.net/2019/07/29/5d3ea6561fbd474647.png)\n故修改为`D:\\OpenCV\\opencv\\build...`,    \n由于OpenCV3.4.4只有 **opencv_world344.lib** 这一个lib文件，故将 `LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib`　修改为 `LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib`\n\n完整的命令为:\n```\nmex generateEllipseCandidates.cpp -ID:\\OpenCV\\opencv\\build\\include \n-ID:\\OpenCV\\opencv\\build\\include\\opencv -ID:\\OpenCV\\opencv\\build\\include\\opencv2 \n-LD:\\OpenCV\\opencv\\build\\x64\\vc15\\lib \n-ID:\\Matlab\\R2019a\\include -LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib\n\n```\n![](https://i.loli.net/2019/07/29/5d3ea65639bdf67747.png)\n编译成功之后生成`generateEllipseCandidates.mexw64`文件\n![](https://i.loli.net/2019/07/29/5d3ea6564e0c183020.png)\n之后再运行`LCS_ellipse.m`\n![7.png](https://i.loli.net/2019/07/29/5d3ea657cb9e659639.png)\n\n##　报错解决办法\n1. 如图\n![](https://i.loli.net/2019/07/29/5d3eabf1c942443319.png)\n在.cpp文件中添加\n```C++\nusing namespace std\n```\n2. 如图\n\n![](https://i.loli.net/2019/07/29/5d3eabf1d457769964.png)\n缺少lib文件，检查一下是不是配置出错了\n","slug":"Day15","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltf000te5g6ecx0hxrh","content":"<h1 id=\"High-quality-ellipse-detection\"><a href=\"#High-quality-ellipse-detection\" class=\"headerlink\" title=\"High-quality-ellipse-detection\"></a>High-quality-ellipse-detection</h1><p><a href=\"https://github.com/AlanLuSun/High-quality-ellipse-detection\" target=\"_blank\" rel=\"noopener\">High-quality-ellipse-detection　Github传送门</a></p>\n<p>个人环境:Matlab 2019a、VS2017、Opencv3.4.4，64位Windows操作系统</p>\n<h2 id=\"OpenCV环境配置请看这篇\"><a href=\"#OpenCV环境配置请看这篇\" class=\"headerlink\" title=\"OpenCV环境配置请看这篇\"></a>OpenCV环境配置请看这篇</h2><p><a href=\"https://kevinnnm.github.io/2019/07/25/OpenCV%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%AF%87/\" target=\"_blank\" rel=\"noopener\">OpenCV入坑指南:环境搭建篇</a></p>\n<h2 id=\"MatLab和C-混合编程环境配置\"><a href=\"#MatLab和C-混合编程环境配置\" class=\"headerlink\" title=\"MatLab和C++混合编程环境配置\"></a>MatLab和C++混合编程环境配置</h2><p>Matlab的安装这里不再说    </p>\n<ol>\n<li>在命令行里输入 <code>mex -setup</code>，选择vs就行了</li>\n<li>执行 <code>mex -setup C++</code>完成配置<br><img src=\"https://i.loli.net/2019/07/29/5d3ea6561215b10575.png\" alt><br><img src=\"https://i.loli.net/2019/07/29/5d3eaa19b300f42041.png\" alt></li>\n</ol>\n<h2 id=\"下载Github文件\"><a href=\"#下载Github文件\" class=\"headerlink\" title=\"下载Github文件\"></a>下载Github文件</h2><p>download Zip即可</p>\n<h2 id=\"导入依赖文件\"><a href=\"#导入依赖文件\" class=\"headerlink\" title=\"导入依赖文件\"></a>导入依赖文件</h2><p>将 <strong>D:\\OpenCV\\opencv\\build\\x64\\vc15\\lib</strong>下的 <strong>opencv_world344.lib</strong>文件复制到你的Matlab安装路径下的 <strong>microsoft</strong>文件夹下,我的是 <strong>D:\\MATLAB\\R2019a\\extern\\lib\\win64\\microsoft</strong></p>\n<p><img src=\"https://i.loli.net/2019/07/29/5d3ea6564f0b271051.png\" alt><br><img src=\"https://i.loli.net/2019/07/29/5d3ea6564ed8016435.png\" alt></p>\n<h2 id=\"在Matlab中导入文件\"><a href=\"#在Matlab中导入文件\" class=\"headerlink\" title=\"在Matlab中导入文件\"></a>在Matlab中导入文件</h2><h2 id=\"在命令行执行以下命令\"><a href=\"#在命令行执行以下命令\" class=\"headerlink\" title=\"在命令行执行以下命令\"></a>在命令行执行以下命令</h2><p>注意作者的命令为:</p>\n<pre><code>mex generateEllipseCandidates.cpp -IF:\\OpenCV\\opencv2.4.9\\build\\include -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv2 -LF:\\OpenCV\\opencv2.4.9\\build\\x64\\vc11\\lib -IF:\\Matlab\\settlein\\extern\\include -LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib</code></pre><p>把OpenCV和Matlab的相关文件的路径改成你的安装路径<br>我这里版本号为OpenCV3.4.4,安装路径如下,<br><img src=\"https://i.loli.net/2019/07/29/5d3ea6561fbd474647.png\" alt><br>故修改为<code>D:\\OpenCV\\opencv\\build...</code>,<br>由于OpenCV3.4.4只有 <strong>opencv_world344.lib</strong> 这一个lib文件，故将 <code>LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib</code>　修改为 <code>LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib</code></p>\n<p>完整的命令为:</p>\n<pre><code>mex generateEllipseCandidates.cpp -ID:\\OpenCV\\opencv\\build\\include \n-ID:\\OpenCV\\opencv\\build\\include\\opencv -ID:\\OpenCV\\opencv\\build\\include\\opencv2 \n-LD:\\OpenCV\\opencv\\build\\x64\\vc15\\lib \n-ID:\\Matlab\\R2019a\\include -LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib\n</code></pre><p><img src=\"https://i.loli.net/2019/07/29/5d3ea65639bdf67747.png\" alt><br>编译成功之后生成<code>generateEllipseCandidates.mexw64</code>文件<br><img src=\"https://i.loli.net/2019/07/29/5d3ea6564e0c183020.png\" alt><br>之后再运行<code>LCS_ellipse.m</code><br><img src=\"https://i.loli.net/2019/07/29/5d3ea657cb9e659639.png\" alt=\"7.png\"></p>\n<p>##　报错解决办法</p>\n<ol>\n<li>如图<br><img src=\"https://i.loli.net/2019/07/29/5d3eabf1c942443319.png\" alt><br>在.cpp文件中添加<pre class=\" language-C++\"><code class=\"language-C++\">using namespace std</code></pre>\n</li>\n<li>如图</li>\n</ol>\n<p><img src=\"https://i.loli.net/2019/07/29/5d3eabf1d457769964.png\" alt><br>缺少lib文件，检查一下是不是配置出错了</p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"High-quality-ellipse-detection\"><a href=\"#High-quality-ellipse-detection\" class=\"headerlink\" title=\"High-quality-ellipse-detection\"></a>High-quality-ellipse-detection</h1><p><a href=\"https://github.com/AlanLuSun/High-quality-ellipse-detection\" target=\"_blank\" rel=\"noopener\">High-quality-ellipse-detection　Github传送门</a></p>\n<p>个人环境:Matlab 2019a、VS2017、Opencv3.4.4，64位Windows操作系统</p>\n<h2 id=\"OpenCV环境配置请看这篇\"><a href=\"#OpenCV环境配置请看这篇\" class=\"headerlink\" title=\"OpenCV环境配置请看这篇\"></a>OpenCV环境配置请看这篇</h2><p><a href=\"https://kevinnnm.github.io/2019/07/25/OpenCV%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%AF%87/\" target=\"_blank\" rel=\"noopener\">OpenCV入坑指南:环境搭建篇</a></p>\n<h2 id=\"MatLab和C-混合编程环境配置\"><a href=\"#MatLab和C-混合编程环境配置\" class=\"headerlink\" title=\"MatLab和C++混合编程环境配置\"></a>MatLab和C++混合编程环境配置</h2><p>Matlab的安装这里不再说    </p>\n<ol>\n<li>在命令行里输入 <code>mex -setup</code>，选择vs就行了</li>\n<li>执行 <code>mex -setup C++</code>完成配置<br><img src=\"https://i.loli.net/2019/07/29/5d3ea6561215b10575.png\" alt><br><img src=\"https://i.loli.net/2019/07/29/5d3eaa19b300f42041.png\" alt></li>\n</ol>\n<h2 id=\"下载Github文件\"><a href=\"#下载Github文件\" class=\"headerlink\" title=\"下载Github文件\"></a>下载Github文件</h2><p>download Zip即可</p>\n<h2 id=\"导入依赖文件\"><a href=\"#导入依赖文件\" class=\"headerlink\" title=\"导入依赖文件\"></a>导入依赖文件</h2><p>将 <strong>D:\\OpenCV\\opencv\\build\\x64\\vc15\\lib</strong>下的 <strong>opencv_world344.lib</strong>文件复制到你的Matlab安装路径下的 <strong>microsoft</strong>文件夹下,我的是 <strong>D:\\MATLAB\\R2019a\\extern\\lib\\win64\\microsoft</strong></p>\n<p><img src=\"https://i.loli.net/2019/07/29/5d3ea6564f0b271051.png\" alt><br><img src=\"https://i.loli.net/2019/07/29/5d3ea6564ed8016435.png\" alt></p>\n<h2 id=\"在Matlab中导入文件\"><a href=\"#在Matlab中导入文件\" class=\"headerlink\" title=\"在Matlab中导入文件\"></a>在Matlab中导入文件</h2><h2 id=\"在命令行执行以下命令\"><a href=\"#在命令行执行以下命令\" class=\"headerlink\" title=\"在命令行执行以下命令\"></a>在命令行执行以下命令</h2><p>注意作者的命令为:</p>\n<pre><code>mex generateEllipseCandidates.cpp -IF:\\OpenCV\\opencv2.4.9\\build\\include -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv -IF:\\OpenCV\\opencv2.4.9\\build\\include\\opencv2 -LF:\\OpenCV\\opencv2.4.9\\build\\x64\\vc11\\lib -IF:\\Matlab\\settlein\\extern\\include -LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib</code></pre><p>把OpenCV和Matlab的相关文件的路径改成你的安装路径<br>我这里版本号为OpenCV3.4.4,安装路径如下,<br><img src=\"https://i.loli.net/2019/07/29/5d3ea6561fbd474647.png\" alt><br>故修改为<code>D:\\OpenCV\\opencv\\build...</code>,<br>由于OpenCV3.4.4只有 <strong>opencv_world344.lib</strong> 这一个lib文件，故将 <code>LF:\\Matlab\\settlein\\extern\\lib\\win64\\microsoft -lopencv_core249 -lopencv_highgui249 -lopencv_imgproc249 -llibmwlapack.lib</code>　修改为 <code>LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib</code></p>\n<p>完整的命令为:</p>\n<pre><code>mex generateEllipseCandidates.cpp -ID:\\OpenCV\\opencv\\build\\include \n-ID:\\OpenCV\\opencv\\build\\include\\opencv -ID:\\OpenCV\\opencv\\build\\include\\opencv2 \n-LD:\\OpenCV\\opencv\\build\\x64\\vc15\\lib \n-ID:\\Matlab\\R2019a\\include -LD:\\Matlab\\R2019a\\extern\\lib\\win64\\microsoft -lopencv_world344 -llibmwlapack.lib\n</code></pre><p><img src=\"https://i.loli.net/2019/07/29/5d3ea65639bdf67747.png\" alt><br>编译成功之后生成<code>generateEllipseCandidates.mexw64</code>文件<br><img src=\"https://i.loli.net/2019/07/29/5d3ea6564e0c183020.png\" alt><br>之后再运行<code>LCS_ellipse.m</code><br><img src=\"https://i.loli.net/2019/07/29/5d3ea657cb9e659639.png\" alt=\"7.png\"></p>\n<p>##　报错解决办法</p>\n<ol>\n<li>如图<br><img src=\"https://i.loli.net/2019/07/29/5d3eabf1c942443319.png\" alt><br>在.cpp文件中添加<pre><code class=\"C++\">using namespace std</code></pre>\n</li>\n<li>如图</li>\n</ol>\n<p><img src=\"https://i.loli.net/2019/07/29/5d3eabf1d457769964.png\" alt><br>缺少lib文件，检查一下是不是配置出错了</p>\n"},{"title":"Day17","date":"2019-07-31T02:05:48.000Z","cover":false,"mathjax":true,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# LBP算法\n\nLBP（Local Binary Patterns，局部二值模式）是一种能够有效地度量和提取图像局部纹理信息的算子，具有旋转不变性和灰度不变性等显著的优点。它是人脸识别中一种提取特征的重要方法，具有对光照不敏感的特性，但是对姿态和表情的鲁棒性不强。\n## 纹理\n\n纹理是由于物体表面物理属性不同所引起的能够表示某个特定表面特征的灰度或颜色信息。纹理反映了图像灰度模式的空间分布，包含了图像的表面信息及其周围环境的关系。\n\n## 基本的LBP算子\n\n局部二值模式是一种灰度范围内的纹理描述方式。最初的LBP算子定义在一个3×3的窗口，以窗口中心像素点为阈值，将相邻的像素的灰度值与其进行比较，若周围的像素值大于中心点的值，则将该像素位置标记为1,否则为0.这样一个3×3邻域内的8个点可产生一个8-bit的无符号数，再按其位置赋予不同权重求和得一整数，即可得到该窗口的 **LBP** 值，并用这个数反映该区域的纹理信息。    \n对比度分量C是邻域中所有大于和等于中心点像素的均值与所有小于中心点像素的均值之差。    \n![](https://i.loli.net/2019/07/31/5d415779ca87257597.jpg)\n\n基本的LBP算子最大的缺陷是只覆盖了一个固定半径范围内的小区域，改进的LBP算子，将3×3邻域扩展到任意邻域，用圆形邻域代替了正方形邻域，该算子允许在半径为R的圆形邻域内有任意多个像素点。\n- 一个局部区域的纹理分布可假设为局部区域内像素灰度的联合分布密度\n$$T = t(g_c,g_0, ....,g_{p-1})$$\n$g_c$表示局部区域的中心点的灰度值,$g_p(p=0,1,...,p)$对应中心点周围等距分布的P个点\n- 采用 **双线性插算法** 对没有完全落在像素位置的点计算灰度值。邻域内的$g_p$点的坐标可以表示为:\n$$(x_p,y_p) = (x_c + Rcos(\\frac{2\\pi}{P}),y_c - Rsin(\\frac{2\\pi}{P}))$$\n$(x_c,y_c)$表示中心点的坐标\n- 将中心点$g_c$的值从邻域像素的灰度值$g_p$中减去，则局部区域的纹理可以用中心点和中心点与周边像素值之差的联合分布来表示:\n$$T = t(g_c,g_0-g_c,....,g_{p-1}-g_c)$$\n- 假设中心像素点$g_c$与周边点像素$g_p$的差值$g_p-g_c(p=0,1,...P)$独立于中心点$g_c$，则\n$$T\\approx t(g_c)(g_0-g_c,...,g_{p-1}-g_c)$$\n- 实际上，$t(g_c)$只是描述了整个图像的亮度分布情况，而和图像的局部纹理无关，它不能为纹理分析提供任何有价值的信息\n$$T\\approx t(g_0-g_c,...,g_{p-1}-g_c)$$\n- 差值的联合分布具有灰度平移不变性，即邻域中所有P+1个像素同时加上或减去某个值，其表征的纹理不变。\n- 为了达到尺度不变的目的，只考虑差值的符号\n$$T\\approx t(s(g_0-g_c),...,s(g_p-g_c))$$\n\n$$s(x)=\\begin{cases}\n1 , \\quad &x > 0  \\\\\\\\\n0 , &x \\geqslant 0\n\\end{cases}\n$$\n\n上式得到了一个8位的二进制数，再对像素按不同位置用$2^p$进行加权求和，这样得到了一个与邻域像素点相关的唯一的 **LBP** 值，这个值称为 **模式**。这个值描述的是以$(x_c,y_c)$为中心的局部区域的纹理，可以表示为\n$$LBP(x_c,y_c) = \\sum_{p=0}^{P-1}s(g_p - g_c)2^P$$\n上式意味着差值的符号转化成一个P-bit的二进制数，进而转化成为一个取值范围为0-$2^p$的离散的LBP值，或者说转化为一种LBP模式。\n- 局部区域的灰度分布或纹理，可以用这个LBP值或LBP模式近似描述为:\n$$T\\approx t(LBP(x_c,y_c))$$\nLBP算子对于任何单调的灰度变化具有鲁棒性，用符号$LBP_P^R$表示在半径为R的圆形邻域内有P个像素点$g_p(p=0,1,...,P)$的LBP算子\n![](https://i.loli.net/2019/07/31/5d415779b84ac47631.jpg)\n\n## LBP等价模式\n### 定义\n当某个局部二进制模式所对应的循环二进制数从０到１或从１到０最多有两次跳变时，该局部二进制模式所对应的二进制就称为一个等价模式类。比如00000000,11111111,10001111都是等价类。\n### 检验方法\n检验某种模式是否是等价模式的简单办法是将其和其移动一位后的二进制模式按位相减的绝对值求和\n$$U(G_p) = |s(g_{p-1}-g_c)-s(g_0-g_c)|+\\sum_{p=1}^{P-1}|s(g_p-g_c)-s(g_{p-1}-g_c)$$\n若某种模式计算得到的 $U(G_p)$小于或等于２，则将其归于等价模式\n![](https://i.loli.net/2019/07/31/5d415779c949196019.jpg)\n\n## 旋转不变的LBP算子\n### 定义\n不断旋转圆形邻域得到一系列的初始定义的LBP值，取其最小值作为该邻域的LBP值，用公式表示为:\n$$LBP_{P,R}^{ri} = min(ROR(LBP_{P,R}^{ri},i)|i=0,1,...,P-1)$$\n$LBP^{ri}$表示旋转不变的LBP算子，$ROR(x,i)$函数为旋转函数，表示将x循环右移i(i<P)位。\n\n### 性质\n- 对于图像旋转，表现的更为鲁棒，并且LBP模式的种类进一步减少，使纹理识别更加容易。\n- 丢失了方向信息\n![](https://i.loli.net/2019/07/31/5d415779b8fed91298.jpg)\n\n## 旋转不变的的等价模式\n### 定义\n将等价模式类进行旋转得到旋转不变的等价模式\n\n$$LBP_{P,R}^{riu2} = \\begin{cases}\n\\sum_{P=0}^{P-1}s(g_p-g_c), & U(G_p) \\leq 2 \\\\\\\\\nP + 1, & U(G_p) >2\n\\end{cases}\n$$\n\n其中$U(G_p)$表示0到1或1到0跳变的次数，$LBP^{riu2}$被称为旋转不变的等价模式\n\n## 几种LBP算子的维数比较\n\n LBP  | 原始模式数 | 等价模式 | 旋转不变等价模式\n:---: | :---: | :---: | :---:\n$LBP_P^R$ | $2^P$ | $P(P-1) + 2$ | $P+1$\n$LBP_8^1$ | 256 | 58(+1) | 9\n$LBP_{16}^2$ | 65536 | 242(+1) | 17\n$LBP_{24}^3$ | 16777216 | 554(+1) | 25\n\n\n\n","source":"_posts/Day17.md","raw":"---\ntitle: Day17\ndate: 2019-07-31 10:05:48\ntags: 实习 OpenCV\ncategories:\ncover: false\nmathjax: true\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# LBP算法\n\nLBP（Local Binary Patterns，局部二值模式）是一种能够有效地度量和提取图像局部纹理信息的算子，具有旋转不变性和灰度不变性等显著的优点。它是人脸识别中一种提取特征的重要方法，具有对光照不敏感的特性，但是对姿态和表情的鲁棒性不强。\n## 纹理\n\n纹理是由于物体表面物理属性不同所引起的能够表示某个特定表面特征的灰度或颜色信息。纹理反映了图像灰度模式的空间分布，包含了图像的表面信息及其周围环境的关系。\n\n## 基本的LBP算子\n\n局部二值模式是一种灰度范围内的纹理描述方式。最初的LBP算子定义在一个3×3的窗口，以窗口中心像素点为阈值，将相邻的像素的灰度值与其进行比较，若周围的像素值大于中心点的值，则将该像素位置标记为1,否则为0.这样一个3×3邻域内的8个点可产生一个8-bit的无符号数，再按其位置赋予不同权重求和得一整数，即可得到该窗口的 **LBP** 值，并用这个数反映该区域的纹理信息。    \n对比度分量C是邻域中所有大于和等于中心点像素的均值与所有小于中心点像素的均值之差。    \n![](https://i.loli.net/2019/07/31/5d415779ca87257597.jpg)\n\n基本的LBP算子最大的缺陷是只覆盖了一个固定半径范围内的小区域，改进的LBP算子，将3×3邻域扩展到任意邻域，用圆形邻域代替了正方形邻域，该算子允许在半径为R的圆形邻域内有任意多个像素点。\n- 一个局部区域的纹理分布可假设为局部区域内像素灰度的联合分布密度\n$$T = t(g_c,g_0, ....,g_{p-1})$$\n$g_c$表示局部区域的中心点的灰度值,$g_p(p=0,1,...,p)$对应中心点周围等距分布的P个点\n- 采用 **双线性插算法** 对没有完全落在像素位置的点计算灰度值。邻域内的$g_p$点的坐标可以表示为:\n$$(x_p,y_p) = (x_c + Rcos(\\frac{2\\pi}{P}),y_c - Rsin(\\frac{2\\pi}{P}))$$\n$(x_c,y_c)$表示中心点的坐标\n- 将中心点$g_c$的值从邻域像素的灰度值$g_p$中减去，则局部区域的纹理可以用中心点和中心点与周边像素值之差的联合分布来表示:\n$$T = t(g_c,g_0-g_c,....,g_{p-1}-g_c)$$\n- 假设中心像素点$g_c$与周边点像素$g_p$的差值$g_p-g_c(p=0,1,...P)$独立于中心点$g_c$，则\n$$T\\approx t(g_c)(g_0-g_c,...,g_{p-1}-g_c)$$\n- 实际上，$t(g_c)$只是描述了整个图像的亮度分布情况，而和图像的局部纹理无关，它不能为纹理分析提供任何有价值的信息\n$$T\\approx t(g_0-g_c,...,g_{p-1}-g_c)$$\n- 差值的联合分布具有灰度平移不变性，即邻域中所有P+1个像素同时加上或减去某个值，其表征的纹理不变。\n- 为了达到尺度不变的目的，只考虑差值的符号\n$$T\\approx t(s(g_0-g_c),...,s(g_p-g_c))$$\n\n$$s(x)=\\begin{cases}\n1 , \\quad &x > 0  \\\\\\\\\n0 , &x \\geqslant 0\n\\end{cases}\n$$\n\n上式得到了一个8位的二进制数，再对像素按不同位置用$2^p$进行加权求和，这样得到了一个与邻域像素点相关的唯一的 **LBP** 值，这个值称为 **模式**。这个值描述的是以$(x_c,y_c)$为中心的局部区域的纹理，可以表示为\n$$LBP(x_c,y_c) = \\sum_{p=0}^{P-1}s(g_p - g_c)2^P$$\n上式意味着差值的符号转化成一个P-bit的二进制数，进而转化成为一个取值范围为0-$2^p$的离散的LBP值，或者说转化为一种LBP模式。\n- 局部区域的灰度分布或纹理，可以用这个LBP值或LBP模式近似描述为:\n$$T\\approx t(LBP(x_c,y_c))$$\nLBP算子对于任何单调的灰度变化具有鲁棒性，用符号$LBP_P^R$表示在半径为R的圆形邻域内有P个像素点$g_p(p=0,1,...,P)$的LBP算子\n![](https://i.loli.net/2019/07/31/5d415779b84ac47631.jpg)\n\n## LBP等价模式\n### 定义\n当某个局部二进制模式所对应的循环二进制数从０到１或从１到０最多有两次跳变时，该局部二进制模式所对应的二进制就称为一个等价模式类。比如00000000,11111111,10001111都是等价类。\n### 检验方法\n检验某种模式是否是等价模式的简单办法是将其和其移动一位后的二进制模式按位相减的绝对值求和\n$$U(G_p) = |s(g_{p-1}-g_c)-s(g_0-g_c)|+\\sum_{p=1}^{P-1}|s(g_p-g_c)-s(g_{p-1}-g_c)$$\n若某种模式计算得到的 $U(G_p)$小于或等于２，则将其归于等价模式\n![](https://i.loli.net/2019/07/31/5d415779c949196019.jpg)\n\n## 旋转不变的LBP算子\n### 定义\n不断旋转圆形邻域得到一系列的初始定义的LBP值，取其最小值作为该邻域的LBP值，用公式表示为:\n$$LBP_{P,R}^{ri} = min(ROR(LBP_{P,R}^{ri},i)|i=0,1,...,P-1)$$\n$LBP^{ri}$表示旋转不变的LBP算子，$ROR(x,i)$函数为旋转函数，表示将x循环右移i(i<P)位。\n\n### 性质\n- 对于图像旋转，表现的更为鲁棒，并且LBP模式的种类进一步减少，使纹理识别更加容易。\n- 丢失了方向信息\n![](https://i.loli.net/2019/07/31/5d415779b8fed91298.jpg)\n\n## 旋转不变的的等价模式\n### 定义\n将等价模式类进行旋转得到旋转不变的等价模式\n\n$$LBP_{P,R}^{riu2} = \\begin{cases}\n\\sum_{P=0}^{P-1}s(g_p-g_c), & U(G_p) \\leq 2 \\\\\\\\\nP + 1, & U(G_p) >2\n\\end{cases}\n$$\n\n其中$U(G_p)$表示0到1或1到0跳变的次数，$LBP^{riu2}$被称为旋转不变的等价模式\n\n## 几种LBP算子的维数比较\n\n LBP  | 原始模式数 | 等价模式 | 旋转不变等价模式\n:---: | :---: | :---: | :---:\n$LBP_P^R$ | $2^P$ | $P(P-1) + 2$ | $P+1$\n$LBP_8^1$ | 256 | 58(+1) | 9\n$LBP_{16}^2$ | 65536 | 242(+1) | 17\n$LBP_{24}^3$ | 16777216 | 554(+1) | 25\n\n\n\n","slug":"Day17","published":1,"updated":"2019-08-10T10:47:34.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltg000ve5g6dwqnsjlw","content":"<h1 id=\"LBP算法\"><a href=\"#LBP算法\" class=\"headerlink\" title=\"LBP算法\"></a>LBP算法</h1><p>LBP（Local Binary Patterns，局部二值模式）是一种能够有效地度量和提取图像局部纹理信息的算子，具有旋转不变性和灰度不变性等显著的优点。它是人脸识别中一种提取特征的重要方法，具有对光照不敏感的特性，但是对姿态和表情的鲁棒性不强。</p>\n<h2 id=\"纹理\"><a href=\"#纹理\" class=\"headerlink\" title=\"纹理\"></a>纹理</h2><p>纹理是由于物体表面物理属性不同所引起的能够表示某个特定表面特征的灰度或颜色信息。纹理反映了图像灰度模式的空间分布，包含了图像的表面信息及其周围环境的关系。</p>\n<h2 id=\"基本的LBP算子\"><a href=\"#基本的LBP算子\" class=\"headerlink\" title=\"基本的LBP算子\"></a>基本的LBP算子</h2><p>局部二值模式是一种灰度范围内的纹理描述方式。最初的LBP算子定义在一个3×3的窗口，以窗口中心像素点为阈值，将相邻的像素的灰度值与其进行比较，若周围的像素值大于中心点的值，则将该像素位置标记为1,否则为0.这样一个3×3邻域内的8个点可产生一个8-bit的无符号数，再按其位置赋予不同权重求和得一整数，即可得到该窗口的 <strong>LBP</strong> 值，并用这个数反映该区域的纹理信息。<br>对比度分量C是邻域中所有大于和等于中心点像素的均值与所有小于中心点像素的均值之差。<br><img src=\"https://i.loli.net/2019/07/31/5d415779ca87257597.jpg\" alt></p>\n<p>基本的LBP算子最大的缺陷是只覆盖了一个固定半径范围内的小区域，改进的LBP算子，将3×3邻域扩展到任意邻域，用圆形邻域代替了正方形邻域，该算子允许在半径为R的圆形邻域内有任意多个像素点。</p>\n<ul>\n<li>一个局部区域的纹理分布可假设为局部区域内像素灰度的联合分布密度<br>$$T = t(g_c,g_0, ….,g_{p-1})$$<br>$g_c$表示局部区域的中心点的灰度值,$g_p(p=0,1,…,p)$对应中心点周围等距分布的P个点</li>\n<li>采用 <strong>双线性插算法</strong> 对没有完全落在像素位置的点计算灰度值。邻域内的$g_p$点的坐标可以表示为:<br>$$(x_p,y_p) = (x_c + Rcos(\\frac{2\\pi}{P}),y_c - Rsin(\\frac{2\\pi}{P}))$$<br>$(x_c,y_c)$表示中心点的坐标</li>\n<li>将中心点$g_c$的值从邻域像素的灰度值$g_p$中减去，则局部区域的纹理可以用中心点和中心点与周边像素值之差的联合分布来表示:<br>$$T = t(g_c,g_0-g_c,….,g_{p-1}-g_c)$$</li>\n<li>假设中心像素点$g_c$与周边点像素$g_p$的差值$g_p-g_c(p=0,1,…P)$独立于中心点$g_c$，则<br>$$T\\approx t(g_c)(g_0-g_c,…,g_{p-1}-g_c)$$</li>\n<li>实际上，$t(g_c)$只是描述了整个图像的亮度分布情况，而和图像的局部纹理无关，它不能为纹理分析提供任何有价值的信息<br>$$T\\approx t(g_0-g_c,…,g_{p-1}-g_c)$$</li>\n<li>差值的联合分布具有灰度平移不变性，即邻域中所有P+1个像素同时加上或减去某个值，其表征的纹理不变。</li>\n<li>为了达到尺度不变的目的，只考虑差值的符号<br>$$T\\approx t(s(g_0-g_c),…,s(g_p-g_c))$$</li>\n</ul>\n<p>$$s(x)=\\begin{cases}<br>1 , \\quad &amp;x &gt; 0  \\\\\\<br>0 , &amp;x \\geqslant 0<br>\\end{cases}<br>$$</p>\n<p>上式得到了一个8位的二进制数，再对像素按不同位置用$2^p$进行加权求和，这样得到了一个与邻域像素点相关的唯一的 <strong>LBP</strong> 值，这个值称为 <strong>模式</strong>。这个值描述的是以$(x_c,y_c)$为中心的局部区域的纹理，可以表示为<br>$$LBP(x_c,y_c) = \\sum_{p=0}^{P-1}s(g_p - g_c)2^P$$<br>上式意味着差值的符号转化成一个P-bit的二进制数，进而转化成为一个取值范围为0-$2^p$的离散的LBP值，或者说转化为一种LBP模式。</p>\n<ul>\n<li>局部区域的灰度分布或纹理，可以用这个LBP值或LBP模式近似描述为:<br>$$T\\approx t(LBP(x_c,y_c))$$<br>LBP算子对于任何单调的灰度变化具有鲁棒性，用符号$LBP_P^R$表示在半径为R的圆形邻域内有P个像素点$g_p(p=0,1,…,P)$的LBP算子<br><img src=\"https://i.loli.net/2019/07/31/5d415779b84ac47631.jpg\" alt></li>\n</ul>\n<h2 id=\"LBP等价模式\"><a href=\"#LBP等价模式\" class=\"headerlink\" title=\"LBP等价模式\"></a>LBP等价模式</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>当某个局部二进制模式所对应的循环二进制数从０到１或从１到０最多有两次跳变时，该局部二进制模式所对应的二进制就称为一个等价模式类。比如00000000,11111111,10001111都是等价类。</p>\n<h3 id=\"检验方法\"><a href=\"#检验方法\" class=\"headerlink\" title=\"检验方法\"></a>检验方法</h3><p>检验某种模式是否是等价模式的简单办法是将其和其移动一位后的二进制模式按位相减的绝对值求和<br>$$U(G_p) = |s(g_{p-1}-g_c)-s(g_0-g_c)|+\\sum_{p=1}^{P-1}|s(g_p-g_c)-s(g_{p-1}-g_c)$$<br>若某种模式计算得到的 $U(G_p)$小于或等于２，则将其归于等价模式<br><img src=\"https://i.loli.net/2019/07/31/5d415779c949196019.jpg\" alt></p>\n<h2 id=\"旋转不变的LBP算子\"><a href=\"#旋转不变的LBP算子\" class=\"headerlink\" title=\"旋转不变的LBP算子\"></a>旋转不变的LBP算子</h2><h3 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>不断旋转圆形邻域得到一系列的初始定义的LBP值，取其最小值作为该邻域的LBP值，用公式表示为:<br>$$LBP_{P,R}^{ri} = min(ROR(LBP_{P,R}^{ri},i)|i=0,1,…,P-1)$$<br>$LBP^{ri}$表示旋转不变的LBP算子，$ROR(x,i)$函数为旋转函数，表示将x循环右移i(i&lt;P)位。</p>\n<h3 id=\"性质\"><a href=\"#性质\" class=\"headerlink\" title=\"性质\"></a>性质</h3><ul>\n<li>对于图像旋转，表现的更为鲁棒，并且LBP模式的种类进一步减少，使纹理识别更加容易。</li>\n<li>丢失了方向信息<br><img src=\"https://i.loli.net/2019/07/31/5d415779b8fed91298.jpg\" alt></li>\n</ul>\n<h2 id=\"旋转不变的的等价模式\"><a href=\"#旋转不变的的等价模式\" class=\"headerlink\" title=\"旋转不变的的等价模式\"></a>旋转不变的的等价模式</h2><h3 id=\"定义-2\"><a href=\"#定义-2\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>将等价模式类进行旋转得到旋转不变的等价模式</p>\n<p>$$LBP_{P,R}^{riu2} = \\begin{cases}<br>\\sum_{P=0}^{P-1}s(g_p-g_c), &amp; U(G_p) \\leq 2 \\\\\\<br>P + 1, &amp; U(G_p) &gt;2<br>\\end{cases}<br>$$</p>\n<p>其中$U(G_p)$表示0到1或1到0跳变的次数，$LBP^{riu2}$被称为旋转不变的等价模式</p>\n<h2 id=\"几种LBP算子的维数比较\"><a href=\"#几种LBP算子的维数比较\" class=\"headerlink\" title=\"几种LBP算子的维数比较\"></a>几种LBP算子的维数比较</h2><table>\n<thead>\n<tr>\n<th align=\"center\">LBP</th>\n<th align=\"center\">原始模式数</th>\n<th align=\"center\">等价模式</th>\n<th align=\"center\">旋转不变等价模式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$LBP_P^R$</td>\n<td align=\"center\">$2^P$</td>\n<td align=\"center\">$P(P-1) + 2$</td>\n<td align=\"center\">$P+1$</td>\n</tr>\n<tr>\n<td align=\"center\">$LBP_8^1$</td>\n<td align=\"center\">256</td>\n<td align=\"center\">58(+1)</td>\n<td align=\"center\">9</td>\n</tr>\n<tr>\n<td align=\"center\">$LBP_{16}^2$</td>\n<td align=\"center\">65536</td>\n<td align=\"center\">242(+1)</td>\n<td align=\"center\">17</td>\n</tr>\n<tr>\n<td align=\"center\">$LBP_{24}^3$</td>\n<td align=\"center\">16777216</td>\n<td align=\"center\">554(+1)</td>\n<td align=\"center\">25</td>\n</tr>\n</tbody></table>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"LBP算法\"><a href=\"#LBP算法\" class=\"headerlink\" title=\"LBP算法\"></a>LBP算法</h1><p>LBP（Local Binary Patterns，局部二值模式）是一种能够有效地度量和提取图像局部纹理信息的算子，具有旋转不变性和灰度不变性等显著的优点。它是人脸识别中一种提取特征的重要方法，具有对光照不敏感的特性，但是对姿态和表情的鲁棒性不强。</p>\n<h2 id=\"纹理\"><a href=\"#纹理\" class=\"headerlink\" title=\"纹理\"></a>纹理</h2><p>纹理是由于物体表面物理属性不同所引起的能够表示某个特定表面特征的灰度或颜色信息。纹理反映了图像灰度模式的空间分布，包含了图像的表面信息及其周围环境的关系。</p>\n<h2 id=\"基本的LBP算子\"><a href=\"#基本的LBP算子\" class=\"headerlink\" title=\"基本的LBP算子\"></a>基本的LBP算子</h2><p>局部二值模式是一种灰度范围内的纹理描述方式。最初的LBP算子定义在一个3×3的窗口，以窗口中心像素点为阈值，将相邻的像素的灰度值与其进行比较，若周围的像素值大于中心点的值，则将该像素位置标记为1,否则为0.这样一个3×3邻域内的8个点可产生一个8-bit的无符号数，再按其位置赋予不同权重求和得一整数，即可得到该窗口的 <strong>LBP</strong> 值，并用这个数反映该区域的纹理信息。<br>对比度分量C是邻域中所有大于和等于中心点像素的均值与所有小于中心点像素的均值之差。<br><img src=\"https://i.loli.net/2019/07/31/5d415779ca87257597.jpg\" alt></p>\n<p>基本的LBP算子最大的缺陷是只覆盖了一个固定半径范围内的小区域，改进的LBP算子，将3×3邻域扩展到任意邻域，用圆形邻域代替了正方形邻域，该算子允许在半径为R的圆形邻域内有任意多个像素点。</p>\n<ul>\n<li>一个局部区域的纹理分布可假设为局部区域内像素灰度的联合分布密度<br>$$T = t(g_c,g_0, ….,g_{p-1})$$<br>$g_c$表示局部区域的中心点的灰度值,$g_p(p=0,1,…,p)$对应中心点周围等距分布的P个点</li>\n<li>采用 <strong>双线性插算法</strong> 对没有完全落在像素位置的点计算灰度值。邻域内的$g_p$点的坐标可以表示为:<br>$$(x_p,y_p) = (x_c + Rcos(\\frac{2\\pi}{P}),y_c - Rsin(\\frac{2\\pi}{P}))$$<br>$(x_c,y_c)$表示中心点的坐标</li>\n<li>将中心点$g_c$的值从邻域像素的灰度值$g_p$中减去，则局部区域的纹理可以用中心点和中心点与周边像素值之差的联合分布来表示:<br>$$T = t(g_c,g_0-g_c,….,g_{p-1}-g_c)$$</li>\n<li>假设中心像素点$g_c$与周边点像素$g_p$的差值$g_p-g_c(p=0,1,…P)$独立于中心点$g_c$，则<br>$$T\\approx t(g_c)(g_0-g_c,…,g_{p-1}-g_c)$$</li>\n<li>实际上，$t(g_c)$只是描述了整个图像的亮度分布情况，而和图像的局部纹理无关，它不能为纹理分析提供任何有价值的信息<br>$$T\\approx t(g_0-g_c,…,g_{p-1}-g_c)$$</li>\n<li>差值的联合分布具有灰度平移不变性，即邻域中所有P+1个像素同时加上或减去某个值，其表征的纹理不变。</li>\n<li>为了达到尺度不变的目的，只考虑差值的符号<br>$$T\\approx t(s(g_0-g_c),…,s(g_p-g_c))$$</li>\n</ul>\n<p>$$s(x)=\\begin{cases}<br>1 , \\quad &amp;x &gt; 0  \\\\\\<br>0 , &amp;x \\geqslant 0<br>\\end{cases}<br>$$</p>\n<p>上式得到了一个8位的二进制数，再对像素按不同位置用$2^p$进行加权求和，这样得到了一个与邻域像素点相关的唯一的 <strong>LBP</strong> 值，这个值称为 <strong>模式</strong>。这个值描述的是以$(x_c,y_c)$为中心的局部区域的纹理，可以表示为<br>$$LBP(x_c,y_c) = \\sum_{p=0}^{P-1}s(g_p - g_c)2^P$$<br>上式意味着差值的符号转化成一个P-bit的二进制数，进而转化成为一个取值范围为0-$2^p$的离散的LBP值，或者说转化为一种LBP模式。</p>\n<ul>\n<li>局部区域的灰度分布或纹理，可以用这个LBP值或LBP模式近似描述为:<br>$$T\\approx t(LBP(x_c,y_c))$$<br>LBP算子对于任何单调的灰度变化具有鲁棒性，用符号$LBP_P^R$表示在半径为R的圆形邻域内有P个像素点$g_p(p=0,1,…,P)$的LBP算子<br><img src=\"https://i.loli.net/2019/07/31/5d415779b84ac47631.jpg\" alt></li>\n</ul>\n<h2 id=\"LBP等价模式\"><a href=\"#LBP等价模式\" class=\"headerlink\" title=\"LBP等价模式\"></a>LBP等价模式</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>当某个局部二进制模式所对应的循环二进制数从０到１或从１到０最多有两次跳变时，该局部二进制模式所对应的二进制就称为一个等价模式类。比如00000000,11111111,10001111都是等价类。</p>\n<h3 id=\"检验方法\"><a href=\"#检验方法\" class=\"headerlink\" title=\"检验方法\"></a>检验方法</h3><p>检验某种模式是否是等价模式的简单办法是将其和其移动一位后的二进制模式按位相减的绝对值求和<br>$$U(G_p) = |s(g_{p-1}-g_c)-s(g_0-g_c)|+\\sum_{p=1}^{P-1}|s(g_p-g_c)-s(g_{p-1}-g_c)$$<br>若某种模式计算得到的 $U(G_p)$小于或等于２，则将其归于等价模式<br><img src=\"https://i.loli.net/2019/07/31/5d415779c949196019.jpg\" alt></p>\n<h2 id=\"旋转不变的LBP算子\"><a href=\"#旋转不变的LBP算子\" class=\"headerlink\" title=\"旋转不变的LBP算子\"></a>旋转不变的LBP算子</h2><h3 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>不断旋转圆形邻域得到一系列的初始定义的LBP值，取其最小值作为该邻域的LBP值，用公式表示为:<br>$$LBP_{P,R}^{ri} = min(ROR(LBP_{P,R}^{ri},i)|i=0,1,…,P-1)$$<br>$LBP^{ri}$表示旋转不变的LBP算子，$ROR(x,i)$函数为旋转函数，表示将x循环右移i(i&lt;P)位。</p>\n<h3 id=\"性质\"><a href=\"#性质\" class=\"headerlink\" title=\"性质\"></a>性质</h3><ul>\n<li>对于图像旋转，表现的更为鲁棒，并且LBP模式的种类进一步减少，使纹理识别更加容易。</li>\n<li>丢失了方向信息<br><img src=\"https://i.loli.net/2019/07/31/5d415779b8fed91298.jpg\" alt></li>\n</ul>\n<h2 id=\"旋转不变的的等价模式\"><a href=\"#旋转不变的的等价模式\" class=\"headerlink\" title=\"旋转不变的的等价模式\"></a>旋转不变的的等价模式</h2><h3 id=\"定义-2\"><a href=\"#定义-2\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>将等价模式类进行旋转得到旋转不变的等价模式</p>\n<p>$$LBP_{P,R}^{riu2} = \\begin{cases}<br>\\sum_{P=0}^{P-1}s(g_p-g_c), &amp; U(G_p) \\leq 2 \\\\\\<br>P + 1, &amp; U(G_p) &gt;2<br>\\end{cases}<br>$$</p>\n<p>其中$U(G_p)$表示0到1或1到0跳变的次数，$LBP^{riu2}$被称为旋转不变的等价模式</p>\n<h2 id=\"几种LBP算子的维数比较\"><a href=\"#几种LBP算子的维数比较\" class=\"headerlink\" title=\"几种LBP算子的维数比较\"></a>几种LBP算子的维数比较</h2><table>\n<thead>\n<tr>\n<th align=\"center\">LBP</th>\n<th align=\"center\">原始模式数</th>\n<th align=\"center\">等价模式</th>\n<th align=\"center\">旋转不变等价模式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$LBP_P^R$</td>\n<td align=\"center\">$2^P$</td>\n<td align=\"center\">$P(P-1) + 2$</td>\n<td align=\"center\">$P+1$</td>\n</tr>\n<tr>\n<td align=\"center\">$LBP_8^1$</td>\n<td align=\"center\">256</td>\n<td align=\"center\">58(+1)</td>\n<td align=\"center\">9</td>\n</tr>\n<tr>\n<td align=\"center\">$LBP_{16}^2$</td>\n<td align=\"center\">65536</td>\n<td align=\"center\">242(+1)</td>\n<td align=\"center\">17</td>\n</tr>\n<tr>\n<td align=\"center\">$LBP_{24}^3$</td>\n<td align=\"center\">16777216</td>\n<td align=\"center\">554(+1)</td>\n<td align=\"center\">25</td>\n</tr>\n</tbody></table>\n"},{"title":"Day19","date":"2019-08-02T02:10:42.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# 基于LBP的人脸检测\n\n在图片人脸检测的基础上加上视频流。    \n原理就是对视频逐帧处理，1s大约分为30帧。\n\n```cpp\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/core/core.hpp>\n#include <opencv2/objdetect/objdetect.hpp>\n#include <iostream>\n\nusing namespace std;\nusing namespace cv;\n\n#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)\nCascadeClassifier faceCascade;\n\n\nint main(int argc, char** argv)\n{\n  //打开摄像头\n  VideoCapture cap(0);\n  if(!cap.isOpened())\n  {\n    return -1;\n  }\n  //读取分类器\n  CascadeClassifier faceDetector(\"lbpcascade_frontalface.xml\");\n  vector<Rect> objects;\n  Mat frame;\n  Mat edges;\n  bool stop = false;\n  while(!stop){\n    cap >> frame;\n    if (frame.empty())\n      stop = true;\n    double scaleFactor=1.1;\n    int minNeighbors = 3;\n    //int flags = 1;\n    //cvtColor(frame, edges, CV_BGR2GRAY);\n    //GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);\n    faceDetector.detectMultiScale(frame, objects,scaleFactor, minNeighbors);\n    for(int i = 0; i < objects.size(); i++){\n      rectangle(frame, objects[i], CV_COLOR_GREEN);\n      rectangle(edges, objects[i], CV_COLOR_GREEN);\n    }\n    //imshow(\"edge\", edges);\n    imshow(\"frame\", frame);\n    if (waitKey(30) >= 0)\n      stop = true;\n  }\n  return 0;\n}\n```\n识别结果:\n\n![](https://i.loli.net/2019/08/02/5d43e017d9e1227148.png)\n![](https://i.loli.net/2019/08/02/5d43e017f281538470.png)\n","source":"_posts/Day19.md","raw":"---\ntitle: Day19\ndate: 2019-08-02 10:10:42\ntags: 实习\ncategories:\n  - OpenCV\n  - C++\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# 基于LBP的人脸检测\n\n在图片人脸检测的基础上加上视频流。    \n原理就是对视频逐帧处理，1s大约分为30帧。\n\n```cpp\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/core/core.hpp>\n#include <opencv2/objdetect/objdetect.hpp>\n#include <iostream>\n\nusing namespace std;\nusing namespace cv;\n\n#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)\nCascadeClassifier faceCascade;\n\n\nint main(int argc, char** argv)\n{\n  //打开摄像头\n  VideoCapture cap(0);\n  if(!cap.isOpened())\n  {\n    return -1;\n  }\n  //读取分类器\n  CascadeClassifier faceDetector(\"lbpcascade_frontalface.xml\");\n  vector<Rect> objects;\n  Mat frame;\n  Mat edges;\n  bool stop = false;\n  while(!stop){\n    cap >> frame;\n    if (frame.empty())\n      stop = true;\n    double scaleFactor=1.1;\n    int minNeighbors = 3;\n    //int flags = 1;\n    //cvtColor(frame, edges, CV_BGR2GRAY);\n    //GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);\n    faceDetector.detectMultiScale(frame, objects,scaleFactor, minNeighbors);\n    for(int i = 0; i < objects.size(); i++){\n      rectangle(frame, objects[i], CV_COLOR_GREEN);\n      rectangle(edges, objects[i], CV_COLOR_GREEN);\n    }\n    //imshow(\"edge\", edges);\n    imshow(\"frame\", frame);\n    if (waitKey(30) >= 0)\n      stop = true;\n  }\n  return 0;\n}\n```\n识别结果:\n\n![](https://i.loli.net/2019/08/02/5d43e017d9e1227148.png)\n![](https://i.loli.net/2019/08/02/5d43e017f281538470.png)\n","slug":"Day19","published":1,"updated":"2019-08-10T10:47:34.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lth000xe5g6zpro8zd1","content":"<h1 id=\"基于LBP的人脸检测\"><a href=\"#基于LBP的人脸检测\" class=\"headerlink\" title=\"基于LBP的人脸检测\"></a>基于LBP的人脸检测</h1><p>在图片人脸检测的基础上加上视频流。<br>原理就是对视频逐帧处理，1s大约分为30帧。</p>\n<pre class=\" language-cpp\"><code class=\"language-cpp\"><span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/highgui/highgui.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/imgproc/imgproc.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/core/core.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/objdetect/objdetect.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;iostream></span></span>\n\n<span class=\"token keyword\">using</span> <span class=\"token keyword\">namespace</span> std<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">using</span> <span class=\"token keyword\">namespace</span> cv<span class=\"token punctuation\">;</span>\n\n<span class=\"token macro property\">#<span class=\"token directive keyword\">define</span> CV_COLOR_GREEN cv::Scalar(0, 255, 0)</span>\nCascadeClassifier faceCascade<span class=\"token punctuation\">;</span>\n\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> argc<span class=\"token punctuation\">,</span> <span class=\"token keyword\">char</span><span class=\"token operator\">*</span><span class=\"token operator\">*</span> argv<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token comment\" spellcheck=\"true\">//打开摄像头</span>\n  VideoCapture <span class=\"token function\">cap</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>cap<span class=\"token punctuation\">.</span><span class=\"token function\">isOpened</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\" spellcheck=\"true\">//读取分类器</span>\n  CascadeClassifier <span class=\"token function\">faceDetector</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"lbpcascade_frontalface.xml\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  vector<span class=\"token operator\">&lt;</span>Rect<span class=\"token operator\">></span> objects<span class=\"token punctuation\">;</span>\n  Mat frame<span class=\"token punctuation\">;</span>\n  Mat edges<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">bool</span> stop <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>stop<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    cap <span class=\"token operator\">>></span> frame<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>frame<span class=\"token punctuation\">.</span><span class=\"token function\">empty</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      stop <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">double</span> scaleFactor<span class=\"token operator\">=</span><span class=\"token number\">1.1</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">int</span> minNeighbors <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\" spellcheck=\"true\">//int flags = 1;</span>\n    <span class=\"token comment\" spellcheck=\"true\">//cvtColor(frame, edges, CV_BGR2GRAY);</span>\n    <span class=\"token comment\" spellcheck=\"true\">//GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);</span>\n    faceDetector<span class=\"token punctuation\">.</span><span class=\"token function\">detectMultiScale</span><span class=\"token punctuation\">(</span>frame<span class=\"token punctuation\">,</span> objects<span class=\"token punctuation\">,</span>scaleFactor<span class=\"token punctuation\">,</span> minNeighbors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> objects<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n      <span class=\"token function\">rectangle</span><span class=\"token punctuation\">(</span>frame<span class=\"token punctuation\">,</span> objects<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> CV_COLOR_GREEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token function\">rectangle</span><span class=\"token punctuation\">(</span>edges<span class=\"token punctuation\">,</span> objects<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> CV_COLOR_GREEN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\" spellcheck=\"true\">//imshow(\"edge\", edges);</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"frame\"</span><span class=\"token punctuation\">,</span> frame<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">waitKey</span><span class=\"token punctuation\">(</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n      stop <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre>\n<p>识别结果:</p>\n<p><img src=\"https://i.loli.net/2019/08/02/5d43e017d9e1227148.png\" alt><br><img src=\"https://i.loli.net/2019/08/02/5d43e017f281538470.png\" alt></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"基于LBP的人脸检测\"><a href=\"#基于LBP的人脸检测\" class=\"headerlink\" title=\"基于LBP的人脸检测\"></a>基于LBP的人脸检测</h1><p>在图片人脸检测的基础上加上视频流。<br>原理就是对视频逐帧处理，1s大约分为30帧。</p>\n<pre><code class=\"cpp\">#include &lt;opencv2/highgui/highgui.hpp&gt;\n#include &lt;opencv2/imgproc/imgproc.hpp&gt;\n#include &lt;opencv2/core/core.hpp&gt;\n#include &lt;opencv2/objdetect/objdetect.hpp&gt;\n#include &lt;iostream&gt;\n\nusing namespace std;\nusing namespace cv;\n\n#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)\nCascadeClassifier faceCascade;\n\n\nint main(int argc, char** argv)\n{\n  //打开摄像头\n  VideoCapture cap(0);\n  if(!cap.isOpened())\n  {\n    return -1;\n  }\n  //读取分类器\n  CascadeClassifier faceDetector(&quot;lbpcascade_frontalface.xml&quot;);\n  vector&lt;Rect&gt; objects;\n  Mat frame;\n  Mat edges;\n  bool stop = false;\n  while(!stop){\n    cap &gt;&gt; frame;\n    if (frame.empty())\n      stop = true;\n    double scaleFactor=1.1;\n    int minNeighbors = 3;\n    //int flags = 1;\n    //cvtColor(frame, edges, CV_BGR2GRAY);\n    //GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);\n    faceDetector.detectMultiScale(frame, objects,scaleFactor, minNeighbors);\n    for(int i = 0; i &lt; objects.size(); i++){\n      rectangle(frame, objects[i], CV_COLOR_GREEN);\n      rectangle(edges, objects[i], CV_COLOR_GREEN);\n    }\n    //imshow(&quot;edge&quot;, edges);\n    imshow(&quot;frame&quot;, frame);\n    if (waitKey(30) &gt;= 0)\n      stop = true;\n  }\n  return 0;\n}</code></pre>\n<p>识别结果:</p>\n<p><img src=\"https://i.loli.net/2019/08/02/5d43e017d9e1227148.png\" alt><br><img src=\"https://i.loli.net/2019/08/02/5d43e017f281538470.png\" alt></p>\n"},{"title":"Enjoy PyTorch-Task1","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2019-08-07T05:11:13.000Z","password":null,"summary":null,"_content":"\n# Installing PyTorch with Anaconda and Conda\n\nMy Particular Environment:\n- OS: Ubuntu 16.04\n- Package Manager: conda\n- Python: 3.6\n- CUDA: None\n\nGetting started with PyTorch is very easy. The recommended best option is to use the Anaconda Pythob package manager.\n\n1. [Download and install Anaconda](https://www.anaconda.com/distribution/)(Go with the latest Python version)    \nYou can download the `.sh` package from the Anaconda website, but it's very slowly for me. So i find another choice.    \nYou can find it in [Tsinghua university open source mirror station](https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/), which i download is `Anaconda3-5.2.0-Linux-x86_64.sh`. Or if you already get the \"wget\", you can run this command in the terminal.\n```bash\nwget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.2.0-Linux-x86_64.sh\n```\nUse `conda -V` to check the Version of Anaconda after open a new terminal.\nIf it isn't work, try,\n```bash\necho 'export PATH=\"~/anaconda3/bin:$PATH\"' >> ~/.bashrc\nsource ./bashrc\n```\n2. Go to the Getting Started section on the [Pytorch website](https://pytorch.org/).\n3. Specify the appropriate configuration options for your particular environment.\n![](1.png)\n4. Run the presented command in the terminal to install Pytorch.\n```bash\nconda install pytorch-cpu torchvision-cpu -c pytorch\n```\n\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.utils.data as Data\n\n# Hyper Parameters\nEPOCH = 1  \nBATCH_SIZE = 50\nLR = 0.001  \nDOWNLOAD_MNIST = True  \n\n# Mnist\ntrain_data = torchvision.datasets.MNIST(\n    root='./mnist/',  \n    train=True,  # this is training data\n    transform=torchvision.transforms.ToTensor(),  # exchange PIL.Image or numpy.ndarray to torch.FloatTensor (C x H x W)\n    download=DOWNLOAD_MNIST,  \n)\n\ntest_data = torchvision.datasets.MNIST(\n    root='./mnist/',\n    train=False\n)\n\n# BATCH_SIZE\ntrain_loader = Data.DataLoader(\n    dataset=train_data,\n    batch_size=BATCH_SIZE,\n    shuffle=True  \n)\n\n# test_data\ntest_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)\ntest_y = test_data.test_labels\n\n\n# cnn\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            # (1, 28, 28)\n            nn.Conv2d(\n                in_channels=1,\n                out_channels=16,\n                kernel_size=5,  \n                stride=1,  \n                padding=2,\n                groups=1\n            ),\n            # (16, 28, 38)\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n            # (16, 14, 14)\n        )\n        self.layer2 = nn.Sequential(\n\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=5,\n                stride=1,\n                padding=2\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.layer3 = nn.Linear(32 * 7 * 7, 10)\n\n    def forward(self, x):\n        # print(x.shape)\n        x = self.layer1(x)\n        # print(x.shape)\n        x = self.layer2(x)\n        # print(x.shape)\n        x = x.view(x.size(0), -1)\n        # print(x.shape)\n        x = self.layer3(x)\n        # print(x.shape)\n        return x\n\n\ncnn = CNN()\n\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nfor epoch in range(EPOCH):\n    for step, (b_x, b_y) in enumerate(train_loader):\n        output = cnn(b_x)\n        loss = loss_function(output, b_y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\nprint('finished training')\ntest_out = cnn(test_x)\npredict_y = torch.argmax(test_out, 1).data.numpy()\nprint('Accuracy in Test : %.4f%%' % (sum(predict_y == test_y.data.numpy()) * 100/ len(predict_y)))\n```\n\n","source":"_posts/Enjoy-PyTorch-Task1.md","raw":"---\ntitle: Enjoy PyTorch-Task1\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2019-08-07 13:11:13\npassword:\nsummary:\ntags:\ncategories:\n---\n\n# Installing PyTorch with Anaconda and Conda\n\nMy Particular Environment:\n- OS: Ubuntu 16.04\n- Package Manager: conda\n- Python: 3.6\n- CUDA: None\n\nGetting started with PyTorch is very easy. The recommended best option is to use the Anaconda Pythob package manager.\n\n1. [Download and install Anaconda](https://www.anaconda.com/distribution/)(Go with the latest Python version)    \nYou can download the `.sh` package from the Anaconda website, but it's very slowly for me. So i find another choice.    \nYou can find it in [Tsinghua university open source mirror station](https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/), which i download is `Anaconda3-5.2.0-Linux-x86_64.sh`. Or if you already get the \"wget\", you can run this command in the terminal.\n```bash\nwget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.2.0-Linux-x86_64.sh\n```\nUse `conda -V` to check the Version of Anaconda after open a new terminal.\nIf it isn't work, try,\n```bash\necho 'export PATH=\"~/anaconda3/bin:$PATH\"' >> ~/.bashrc\nsource ./bashrc\n```\n2. Go to the Getting Started section on the [Pytorch website](https://pytorch.org/).\n3. Specify the appropriate configuration options for your particular environment.\n![](1.png)\n4. Run the presented command in the terminal to install Pytorch.\n```bash\nconda install pytorch-cpu torchvision-cpu -c pytorch\n```\n\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.utils.data as Data\n\n# Hyper Parameters\nEPOCH = 1  \nBATCH_SIZE = 50\nLR = 0.001  \nDOWNLOAD_MNIST = True  \n\n# Mnist\ntrain_data = torchvision.datasets.MNIST(\n    root='./mnist/',  \n    train=True,  # this is training data\n    transform=torchvision.transforms.ToTensor(),  # exchange PIL.Image or numpy.ndarray to torch.FloatTensor (C x H x W)\n    download=DOWNLOAD_MNIST,  \n)\n\ntest_data = torchvision.datasets.MNIST(\n    root='./mnist/',\n    train=False\n)\n\n# BATCH_SIZE\ntrain_loader = Data.DataLoader(\n    dataset=train_data,\n    batch_size=BATCH_SIZE,\n    shuffle=True  \n)\n\n# test_data\ntest_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)\ntest_y = test_data.test_labels\n\n\n# cnn\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            # (1, 28, 28)\n            nn.Conv2d(\n                in_channels=1,\n                out_channels=16,\n                kernel_size=5,  \n                stride=1,  \n                padding=2,\n                groups=1\n            ),\n            # (16, 28, 38)\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n            # (16, 14, 14)\n        )\n        self.layer2 = nn.Sequential(\n\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=5,\n                stride=1,\n                padding=2\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.layer3 = nn.Linear(32 * 7 * 7, 10)\n\n    def forward(self, x):\n        # print(x.shape)\n        x = self.layer1(x)\n        # print(x.shape)\n        x = self.layer2(x)\n        # print(x.shape)\n        x = x.view(x.size(0), -1)\n        # print(x.shape)\n        x = self.layer3(x)\n        # print(x.shape)\n        return x\n\n\ncnn = CNN()\n\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nfor epoch in range(EPOCH):\n    for step, (b_x, b_y) in enumerate(train_loader):\n        output = cnn(b_x)\n        loss = loss_function(output, b_y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\nprint('finished training')\ntest_out = cnn(test_x)\npredict_y = torch.argmax(test_out, 1).data.numpy()\nprint('Accuracy in Test : %.4f%%' % (sum(predict_y == test_y.data.numpy()) * 100/ len(predict_y)))\n```\n\n","slug":"Enjoy-PyTorch-Task1","published":1,"updated":"2019-08-10T10:47:34.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lti0010e5g689hs8t1h","content":"<h1 id=\"Installing-PyTorch-with-Anaconda-and-Conda\"><a href=\"#Installing-PyTorch-with-Anaconda-and-Conda\" class=\"headerlink\" title=\"Installing PyTorch with Anaconda and Conda\"></a>Installing PyTorch with Anaconda and Conda</h1><p>My Particular Environment:</p>\n<ul>\n<li>OS: Ubuntu 16.04</li>\n<li>Package Manager: conda</li>\n<li>Python: 3.6</li>\n<li>CUDA: None</li>\n</ul>\n<p>Getting started with PyTorch is very easy. The recommended best option is to use the Anaconda Pythob package manager.</p>\n<ol>\n<li><a href=\"https://www.anaconda.com/distribution/\" target=\"_blank\" rel=\"noopener\">Download and install Anaconda</a>(Go with the latest Python version)<br>You can download the <code>.sh</code> package from the Anaconda website, but it’s very slowly for me. So i find another choice.<br>You can find it in <a href=\"https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/\" target=\"_blank\" rel=\"noopener\">Tsinghua university open source mirror station</a>, which i download is <code>Anaconda3-5.2.0-Linux-x86_64.sh</code>. Or if you already get the “wget”, you can run this command in the terminal.<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.2.0-Linux-x86_64.sh</code></pre>\nUse <code>conda -V</code> to check the Version of Anaconda after open a new terminal.<br>If it isn’t work, try,<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token keyword\">echo</span> <span class=\"token string\">'export PATH=\"~/anaconda3/bin:<span class=\"token variable\">$PATH</span>\"'</span> <span class=\"token operator\">>></span> ~/.bashrc\n<span class=\"token function\">source</span> ./bashrc</code></pre>\n</li>\n<li>Go to the Getting Started section on the <a href=\"https://pytorch.org/\" target=\"_blank\" rel=\"noopener\">Pytorch website</a>.</li>\n<li>Specify the appropriate configuration options for your particular environment.<br><img src=\"1.png\" alt></li>\n<li>Run the presented command in the terminal to install Pytorch.<pre class=\" language-bash\"><code class=\"language-bash\">conda <span class=\"token function\">install</span> pytorch-cpu torchvision-cpu -c pytorch</code></pre>\n</li>\n</ol>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torchvision\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>data <span class=\"token keyword\">as</span> Data\n\n<span class=\"token comment\" spellcheck=\"true\"># Hyper Parameters</span>\nEPOCH <span class=\"token operator\">=</span> <span class=\"token number\">1</span>  \nBATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">50</span>\nLR <span class=\"token operator\">=</span> <span class=\"token number\">0.001</span>  \nDOWNLOAD_MNIST <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>  \n\n<span class=\"token comment\" spellcheck=\"true\"># Mnist</span>\ntrain_data <span class=\"token operator\">=</span> torchvision<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>MNIST<span class=\"token punctuation\">(</span>\n    root<span class=\"token operator\">=</span><span class=\"token string\">'./mnist/'</span><span class=\"token punctuation\">,</span>  \n    train<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\" spellcheck=\"true\"># this is training data</span>\n    transform<span class=\"token operator\">=</span>torchvision<span class=\"token punctuation\">.</span>transforms<span class=\"token punctuation\">.</span>ToTensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\" spellcheck=\"true\"># exchange PIL.Image or numpy.ndarray to torch.FloatTensor (C x H x W)</span>\n    download<span class=\"token operator\">=</span>DOWNLOAD_MNIST<span class=\"token punctuation\">,</span>  \n<span class=\"token punctuation\">)</span>\n\ntest_data <span class=\"token operator\">=</span> torchvision<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>MNIST<span class=\"token punctuation\">(</span>\n    root<span class=\"token operator\">=</span><span class=\"token string\">'./mnist/'</span><span class=\"token punctuation\">,</span>\n    train<span class=\"token operator\">=</span><span class=\"token boolean\">False</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># BATCH_SIZE</span>\ntrain_loader <span class=\"token operator\">=</span> Data<span class=\"token punctuation\">.</span>DataLoader<span class=\"token punctuation\">(</span>\n    dataset<span class=\"token operator\">=</span>train_data<span class=\"token punctuation\">,</span>\n    batch_size<span class=\"token operator\">=</span>BATCH_SIZE<span class=\"token punctuation\">,</span>\n    shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>  \n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># test_data</span>\ntest_x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">.</span>test_data<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>type<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>FloatTensor<span class=\"token punctuation\">)</span>\ntest_y <span class=\"token operator\">=</span> test_data<span class=\"token punctuation\">.</span>test_labels\n\n\n<span class=\"token comment\" spellcheck=\"true\"># cnn</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CNN</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        super<span class=\"token punctuation\">(</span>CNN<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>layer1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\" spellcheck=\"true\"># (1, 28, 28)</span>\n            nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>\n                in_channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                out_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span>\n                kernel_size<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span>  \n                stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>  \n                padding<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n                groups<span class=\"token operator\">=</span><span class=\"token number\">1</span>\n            <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\" spellcheck=\"true\"># (16, 28, 38)</span>\n            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\" spellcheck=\"true\"># (16, 14, 14)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>layer2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n\n            nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>\n                in_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span>\n                out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span>\n                kernel_size<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\n                stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                padding<span class=\"token operator\">=</span><span class=\"token number\">2</span>\n            <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>layer3 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">32</span> <span class=\"token operator\">*</span> <span class=\"token number\">7</span> <span class=\"token operator\">*</span> <span class=\"token number\">7</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\"># print(x.shape)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>layer1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\" spellcheck=\"true\"># print(x.shape)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>layer2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\" spellcheck=\"true\"># print(x.shape)</span>\n        x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\" spellcheck=\"true\"># print(x.shape)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>layer3<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\" spellcheck=\"true\"># print(x.shape)</span>\n        <span class=\"token keyword\">return</span> x\n\n\ncnn <span class=\"token operator\">=</span> CNN<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\noptimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>cnn<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span>LR<span class=\"token punctuation\">)</span>\nloss_function <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>CrossEntropyLoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>EPOCH<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> step<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>b_x<span class=\"token punctuation\">,</span> b_y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output <span class=\"token operator\">=</span> cnn<span class=\"token punctuation\">(</span>b_x<span class=\"token punctuation\">)</span>\n        loss <span class=\"token operator\">=</span> loss_function<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">,</span> b_y<span class=\"token punctuation\">)</span>\n        optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'finished training'</span><span class=\"token punctuation\">)</span>\ntest_out <span class=\"token operator\">=</span> cnn<span class=\"token punctuation\">(</span>test_x<span class=\"token punctuation\">)</span>\npredict_y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>test_out<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy in Test : %.4f%%'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>sum<span class=\"token punctuation\">(</span>predict_y <span class=\"token operator\">==</span> test_y<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">100</span><span class=\"token operator\">/</span> len<span class=\"token punctuation\">(</span>predict_y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"Installing-PyTorch-with-Anaconda-and-Conda\"><a href=\"#Installing-PyTorch-with-Anaconda-and-Conda\" class=\"headerlink\" title=\"Installing PyTorch with Anaconda and Conda\"></a>Installing PyTorch with Anaconda and Conda</h1><p>My Particular Environment:</p>\n<ul>\n<li>OS: Ubuntu 16.04</li>\n<li>Package Manager: conda</li>\n<li>Python: 3.6</li>\n<li>CUDA: None</li>\n</ul>\n<p>Getting started with PyTorch is very easy. The recommended best option is to use the Anaconda Pythob package manager.</p>\n<ol>\n<li><a href=\"https://www.anaconda.com/distribution/\" target=\"_blank\" rel=\"noopener\">Download and install Anaconda</a>(Go with the latest Python version)<br>You can download the <code>.sh</code> package from the Anaconda website, but it’s very slowly for me. So i find another choice.<br>You can find it in <a href=\"https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/\" target=\"_blank\" rel=\"noopener\">Tsinghua university open source mirror station</a>, which i download is <code>Anaconda3-5.2.0-Linux-x86_64.sh</code>. Or if you already get the “wget”, you can run this command in the terminal.<pre><code class=\"bash\">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.2.0-Linux-x86_64.sh</code></pre>\nUse <code>conda -V</code> to check the Version of Anaconda after open a new terminal.<br>If it isn’t work, try,<pre><code class=\"bash\">echo &#39;export PATH=&quot;~/anaconda3/bin:$PATH&quot;&#39; &gt;&gt; ~/.bashrc\nsource ./bashrc</code></pre>\n</li>\n<li>Go to the Getting Started section on the <a href=\"https://pytorch.org/\" target=\"_blank\" rel=\"noopener\">Pytorch website</a>.</li>\n<li>Specify the appropriate configuration options for your particular environment.<br><img src=\"1.png\" alt></li>\n<li>Run the presented command in the terminal to install Pytorch.<pre><code class=\"bash\">conda install pytorch-cpu torchvision-cpu -c pytorch</code></pre>\n</li>\n</ol>\n<pre><code class=\"python\">import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.utils.data as Data\n\n# Hyper Parameters\nEPOCH = 1  \nBATCH_SIZE = 50\nLR = 0.001  \nDOWNLOAD_MNIST = True  \n\n# Mnist\ntrain_data = torchvision.datasets.MNIST(\n    root=&#39;./mnist/&#39;,  \n    train=True,  # this is training data\n    transform=torchvision.transforms.ToTensor(),  # exchange PIL.Image or numpy.ndarray to torch.FloatTensor (C x H x W)\n    download=DOWNLOAD_MNIST,  \n)\n\ntest_data = torchvision.datasets.MNIST(\n    root=&#39;./mnist/&#39;,\n    train=False\n)\n\n# BATCH_SIZE\ntrain_loader = Data.DataLoader(\n    dataset=train_data,\n    batch_size=BATCH_SIZE,\n    shuffle=True  \n)\n\n# test_data\ntest_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)\ntest_y = test_data.test_labels\n\n\n# cnn\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            # (1, 28, 28)\n            nn.Conv2d(\n                in_channels=1,\n                out_channels=16,\n                kernel_size=5,  \n                stride=1,  \n                padding=2,\n                groups=1\n            ),\n            # (16, 28, 38)\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n            # (16, 14, 14)\n        )\n        self.layer2 = nn.Sequential(\n\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=5,\n                stride=1,\n                padding=2\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.layer3 = nn.Linear(32 * 7 * 7, 10)\n\n    def forward(self, x):\n        # print(x.shape)\n        x = self.layer1(x)\n        # print(x.shape)\n        x = self.layer2(x)\n        # print(x.shape)\n        x = x.view(x.size(0), -1)\n        # print(x.shape)\n        x = self.layer3(x)\n        # print(x.shape)\n        return x\n\n\ncnn = CNN()\n\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nfor epoch in range(EPOCH):\n    for step, (b_x, b_y) in enumerate(train_loader):\n        output = cnn(b_x)\n        loss = loss_function(output, b_y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\nprint(&#39;finished training&#39;)\ntest_out = cnn(test_x)\npredict_y = torch.argmax(test_out, 1).data.numpy()\nprint(&#39;Accuracy in Test : %.4f%%&#39; % (sum(predict_y == test_y.data.numpy()) * 100/ len(predict_y)))</code></pre>\n"},{"title":"Enjoy PyTorch","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2019-08-07T04:56:29.000Z","password":null,"img":"https://i.loli.net/2019/08/07/qwgZ9yezahmipo2.png","summary":null,"_content":"","source":"_posts/Enjoy-PyTorch.md","raw":"---\ntitle: Enjoy PyTorch\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2019-08-07 12:56:29\npassword:\nimg: https://i.loli.net/2019/08/07/qwgZ9yezahmipo2.png\nsummary:\ntags:\ncategories:\n---\n","slug":"Enjoy-PyTorch","published":1,"updated":"2019-08-10T10:47:34.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltk0013e5g663pwqdiz","content":"","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":""},{"title":"Face Recognition with OpenCV","top":false,"cover":false,"toc":true,"mathjax":false,"date":"2019-08-09T04:00:00.000Z","password":null,"summary":null,"_content":"\n# The first step of Face Recognition: Image Acquisition and Face Database Creation\n\n## Face Database Creation\nThe official document provides a download of the face database, and i use the [AT&T Facedatabase](http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html) to creat my face databse. I have updated this zip file to my github, you can download it from [here](att_faces.zip) faster.\nAT&T Face Database is also konwn as the OCR face database, 40 people, 10 photos per person. The photos are token at different times, different lighting, different expressions(closed eyes, laughing or not laughing), diffenent face details(with or without glasses). All images were captured on a dark , eveb background with a vertical face o the front(some with a slight rotation).\n\n","source":"_posts/Face-Recognition-with-OpenCV.md","raw":"---\ntitle: Face Recognition with OpenCV\ntop: false\ncover: false\ntoc: true\nmathjax: false\ndate: 2019-08-09 12:00:00\npassword:\nsummary:\ntags:\ncategories:\n---\n\n# The first step of Face Recognition: Image Acquisition and Face Database Creation\n\n## Face Database Creation\nThe official document provides a download of the face database, and i use the [AT&T Facedatabase](http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html) to creat my face databse. I have updated this zip file to my github, you can download it from [here](att_faces.zip) faster.\nAT&T Face Database is also konwn as the OCR face database, 40 people, 10 photos per person. The photos are token at different times, different lighting, different expressions(closed eyes, laughing or not laughing), diffenent face details(with or without glasses). All images were captured on a dark , eveb background with a vertical face o the front(some with a slight rotation).\n\n","slug":"Face-Recognition-with-OpenCV","published":1,"updated":"2019-08-10T10:47:34.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltl0015e5g6bh9w9qsu","content":"<h1 id=\"The-first-step-of-Face-Recognition-Image-Acquisition-and-Face-Database-Creation\"><a href=\"#The-first-step-of-Face-Recognition-Image-Acquisition-and-Face-Database-Creation\" class=\"headerlink\" title=\"The first step of Face Recognition: Image Acquisition and Face Database Creation\"></a>The first step of Face Recognition: Image Acquisition and Face Database Creation</h1><h2 id=\"Face-Database-Creation\"><a href=\"#Face-Database-Creation\" class=\"headerlink\" title=\"Face Database Creation\"></a>Face Database Creation</h2><p>The official document provides a download of the face database, and i use the <a href=\"http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\" target=\"_blank\" rel=\"noopener\">AT&amp;T Facedatabase</a> to creat my face databse. I have updated this zip file to my github, you can download it from <a href=\"att_faces.zip\">here</a> faster.<br>AT&amp;T Face Database is also konwn as the OCR face database, 40 people, 10 photos per person. The photos are token at different times, different lighting, different expressions(closed eyes, laughing or not laughing), diffenent face details(with or without glasses). All images were captured on a dark , eveb background with a vertical face o the front(some with a slight rotation).</p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"The-first-step-of-Face-Recognition-Image-Acquisition-and-Face-Database-Creation\"><a href=\"#The-first-step-of-Face-Recognition-Image-Acquisition-and-Face-Database-Creation\" class=\"headerlink\" title=\"The first step of Face Recognition: Image Acquisition and Face Database Creation\"></a>The first step of Face Recognition: Image Acquisition and Face Database Creation</h1><h2 id=\"Face-Database-Creation\"><a href=\"#Face-Database-Creation\" class=\"headerlink\" title=\"Face Database Creation\"></a>Face Database Creation</h2><p>The official document provides a download of the face database, and i use the <a href=\"http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\" target=\"_blank\" rel=\"noopener\">AT&amp;T Facedatabase</a> to creat my face databse. I have updated this zip file to my github, you can download it from <a href=\"att_faces.zip\">here</a> faster.<br>AT&amp;T Face Database is also konwn as the OCR face database, 40 people, 10 photos per person. The photos are token at different times, different lighting, different expressions(closed eyes, laughing or not laughing), diffenent face details(with or without glasses). All images were captured on a dark , eveb background with a vertical face o the front(some with a slight rotation).</p>\n"},{"title":"How to install OpenCV and OpenCV_contrib in Ubuntu16.04","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2019-08-09T03:49:11.000Z","password":null,"summary":null,"_content":"","source":"_posts/How-to-install-OpenCV-and-OpenCV-contrib-in-Ubuntu16-04.md","raw":"---\ntitle: How to install OpenCV and OpenCV_contrib in Ubuntu16.04\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2019-08-09 11:49:11\npassword:\nsummary:\ntags:\ncategories:\n---\n","slug":"How-to-install-OpenCV-and-OpenCV-contrib-in-Ubuntu16-04","published":1,"updated":"2019-08-10T10:47:34.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltm0017e5g6r8ha31am","content":"","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":""},{"title":"Markdown数学公式汇总","date":"2019-07-19T07:31:03.000Z","mathjax":true,"img":"https://i.loli.net/2019/07/08/5d235019a672f97339.jpg","_content":"\n[TOC]\n### 参考\n#### 分数、上标、下标、方根、求和、积分\n分数 ` $\\dfrac{2}{3}$ `表示$\\dfrac{2}{3}$，` $\\tfrac{2}{3}$ `表示$\\tfrac{2}{3}$\n```\n\\begin{eqnarray\\*}\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 + \\cdots}}}\n\\end{eqnarray\\*}\n```\n表示\n\\begin{eqnarray\\*}\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 + \\cdots}}}\n\\end{eqnarray\\*}\n\n***\n上标$A^2$、$A^{上标}$\n` $$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$ `表示$$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$\n\n***\n下标$A_2$、$A_{下标}$\n` $$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$ `表示$$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$\n\n***\n开方数$\\sqrt[开方数]{参数}$\n` $$\\sqrt[开方数]{参数}$$`表示$$\\sqrt[开方数]{参数}$$\n\n***\n求和$\\sum$\n$$\\sum ^2_3\\;\\sum \\nolimits^2_3$$\n\n***\n分$\\int$\n$$\\int ^2_3\\;\\int \\limits^2_3$$\n\n***\n\n#### 行内公式\n$R^s_r(t_r,t_e)=(t_r-t_e)c$\n***\n#### 显示公式\n$$R^s_r(t_r,t_e)=(t_r-t_e)c$$\n***\n#### 带有编号的显示公式\n\\begin{equation}\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{equation}\n***\n#### 带有编号的多行公式\n\\begin{eqnarray}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray}\n***\n#### 取消某一编号的多行公式\n\\begin{eqnarray}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\nonumber\\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray}\n***\n#### 带有指定编号的多行公式\n\\begin{eqnarray\\*}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\tag{1}\\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray\\*}\n***\n#### 不带编号的多行公式\n\\begin{eqnarray\\*}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray\\*}\n***\n#### 指定对齐方式的多行公式\n\\begin{eqnarray}\n    &R^s_r(t_r,t_e)&=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)& = &(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=&(t_r-t_e)c&\n\\end{eqnarray}\n***\n#### 输入矩阵\n\\begin{matrix}\n    0 & 1 \\\\\\\n    1 & 0\n\\end{matrix}\n***\n\\begin{pmatrix}\n    0 & -i \\\\\\\n    i & 0\n\\end{pmatrix}\n***\n\\begin{bmatrix}\n    0 & -1 \\\\\\\n    1 & 0\n\\end{bmatrix}\n***\n\\begin{Bmatrix}\n    1 & 0 \\\\\\\n    0 & -1\n\\end{Bmatrix}\n***\n\\begin{vmatrix}\n    a & b \\\\\\\n    c & d\n\\end{vmatrix}\n***\n\\begin{Vmatrix}\n    i & 0 \\\\\\\n     0 & -i\n\\end{Vmatrix}\n***\n#### 数学符号\n##### 操作符号\n$$\n\\pm    \\mp    \\times    \\div    \\ast    \\star    \\circ    \\bullet    \\divideontimes    \\ltimes    \\rtimes    \\cdot    \\dotplus    \\leftthreetimes    \\rightthreetimes    \\amalg    \\otimes    \\oplus    \\ominus    \\oslash    \\odot    \\circledcirc    \\circleddash    \\circledast    \\bigcirc \\boxdot    \\boxminus    \\boxplus    \\boxtimes    \\diamond    \\bigtriangleup    \\bigtriangledown    \\triangleleft    \\triangleright    \\lhd    \\rhd    \\unlhd    \\unrhd    \\cup    \\cap    \\uplus    \\Cup    \\Cap    \\wr    \\setminus    \\smallsetminus    \\sqcap    \\sqcup \\wedge    \\vee    \\barwedge    \\veebar    \\doublebarwedge    \\curlywedge    \\curlyvee    \\dagger    \\ddagger    \\intercal    \\bigcap    \\bigcup    \\biguplus    \\bigsqcup    \\prod    \\coprod    \\bigwedge    \\bigvee    \\bigodot    \\bigoplus    \\bigotimes    \\sum \\int    \\oint    \\iint    \\iiint    \\iiiint    \\idotsint    \\arccos    \\arcsin    \\arctan    \\arg    \\cos    \\cosh    \\cot    \\coth    \\csc    \\deg    \\det    \\dim    \\exp    \\gcd    \\hom    \\inf    \\ker    \\lg    \\lim    \\liminf    \\limsup    \\ln    \\log    \\max    \\min    \\Pr    \\projlim    \\sec\\sin\\sinh    \\sup    \\tan    \\tanh \\varlimsup    \\varliminf    \\varinjlim    \\varprojlim\n $$\n##### 关系符号\n$$\n\\bowtie    \\Join    \\propto    \\varpropto    \\multimap    \\pitchfork  \\therefore    \\because    =    \\neq    \\equiv    \\approx    \\sim    \\simeq    \\backsimeq    \\approxeq    \\cong    \\ncong        \\smile    \\frown    \\asymp    \\smallfrown    \\smallsmile    \\between    \\prec    \\succ    \\nprec    \\nsucc    \\preceq    \\succeq    \\npreceq    \\nsucceq    \\preccurlyeq    \\succcurlyeq    \\curlyeqprec    \\curlyeqsucc    \\precsim    \\succsim    \\precnsim    \\succnsim    \\precapprox    \\succapprox    \\precnapprox    \\succnapprox    \\perp    \\vdash    \\dashv    \\nvdash    \\Vdash    \\Vvdash    \\models    \\vDash    \\nvDash    \\nVDash    \\mid    \\nmid    \\parallel    \\nparallel    \\shortmid    \\nshortmid    \\shortparallel    \\nshortparallel    <    >    \\nless    \\ngtr    \\lessdot    \\gtrdot    \\ll    \\gg    \\lll    \\ggg    \\leq    \\geq    \\lneq    \\gneq    \\nleq    \\ngeq    \\leqq    \\geqq    \\lneqq    \\gneqq    \\lvertneqq    \\gvertneqq    \\nleqq    \\ngeqq    \\leqslant    \\geqslant    \\nleqslant    \\ngeqslant    \\eqslantless    \\eqslantgtr    \\lessgtr    \\gtrless    \\lesseqgtr    \\gtreqless    \\lesseqqgtr    \\gtreqqless    \\lesssim    \\gtrsim    \\lnsim    \\gnsim    \\lessapprox    \\gtrapprox    \\lnapprox    \\gnapprox    \\vartriangleleft    \\vartriangleright    \\ntriangleleft    \\ntriangleright    \\trianglelefteq    \\trianglerighteq    \\ntrianglelefteq    \\ntrianglerighteq    \\blacktriangleleft    \\blacktriangleright    \\subset    \\supset    \\subseteq    \\supseteq    \\subsetneq    \\supsetneq    \\varsubsetneq    \\varsupsetneq    \\nsubseteq    \\nsupseteq    \\subseteqq    \\supseteqq    \\subsetneqq    \\supsetneqq    \\nsubseteqq    \\nsupseteqq    \\backepsilon    \\Subset    \\Supset    \\sqsubset    \\sqsupset    \\sqsubseteq    \\sqsupseteq\n$$\n##### 箭头符号\n$$\n\\leftarrow    \\leftrightarrow    \\rightarrow    \\mapsto    \\longleftarrow        \\longleftrightarrow    \\longrightarrow    \\longmapsto    \\downarrow    \\updownarrow    \\uparrow    \\nwarrow        \\searrow    \\nearrow    \\swarrow        \\nleftarrow            \\nleftrightarrow        \\nrightarrow        \\hookleftarrow        \\hookrightarrow        \\twoheadleftarrow        \\twoheadrightarrow        \\leftarrowtail        \\rightarrowtail        \\Leftarrow        \\Leftrightarrow        \\Rightarrow        \\Longleftarrow        \\Longleftrightarrow        \\Longrightarrow            \\Updownarrow        \\Uparrow        \\Downarrow        \\nLeftarrow        \\nLeftrightarrow    \\nRightarrow        \\leftleftarrows        \\leftrightarrows        \\rightleftarrows        \\rightrightarrows        \\downdownarrows        \\upuparrows        \\circlearrowleft        \\circlearrowright        \\curvearrowleft        \\curvearrowright        \\Lsh        \\Rsh        \\looparrowleft        \\looparrowright        \\dashleftarrow        \\dashrightarrow        \\leftrightsquigarrow        \\rightsquigarrow        \\Lleftarrow        \\leftharpoondown        \\rightharpoondown        \\leftharpoonup        \\rightharpoonup        \\rightleftharpoons        \\leftrightharpoons        \\downharpoonleft        \\upharpoonleft        \\downharpoonright            \\upharpoonright\n$$\n##### 分隔符\n$$\n\\downarrow    \\Downarrow    \\langle \\rangle [ ] | \\| \\lceil \\rceil \\uparrow    \\Uparrow    \\lfloor        \\rfloor    \\updownarrow    \\Updownarrow    (        )    \\{    \\} \\backslash    \\lmoustache        \\rmoustache    \\lgroup    \\rgroup    \\arrowvert    \\Arrowvert    \\bracevert    \\lvert    \\rvert    \\lVert        \\rVert    \\ulcorner    \\urcorner \\llcorner \\lrcorner\n$$\n##### 希腊字符\n$$\n\\alpha    \\beta        \\gamma    \\delta    \\epsilon    \\zeta    \\eta    \\theta    \\vartheta    \\iota    \\kappa    \\lambda    \\mu    \\nu    \\xi    o    \\pi    \\varpi    \\rho    \\varrho    \\sigma    \\varsigma    \\tau    \\upsilon    \\phi    \\varphi    \\chi    \\psi    \\omega    A    B    \\Gamma    \\varGamma    \\Delta    \\varDelta    E    Z    H    \\Theta    \\varTheta    I    K    \\Lambda    \\varLambda    M    N    \\Xi    \\varXi    O    \\Pi    \\varPi    P    \\Sigma        \\Upsilon    \\varUpsilon    \\Phi    \\varPhi    X    \\varPsi    \\Omega    \\varOmega\n$$\n\n\n\n","source":"_posts/Markdown数学公式汇总.md","raw":"---\ntitle: Markdown数学公式汇总\ndate: 2019-07-19 15:31:03\ntags: Markdown\nmathjax: true\nimg: https://i.loli.net/2019/07/08/5d235019a672f97339.jpg\n---\n\n[TOC]\n### 参考\n#### 分数、上标、下标、方根、求和、积分\n分数 ` $\\dfrac{2}{3}$ `表示$\\dfrac{2}{3}$，` $\\tfrac{2}{3}$ `表示$\\tfrac{2}{3}$\n```\n\\begin{eqnarray\\*}\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 + \\cdots}}}\n\\end{eqnarray\\*}\n```\n表示\n\\begin{eqnarray\\*}\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 + \\cdots}}}\n\\end{eqnarray\\*}\n\n***\n上标$A^2$、$A^{上标}$\n` $$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$ `表示$$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$\n\n***\n下标$A_2$、$A_{下标}$\n` $$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$ `表示$$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$\n\n***\n开方数$\\sqrt[开方数]{参数}$\n` $$\\sqrt[开方数]{参数}$$`表示$$\\sqrt[开方数]{参数}$$\n\n***\n求和$\\sum$\n$$\\sum ^2_3\\;\\sum \\nolimits^2_3$$\n\n***\n分$\\int$\n$$\\int ^2_3\\;\\int \\limits^2_3$$\n\n***\n\n#### 行内公式\n$R^s_r(t_r,t_e)=(t_r-t_e)c$\n***\n#### 显示公式\n$$R^s_r(t_r,t_e)=(t_r-t_e)c$$\n***\n#### 带有编号的显示公式\n\\begin{equation}\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{equation}\n***\n#### 带有编号的多行公式\n\\begin{eqnarray}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray}\n***\n#### 取消某一编号的多行公式\n\\begin{eqnarray}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\nonumber\\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray}\n***\n#### 带有指定编号的多行公式\n\\begin{eqnarray\\*}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\tag{1}\\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray\\*}\n***\n#### 不带编号的多行公式\n\\begin{eqnarray\\*}\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=(t_r-t_e)c\n\\end{eqnarray\\*}\n***\n#### 指定对齐方式的多行公式\n\\begin{eqnarray}\n    &R^s_r(t_r,t_e)&=(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)& = &(t_r-t_e)c \\\\\\\n    R^s_r(t_r,t_e)=&(t_r-t_e)c&\n\\end{eqnarray}\n***\n#### 输入矩阵\n\\begin{matrix}\n    0 & 1 \\\\\\\n    1 & 0\n\\end{matrix}\n***\n\\begin{pmatrix}\n    0 & -i \\\\\\\n    i & 0\n\\end{pmatrix}\n***\n\\begin{bmatrix}\n    0 & -1 \\\\\\\n    1 & 0\n\\end{bmatrix}\n***\n\\begin{Bmatrix}\n    1 & 0 \\\\\\\n    0 & -1\n\\end{Bmatrix}\n***\n\\begin{vmatrix}\n    a & b \\\\\\\n    c & d\n\\end{vmatrix}\n***\n\\begin{Vmatrix}\n    i & 0 \\\\\\\n     0 & -i\n\\end{Vmatrix}\n***\n#### 数学符号\n##### 操作符号\n$$\n\\pm    \\mp    \\times    \\div    \\ast    \\star    \\circ    \\bullet    \\divideontimes    \\ltimes    \\rtimes    \\cdot    \\dotplus    \\leftthreetimes    \\rightthreetimes    \\amalg    \\otimes    \\oplus    \\ominus    \\oslash    \\odot    \\circledcirc    \\circleddash    \\circledast    \\bigcirc \\boxdot    \\boxminus    \\boxplus    \\boxtimes    \\diamond    \\bigtriangleup    \\bigtriangledown    \\triangleleft    \\triangleright    \\lhd    \\rhd    \\unlhd    \\unrhd    \\cup    \\cap    \\uplus    \\Cup    \\Cap    \\wr    \\setminus    \\smallsetminus    \\sqcap    \\sqcup \\wedge    \\vee    \\barwedge    \\veebar    \\doublebarwedge    \\curlywedge    \\curlyvee    \\dagger    \\ddagger    \\intercal    \\bigcap    \\bigcup    \\biguplus    \\bigsqcup    \\prod    \\coprod    \\bigwedge    \\bigvee    \\bigodot    \\bigoplus    \\bigotimes    \\sum \\int    \\oint    \\iint    \\iiint    \\iiiint    \\idotsint    \\arccos    \\arcsin    \\arctan    \\arg    \\cos    \\cosh    \\cot    \\coth    \\csc    \\deg    \\det    \\dim    \\exp    \\gcd    \\hom    \\inf    \\ker    \\lg    \\lim    \\liminf    \\limsup    \\ln    \\log    \\max    \\min    \\Pr    \\projlim    \\sec\\sin\\sinh    \\sup    \\tan    \\tanh \\varlimsup    \\varliminf    \\varinjlim    \\varprojlim\n $$\n##### 关系符号\n$$\n\\bowtie    \\Join    \\propto    \\varpropto    \\multimap    \\pitchfork  \\therefore    \\because    =    \\neq    \\equiv    \\approx    \\sim    \\simeq    \\backsimeq    \\approxeq    \\cong    \\ncong        \\smile    \\frown    \\asymp    \\smallfrown    \\smallsmile    \\between    \\prec    \\succ    \\nprec    \\nsucc    \\preceq    \\succeq    \\npreceq    \\nsucceq    \\preccurlyeq    \\succcurlyeq    \\curlyeqprec    \\curlyeqsucc    \\precsim    \\succsim    \\precnsim    \\succnsim    \\precapprox    \\succapprox    \\precnapprox    \\succnapprox    \\perp    \\vdash    \\dashv    \\nvdash    \\Vdash    \\Vvdash    \\models    \\vDash    \\nvDash    \\nVDash    \\mid    \\nmid    \\parallel    \\nparallel    \\shortmid    \\nshortmid    \\shortparallel    \\nshortparallel    <    >    \\nless    \\ngtr    \\lessdot    \\gtrdot    \\ll    \\gg    \\lll    \\ggg    \\leq    \\geq    \\lneq    \\gneq    \\nleq    \\ngeq    \\leqq    \\geqq    \\lneqq    \\gneqq    \\lvertneqq    \\gvertneqq    \\nleqq    \\ngeqq    \\leqslant    \\geqslant    \\nleqslant    \\ngeqslant    \\eqslantless    \\eqslantgtr    \\lessgtr    \\gtrless    \\lesseqgtr    \\gtreqless    \\lesseqqgtr    \\gtreqqless    \\lesssim    \\gtrsim    \\lnsim    \\gnsim    \\lessapprox    \\gtrapprox    \\lnapprox    \\gnapprox    \\vartriangleleft    \\vartriangleright    \\ntriangleleft    \\ntriangleright    \\trianglelefteq    \\trianglerighteq    \\ntrianglelefteq    \\ntrianglerighteq    \\blacktriangleleft    \\blacktriangleright    \\subset    \\supset    \\subseteq    \\supseteq    \\subsetneq    \\supsetneq    \\varsubsetneq    \\varsupsetneq    \\nsubseteq    \\nsupseteq    \\subseteqq    \\supseteqq    \\subsetneqq    \\supsetneqq    \\nsubseteqq    \\nsupseteqq    \\backepsilon    \\Subset    \\Supset    \\sqsubset    \\sqsupset    \\sqsubseteq    \\sqsupseteq\n$$\n##### 箭头符号\n$$\n\\leftarrow    \\leftrightarrow    \\rightarrow    \\mapsto    \\longleftarrow        \\longleftrightarrow    \\longrightarrow    \\longmapsto    \\downarrow    \\updownarrow    \\uparrow    \\nwarrow        \\searrow    \\nearrow    \\swarrow        \\nleftarrow            \\nleftrightarrow        \\nrightarrow        \\hookleftarrow        \\hookrightarrow        \\twoheadleftarrow        \\twoheadrightarrow        \\leftarrowtail        \\rightarrowtail        \\Leftarrow        \\Leftrightarrow        \\Rightarrow        \\Longleftarrow        \\Longleftrightarrow        \\Longrightarrow            \\Updownarrow        \\Uparrow        \\Downarrow        \\nLeftarrow        \\nLeftrightarrow    \\nRightarrow        \\leftleftarrows        \\leftrightarrows        \\rightleftarrows        \\rightrightarrows        \\downdownarrows        \\upuparrows        \\circlearrowleft        \\circlearrowright        \\curvearrowleft        \\curvearrowright        \\Lsh        \\Rsh        \\looparrowleft        \\looparrowright        \\dashleftarrow        \\dashrightarrow        \\leftrightsquigarrow        \\rightsquigarrow        \\Lleftarrow        \\leftharpoondown        \\rightharpoondown        \\leftharpoonup        \\rightharpoonup        \\rightleftharpoons        \\leftrightharpoons        \\downharpoonleft        \\upharpoonleft        \\downharpoonright            \\upharpoonright\n$$\n##### 分隔符\n$$\n\\downarrow    \\Downarrow    \\langle \\rangle [ ] | \\| \\lceil \\rceil \\uparrow    \\Uparrow    \\lfloor        \\rfloor    \\updownarrow    \\Updownarrow    (        )    \\{    \\} \\backslash    \\lmoustache        \\rmoustache    \\lgroup    \\rgroup    \\arrowvert    \\Arrowvert    \\bracevert    \\lvert    \\rvert    \\lVert        \\rVert    \\ulcorner    \\urcorner \\llcorner \\lrcorner\n$$\n##### 希腊字符\n$$\n\\alpha    \\beta        \\gamma    \\delta    \\epsilon    \\zeta    \\eta    \\theta    \\vartheta    \\iota    \\kappa    \\lambda    \\mu    \\nu    \\xi    o    \\pi    \\varpi    \\rho    \\varrho    \\sigma    \\varsigma    \\tau    \\upsilon    \\phi    \\varphi    \\chi    \\psi    \\omega    A    B    \\Gamma    \\varGamma    \\Delta    \\varDelta    E    Z    H    \\Theta    \\varTheta    I    K    \\Lambda    \\varLambda    M    N    \\Xi    \\varXi    O    \\Pi    \\varPi    P    \\Sigma        \\Upsilon    \\varUpsilon    \\Phi    \\varPhi    X    \\varPsi    \\Omega    \\varOmega\n$$\n\n\n\n","slug":"Markdown数学公式汇总","published":1,"updated":"2019-08-10T10:47:34.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltn0018e5g6emkb5xbn","content":"<p>[TOC]</p>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><h4 id=\"分数、上标、下标、方根、求和、积分\"><a href=\"#分数、上标、下标、方根、求和、积分\" class=\"headerlink\" title=\"分数、上标、下标、方根、求和、积分\"></a>分数、上标、下标、方根、求和、积分</h4><p>分数 <code>$\\dfrac{2}{3}$</code>表示$\\dfrac{2}{3}$，<code>$\\tfrac{2}{3}$</code>表示$\\tfrac{2}{3}$</p>\n<pre><code>\\begin{eqnarray\\*}\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 + \\cdots}}}\n\\end{eqnarray\\*}</code></pre><p>表示<br>\\begin{eqnarray*}<br>    \\dfrac{1}{\\sqrt 2 +<br>    \\dfrac{1}{\\sqrt 2 +<br>    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;<br>    \\tfrac{1}{\\sqrt 2 +<br>    \\tfrac{1}{\\sqrt 2 +<br>    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;<br>    \\frac{1}{\\sqrt 2 +<br>    \\frac{1}{\\sqrt 2 +<br>    \\frac{1}{\\sqrt 2 + \\cdots}}}<br>\\end{eqnarray*}</p>\n<hr>\n<p>上标$A^2$、$A^{上标}$<br><code>$$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$</code>表示$$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$</p>\n<hr>\n<p>下标$A_2$、$A_{下标}$<br><code>$$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$</code>表示$$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$</p>\n<hr>\n<p>开方数$\\sqrt[开方数]{参数}$<br><code>$$\\sqrt[开方数]{参数}$$</code>表示$$\\sqrt[开方数]{参数}$$</p>\n<hr>\n<p>求和$\\sum$<br>$$\\sum ^2_3\\;\\sum \\nolimits^2_3$$</p>\n<hr>\n<p>分$\\int$<br>$$\\int ^2_3\\;\\int \\limits^2_3$$</p>\n<hr>\n<h4 id=\"行内公式\"><a href=\"#行内公式\" class=\"headerlink\" title=\"行内公式\"></a>行内公式</h4><p>$R^s_r(t_r,t_e)=(t_r-t_e)c$</p>\n<hr>\n<h4 id=\"显示公式\"><a href=\"#显示公式\" class=\"headerlink\" title=\"显示公式\"></a>显示公式</h4><p>$$R^s_r(t_r,t_e)=(t_r-t_e)c$$</p>\n<hr>\n<h4 id=\"带有编号的显示公式\"><a href=\"#带有编号的显示公式\" class=\"headerlink\" title=\"带有编号的显示公式\"></a>带有编号的显示公式</h4><p>\\begin{equation}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{equation}</p>\n<hr>\n<h4 id=\"带有编号的多行公式\"><a href=\"#带有编号的多行公式\" class=\"headerlink\" title=\"带有编号的多行公式\"></a>带有编号的多行公式</h4><p>\\begin{eqnarray}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray}</p>\n<hr>\n<h4 id=\"取消某一编号的多行公式\"><a href=\"#取消某一编号的多行公式\" class=\"headerlink\" title=\"取消某一编号的多行公式\"></a>取消某一编号的多行公式</h4><p>\\begin{eqnarray}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\nonumber\\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray}</p>\n<hr>\n<h4 id=\"带有指定编号的多行公式\"><a href=\"#带有指定编号的多行公式\" class=\"headerlink\" title=\"带有指定编号的多行公式\"></a>带有指定编号的多行公式</h4><p>\\begin{eqnarray*}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\tag{1}\\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray*}</p>\n<hr>\n<h4 id=\"不带编号的多行公式\"><a href=\"#不带编号的多行公式\" class=\"headerlink\" title=\"不带编号的多行公式\"></a>不带编号的多行公式</h4><p>\\begin{eqnarray*}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray*}</p>\n<hr>\n<h4 id=\"指定对齐方式的多行公式\"><a href=\"#指定对齐方式的多行公式\" class=\"headerlink\" title=\"指定对齐方式的多行公式\"></a>指定对齐方式的多行公式</h4><p>\\begin{eqnarray}<br>    &amp;R^s_r(t_r,t_e)&amp;=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)&amp; = &amp;(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=&amp;(t_r-t_e)c&amp;<br>\\end{eqnarray}</p>\n<hr>\n<h4 id=\"输入矩阵\"><a href=\"#输入矩阵\" class=\"headerlink\" title=\"输入矩阵\"></a>输入矩阵</h4><p>\\begin{matrix}<br>    0 &amp; 1 \\\\<br>    1 &amp; 0<br>\\end{matrix}</p>\n<hr>\n<p>\\begin{pmatrix}<br>    0 &amp; -i \\\\<br>    i &amp; 0<br>\\end{pmatrix}</p>\n<hr>\n<p>\\begin{bmatrix}<br>    0 &amp; -1 \\\\<br>    1 &amp; 0<br>\\end{bmatrix}</p>\n<hr>\n<p>\\begin{Bmatrix}<br>    1 &amp; 0 \\\\<br>    0 &amp; -1<br>\\end{Bmatrix}</p>\n<hr>\n<p>\\begin{vmatrix}<br>    a &amp; b \\\\<br>    c &amp; d<br>\\end{vmatrix}</p>\n<hr>\n<p>\\begin{Vmatrix}<br>    i &amp; 0 \\\\<br>     0 &amp; -i<br>\\end{Vmatrix}</p>\n<hr>\n<h4 id=\"数学符号\"><a href=\"#数学符号\" class=\"headerlink\" title=\"数学符号\"></a>数学符号</h4><h5 id=\"操作符号\"><a href=\"#操作符号\" class=\"headerlink\" title=\"操作符号\"></a>操作符号</h5><p>$$<br>\\pm    \\mp    \\times    \\div    \\ast    \\star    \\circ    \\bullet    \\divideontimes    \\ltimes    \\rtimes    \\cdot    \\dotplus    \\leftthreetimes    \\rightthreetimes    \\amalg    \\otimes    \\oplus    \\ominus    \\oslash    \\odot    \\circledcirc    \\circleddash    \\circledast    \\bigcirc \\boxdot    \\boxminus    \\boxplus    \\boxtimes    \\diamond    \\bigtriangleup    \\bigtriangledown    \\triangleleft    \\triangleright    \\lhd    \\rhd    \\unlhd    \\unrhd    \\cup    \\cap    \\uplus    \\Cup    \\Cap    \\wr    \\setminus    \\smallsetminus    \\sqcap    \\sqcup \\wedge    \\vee    \\barwedge    \\veebar    \\doublebarwedge    \\curlywedge    \\curlyvee    \\dagger    \\ddagger    \\intercal    \\bigcap    \\bigcup    \\biguplus    \\bigsqcup    \\prod    \\coprod    \\bigwedge    \\bigvee    \\bigodot    \\bigoplus    \\bigotimes    \\sum \\int    \\oint    \\iint    \\iiint    \\iiiint    \\idotsint    \\arccos    \\arcsin    \\arctan    \\arg    \\cos    \\cosh    \\cot    \\coth    \\csc    \\deg    \\det    \\dim    \\exp    \\gcd    \\hom    \\inf    \\ker    \\lg    \\lim    \\liminf    \\limsup    \\ln    \\log    \\max    \\min    \\Pr    \\projlim    \\sec\\sin\\sinh    \\sup    \\tan    \\tanh \\varlimsup    \\varliminf    \\varinjlim    \\varprojlim<br> $$</p>\n<h5 id=\"关系符号\"><a href=\"#关系符号\" class=\"headerlink\" title=\"关系符号\"></a>关系符号</h5><p>$$<br>\\bowtie    \\Join    \\propto    \\varpropto    \\multimap    \\pitchfork  \\therefore    \\because    =    \\neq    \\equiv    \\approx    \\sim    \\simeq    \\backsimeq    \\approxeq    \\cong    \\ncong        \\smile    \\frown    \\asymp    \\smallfrown    \\smallsmile    \\between    \\prec    \\succ    \\nprec    \\nsucc    \\preceq    \\succeq    \\npreceq    \\nsucceq    \\preccurlyeq    \\succcurlyeq    \\curlyeqprec    \\curlyeqsucc    \\precsim    \\succsim    \\precnsim    \\succnsim    \\precapprox    \\succapprox    \\precnapprox    \\succnapprox    \\perp    \\vdash    \\dashv    \\nvdash    \\Vdash    \\Vvdash    \\models    \\vDash    \\nvDash    \\nVDash    \\mid    \\nmid    \\parallel    \\nparallel    \\shortmid    \\nshortmid    \\shortparallel    \\nshortparallel    &lt;    &gt;    \\nless    \\ngtr    \\lessdot    \\gtrdot    \\ll    \\gg    \\lll    \\ggg    \\leq    \\geq    \\lneq    \\gneq    \\nleq    \\ngeq    \\leqq    \\geqq    \\lneqq    \\gneqq    \\lvertneqq    \\gvertneqq    \\nleqq    \\ngeqq    \\leqslant    \\geqslant    \\nleqslant    \\ngeqslant    \\eqslantless    \\eqslantgtr    \\lessgtr    \\gtrless    \\lesseqgtr    \\gtreqless    \\lesseqqgtr    \\gtreqqless    \\lesssim    \\gtrsim    \\lnsim    \\gnsim    \\lessapprox    \\gtrapprox    \\lnapprox    \\gnapprox    \\vartriangleleft    \\vartriangleright    \\ntriangleleft    \\ntriangleright    \\trianglelefteq    \\trianglerighteq    \\ntrianglelefteq    \\ntrianglerighteq    \\blacktriangleleft    \\blacktriangleright    \\subset    \\supset    \\subseteq    \\supseteq    \\subsetneq    \\supsetneq    \\varsubsetneq    \\varsupsetneq    \\nsubseteq    \\nsupseteq    \\subseteqq    \\supseteqq    \\subsetneqq    \\supsetneqq    \\nsubseteqq    \\nsupseteqq    \\backepsilon    \\Subset    \\Supset    \\sqsubset    \\sqsupset    \\sqsubseteq    \\sqsupseteq<br>$$</p>\n<h5 id=\"箭头符号\"><a href=\"#箭头符号\" class=\"headerlink\" title=\"箭头符号\"></a>箭头符号</h5><p>$$<br>\\leftarrow    \\leftrightarrow    \\rightarrow    \\mapsto    \\longleftarrow        \\longleftrightarrow    \\longrightarrow    \\longmapsto    \\downarrow    \\updownarrow    \\uparrow    \\nwarrow        \\searrow    \\nearrow    \\swarrow        \\nleftarrow            \\nleftrightarrow        \\nrightarrow        \\hookleftarrow        \\hookrightarrow        \\twoheadleftarrow        \\twoheadrightarrow        \\leftarrowtail        \\rightarrowtail        \\Leftarrow        \\Leftrightarrow        \\Rightarrow        \\Longleftarrow        \\Longleftrightarrow        \\Longrightarrow            \\Updownarrow        \\Uparrow        \\Downarrow        \\nLeftarrow        \\nLeftrightarrow    \\nRightarrow        \\leftleftarrows        \\leftrightarrows        \\rightleftarrows        \\rightrightarrows        \\downdownarrows        \\upuparrows        \\circlearrowleft        \\circlearrowright        \\curvearrowleft        \\curvearrowright        \\Lsh        \\Rsh        \\looparrowleft        \\looparrowright        \\dashleftarrow        \\dashrightarrow        \\leftrightsquigarrow        \\rightsquigarrow        \\Lleftarrow        \\leftharpoondown        \\rightharpoondown        \\leftharpoonup        \\rightharpoonup        \\rightleftharpoons        \\leftrightharpoons        \\downharpoonleft        \\upharpoonleft        \\downharpoonright            \\upharpoonright<br>$$</p>\n<h5 id=\"分隔符\"><a href=\"#分隔符\" class=\"headerlink\" title=\"分隔符\"></a>分隔符</h5><p>$$<br>\\downarrow    \\Downarrow    \\langle \\rangle [ ] | | \\lceil \\rceil \\uparrow    \\Uparrow    \\lfloor        \\rfloor    \\updownarrow    \\Updownarrow    (        )    \\{    \\} \\backslash    \\lmoustache        \\rmoustache    \\lgroup    \\rgroup    \\arrowvert    \\Arrowvert    \\bracevert    \\lvert    \\rvert    \\lVert        \\rVert    \\ulcorner    \\urcorner \\llcorner \\lrcorner<br>$$</p>\n<h5 id=\"希腊字符\"><a href=\"#希腊字符\" class=\"headerlink\" title=\"希腊字符\"></a>希腊字符</h5><p>$$<br>\\alpha    \\beta        \\gamma    \\delta    \\epsilon    \\zeta    \\eta    \\theta    \\vartheta    \\iota    \\kappa    \\lambda    \\mu    \\nu    \\xi    o    \\pi    \\varpi    \\rho    \\varrho    \\sigma    \\varsigma    \\tau    \\upsilon    \\phi    \\varphi    \\chi    \\psi    \\omega    A    B    \\Gamma    \\varGamma    \\Delta    \\varDelta    E    Z    H    \\Theta    \\varTheta    I    K    \\Lambda    \\varLambda    M    N    \\Xi    \\varXi    O    \\Pi    \\varPi    P    \\Sigma        \\Upsilon    \\varUpsilon    \\Phi    \\varPhi    X    \\varPsi    \\Omega    \\varOmega<br>$$</p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<p>[TOC]</p>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><h4 id=\"分数、上标、下标、方根、求和、积分\"><a href=\"#分数、上标、下标、方根、求和、积分\" class=\"headerlink\" title=\"分数、上标、下标、方根、求和、积分\"></a>分数、上标、下标、方根、求和、积分</h4><p>分数 <code>$\\dfrac{2}{3}$</code>表示$\\dfrac{2}{3}$，<code>$\\tfrac{2}{3}$</code>表示$\\tfrac{2}{3}$</p>\n<pre><code>\\begin{eqnarray\\*}\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 +\n    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 +\n    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 +\n    \\frac{1}{\\sqrt 2 + \\cdots}}}\n\\end{eqnarray\\*}</code></pre><p>表示<br>\\begin{eqnarray*}<br>    \\dfrac{1}{\\sqrt 2 +<br>    \\dfrac{1}{\\sqrt 2 +<br>    \\dfrac{1}{\\sqrt 2 + \\dotsb}}}\\;<br>    \\tfrac{1}{\\sqrt 2 +<br>    \\tfrac{1}{\\sqrt 2 +<br>    \\tfrac{1}{\\sqrt 2 + \\cdots}}}\\;<br>    \\frac{1}{\\sqrt 2 +<br>    \\frac{1}{\\sqrt 2 +<br>    \\frac{1}{\\sqrt 2 + \\cdots}}}<br>\\end{eqnarray*}</p>\n<hr>\n<p>上标$A^2$、$A^{上标}$<br><code>$$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$</code>表示$$A^2 \\; A^{上标} \\; \\mathop{A}\\limits^2$$</p>\n<hr>\n<p>下标$A_2$、$A_{下标}$<br><code>$$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$</code>表示$$A_2 \\; A_{下标}\\; \\mathop{A}\\limits_2$$</p>\n<hr>\n<p>开方数$\\sqrt[开方数]{参数}$<br><code>$$\\sqrt[开方数]{参数}$$</code>表示$$\\sqrt[开方数]{参数}$$</p>\n<hr>\n<p>求和$\\sum$<br>$$\\sum ^2_3\\;\\sum \\nolimits^2_3$$</p>\n<hr>\n<p>分$\\int$<br>$$\\int ^2_3\\;\\int \\limits^2_3$$</p>\n<hr>\n<h4 id=\"行内公式\"><a href=\"#行内公式\" class=\"headerlink\" title=\"行内公式\"></a>行内公式</h4><p>$R^s_r(t_r,t_e)=(t_r-t_e)c$</p>\n<hr>\n<h4 id=\"显示公式\"><a href=\"#显示公式\" class=\"headerlink\" title=\"显示公式\"></a>显示公式</h4><p>$$R^s_r(t_r,t_e)=(t_r-t_e)c$$</p>\n<hr>\n<h4 id=\"带有编号的显示公式\"><a href=\"#带有编号的显示公式\" class=\"headerlink\" title=\"带有编号的显示公式\"></a>带有编号的显示公式</h4><p>\\begin{equation}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{equation}</p>\n<hr>\n<h4 id=\"带有编号的多行公式\"><a href=\"#带有编号的多行公式\" class=\"headerlink\" title=\"带有编号的多行公式\"></a>带有编号的多行公式</h4><p>\\begin{eqnarray}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray}</p>\n<hr>\n<h4 id=\"取消某一编号的多行公式\"><a href=\"#取消某一编号的多行公式\" class=\"headerlink\" title=\"取消某一编号的多行公式\"></a>取消某一编号的多行公式</h4><p>\\begin{eqnarray}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\nonumber\\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray}</p>\n<hr>\n<h4 id=\"带有指定编号的多行公式\"><a href=\"#带有指定编号的多行公式\" class=\"headerlink\" title=\"带有指定编号的多行公式\"></a>带有指定编号的多行公式</h4><p>\\begin{eqnarray*}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\tag{1}\\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray*}</p>\n<hr>\n<h4 id=\"不带编号的多行公式\"><a href=\"#不带编号的多行公式\" class=\"headerlink\" title=\"不带编号的多行公式\"></a>不带编号的多行公式</h4><p>\\begin{eqnarray*}<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=(t_r-t_e)c<br>\\end{eqnarray*}</p>\n<hr>\n<h4 id=\"指定对齐方式的多行公式\"><a href=\"#指定对齐方式的多行公式\" class=\"headerlink\" title=\"指定对齐方式的多行公式\"></a>指定对齐方式的多行公式</h4><p>\\begin{eqnarray}<br>    &amp;R^s_r(t_r,t_e)&amp;=(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)&amp; = &amp;(t_r-t_e)c \\\\<br>    R^s_r(t_r,t_e)=&amp;(t_r-t_e)c&amp;<br>\\end{eqnarray}</p>\n<hr>\n<h4 id=\"输入矩阵\"><a href=\"#输入矩阵\" class=\"headerlink\" title=\"输入矩阵\"></a>输入矩阵</h4><p>\\begin{matrix}<br>    0 &amp; 1 \\\\<br>    1 &amp; 0<br>\\end{matrix}</p>\n<hr>\n<p>\\begin{pmatrix}<br>    0 &amp; -i \\\\<br>    i &amp; 0<br>\\end{pmatrix}</p>\n<hr>\n<p>\\begin{bmatrix}<br>    0 &amp; -1 \\\\<br>    1 &amp; 0<br>\\end{bmatrix}</p>\n<hr>\n<p>\\begin{Bmatrix}<br>    1 &amp; 0 \\\\<br>    0 &amp; -1<br>\\end{Bmatrix}</p>\n<hr>\n<p>\\begin{vmatrix}<br>    a &amp; b \\\\<br>    c &amp; d<br>\\end{vmatrix}</p>\n<hr>\n<p>\\begin{Vmatrix}<br>    i &amp; 0 \\\\<br>     0 &amp; -i<br>\\end{Vmatrix}</p>\n<hr>\n<h4 id=\"数学符号\"><a href=\"#数学符号\" class=\"headerlink\" title=\"数学符号\"></a>数学符号</h4><h5 id=\"操作符号\"><a href=\"#操作符号\" class=\"headerlink\" title=\"操作符号\"></a>操作符号</h5><p>$$<br>\\pm    \\mp    \\times    \\div    \\ast    \\star    \\circ    \\bullet    \\divideontimes    \\ltimes    \\rtimes    \\cdot    \\dotplus    \\leftthreetimes    \\rightthreetimes    \\amalg    \\otimes    \\oplus    \\ominus    \\oslash    \\odot    \\circledcirc    \\circleddash    \\circledast    \\bigcirc \\boxdot    \\boxminus    \\boxplus    \\boxtimes    \\diamond    \\bigtriangleup    \\bigtriangledown    \\triangleleft    \\triangleright    \\lhd    \\rhd    \\unlhd    \\unrhd    \\cup    \\cap    \\uplus    \\Cup    \\Cap    \\wr    \\setminus    \\smallsetminus    \\sqcap    \\sqcup \\wedge    \\vee    \\barwedge    \\veebar    \\doublebarwedge    \\curlywedge    \\curlyvee    \\dagger    \\ddagger    \\intercal    \\bigcap    \\bigcup    \\biguplus    \\bigsqcup    \\prod    \\coprod    \\bigwedge    \\bigvee    \\bigodot    \\bigoplus    \\bigotimes    \\sum \\int    \\oint    \\iint    \\iiint    \\iiiint    \\idotsint    \\arccos    \\arcsin    \\arctan    \\arg    \\cos    \\cosh    \\cot    \\coth    \\csc    \\deg    \\det    \\dim    \\exp    \\gcd    \\hom    \\inf    \\ker    \\lg    \\lim    \\liminf    \\limsup    \\ln    \\log    \\max    \\min    \\Pr    \\projlim    \\sec\\sin\\sinh    \\sup    \\tan    \\tanh \\varlimsup    \\varliminf    \\varinjlim    \\varprojlim<br> $$</p>\n<h5 id=\"关系符号\"><a href=\"#关系符号\" class=\"headerlink\" title=\"关系符号\"></a>关系符号</h5><p>$$<br>\\bowtie    \\Join    \\propto    \\varpropto    \\multimap    \\pitchfork  \\therefore    \\because    =    \\neq    \\equiv    \\approx    \\sim    \\simeq    \\backsimeq    \\approxeq    \\cong    \\ncong        \\smile    \\frown    \\asymp    \\smallfrown    \\smallsmile    \\between    \\prec    \\succ    \\nprec    \\nsucc    \\preceq    \\succeq    \\npreceq    \\nsucceq    \\preccurlyeq    \\succcurlyeq    \\curlyeqprec    \\curlyeqsucc    \\precsim    \\succsim    \\precnsim    \\succnsim    \\precapprox    \\succapprox    \\precnapprox    \\succnapprox    \\perp    \\vdash    \\dashv    \\nvdash    \\Vdash    \\Vvdash    \\models    \\vDash    \\nvDash    \\nVDash    \\mid    \\nmid    \\parallel    \\nparallel    \\shortmid    \\nshortmid    \\shortparallel    \\nshortparallel    &lt;    &gt;    \\nless    \\ngtr    \\lessdot    \\gtrdot    \\ll    \\gg    \\lll    \\ggg    \\leq    \\geq    \\lneq    \\gneq    \\nleq    \\ngeq    \\leqq    \\geqq    \\lneqq    \\gneqq    \\lvertneqq    \\gvertneqq    \\nleqq    \\ngeqq    \\leqslant    \\geqslant    \\nleqslant    \\ngeqslant    \\eqslantless    \\eqslantgtr    \\lessgtr    \\gtrless    \\lesseqgtr    \\gtreqless    \\lesseqqgtr    \\gtreqqless    \\lesssim    \\gtrsim    \\lnsim    \\gnsim    \\lessapprox    \\gtrapprox    \\lnapprox    \\gnapprox    \\vartriangleleft    \\vartriangleright    \\ntriangleleft    \\ntriangleright    \\trianglelefteq    \\trianglerighteq    \\ntrianglelefteq    \\ntrianglerighteq    \\blacktriangleleft    \\blacktriangleright    \\subset    \\supset    \\subseteq    \\supseteq    \\subsetneq    \\supsetneq    \\varsubsetneq    \\varsupsetneq    \\nsubseteq    \\nsupseteq    \\subseteqq    \\supseteqq    \\subsetneqq    \\supsetneqq    \\nsubseteqq    \\nsupseteqq    \\backepsilon    \\Subset    \\Supset    \\sqsubset    \\sqsupset    \\sqsubseteq    \\sqsupseteq<br>$$</p>\n<h5 id=\"箭头符号\"><a href=\"#箭头符号\" class=\"headerlink\" title=\"箭头符号\"></a>箭头符号</h5><p>$$<br>\\leftarrow    \\leftrightarrow    \\rightarrow    \\mapsto    \\longleftarrow        \\longleftrightarrow    \\longrightarrow    \\longmapsto    \\downarrow    \\updownarrow    \\uparrow    \\nwarrow        \\searrow    \\nearrow    \\swarrow        \\nleftarrow            \\nleftrightarrow        \\nrightarrow        \\hookleftarrow        \\hookrightarrow        \\twoheadleftarrow        \\twoheadrightarrow        \\leftarrowtail        \\rightarrowtail        \\Leftarrow        \\Leftrightarrow        \\Rightarrow        \\Longleftarrow        \\Longleftrightarrow        \\Longrightarrow            \\Updownarrow        \\Uparrow        \\Downarrow        \\nLeftarrow        \\nLeftrightarrow    \\nRightarrow        \\leftleftarrows        \\leftrightarrows        \\rightleftarrows        \\rightrightarrows        \\downdownarrows        \\upuparrows        \\circlearrowleft        \\circlearrowright        \\curvearrowleft        \\curvearrowright        \\Lsh        \\Rsh        \\looparrowleft        \\looparrowright        \\dashleftarrow        \\dashrightarrow        \\leftrightsquigarrow        \\rightsquigarrow        \\Lleftarrow        \\leftharpoondown        \\rightharpoondown        \\leftharpoonup        \\rightharpoonup        \\rightleftharpoons        \\leftrightharpoons        \\downharpoonleft        \\upharpoonleft        \\downharpoonright            \\upharpoonright<br>$$</p>\n<h5 id=\"分隔符\"><a href=\"#分隔符\" class=\"headerlink\" title=\"分隔符\"></a>分隔符</h5><p>$$<br>\\downarrow    \\Downarrow    \\langle \\rangle [ ] | | \\lceil \\rceil \\uparrow    \\Uparrow    \\lfloor        \\rfloor    \\updownarrow    \\Updownarrow    (        )    \\{    \\} \\backslash    \\lmoustache        \\rmoustache    \\lgroup    \\rgroup    \\arrowvert    \\Arrowvert    \\bracevert    \\lvert    \\rvert    \\lVert        \\rVert    \\ulcorner    \\urcorner \\llcorner \\lrcorner<br>$$</p>\n<h5 id=\"希腊字符\"><a href=\"#希腊字符\" class=\"headerlink\" title=\"希腊字符\"></a>希腊字符</h5><p>$$<br>\\alpha    \\beta        \\gamma    \\delta    \\epsilon    \\zeta    \\eta    \\theta    \\vartheta    \\iota    \\kappa    \\lambda    \\mu    \\nu    \\xi    o    \\pi    \\varpi    \\rho    \\varrho    \\sigma    \\varsigma    \\tau    \\upsilon    \\phi    \\varphi    \\chi    \\psi    \\omega    A    B    \\Gamma    \\varGamma    \\Delta    \\varDelta    E    Z    H    \\Theta    \\varTheta    I    K    \\Lambda    \\varLambda    M    N    \\Xi    \\varXi    O    \\Pi    \\varPi    P    \\Sigma        \\Upsilon    \\varUpsilon    \\Phi    \\varPhi    X    \\varPsi    \\Omega    \\varOmega<br>$$</p>\n"},{"title":"My plan","date":"2019-07-05T15:52:51.000Z","cover":true,"img":"http://images2.fanpop.com/image/photos/10500000/simple-plan-simple-plan-10550897-1024-768.jpg","_content":"\n\n\n# 写一下近期要做的事情：\n- 整理一下之前做过的项目\n\n- 写一下manjaro+i3wm配置相关的教程，其中包括：\n\n![config](https://github.com/liuyaanng/.config/raw/master/config.png)\n- **配置vim**\n\n- 从零开始的narkdown教程\n\n- Python单排系列\n\n- 人工智能笔记\n","source":"_posts/My-plan.md","raw":"---\ntitle: My plan\ndate: 2019-07-05 23:52:51\ntags: plan\ncover: true\nimg: http://images2.fanpop.com/image/photos/10500000/simple-plan-simple-plan-10550897-1024-768.jpg\n---\n\n\n\n# 写一下近期要做的事情：\n- 整理一下之前做过的项目\n\n- 写一下manjaro+i3wm配置相关的教程，其中包括：\n\n![config](https://github.com/liuyaanng/.config/raw/master/config.png)\n- **配置vim**\n\n- 从零开始的narkdown教程\n\n- Python单排系列\n\n- 人工智能笔记\n","slug":"My-plan","published":1,"updated":"2019-08-10T10:47:34.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lto001ae5g6lutat315","content":"<h1 id=\"写一下近期要做的事情：\"><a href=\"#写一下近期要做的事情：\" class=\"headerlink\" title=\"写一下近期要做的事情：\"></a>写一下近期要做的事情：</h1><ul>\n<li><p>整理一下之前做过的项目</p>\n</li>\n<li><p>写一下manjaro+i3wm配置相关的教程，其中包括：</p>\n</li>\n</ul>\n<p><img src=\"https://github.com/liuyaanng/.config/raw/master/config.png\" alt=\"config\"></p>\n<ul>\n<li><p><strong>配置vim</strong></p>\n</li>\n<li><p>从零开始的narkdown教程</p>\n</li>\n<li><p>Python单排系列</p>\n</li>\n<li><p>人工智能笔记</p>\n</li>\n</ul>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"写一下近期要做的事情：\"><a href=\"#写一下近期要做的事情：\" class=\"headerlink\" title=\"写一下近期要做的事情：\"></a>写一下近期要做的事情：</h1><ul>\n<li><p>整理一下之前做过的项目</p>\n</li>\n<li><p>写一下manjaro+i3wm配置相关的教程，其中包括：</p>\n</li>\n</ul>\n<p><img src=\"https://github.com/liuyaanng/.config/raw/master/config.png\" alt=\"config\"></p>\n<ul>\n<li><p><strong>配置vim</strong></p>\n</li>\n<li><p>从零开始的narkdown教程</p>\n</li>\n<li><p>Python单排系列</p>\n</li>\n<li><p>人工智能笔记</p>\n</li>\n</ul>\n"},{"title":"OpenCV入坑指南:环境搭建篇","date":"2019-07-25T13:12:11.000Z","cover":false,"top":true,"img":"https://i.loli.net/2019/08/03/e2qDLXKy9vWnpfa.png","_content":"# OpenCV\n## 什么是OpenCV\n[OpenCv](https://opencv.org/about/)是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。    \nOpenCV用C++语言编写，它的主要接口也是C++语言，但是依然保留了大量的C语言接口。该库也有大量的Python、Java and MATLAB/OCTAVE（版本2.5）的接口。这些语言的API接口函数可以通过在线文档获得。如今也提供对于C#、Ch、Ruby,GO的支持。\n## OpenCV可以来做什么\n使用OpenCV，你几乎可以做任何你能够想到的计算机视觉任务。    \n1. 内置数据结构和输入/输出(In-build data structures and input/output)\n2. 图像处理操作(Image processing operations)\n\n3. 构建图形用户界面(Build GUI)\n\n4. 视频分析(Video analysis)\n\n5. 3D重建(3D reconstruction)\n\n6. 特征提取(Feature extraction)\n\n7. 目标检测(Object detection)\n\n8. 机器学习(Machine learning)\n\n9. 计算摄影(Computational photography)\n\n10. 形状分析(Shape analysis)\n\n11. 光流算法(Optical flow algorithms)\n\n12. 人脸和目标识别(Face and object recognition)\n\n13. 表面匹配(Surface matching)\n\n14. 文本检测和识别(Text detection and recognition)\n\n---\n\n# Microsoft Visual Studio\n\n宇宙最强IDE(逃),不多说了\n\n---\n\n# OpenCV + VS学习(装×)环境搭建\n工欲善其事，必先利其器。当你准备好入坑OpenCV时，你首先要把学习环境搭建起来，光是这一关不知道劝退了多少人，我在搭建的过程中也是踩了很多坑，也遇到了各种各样刁钻的问题，现在总结一下，给自己踩过的雷做一下记录，也希望能够帮到即将入坑的你们。\n\n## 版本选择\n为什么把这个放到第一个呢？因为这是我遇到并纠结了一天的问题！我在网上查找教程的时候很多人都没有标注这个问题，当然也是自己蠢，在所有的配置都配置完成之后，还是不能正常跑程序，又重新安装重新配置，反复好几次，都快怀疑人生了，最后才发现是版本号不对。废话不多说，下面是OpenCV版本和VS版本的对应表，选择的时候一定要擦亮眼睛。我选择的环境是VS2017+OpenCV3.4.4    \n\nVisual Studio 版本 | VC 版本\n:---: | :---:\nVS 6 | vc6\nVS 2003 | vc7\nVS 2005 | vc8\nVS 2008 | vc9\nVS 2010 | vc10\nVS 2013 | vc12\nVS 2015 | vc14\nVS 2017 | vc15\n\nOpenCV对VC版本的支持情况(不全)\n\nOpenCV 2.4.10 | vc10、vc11、vc12\n:---: | :---:\nOpenCV 2.4.13 | vc11、vc12\nOpenCV 3.4.0 | vc14、vc15\nOpenCv 3.4.1 | vc14、vc15\n\n## VS2017安装\n我的VS安装的时间太久了，网上教程一大堆，给你们挑一篇吧，这里就不再多说了\n\n## OpenCV3.4.4下载与安装\n\n### 下载\n1. 官网下载\nOpenCV官网给我们提供了下载，不过下载速度嘛～自求多福    \n[OpenCV下载](https://opencv.org/releases/),里面有各个版本可以选择\n2. OpenCV下载驿站    \n[OpenCV各版本汇总下载](https://blog.csdn.net/oMoDao1/article/details/80276834)    \n感谢这位大哥的总结\n\n### 安装\n找一个你能记住名字的路径安装进去就OK了，一定要记住这个路径，非常重要\n![](https://i.loli.net/2019/07/27/5d3c0e0f7a6db16095.png)\n## 系统环境变量配置\n\n1. 找到此电脑\n2. 依次找到 属性->高级->环境变量,找到系统变量里的Path，双击进去编辑，如图所示，添加的路径 **\"D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin\"**,把\"D:\\OpenCV\\\"替换成你的安装路径即可\n\n![](https://i.loli.net/2019/07/27/5d3c0e0f9cd5286868.png)\n![](https://i.loli.net/2019/07/27/5d3c0e0fa09f948672.png)\n![](https://i.loli.net/2019/07/27/5d3c0e0fa634780591.png)\n![](https://i.loli.net/2019/07/27/5d3c0e0fa37ce25025.png)\n\n到这就完成了系统环境的配置了\n\n## 一些文件的配置\n\n这一步的目的是为了解决以后可能会出现的关于缺少.dll的问题\n\n将 **\"D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin\"** 里面的三个 **.dll** 文件复制到 **C:\\Windows“** 目录下的 **System32**和 **SysWOW64**目录下\n\n![](https://i.loli.net/2019/07/28/5d3d5857adbe920715.png)\n![](https://i.loli.net/2019/07/28/5d3d5857bd82f79652.png)\n\n## VS2017配置\n\n1. 新建一个空项目\n2. 进入属性管理器  视图->其他窗口->属性管理器\n![](https://i.loli.net/2019/07/27/5d3c156f6359d16629.png)\n3. 选择Debug | x64 的 Microsoft.Cpp.x64.user\n![8.png](https://i.loli.net/2019/07/27/5d3c156ecb8ad31557.png)\n4. 选择VC++目录，对包含目录和库目录进行配置    \n   ![](https://i.loli.net/2019/07/27/5d3c156f2e22b74192.png)\n   - 在包含目录里添加 **D:\\OpenCV\\opencv\\bulid\\include**,**D:\\OpenCV\\opencv\\bulid\\include\\opencv**,**D:\\OpenCV\\opencv\\bulid\\include\\opencv2**    \n![](https://i.loli.net/2019/07/27/5d3c156f2132f35424.png)\n   - 在库目录里添加 **D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\lib**   \n   ![](https://i.loli.net/2019/07/27/5d3c156f492f430904.png)\n5. 选择 链接器->输入->附加依赖项,    \n   ![12.png](https://i.loli.net/2019/07/27/5d3c156f13aac74119.png)\n   在里面添加 **opencv_world344d.lib**，这个lib文件根据你的OpenCV版本号灵活变动\n   ![](https://i.loli.net/2019/07/27/5d3c156f0828190561.png)\n6. 点击应用，确定即可\n到这里，OpenCV的所有配置工作已经完成了，要注意的是解决方案那一栏要换成x64(因为我们一直在配置的就是x64)\n![](https://i.loli.net/2019/07/27/5d3c156ee8b6668598.png)\n## 测试\n这是一段读取并显示本地图片的代码，测试一下你的OpenCV环境是否配置好\n\n```cpp\n#include <iostream>\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n\nusing namespace cv;\n\nint main()\n{\n\tMat img = imread(\"1.bmp\");\n\tnamedWindow(\"图片\");\n\timshow(\"图片\", img);\n\twaitKey(6000);\n\treturn 0;\n}\n```\n\n运行结果如下：\n![](https://i.loli.net/2019/07/27/5d3c15857414f57549.png)\n\n## 需要注意的问题\n1. 导入包的时候不报错，但运行程序时出现一下错误\n![15.png](https://i.loli.net/2019/07/27/5d3c156f55e6b74341.png)\n![16.png](https://i.loli.net/2019/07/27/5d3c156f39a4e29681.png)\n出现这个问题，目前已知的有两个原因    \n  - imread函数读不到图片，即你的图片路径写的有问题    \n    这里给出两种基本的路径书写形式    \n    1. 绝对路径    \n    Mat img = imread(\"D:\\\\Pictures\\\\1.bmp\");    \n    一定要注意这里是双斜杠\n    2. 图片路径    \n    Mat img = imread(\"1.bmp\");    \n    使用这个的前提是图片的位置在你的工程目录下\n  - 链接器的附加依赖项配置的有问题    \n    在Debug模式下，附加依赖项添加的是 **opencv_world344d.lib**   \n    在Release模式下，附加依赖项添加的是 **opencv_world344.lib**    \n    有些教程是两个都添加，这是不对的，一定要注意。\n    \n---\n好了，教程到此结束，    \n接下来你就可以放心地去玩耍了，Enjoy Your OpenCV!\n","source":"_posts/OpenCV入坑指南-环境搭建篇.md","raw":"---\ntitle: 'OpenCV入坑指南:环境搭建篇'\ndate: 2019-07-25 21:12:11\ntags: OpenCV\ncover: false\ntop: true\nimg: https://i.loli.net/2019/08/03/e2qDLXKy9vWnpfa.png\n---\n# OpenCV\n## 什么是OpenCV\n[OpenCv](https://opencv.org/about/)是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。    \nOpenCV用C++语言编写，它的主要接口也是C++语言，但是依然保留了大量的C语言接口。该库也有大量的Python、Java and MATLAB/OCTAVE（版本2.5）的接口。这些语言的API接口函数可以通过在线文档获得。如今也提供对于C#、Ch、Ruby,GO的支持。\n## OpenCV可以来做什么\n使用OpenCV，你几乎可以做任何你能够想到的计算机视觉任务。    \n1. 内置数据结构和输入/输出(In-build data structures and input/output)\n2. 图像处理操作(Image processing operations)\n\n3. 构建图形用户界面(Build GUI)\n\n4. 视频分析(Video analysis)\n\n5. 3D重建(3D reconstruction)\n\n6. 特征提取(Feature extraction)\n\n7. 目标检测(Object detection)\n\n8. 机器学习(Machine learning)\n\n9. 计算摄影(Computational photography)\n\n10. 形状分析(Shape analysis)\n\n11. 光流算法(Optical flow algorithms)\n\n12. 人脸和目标识别(Face and object recognition)\n\n13. 表面匹配(Surface matching)\n\n14. 文本检测和识别(Text detection and recognition)\n\n---\n\n# Microsoft Visual Studio\n\n宇宙最强IDE(逃),不多说了\n\n---\n\n# OpenCV + VS学习(装×)环境搭建\n工欲善其事，必先利其器。当你准备好入坑OpenCV时，你首先要把学习环境搭建起来，光是这一关不知道劝退了多少人，我在搭建的过程中也是踩了很多坑，也遇到了各种各样刁钻的问题，现在总结一下，给自己踩过的雷做一下记录，也希望能够帮到即将入坑的你们。\n\n## 版本选择\n为什么把这个放到第一个呢？因为这是我遇到并纠结了一天的问题！我在网上查找教程的时候很多人都没有标注这个问题，当然也是自己蠢，在所有的配置都配置完成之后，还是不能正常跑程序，又重新安装重新配置，反复好几次，都快怀疑人生了，最后才发现是版本号不对。废话不多说，下面是OpenCV版本和VS版本的对应表，选择的时候一定要擦亮眼睛。我选择的环境是VS2017+OpenCV3.4.4    \n\nVisual Studio 版本 | VC 版本\n:---: | :---:\nVS 6 | vc6\nVS 2003 | vc7\nVS 2005 | vc8\nVS 2008 | vc9\nVS 2010 | vc10\nVS 2013 | vc12\nVS 2015 | vc14\nVS 2017 | vc15\n\nOpenCV对VC版本的支持情况(不全)\n\nOpenCV 2.4.10 | vc10、vc11、vc12\n:---: | :---:\nOpenCV 2.4.13 | vc11、vc12\nOpenCV 3.4.0 | vc14、vc15\nOpenCv 3.4.1 | vc14、vc15\n\n## VS2017安装\n我的VS安装的时间太久了，网上教程一大堆，给你们挑一篇吧，这里就不再多说了\n\n## OpenCV3.4.4下载与安装\n\n### 下载\n1. 官网下载\nOpenCV官网给我们提供了下载，不过下载速度嘛～自求多福    \n[OpenCV下载](https://opencv.org/releases/),里面有各个版本可以选择\n2. OpenCV下载驿站    \n[OpenCV各版本汇总下载](https://blog.csdn.net/oMoDao1/article/details/80276834)    \n感谢这位大哥的总结\n\n### 安装\n找一个你能记住名字的路径安装进去就OK了，一定要记住这个路径，非常重要\n![](https://i.loli.net/2019/07/27/5d3c0e0f7a6db16095.png)\n## 系统环境变量配置\n\n1. 找到此电脑\n2. 依次找到 属性->高级->环境变量,找到系统变量里的Path，双击进去编辑，如图所示，添加的路径 **\"D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin\"**,把\"D:\\OpenCV\\\"替换成你的安装路径即可\n\n![](https://i.loli.net/2019/07/27/5d3c0e0f9cd5286868.png)\n![](https://i.loli.net/2019/07/27/5d3c0e0fa09f948672.png)\n![](https://i.loli.net/2019/07/27/5d3c0e0fa634780591.png)\n![](https://i.loli.net/2019/07/27/5d3c0e0fa37ce25025.png)\n\n到这就完成了系统环境的配置了\n\n## 一些文件的配置\n\n这一步的目的是为了解决以后可能会出现的关于缺少.dll的问题\n\n将 **\"D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin\"** 里面的三个 **.dll** 文件复制到 **C:\\Windows“** 目录下的 **System32**和 **SysWOW64**目录下\n\n![](https://i.loli.net/2019/07/28/5d3d5857adbe920715.png)\n![](https://i.loli.net/2019/07/28/5d3d5857bd82f79652.png)\n\n## VS2017配置\n\n1. 新建一个空项目\n2. 进入属性管理器  视图->其他窗口->属性管理器\n![](https://i.loli.net/2019/07/27/5d3c156f6359d16629.png)\n3. 选择Debug | x64 的 Microsoft.Cpp.x64.user\n![8.png](https://i.loli.net/2019/07/27/5d3c156ecb8ad31557.png)\n4. 选择VC++目录，对包含目录和库目录进行配置    \n   ![](https://i.loli.net/2019/07/27/5d3c156f2e22b74192.png)\n   - 在包含目录里添加 **D:\\OpenCV\\opencv\\bulid\\include**,**D:\\OpenCV\\opencv\\bulid\\include\\opencv**,**D:\\OpenCV\\opencv\\bulid\\include\\opencv2**    \n![](https://i.loli.net/2019/07/27/5d3c156f2132f35424.png)\n   - 在库目录里添加 **D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\lib**   \n   ![](https://i.loli.net/2019/07/27/5d3c156f492f430904.png)\n5. 选择 链接器->输入->附加依赖项,    \n   ![12.png](https://i.loli.net/2019/07/27/5d3c156f13aac74119.png)\n   在里面添加 **opencv_world344d.lib**，这个lib文件根据你的OpenCV版本号灵活变动\n   ![](https://i.loli.net/2019/07/27/5d3c156f0828190561.png)\n6. 点击应用，确定即可\n到这里，OpenCV的所有配置工作已经完成了，要注意的是解决方案那一栏要换成x64(因为我们一直在配置的就是x64)\n![](https://i.loli.net/2019/07/27/5d3c156ee8b6668598.png)\n## 测试\n这是一段读取并显示本地图片的代码，测试一下你的OpenCV环境是否配置好\n\n```cpp\n#include <iostream>\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n\nusing namespace cv;\n\nint main()\n{\n\tMat img = imread(\"1.bmp\");\n\tnamedWindow(\"图片\");\n\timshow(\"图片\", img);\n\twaitKey(6000);\n\treturn 0;\n}\n```\n\n运行结果如下：\n![](https://i.loli.net/2019/07/27/5d3c15857414f57549.png)\n\n## 需要注意的问题\n1. 导入包的时候不报错，但运行程序时出现一下错误\n![15.png](https://i.loli.net/2019/07/27/5d3c156f55e6b74341.png)\n![16.png](https://i.loli.net/2019/07/27/5d3c156f39a4e29681.png)\n出现这个问题，目前已知的有两个原因    \n  - imread函数读不到图片，即你的图片路径写的有问题    \n    这里给出两种基本的路径书写形式    \n    1. 绝对路径    \n    Mat img = imread(\"D:\\\\Pictures\\\\1.bmp\");    \n    一定要注意这里是双斜杠\n    2. 图片路径    \n    Mat img = imread(\"1.bmp\");    \n    使用这个的前提是图片的位置在你的工程目录下\n  - 链接器的附加依赖项配置的有问题    \n    在Debug模式下，附加依赖项添加的是 **opencv_world344d.lib**   \n    在Release模式下，附加依赖项添加的是 **opencv_world344.lib**    \n    有些教程是两个都添加，这是不对的，一定要注意。\n    \n---\n好了，教程到此结束，    \n接下来你就可以放心地去玩耍了，Enjoy Your OpenCV!\n","slug":"OpenCV入坑指南-环境搭建篇","published":1,"updated":"2019-08-10T10:47:34.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltp001ce5g68esna7o6","content":"<h1 id=\"OpenCV\"><a href=\"#OpenCV\" class=\"headerlink\" title=\"OpenCV\"></a>OpenCV</h1><h2 id=\"什么是OpenCV\"><a href=\"#什么是OpenCV\" class=\"headerlink\" title=\"什么是OpenCV\"></a>什么是OpenCV</h2><p><a href=\"https://opencv.org/about/\" target=\"_blank\" rel=\"noopener\">OpenCv</a>是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。<br>OpenCV用C++语言编写，它的主要接口也是C++语言，但是依然保留了大量的C语言接口。该库也有大量的Python、Java and MATLAB/OCTAVE（版本2.5）的接口。这些语言的API接口函数可以通过在线文档获得。如今也提供对于C#、Ch、Ruby,GO的支持。</p>\n<h2 id=\"OpenCV可以来做什么\"><a href=\"#OpenCV可以来做什么\" class=\"headerlink\" title=\"OpenCV可以来做什么\"></a>OpenCV可以来做什么</h2><p>使用OpenCV，你几乎可以做任何你能够想到的计算机视觉任务。    </p>\n<ol>\n<li><p>内置数据结构和输入/输出(In-build data structures and input/output)</p>\n</li>\n<li><p>图像处理操作(Image processing operations)</p>\n</li>\n<li><p>构建图形用户界面(Build GUI)</p>\n</li>\n<li><p>视频分析(Video analysis)</p>\n</li>\n<li><p>3D重建(3D reconstruction)</p>\n</li>\n<li><p>特征提取(Feature extraction)</p>\n</li>\n<li><p>目标检测(Object detection)</p>\n</li>\n<li><p>机器学习(Machine learning)</p>\n</li>\n<li><p>计算摄影(Computational photography)</p>\n</li>\n<li><p>形状分析(Shape analysis)</p>\n</li>\n<li><p>光流算法(Optical flow algorithms)</p>\n</li>\n<li><p>人脸和目标识别(Face and object recognition)</p>\n</li>\n<li><p>表面匹配(Surface matching)</p>\n</li>\n<li><p>文本检测和识别(Text detection and recognition)</p>\n</li>\n</ol>\n<hr>\n<h1 id=\"Microsoft-Visual-Studio\"><a href=\"#Microsoft-Visual-Studio\" class=\"headerlink\" title=\"Microsoft Visual Studio\"></a>Microsoft Visual Studio</h1><p>宇宙最强IDE(逃),不多说了</p>\n<hr>\n<h1 id=\"OpenCV-VS学习-装×-环境搭建\"><a href=\"#OpenCV-VS学习-装×-环境搭建\" class=\"headerlink\" title=\"OpenCV + VS学习(装×)环境搭建\"></a>OpenCV + VS学习(装×)环境搭建</h1><p>工欲善其事，必先利其器。当你准备好入坑OpenCV时，你首先要把学习环境搭建起来，光是这一关不知道劝退了多少人，我在搭建的过程中也是踩了很多坑，也遇到了各种各样刁钻的问题，现在总结一下，给自己踩过的雷做一下记录，也希望能够帮到即将入坑的你们。</p>\n<h2 id=\"版本选择\"><a href=\"#版本选择\" class=\"headerlink\" title=\"版本选择\"></a>版本选择</h2><p>为什么把这个放到第一个呢？因为这是我遇到并纠结了一天的问题！我在网上查找教程的时候很多人都没有标注这个问题，当然也是自己蠢，在所有的配置都配置完成之后，还是不能正常跑程序，又重新安装重新配置，反复好几次，都快怀疑人生了，最后才发现是版本号不对。废话不多说，下面是OpenCV版本和VS版本的对应表，选择的时候一定要擦亮眼睛。我选择的环境是VS2017+OpenCV3.4.4    </p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Visual Studio 版本</th>\n<th align=\"center\">VC 版本</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">VS 6</td>\n<td align=\"center\">vc6</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2003</td>\n<td align=\"center\">vc7</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2005</td>\n<td align=\"center\">vc8</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2008</td>\n<td align=\"center\">vc9</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2010</td>\n<td align=\"center\">vc10</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2013</td>\n<td align=\"center\">vc12</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2015</td>\n<td align=\"center\">vc14</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2017</td>\n<td align=\"center\">vc15</td>\n</tr>\n</tbody></table>\n<p>OpenCV对VC版本的支持情况(不全)</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">OpenCV 2.4.10</th>\n<th align=\"center\">vc10、vc11、vc12</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">OpenCV 2.4.13</td>\n<td align=\"center\">vc11、vc12</td>\n</tr>\n<tr>\n<td align=\"center\">OpenCV 3.4.0</td>\n<td align=\"center\">vc14、vc15</td>\n</tr>\n<tr>\n<td align=\"center\">OpenCv 3.4.1</td>\n<td align=\"center\">vc14、vc15</td>\n</tr>\n</tbody></table>\n<h2 id=\"VS2017安装\"><a href=\"#VS2017安装\" class=\"headerlink\" title=\"VS2017安装\"></a>VS2017安装</h2><p>我的VS安装的时间太久了，网上教程一大堆，给你们挑一篇吧，这里就不再多说了</p>\n<h2 id=\"OpenCV3-4-4下载与安装\"><a href=\"#OpenCV3-4-4下载与安装\" class=\"headerlink\" title=\"OpenCV3.4.4下载与安装\"></a>OpenCV3.4.4下载与安装</h2><h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><ol>\n<li>官网下载<br>OpenCV官网给我们提供了下载，不过下载速度嘛～自求多福<br><a href=\"https://opencv.org/releases/\" target=\"_blank\" rel=\"noopener\">OpenCV下载</a>,里面有各个版本可以选择</li>\n<li>OpenCV下载驿站<br><a href=\"https://blog.csdn.net/oMoDao1/article/details/80276834\" target=\"_blank\" rel=\"noopener\">OpenCV各版本汇总下载</a><br>感谢这位大哥的总结</li>\n</ol>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找一个你能记住名字的路径安装进去就OK了，一定要记住这个路径，非常重要<br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0f7a6db16095.png\" alt></p>\n<h2 id=\"系统环境变量配置\"><a href=\"#系统环境变量配置\" class=\"headerlink\" title=\"系统环境变量配置\"></a>系统环境变量配置</h2><ol>\n<li>找到此电脑</li>\n<li>依次找到 属性-&gt;高级-&gt;环境变量,找到系统变量里的Path，双击进去编辑，如图所示，添加的路径 <strong>“D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin”</strong>,把”D:\\OpenCV\\”替换成你的安装路径即可</li>\n</ol>\n<p><img src=\"https://i.loli.net/2019/07/27/5d3c0e0f9cd5286868.png\" alt><br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0fa09f948672.png\" alt><br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0fa634780591.png\" alt><br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0fa37ce25025.png\" alt></p>\n<p>到这就完成了系统环境的配置了</p>\n<h2 id=\"一些文件的配置\"><a href=\"#一些文件的配置\" class=\"headerlink\" title=\"一些文件的配置\"></a>一些文件的配置</h2><p>这一步的目的是为了解决以后可能会出现的关于缺少.dll的问题</p>\n<p>将 <strong>“D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin”</strong> 里面的三个 <strong>.dll</strong> 文件复制到 <strong>C:\\Windows“</strong> 目录下的 <strong>System32</strong>和 <strong>SysWOW64</strong>目录下</p>\n<p><img src=\"https://i.loli.net/2019/07/28/5d3d5857adbe920715.png\" alt><br><img src=\"https://i.loli.net/2019/07/28/5d3d5857bd82f79652.png\" alt></p>\n<h2 id=\"VS2017配置\"><a href=\"#VS2017配置\" class=\"headerlink\" title=\"VS2017配置\"></a>VS2017配置</h2><ol>\n<li>新建一个空项目</li>\n<li>进入属性管理器  视图-&gt;其他窗口-&gt;属性管理器<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f6359d16629.png\" alt></li>\n<li>选择Debug | x64 的 Microsoft.Cpp.x64.user<br><img src=\"https://i.loli.net/2019/07/27/5d3c156ecb8ad31557.png\" alt=\"8.png\"></li>\n<li>选择VC++目录，对包含目录和库目录进行配置<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f2e22b74192.png\" alt><ul>\n<li>在包含目录里添加 <strong>D:\\OpenCV\\opencv\\bulid\\include</strong>,<strong>D:\\OpenCV\\opencv\\bulid\\include\\opencv</strong>,<strong>D:\\OpenCV\\opencv\\bulid\\include\\opencv2</strong><br><img src=\"https://i.loli.net/2019/07/27/5d3c156f2132f35424.png\" alt></li>\n<li>在库目录里添加 <strong>D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\lib</strong><br><img src=\"https://i.loli.net/2019/07/27/5d3c156f492f430904.png\" alt></li>\n</ul>\n</li>\n<li>选择 链接器-&gt;输入-&gt;附加依赖项,<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f13aac74119.png\" alt=\"12.png\"><br>在里面添加 <strong>opencv_world344d.lib</strong>，这个lib文件根据你的OpenCV版本号灵活变动<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f0828190561.png\" alt></li>\n<li>点击应用，确定即可<br>到这里，OpenCV的所有配置工作已经完成了，要注意的是解决方案那一栏要换成x64(因为我们一直在配置的就是x64)<br><img src=\"https://i.loli.net/2019/07/27/5d3c156ee8b6668598.png\" alt><h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2>这是一段读取并显示本地图片的代码，测试一下你的OpenCV环境是否配置好</li>\n</ol>\n<pre class=\" language-cpp\"><code class=\"language-cpp\"><span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;iostream></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/core/core.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/highgui/highgui.hpp></span></span>\n\n<span class=\"token keyword\">using</span> <span class=\"token keyword\">namespace</span> cv<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{</span>\n    Mat img <span class=\"token operator\">=</span> <span class=\"token function\">imread</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1.bmp\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">namedWindow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"图片\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"图片\"</span><span class=\"token punctuation\">,</span> img<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">waitKey</span><span class=\"token punctuation\">(</span><span class=\"token number\">6000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre>\n<p>运行结果如下：<br><img src=\"https://i.loli.net/2019/07/27/5d3c15857414f57549.png\" alt></p>\n<h2 id=\"需要注意的问题\"><a href=\"#需要注意的问题\" class=\"headerlink\" title=\"需要注意的问题\"></a>需要注意的问题</h2><ol>\n<li>导入包的时候不报错，但运行程序时出现一下错误<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f55e6b74341.png\" alt=\"15.png\"><br><img src=\"https://i.loli.net/2019/07/27/5d3c156f39a4e29681.png\" alt=\"16.png\"><br>出现这个问题，目前已知的有两个原因    <ul>\n<li>imread函数读不到图片，即你的图片路径写的有问题<br>这里给出两种基本的路径书写形式    <ol>\n<li>绝对路径<br>Mat img = imread(“D:\\\\Pictures\\\\1.bmp”);<br>一定要注意这里是双斜杠</li>\n<li>图片路径<br>Mat img = imread(“1.bmp”);<br>使用这个的前提是图片的位置在你的工程目录下</li>\n</ol>\n</li>\n<li>链接器的附加依赖项配置的有问题<br>在Debug模式下，附加依赖项添加的是 <strong>opencv_world344d.lib</strong><br>在Release模式下，附加依赖项添加的是 <strong>opencv_world344.lib</strong><br>有些教程是两个都添加，这是不对的，一定要注意。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<p>好了，教程到此结束，<br>接下来你就可以放心地去玩耍了，Enjoy Your OpenCV!</p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"OpenCV\"><a href=\"#OpenCV\" class=\"headerlink\" title=\"OpenCV\"></a>OpenCV</h1><h2 id=\"什么是OpenCV\"><a href=\"#什么是OpenCV\" class=\"headerlink\" title=\"什么是OpenCV\"></a>什么是OpenCV</h2><p><a href=\"https://opencv.org/about/\" target=\"_blank\" rel=\"noopener\">OpenCv</a>是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。<br>OpenCV用C++语言编写，它的主要接口也是C++语言，但是依然保留了大量的C语言接口。该库也有大量的Python、Java and MATLAB/OCTAVE（版本2.5）的接口。这些语言的API接口函数可以通过在线文档获得。如今也提供对于C#、Ch、Ruby,GO的支持。</p>\n<h2 id=\"OpenCV可以来做什么\"><a href=\"#OpenCV可以来做什么\" class=\"headerlink\" title=\"OpenCV可以来做什么\"></a>OpenCV可以来做什么</h2><p>使用OpenCV，你几乎可以做任何你能够想到的计算机视觉任务。    </p>\n<ol>\n<li><p>内置数据结构和输入/输出(In-build data structures and input/output)</p>\n</li>\n<li><p>图像处理操作(Image processing operations)</p>\n</li>\n<li><p>构建图形用户界面(Build GUI)</p>\n</li>\n<li><p>视频分析(Video analysis)</p>\n</li>\n<li><p>3D重建(3D reconstruction)</p>\n</li>\n<li><p>特征提取(Feature extraction)</p>\n</li>\n<li><p>目标检测(Object detection)</p>\n</li>\n<li><p>机器学习(Machine learning)</p>\n</li>\n<li><p>计算摄影(Computational photography)</p>\n</li>\n<li><p>形状分析(Shape analysis)</p>\n</li>\n<li><p>光流算法(Optical flow algorithms)</p>\n</li>\n<li><p>人脸和目标识别(Face and object recognition)</p>\n</li>\n<li><p>表面匹配(Surface matching)</p>\n</li>\n<li><p>文本检测和识别(Text detection and recognition)</p>\n</li>\n</ol>\n<hr>\n<h1 id=\"Microsoft-Visual-Studio\"><a href=\"#Microsoft-Visual-Studio\" class=\"headerlink\" title=\"Microsoft Visual Studio\"></a>Microsoft Visual Studio</h1><p>宇宙最强IDE(逃),不多说了</p>\n<hr>\n<h1 id=\"OpenCV-VS学习-装×-环境搭建\"><a href=\"#OpenCV-VS学习-装×-环境搭建\" class=\"headerlink\" title=\"OpenCV + VS学习(装×)环境搭建\"></a>OpenCV + VS学习(装×)环境搭建</h1><p>工欲善其事，必先利其器。当你准备好入坑OpenCV时，你首先要把学习环境搭建起来，光是这一关不知道劝退了多少人，我在搭建的过程中也是踩了很多坑，也遇到了各种各样刁钻的问题，现在总结一下，给自己踩过的雷做一下记录，也希望能够帮到即将入坑的你们。</p>\n<h2 id=\"版本选择\"><a href=\"#版本选择\" class=\"headerlink\" title=\"版本选择\"></a>版本选择</h2><p>为什么把这个放到第一个呢？因为这是我遇到并纠结了一天的问题！我在网上查找教程的时候很多人都没有标注这个问题，当然也是自己蠢，在所有的配置都配置完成之后，还是不能正常跑程序，又重新安装重新配置，反复好几次，都快怀疑人生了，最后才发现是版本号不对。废话不多说，下面是OpenCV版本和VS版本的对应表，选择的时候一定要擦亮眼睛。我选择的环境是VS2017+OpenCV3.4.4    </p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Visual Studio 版本</th>\n<th align=\"center\">VC 版本</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">VS 6</td>\n<td align=\"center\">vc6</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2003</td>\n<td align=\"center\">vc7</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2005</td>\n<td align=\"center\">vc8</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2008</td>\n<td align=\"center\">vc9</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2010</td>\n<td align=\"center\">vc10</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2013</td>\n<td align=\"center\">vc12</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2015</td>\n<td align=\"center\">vc14</td>\n</tr>\n<tr>\n<td align=\"center\">VS 2017</td>\n<td align=\"center\">vc15</td>\n</tr>\n</tbody></table>\n<p>OpenCV对VC版本的支持情况(不全)</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">OpenCV 2.4.10</th>\n<th align=\"center\">vc10、vc11、vc12</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">OpenCV 2.4.13</td>\n<td align=\"center\">vc11、vc12</td>\n</tr>\n<tr>\n<td align=\"center\">OpenCV 3.4.0</td>\n<td align=\"center\">vc14、vc15</td>\n</tr>\n<tr>\n<td align=\"center\">OpenCv 3.4.1</td>\n<td align=\"center\">vc14、vc15</td>\n</tr>\n</tbody></table>\n<h2 id=\"VS2017安装\"><a href=\"#VS2017安装\" class=\"headerlink\" title=\"VS2017安装\"></a>VS2017安装</h2><p>我的VS安装的时间太久了，网上教程一大堆，给你们挑一篇吧，这里就不再多说了</p>\n<h2 id=\"OpenCV3-4-4下载与安装\"><a href=\"#OpenCV3-4-4下载与安装\" class=\"headerlink\" title=\"OpenCV3.4.4下载与安装\"></a>OpenCV3.4.4下载与安装</h2><h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><ol>\n<li>官网下载<br>OpenCV官网给我们提供了下载，不过下载速度嘛～自求多福<br><a href=\"https://opencv.org/releases/\" target=\"_blank\" rel=\"noopener\">OpenCV下载</a>,里面有各个版本可以选择</li>\n<li>OpenCV下载驿站<br><a href=\"https://blog.csdn.net/oMoDao1/article/details/80276834\" target=\"_blank\" rel=\"noopener\">OpenCV各版本汇总下载</a><br>感谢这位大哥的总结</li>\n</ol>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>找一个你能记住名字的路径安装进去就OK了，一定要记住这个路径，非常重要<br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0f7a6db16095.png\" alt></p>\n<h2 id=\"系统环境变量配置\"><a href=\"#系统环境变量配置\" class=\"headerlink\" title=\"系统环境变量配置\"></a>系统环境变量配置</h2><ol>\n<li>找到此电脑</li>\n<li>依次找到 属性-&gt;高级-&gt;环境变量,找到系统变量里的Path，双击进去编辑，如图所示，添加的路径 <strong>“D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin”</strong>,把”D:\\OpenCV\\”替换成你的安装路径即可</li>\n</ol>\n<p><img src=\"https://i.loli.net/2019/07/27/5d3c0e0f9cd5286868.png\" alt><br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0fa09f948672.png\" alt><br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0fa634780591.png\" alt><br><img src=\"https://i.loli.net/2019/07/27/5d3c0e0fa37ce25025.png\" alt></p>\n<p>到这就完成了系统环境的配置了</p>\n<h2 id=\"一些文件的配置\"><a href=\"#一些文件的配置\" class=\"headerlink\" title=\"一些文件的配置\"></a>一些文件的配置</h2><p>这一步的目的是为了解决以后可能会出现的关于缺少.dll的问题</p>\n<p>将 <strong>“D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\bin”</strong> 里面的三个 <strong>.dll</strong> 文件复制到 <strong>C:\\Windows“</strong> 目录下的 <strong>System32</strong>和 <strong>SysWOW64</strong>目录下</p>\n<p><img src=\"https://i.loli.net/2019/07/28/5d3d5857adbe920715.png\" alt><br><img src=\"https://i.loli.net/2019/07/28/5d3d5857bd82f79652.png\" alt></p>\n<h2 id=\"VS2017配置\"><a href=\"#VS2017配置\" class=\"headerlink\" title=\"VS2017配置\"></a>VS2017配置</h2><ol>\n<li>新建一个空项目</li>\n<li>进入属性管理器  视图-&gt;其他窗口-&gt;属性管理器<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f6359d16629.png\" alt></li>\n<li>选择Debug | x64 的 Microsoft.Cpp.x64.user<br><img src=\"https://i.loli.net/2019/07/27/5d3c156ecb8ad31557.png\" alt=\"8.png\"></li>\n<li>选择VC++目录，对包含目录和库目录进行配置<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f2e22b74192.png\" alt><ul>\n<li>在包含目录里添加 <strong>D:\\OpenCV\\opencv\\bulid\\include</strong>,<strong>D:\\OpenCV\\opencv\\bulid\\include\\opencv</strong>,<strong>D:\\OpenCV\\opencv\\bulid\\include\\opencv2</strong><br><img src=\"https://i.loli.net/2019/07/27/5d3c156f2132f35424.png\" alt></li>\n<li>在库目录里添加 <strong>D:\\OpenCV\\opencv\\bulid\\x64\\vc15\\lib</strong><br><img src=\"https://i.loli.net/2019/07/27/5d3c156f492f430904.png\" alt></li>\n</ul>\n</li>\n<li>选择 链接器-&gt;输入-&gt;附加依赖项,<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f13aac74119.png\" alt=\"12.png\"><br>在里面添加 <strong>opencv_world344d.lib</strong>，这个lib文件根据你的OpenCV版本号灵活变动<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f0828190561.png\" alt></li>\n<li>点击应用，确定即可<br>到这里，OpenCV的所有配置工作已经完成了，要注意的是解决方案那一栏要换成x64(因为我们一直在配置的就是x64)<br><img src=\"https://i.loli.net/2019/07/27/5d3c156ee8b6668598.png\" alt><h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2>这是一段读取并显示本地图片的代码，测试一下你的OpenCV环境是否配置好</li>\n</ol>\n<pre><code class=\"cpp\">#include &lt;iostream&gt;\n#include &lt;opencv2/core/core.hpp&gt;\n#include &lt;opencv2/highgui/highgui.hpp&gt;\n\nusing namespace cv;\n\nint main()\n{\n    Mat img = imread(&quot;1.bmp&quot;);\n    namedWindow(&quot;图片&quot;);\n    imshow(&quot;图片&quot;, img);\n    waitKey(6000);\n    return 0;\n}</code></pre>\n<p>运行结果如下：<br><img src=\"https://i.loli.net/2019/07/27/5d3c15857414f57549.png\" alt></p>\n<h2 id=\"需要注意的问题\"><a href=\"#需要注意的问题\" class=\"headerlink\" title=\"需要注意的问题\"></a>需要注意的问题</h2><ol>\n<li>导入包的时候不报错，但运行程序时出现一下错误<br><img src=\"https://i.loli.net/2019/07/27/5d3c156f55e6b74341.png\" alt=\"15.png\"><br><img src=\"https://i.loli.net/2019/07/27/5d3c156f39a4e29681.png\" alt=\"16.png\"><br>出现这个问题，目前已知的有两个原因    <ul>\n<li>imread函数读不到图片，即你的图片路径写的有问题<br>这里给出两种基本的路径书写形式    <ol>\n<li>绝对路径<br>Mat img = imread(“D:\\\\Pictures\\\\1.bmp”);<br>一定要注意这里是双斜杠</li>\n<li>图片路径<br>Mat img = imread(“1.bmp”);<br>使用这个的前提是图片的位置在你的工程目录下</li>\n</ol>\n</li>\n<li>链接器的附加依赖项配置的有问题<br>在Debug模式下，附加依赖项添加的是 <strong>opencv_world344d.lib</strong><br>在Release模式下，附加依赖项添加的是 <strong>opencv_world344.lib</strong><br>有些教程是两个都添加，这是不对的，一定要注意。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<p>好了，教程到此结束，<br>接下来你就可以放心地去玩耍了，Enjoy Your OpenCV!</p>\n"},{"title":"Day10","date":"2019-07-24T01:34:30.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"\n# 图像分割\n\n## 基本边缘检测\n\n### 边缘模型\n\n- 台阶模型\n在一个像素的距离上发生两次灰度级间理想的过渡\n- 斜坡模型\n数字图像存在被模糊或有噪声的边缘，这时的边缘被建模成一个更接近灰度斜坡的剖面，斜坡的斜度与边缘的模糊程度成反比\n- 屋顶模型\n通过一个区域的线的模型，屋顶边缘的基底(宽度)由该线的宽度和尖锐度决定\n![](https://i.loli.net/2019/07/24/5d382004cd3e437707.jpg)\n\n结合前面提到的一阶导数和二阶导数的性质，可以得出结论:\n1. 一阶导数的幅值可用于检测图像中的某个点处是否存在一个边缘\n2. 二阶导数的符号可用于确定一个边缘像素位于该边缘的暗的一侧还是亮的一侧\n3. 对图像的每个边缘，二阶导数生成两个值\n4. 二阶导数的零交叉点可用于定位粗边缘的中心\n- 执行边缘检测的三个步骤:    \n  1. 为降噪对图像进行平滑处理\n  2. 边缘点的检测\n  3. 边缘定位\n\n### 梯度\n\n- 二维函数f(x,y)的梯度定义为一个向量：\n$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$\n这个向量的幅值\n$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$\n为了简化计算，通常省略平方根或取绝对值\n$$\\triangledown f = |g_x| + |g_y|$$\n通常用梯度没的幅值或者近似值来简单作为'梯度'    \n梯度的性质是:梯度向量指向(x,y)坐标处f的最大变换率方向。最大变化率发生的角度是:\n$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$\n\n### 使用函数edge的边缘检测\n- 语法\n```\n[g,t] = edge(f, 'method', parameters);\n```\nf是输入图像，method是边缘检测方法，parameters是附加参数\n### 边缘检测算子\n图像邻域如下图所示:\n\n$z_1$ | $z_2$ | $z_3$\n:---: | :---: | :---:\n$z_4$ | $z_5$ | $z_6$\n$z_7$ | $z_8$ | $z_9$\n\n#### Sobel边缘检测算子\n- Sobel边缘检测算子模板\n\n-1 | -2 | -1\n:---: | :---: | :---:\n0 | 0 | 0\n1 | 2 | 1\n\n$$g_x=(z_7+2z_8+z_9)-(z_1+2z_2+z_3)$$\n\n-1 | 0 | 1\n:---:  | :---: | :---:\n-2 | 0 | 2\n-1 | 0 | 1\n\n$$g_y = (z_3+2z_6+z_9)-(z_1+2z_4+z_7)$$\n每一行和每一列的中心像素用2来加权以提供平滑\n- MATLAB语法\n```\n[g, t] = edge(f, 'sobel', T, dir);\n```\nf是输入的图像，T是指定的阀值，dir是指定的检测边缘的首选方向:'horizontal','vertical','both'(默认值)    \nt是可选的，T未指定，则t自动设置\n\n#### Prewitt边缘检测算子\n- Prewitt边缘检测算子模板\n\n-1 | -1 | -1\n:---:  | :---: | :---:\n0 | 0 | 0\n1 | 1 | 1\n\n$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$\n\n-1 | 0 | 1\n:---:  | :---: | :---:\n-1 | 0 | 1\n-1 | 0 | 1\n\n$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$\n\n- MATLAB语法\n```\n[g, t] = edge(f, 'prewitt', T ,dir);\n```\n计算简单，但容易产生噪声\n\n#### Roberts边缘检测算子\n- Roberts边缘检测算子模板\n\n-1 | 0\n:---:  | :---: \n0 | 1\n\n$$g_x = z_9 - z_5$$\n\n0 | 1\n:---:  | :---:\n1 | 0\n\n$$g_y = z_8 - z_6$$\n\n- MATLAB语法\n```\n[g, t] = edge(f, 'roberts', T , dir);\n```\n#### LoG检测算子\n- LoG\n\n考虑高斯函数\n$$G(x,y) = e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}$$\n$\\sigma$是标准差。这是平滑函数，如果和图像卷积，会使图像变模糊，模糊程度由$\\sigma$决定    \n这个函数的Laplace算法是:\n$$\\triangledown^2G(x,y) = \\frac{\\partial ^2 G(x,y)}{\\partial x^2}+\\frac{\\partial ^2 G(x,y)}{\\partial y^2} = [\\frac{x^2 + y^2-2\\sigma ^2}{\\sigma ^4}]^{e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}}$$\n\n用$\\triangledown ^2G(x,y)$卷积(滤波)这幅图像与先用平滑函数对图像卷积，再对结果进行Laplace变换的结果是一样的    \n用$\\triangledown ^2G(x,y)$卷积图像，可以得到两个效果:平滑图像(因而减少了噪声);计算Laplace，从而产生双边缘图像，然后在双边缘之间定位由发现的零交叉组成的边缘\n- MATLAB语法\n```\n[g, t] = edge(f, 'log', T , sigma);\n```\nsigma默认值是2\n\n#### 零交叉检测算子\n- 基于LoG，卷积使用特殊的滤波函数H来完成\n- MATLAB语法\n```\n[g, t] = edge(f, 'zerocross', T , H);\n```\n#### Canny检测算子\n- edge函数中最强的边缘检测算子\n- MATLAB语法\n```\n[g, t] = edge(f, 'canny', T , sigma);\n```\n### MATLAB实现\n- 几种边缘检测算法的比较(Sobel,LoG,Canny)\n```\nf = imread('timg1.jpg');\nimshow(f),title('currect image');\nf = rgb2gray(f);\n%Default Output\n[gSobel_default,ts] = edge(f, 'sobel');\n[gLoG_default, tlog] = edge(f, 'log');\n[gCanny_default, tc] = edge(f,'canny');\n\n%Best Output\n\ngSobel_best = edge(f,'sobel',0.165);\ngLoG_best = edge(f,'log',0.008, 2.25);\ngCanny_best = edge(f,'canny',[0.05, 0.4], 1.5);\n\n\nfigure,imshow(f),title('Gary images');\nfigure,imshow(gSobel_default),title('gSobel default');\nfigure,imshow(gSobel_best),title('gSobel best');\nfigure,imshow(gLoG_default),title('gLoG default');\nfigure,imshow(gLoG_best),title('gLoG best');\nfigure,imshow(gCanny_default),title('gCanny default');\nfigure,imshow(gCanny_best),title('gCanny best');\n```\n其中最佳输出的阀值是根据得到的ts,tlog,tc的值来确定的\n结果:\n![](https://i.loli.net/2019/07/24/5d37d6b4bec1777947.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b5886d994031.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3ad9b270352.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b573bae72055.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b61724d14715.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b51df2874618.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b65663011930.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3e566366232.jpg)\n综合结果来看，Canny边缘检测算子可以得到最好的结果\n\n## 霍夫变换\n### 介绍与应用场景\n\n[霍夫变换](https://zh.wikipedia.org/wiki/%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2)(Hough Transform)是图像处理中的一种特征提取技术，该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。经典霍夫变换用来检测图像中的直线，后来霍夫变换扩展到任意形状物体的识别，多为圆和椭圆。霍夫变换运用两个坐标空间之间的变换将在一个空间中具有相同形状的曲线或直线映射到另一个坐标空间的一个点上形成峰值，从而把检测任意形状的问题转化为统计峰值问题。\n\n### 基本原理\n考虑点$(x_i,y_i)$及通过这个点的线,有无穷多的线通过点$(x_i,y_i)$，针对a和b的一些值，满足斜截式$y_i = ax_i + b$的所有线都通过该点。该公式也可以写为$b = -ax_i + y_i$，考虑ab平面(即**参数空间**)对固定点$(x_i,y_i)$得到一条线的方程。另外，第二个点$(x_j,y_j)$也有一条在参数空间中与之相关的线，这条线和与$(x_i,y_i)$**相关**的线交于点$(a',b')$，其中$a'$是斜率，$b'$是在**xy平面**上包含点$(x_i,y_i)$和$(x_j,y_j)$的线的截距。在**参数空间**中，这条线包含的所有点都有相交于$(a',b')$点的直线。    \n简单理解，直线由两个点$A(x_1,y_1)$和$B(x_2,y_2)$定义，在参数空间中，两条直线的唯一公共点是在原图像空间中表示连接点A和B的唯一存在的直线\n![](https://i.loli.net/2019/07/24/5d38129f0e9f156720.jpg)\n因此，给定很多点，判断这些点是否共线的问题，经由霍夫变换之后，变成判断一堆曲线(每一个点在$(r, \\theta)$平面上代表一条曲线)是否 在 $(r,\\theta)$平面上相交于同一点的问题\n另外用法线表示法:\n$$xcos\\theta + ysin\\theta = \\rho$$\n水平线的$\\theta$=0,$\\rho$等于正的x的截距，垂直线的$\\theta=90$度，$\\rho$等于正的y的截距\n![](https://i.loli.net/2019/07/24/5d382004e2bab23873.jpg)\n\n在坐标(i, j)的单元位置，累加器的值是 A(i, j)，对应于参数空间坐标$(\\rho_i,\\theta_j)$的正方形。最初， 这些单元位置为零。然后，对于每个图像平面上的非背景点$(x_k,y_k)$(就是 xy 平面)，我们令 θ 等 于在 θ 轴上允许的细分值，并通过公式$\\rho = x_kcos\\theta+y_ksin\\theta$解出相应的 ρ 值。然后，得到的 ρ 值四 舍五入为最接近的 ρ 轴上允许的单元值。相应的累加器单元增加一个增量。在这个过程的最后， 累加单元 A(i, j)中的值 Q 就意味着 xy 平面上位于线$xcos\\theta_j+ysin\\theta_j = \\rho_i$上的点有 Q 个。在$\\rho\\theta$平面上，细分的数目决定了这些点的共线的精确度。累加器数组在工具箱中叫做霍夫变换矩阵，简称霍夫变换。\n\n### MATLAB工具箱函数\n#### hough函数\n默认语法\n```\n[H, theta, rho] = hough(f)\n```\nH是霍夫变换矩阵，theta和rho是$\\theta$和$\\rho$的值    \n下面这个例子可以加深对霍夫变换的理解\n```\nf = zeros(101,101);\n\nf(1,1) = 1;\n\nf(101,1) = 1;\n\nf(1,101) = 1;\n\nf(101, 101) = 1;\n\nf(51, 51) = 1;\n\n% H = hough(f);\n\n[H, theta, rho] = hough(f);\n\nimshow(H, [],'XData', theta,'YData', rho, 'InitialMagnification', 'fit')\n\naxis on, axis normal\n\nxlabel('\\theta'),ylabel('\\rho')\n```\n结果:\n![](https://i.loli.net/2019/07/24/5d381e6cd3ce994397.jpg)\n观察图可以看打到三条曲线在+45度和-45度处的交点指出:f中有两组三个共线的点。两条曲线在$(\\rho,\\theta)$ = (0,-90)、(-100,-90)、(0,0)、(100,0)处的交点指出:有4组位于**垂直线**和**水平线**上的公共点\n\n#### houghpeaks函数\n寻找指定的峰值数    \n默认语法\n```\npeaks = houghpeaks(H, NumPeaks)\n```\nH是霍夫变换矩阵\n\n#### houghlines函数\n决定线的起点和终点\n默认语法\n```\nlines = houghlines(f, theta, rho, peaks)\n```\n输出lines是结构数组，长度等于找到的线段。结构中的每个元素可以看成一条线，并含有下列字段:    \n  1. point1:两元素向量[r1,c1]，指定了线段终点的行列坐标。\n  2. point2:两元素向量[r2,c2]，指定了线段其他终点的行列坐标。\n  3. theta:与线相关的霍夫变换的以度计量的角度。\n  4. rho:与线相关的霍夫变换的$\\rho$轴位置。\n#### MATLAB使用霍夫变换检测和连接线\n\n```\nf = imread('timg1.jpg');\n\nf = rgb2gray(f);\n\nBW = edge(f,'canny');\n\n[H ,theta, rho] = hough(BW, 'ThetaResolution', 0.2);\n\nimshow(H, [],'XData', theta,'YData', rho, 'InitialMagnification', 'fit')\n\naxis on, axis normal\n\nxlabel('\\theta'),ylabel('\\rho')\n\n\n\npeaks = houghpeaks(H, 5);\n\nhold on\n\nplot(theta(peaks( :, 2)), rho(peaks(:, 1)),...\n\n    'linestyle', 'none', 'marker', 's', 'color', 'w');\n\n\nlines = houghlines(f, theta, rho, peaks);\n\nfigure, imshow(f), hold on\n\nfor k = 1:length(lines)\n\n    xy = [lines(k).point1 ; lines(k).point2];\n\n    plot(xy(:,1), xy(:,2), 'LineWidth', 4, 'color', 'red');\n\nend\n```\n结果:\n![](https://i.loli.net/2019/07/24/5d381d8d80bff63571.jpg)\n![](https://i.loli.net/2019/07/24/5d381de2778c421022.jpg)\n","source":"_posts/Day10.md","raw":"---\ntitle: Day10\ndate: 2019-07-24 09:34:30\ntags: 实习\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n\n# 图像分割\n\n## 基本边缘检测\n\n### 边缘模型\n\n- 台阶模型\n在一个像素的距离上发生两次灰度级间理想的过渡\n- 斜坡模型\n数字图像存在被模糊或有噪声的边缘，这时的边缘被建模成一个更接近灰度斜坡的剖面，斜坡的斜度与边缘的模糊程度成反比\n- 屋顶模型\n通过一个区域的线的模型，屋顶边缘的基底(宽度)由该线的宽度和尖锐度决定\n![](https://i.loli.net/2019/07/24/5d382004cd3e437707.jpg)\n\n结合前面提到的一阶导数和二阶导数的性质，可以得出结论:\n1. 一阶导数的幅值可用于检测图像中的某个点处是否存在一个边缘\n2. 二阶导数的符号可用于确定一个边缘像素位于该边缘的暗的一侧还是亮的一侧\n3. 对图像的每个边缘，二阶导数生成两个值\n4. 二阶导数的零交叉点可用于定位粗边缘的中心\n- 执行边缘检测的三个步骤:    \n  1. 为降噪对图像进行平滑处理\n  2. 边缘点的检测\n  3. 边缘定位\n\n### 梯度\n\n- 二维函数f(x,y)的梯度定义为一个向量：\n$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$\n这个向量的幅值\n$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$\n为了简化计算，通常省略平方根或取绝对值\n$$\\triangledown f = |g_x| + |g_y|$$\n通常用梯度没的幅值或者近似值来简单作为'梯度'    \n梯度的性质是:梯度向量指向(x,y)坐标处f的最大变换率方向。最大变化率发生的角度是:\n$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$\n\n### 使用函数edge的边缘检测\n- 语法\n```\n[g,t] = edge(f, 'method', parameters);\n```\nf是输入图像，method是边缘检测方法，parameters是附加参数\n### 边缘检测算子\n图像邻域如下图所示:\n\n$z_1$ | $z_2$ | $z_3$\n:---: | :---: | :---:\n$z_4$ | $z_5$ | $z_6$\n$z_7$ | $z_8$ | $z_9$\n\n#### Sobel边缘检测算子\n- Sobel边缘检测算子模板\n\n-1 | -2 | -1\n:---: | :---: | :---:\n0 | 0 | 0\n1 | 2 | 1\n\n$$g_x=(z_7+2z_8+z_9)-(z_1+2z_2+z_3)$$\n\n-1 | 0 | 1\n:---:  | :---: | :---:\n-2 | 0 | 2\n-1 | 0 | 1\n\n$$g_y = (z_3+2z_6+z_9)-(z_1+2z_4+z_7)$$\n每一行和每一列的中心像素用2来加权以提供平滑\n- MATLAB语法\n```\n[g, t] = edge(f, 'sobel', T, dir);\n```\nf是输入的图像，T是指定的阀值，dir是指定的检测边缘的首选方向:'horizontal','vertical','both'(默认值)    \nt是可选的，T未指定，则t自动设置\n\n#### Prewitt边缘检测算子\n- Prewitt边缘检测算子模板\n\n-1 | -1 | -1\n:---:  | :---: | :---:\n0 | 0 | 0\n1 | 1 | 1\n\n$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$\n\n-1 | 0 | 1\n:---:  | :---: | :---:\n-1 | 0 | 1\n-1 | 0 | 1\n\n$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$\n\n- MATLAB语法\n```\n[g, t] = edge(f, 'prewitt', T ,dir);\n```\n计算简单，但容易产生噪声\n\n#### Roberts边缘检测算子\n- Roberts边缘检测算子模板\n\n-1 | 0\n:---:  | :---: \n0 | 1\n\n$$g_x = z_9 - z_5$$\n\n0 | 1\n:---:  | :---:\n1 | 0\n\n$$g_y = z_8 - z_6$$\n\n- MATLAB语法\n```\n[g, t] = edge(f, 'roberts', T , dir);\n```\n#### LoG检测算子\n- LoG\n\n考虑高斯函数\n$$G(x,y) = e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}$$\n$\\sigma$是标准差。这是平滑函数，如果和图像卷积，会使图像变模糊，模糊程度由$\\sigma$决定    \n这个函数的Laplace算法是:\n$$\\triangledown^2G(x,y) = \\frac{\\partial ^2 G(x,y)}{\\partial x^2}+\\frac{\\partial ^2 G(x,y)}{\\partial y^2} = [\\frac{x^2 + y^2-2\\sigma ^2}{\\sigma ^4}]^{e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}}$$\n\n用$\\triangledown ^2G(x,y)$卷积(滤波)这幅图像与先用平滑函数对图像卷积，再对结果进行Laplace变换的结果是一样的    \n用$\\triangledown ^2G(x,y)$卷积图像，可以得到两个效果:平滑图像(因而减少了噪声);计算Laplace，从而产生双边缘图像，然后在双边缘之间定位由发现的零交叉组成的边缘\n- MATLAB语法\n```\n[g, t] = edge(f, 'log', T , sigma);\n```\nsigma默认值是2\n\n#### 零交叉检测算子\n- 基于LoG，卷积使用特殊的滤波函数H来完成\n- MATLAB语法\n```\n[g, t] = edge(f, 'zerocross', T , H);\n```\n#### Canny检测算子\n- edge函数中最强的边缘检测算子\n- MATLAB语法\n```\n[g, t] = edge(f, 'canny', T , sigma);\n```\n### MATLAB实现\n- 几种边缘检测算法的比较(Sobel,LoG,Canny)\n```\nf = imread('timg1.jpg');\nimshow(f),title('currect image');\nf = rgb2gray(f);\n%Default Output\n[gSobel_default,ts] = edge(f, 'sobel');\n[gLoG_default, tlog] = edge(f, 'log');\n[gCanny_default, tc] = edge(f,'canny');\n\n%Best Output\n\ngSobel_best = edge(f,'sobel',0.165);\ngLoG_best = edge(f,'log',0.008, 2.25);\ngCanny_best = edge(f,'canny',[0.05, 0.4], 1.5);\n\n\nfigure,imshow(f),title('Gary images');\nfigure,imshow(gSobel_default),title('gSobel default');\nfigure,imshow(gSobel_best),title('gSobel best');\nfigure,imshow(gLoG_default),title('gLoG default');\nfigure,imshow(gLoG_best),title('gLoG best');\nfigure,imshow(gCanny_default),title('gCanny default');\nfigure,imshow(gCanny_best),title('gCanny best');\n```\n其中最佳输出的阀值是根据得到的ts,tlog,tc的值来确定的\n结果:\n![](https://i.loli.net/2019/07/24/5d37d6b4bec1777947.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b5886d994031.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3ad9b270352.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b573bae72055.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b61724d14715.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b51df2874618.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b65663011930.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3e566366232.jpg)\n综合结果来看，Canny边缘检测算子可以得到最好的结果\n\n## 霍夫变换\n### 介绍与应用场景\n\n[霍夫变换](https://zh.wikipedia.org/wiki/%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2)(Hough Transform)是图像处理中的一种特征提取技术，该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。经典霍夫变换用来检测图像中的直线，后来霍夫变换扩展到任意形状物体的识别，多为圆和椭圆。霍夫变换运用两个坐标空间之间的变换将在一个空间中具有相同形状的曲线或直线映射到另一个坐标空间的一个点上形成峰值，从而把检测任意形状的问题转化为统计峰值问题。\n\n### 基本原理\n考虑点$(x_i,y_i)$及通过这个点的线,有无穷多的线通过点$(x_i,y_i)$，针对a和b的一些值，满足斜截式$y_i = ax_i + b$的所有线都通过该点。该公式也可以写为$b = -ax_i + y_i$，考虑ab平面(即**参数空间**)对固定点$(x_i,y_i)$得到一条线的方程。另外，第二个点$(x_j,y_j)$也有一条在参数空间中与之相关的线，这条线和与$(x_i,y_i)$**相关**的线交于点$(a',b')$，其中$a'$是斜率，$b'$是在**xy平面**上包含点$(x_i,y_i)$和$(x_j,y_j)$的线的截距。在**参数空间**中，这条线包含的所有点都有相交于$(a',b')$点的直线。    \n简单理解，直线由两个点$A(x_1,y_1)$和$B(x_2,y_2)$定义，在参数空间中，两条直线的唯一公共点是在原图像空间中表示连接点A和B的唯一存在的直线\n![](https://i.loli.net/2019/07/24/5d38129f0e9f156720.jpg)\n因此，给定很多点，判断这些点是否共线的问题，经由霍夫变换之后，变成判断一堆曲线(每一个点在$(r, \\theta)$平面上代表一条曲线)是否 在 $(r,\\theta)$平面上相交于同一点的问题\n另外用法线表示法:\n$$xcos\\theta + ysin\\theta = \\rho$$\n水平线的$\\theta$=0,$\\rho$等于正的x的截距，垂直线的$\\theta=90$度，$\\rho$等于正的y的截距\n![](https://i.loli.net/2019/07/24/5d382004e2bab23873.jpg)\n\n在坐标(i, j)的单元位置，累加器的值是 A(i, j)，对应于参数空间坐标$(\\rho_i,\\theta_j)$的正方形。最初， 这些单元位置为零。然后，对于每个图像平面上的非背景点$(x_k,y_k)$(就是 xy 平面)，我们令 θ 等 于在 θ 轴上允许的细分值，并通过公式$\\rho = x_kcos\\theta+y_ksin\\theta$解出相应的 ρ 值。然后，得到的 ρ 值四 舍五入为最接近的 ρ 轴上允许的单元值。相应的累加器单元增加一个增量。在这个过程的最后， 累加单元 A(i, j)中的值 Q 就意味着 xy 平面上位于线$xcos\\theta_j+ysin\\theta_j = \\rho_i$上的点有 Q 个。在$\\rho\\theta$平面上，细分的数目决定了这些点的共线的精确度。累加器数组在工具箱中叫做霍夫变换矩阵，简称霍夫变换。\n\n### MATLAB工具箱函数\n#### hough函数\n默认语法\n```\n[H, theta, rho] = hough(f)\n```\nH是霍夫变换矩阵，theta和rho是$\\theta$和$\\rho$的值    \n下面这个例子可以加深对霍夫变换的理解\n```\nf = zeros(101,101);\n\nf(1,1) = 1;\n\nf(101,1) = 1;\n\nf(1,101) = 1;\n\nf(101, 101) = 1;\n\nf(51, 51) = 1;\n\n% H = hough(f);\n\n[H, theta, rho] = hough(f);\n\nimshow(H, [],'XData', theta,'YData', rho, 'InitialMagnification', 'fit')\n\naxis on, axis normal\n\nxlabel('\\theta'),ylabel('\\rho')\n```\n结果:\n![](https://i.loli.net/2019/07/24/5d381e6cd3ce994397.jpg)\n观察图可以看打到三条曲线在+45度和-45度处的交点指出:f中有两组三个共线的点。两条曲线在$(\\rho,\\theta)$ = (0,-90)、(-100,-90)、(0,0)、(100,0)处的交点指出:有4组位于**垂直线**和**水平线**上的公共点\n\n#### houghpeaks函数\n寻找指定的峰值数    \n默认语法\n```\npeaks = houghpeaks(H, NumPeaks)\n```\nH是霍夫变换矩阵\n\n#### houghlines函数\n决定线的起点和终点\n默认语法\n```\nlines = houghlines(f, theta, rho, peaks)\n```\n输出lines是结构数组，长度等于找到的线段。结构中的每个元素可以看成一条线，并含有下列字段:    \n  1. point1:两元素向量[r1,c1]，指定了线段终点的行列坐标。\n  2. point2:两元素向量[r2,c2]，指定了线段其他终点的行列坐标。\n  3. theta:与线相关的霍夫变换的以度计量的角度。\n  4. rho:与线相关的霍夫变换的$\\rho$轴位置。\n#### MATLAB使用霍夫变换检测和连接线\n\n```\nf = imread('timg1.jpg');\n\nf = rgb2gray(f);\n\nBW = edge(f,'canny');\n\n[H ,theta, rho] = hough(BW, 'ThetaResolution', 0.2);\n\nimshow(H, [],'XData', theta,'YData', rho, 'InitialMagnification', 'fit')\n\naxis on, axis normal\n\nxlabel('\\theta'),ylabel('\\rho')\n\n\n\npeaks = houghpeaks(H, 5);\n\nhold on\n\nplot(theta(peaks( :, 2)), rho(peaks(:, 1)),...\n\n    'linestyle', 'none', 'marker', 's', 'color', 'w');\n\n\nlines = houghlines(f, theta, rho, peaks);\n\nfigure, imshow(f), hold on\n\nfor k = 1:length(lines)\n\n    xy = [lines(k).point1 ; lines(k).point2];\n\n    plot(xy(:,1), xy(:,2), 'LineWidth', 4, 'color', 'red');\n\nend\n```\n结果:\n![](https://i.loli.net/2019/07/24/5d381d8d80bff63571.jpg)\n![](https://i.loli.net/2019/07/24/5d381de2778c421022.jpg)\n","slug":"Day10","published":1,"updated":"2019-08-10T10:47:34.074Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltu001ke5g60whxxyfi","content":"<h1 id=\"图像分割\"><a href=\"#图像分割\" class=\"headerlink\" title=\"图像分割\"></a>图像分割</h1><h2 id=\"基本边缘检测\"><a href=\"#基本边缘检测\" class=\"headerlink\" title=\"基本边缘检测\"></a>基本边缘检测</h2><h3 id=\"边缘模型\"><a href=\"#边缘模型\" class=\"headerlink\" title=\"边缘模型\"></a>边缘模型</h3><ul>\n<li>台阶模型<br>在一个像素的距离上发生两次灰度级间理想的过渡</li>\n<li>斜坡模型<br>数字图像存在被模糊或有噪声的边缘，这时的边缘被建模成一个更接近灰度斜坡的剖面，斜坡的斜度与边缘的模糊程度成反比</li>\n<li>屋顶模型<br>通过一个区域的线的模型，屋顶边缘的基底(宽度)由该线的宽度和尖锐度决定<br><img src=\"https://i.loli.net/2019/07/24/5d382004cd3e437707.jpg\" alt></li>\n</ul>\n<p>结合前面提到的一阶导数和二阶导数的性质，可以得出结论:</p>\n<ol>\n<li>一阶导数的幅值可用于检测图像中的某个点处是否存在一个边缘</li>\n<li>二阶导数的符号可用于确定一个边缘像素位于该边缘的暗的一侧还是亮的一侧</li>\n<li>对图像的每个边缘，二阶导数生成两个值</li>\n<li>二阶导数的零交叉点可用于定位粗边缘的中心</li>\n</ol>\n<ul>\n<li>执行边缘检测的三个步骤:    <ol>\n<li>为降噪对图像进行平滑处理</li>\n<li>边缘点的检测</li>\n<li>边缘定位</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"梯度\"><a href=\"#梯度\" class=\"headerlink\" title=\"梯度\"></a>梯度</h3><ul>\n<li>二维函数f(x,y)的梯度定义为一个向量：<br>$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$<br>这个向量的幅值<br>$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$<br>为了简化计算，通常省略平方根或取绝对值<br>$$\\triangledown f = |g_x| + |g_y|$$<br>通常用梯度没的幅值或者近似值来简单作为’梯度’<br>梯度的性质是:梯度向量指向(x,y)坐标处f的最大变换率方向。最大变化率发生的角度是:<br>$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$</li>\n</ul>\n<h3 id=\"使用函数edge的边缘检测\"><a href=\"#使用函数edge的边缘检测\" class=\"headerlink\" title=\"使用函数edge的边缘检测\"></a>使用函数edge的边缘检测</h3><ul>\n<li>语法<pre><code>[g,t] = edge(f, &#39;method&#39;, parameters);</code></pre>f是输入图像，method是边缘检测方法，parameters是附加参数<h3 id=\"边缘检测算子\"><a href=\"#边缘检测算子\" class=\"headerlink\" title=\"边缘检测算子\"></a>边缘检测算子</h3>图像邻域如下图所示:</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">$z_1$</th>\n<th align=\"center\">$z_2$</th>\n<th align=\"center\">$z_3$</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$z_4$</td>\n<td align=\"center\">$z_5$</td>\n<td align=\"center\">$z_6$</td>\n</tr>\n<tr>\n<td align=\"center\">$z_7$</td>\n<td align=\"center\">$z_8$</td>\n<td align=\"center\">$z_9$</td>\n</tr>\n</tbody></table>\n<h4 id=\"Sobel边缘检测算子\"><a href=\"#Sobel边缘检测算子\" class=\"headerlink\" title=\"Sobel边缘检测算子\"></a>Sobel边缘检测算子</h4><ul>\n<li>Sobel边缘检测算子模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-2</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_x=(z_7+2z_8+z_9)-(z_1+2z_2+z_3)$$</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">0</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-2</td>\n<td align=\"center\">0</td>\n<td align=\"center\">2</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_y = (z_3+2z_6+z_9)-(z_1+2z_4+z_7)$$<br>每一行和每一列的中心像素用2来加权以提供平滑</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;sobel&#39;, T, dir);</code></pre>f是输入的图像，T是指定的阀值，dir是指定的检测边缘的首选方向:’horizontal’,’vertical’,’both’(默认值)<br>t是可选的，T未指定，则t自动设置</li>\n</ul>\n<h4 id=\"Prewitt边缘检测算子\"><a href=\"#Prewitt边缘检测算子\" class=\"headerlink\" title=\"Prewitt边缘检测算子\"></a>Prewitt边缘检测算子</h4><ul>\n<li>Prewitt边缘检测算子模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">0</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;prewitt&#39;, T ,dir);</code></pre>计算简单，但容易产生噪声</li>\n</ul>\n<h4 id=\"Roberts边缘检测算子\"><a href=\"#Roberts边缘检测算子\" class=\"headerlink\" title=\"Roberts边缘检测算子\"></a>Roberts边缘检测算子</h4><ul>\n<li>Roberts边缘检测算子模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">0</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_x = z_9 - z_5$$</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">0</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n</tbody></table>\n<p>$$g_y = z_8 - z_6$$</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;roberts&#39;, T , dir);</code></pre><h4 id=\"LoG检测算子\"><a href=\"#LoG检测算子\" class=\"headerlink\" title=\"LoG检测算子\"></a>LoG检测算子</h4></li>\n<li>LoG</li>\n</ul>\n<p>考虑高斯函数<br>$$G(x,y) = e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}$$<br>$\\sigma$是标准差。这是平滑函数，如果和图像卷积，会使图像变模糊，模糊程度由$\\sigma$决定<br>这个函数的Laplace算法是:<br>$$\\triangledown^2G(x,y) = \\frac{\\partial ^2 G(x,y)}{\\partial x^2}+\\frac{\\partial ^2 G(x,y)}{\\partial y^2} = [\\frac{x^2 + y^2-2\\sigma ^2}{\\sigma ^4}]^{e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}}$$</p>\n<p>用$\\triangledown ^2G(x,y)$卷积(滤波)这幅图像与先用平滑函数对图像卷积，再对结果进行Laplace变换的结果是一样的<br>用$\\triangledown ^2G(x,y)$卷积图像，可以得到两个效果:平滑图像(因而减少了噪声);计算Laplace，从而产生双边缘图像，然后在双边缘之间定位由发现的零交叉组成的边缘</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;log&#39;, T , sigma);</code></pre>sigma默认值是2</li>\n</ul>\n<h4 id=\"零交叉检测算子\"><a href=\"#零交叉检测算子\" class=\"headerlink\" title=\"零交叉检测算子\"></a>零交叉检测算子</h4><ul>\n<li>基于LoG，卷积使用特殊的滤波函数H来完成</li>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;zerocross&#39;, T , H);</code></pre><h4 id=\"Canny检测算子\"><a href=\"#Canny检测算子\" class=\"headerlink\" title=\"Canny检测算子\"></a>Canny检测算子</h4></li>\n<li>edge函数中最强的边缘检测算子</li>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;canny&#39;, T , sigma);</code></pre><h3 id=\"MATLAB实现\"><a href=\"#MATLAB实现\" class=\"headerlink\" title=\"MATLAB实现\"></a>MATLAB实现</h3></li>\n<li>几种边缘检测算法的比较(Sobel,LoG,Canny)<pre><code>f = imread(&#39;timg1.jpg&#39;);\nimshow(f),title(&#39;currect image&#39;);\nf = rgb2gray(f);\n%Default Output\n[gSobel_default,ts] = edge(f, &#39;sobel&#39;);\n[gLoG_default, tlog] = edge(f, &#39;log&#39;);\n[gCanny_default, tc] = edge(f,&#39;canny&#39;);\n</code></pre></li>\n</ul>\n<p>%Best Output</p>\n<p>gSobel_best = edge(f,’sobel’,0.165);<br>gLoG_best = edge(f,’log’,0.008, 2.25);<br>gCanny_best = edge(f,’canny’,[0.05, 0.4], 1.5);</p>\n<p>figure,imshow(f),title(‘Gary images’);<br>figure,imshow(gSobel_default),title(‘gSobel default’);<br>figure,imshow(gSobel_best),title(‘gSobel best’);<br>figure,imshow(gLoG_default),title(‘gLoG default’);<br>figure,imshow(gLoG_best),title(‘gLoG best’);<br>figure,imshow(gCanny_default),title(‘gCanny default’);<br>figure,imshow(gCanny_best),title(‘gCanny best’);</p>\n<pre><code>其中最佳输出的阀值是根据得到的ts,tlog,tc的值来确定的\n结果:\n![](https://i.loli.net/2019/07/24/5d37d6b4bec1777947.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b5886d994031.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3ad9b270352.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b573bae72055.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b61724d14715.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b51df2874618.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b65663011930.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3e566366232.jpg)\n综合结果来看，Canny边缘检测算子可以得到最好的结果\n\n## 霍夫变换\n### 介绍与应用场景\n\n[霍夫变换](https://zh.wikipedia.org/wiki/%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2)(Hough Transform)是图像处理中的一种特征提取技术，该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。经典霍夫变换用来检测图像中的直线，后来霍夫变换扩展到任意形状物体的识别，多为圆和椭圆。霍夫变换运用两个坐标空间之间的变换将在一个空间中具有相同形状的曲线或直线映射到另一个坐标空间的一个点上形成峰值，从而把检测任意形状的问题转化为统计峰值问题。\n\n### 基本原理\n考虑点$(x_i,y_i)$及通过这个点的线,有无穷多的线通过点$(x_i,y_i)$，针对a和b的一些值，满足斜截式$y_i = ax_i + b$的所有线都通过该点。该公式也可以写为$b = -ax_i + y_i$，考虑ab平面(即**参数空间**)对固定点$(x_i,y_i)$得到一条线的方程。另外，第二个点$(x_j,y_j)$也有一条在参数空间中与之相关的线，这条线和与$(x_i,y_i)$**相关**的线交于点$(a&#39;,b&#39;)$，其中$a&#39;$是斜率，$b&#39;$是在**xy平面**上包含点$(x_i,y_i)$和$(x_j,y_j)$的线的截距。在**参数空间**中，这条线包含的所有点都有相交于$(a&#39;,b&#39;)$点的直线。    \n简单理解，直线由两个点$A(x_1,y_1)$和$B(x_2,y_2)$定义，在参数空间中，两条直线的唯一公共点是在原图像空间中表示连接点A和B的唯一存在的直线\n![](https://i.loli.net/2019/07/24/5d38129f0e9f156720.jpg)\n因此，给定很多点，判断这些点是否共线的问题，经由霍夫变换之后，变成判断一堆曲线(每一个点在$(r, \\theta)$平面上代表一条曲线)是否 在 $(r,\\theta)$平面上相交于同一点的问题\n另外用法线表示法:\n$$xcos\\theta + ysin\\theta = \\rho$$\n水平线的$\\theta$=0,$\\rho$等于正的x的截距，垂直线的$\\theta=90$度，$\\rho$等于正的y的截距\n![](https://i.loli.net/2019/07/24/5d382004e2bab23873.jpg)\n\n在坐标(i, j)的单元位置，累加器的值是 A(i, j)，对应于参数空间坐标$(\\rho_i,\\theta_j)$的正方形。最初， 这些单元位置为零。然后，对于每个图像平面上的非背景点$(x_k,y_k)$(就是 xy 平面)，我们令 θ 等 于在 θ 轴上允许的细分值，并通过公式$\\rho = x_kcos\\theta+y_ksin\\theta$解出相应的 ρ 值。然后，得到的 ρ 值四 舍五入为最接近的 ρ 轴上允许的单元值。相应的累加器单元增加一个增量。在这个过程的最后， 累加单元 A(i, j)中的值 Q 就意味着 xy 平面上位于线$xcos\\theta_j+ysin\\theta_j = \\rho_i$上的点有 Q 个。在$\\rho\\theta$平面上，细分的数目决定了这些点的共线的精确度。累加器数组在工具箱中叫做霍夫变换矩阵，简称霍夫变换。\n\n### MATLAB工具箱函数\n#### hough函数\n默认语法</code></pre><p>[H, theta, rho] = hough(f)</p>\n<pre><code>H是霍夫变换矩阵，theta和rho是$\\theta$和$\\rho$的值    \n下面这个例子可以加深对霍夫变换的理解</code></pre><p>f = zeros(101,101);</p>\n<p>f(1,1) = 1;</p>\n<p>f(101,1) = 1;</p>\n<p>f(1,101) = 1;</p>\n<p>f(101, 101) = 1;</p>\n<p>f(51, 51) = 1;</p>\n<p>% H = hough(f);</p>\n<p>[H, theta, rho] = hough(f);</p>\n<p>imshow(H, [],’XData’, theta,’YData’, rho, ‘InitialMagnification’, ‘fit’)</p>\n<p>axis on, axis normal</p>\n<p>xlabel(‘\\theta’),ylabel(‘\\rho’)</p>\n<pre><code>结果:\n![](https://i.loli.net/2019/07/24/5d381e6cd3ce994397.jpg)\n观察图可以看打到三条曲线在+45度和-45度处的交点指出:f中有两组三个共线的点。两条曲线在$(\\rho,\\theta)$ = (0,-90)、(-100,-90)、(0,0)、(100,0)处的交点指出:有4组位于**垂直线**和**水平线**上的公共点\n\n#### houghpeaks函数\n寻找指定的峰值数    \n默认语法</code></pre><p>peaks = houghpeaks(H, NumPeaks)</p>\n<pre><code>H是霍夫变换矩阵\n\n#### houghlines函数\n决定线的起点和终点\n默认语法</code></pre><p>lines = houghlines(f, theta, rho, peaks)</p>\n<pre><code>输出lines是结构数组，长度等于找到的线段。结构中的每个元素可以看成一条线，并含有下列字段:    \n  1. point1:两元素向量[r1,c1]，指定了线段终点的行列坐标。\n  2. point2:两元素向量[r2,c2]，指定了线段其他终点的行列坐标。\n  3. theta:与线相关的霍夫变换的以度计量的角度。\n  4. rho:与线相关的霍夫变换的$\\rho$轴位置。\n#### MATLAB使用霍夫变换检测和连接线\n</code></pre><p>f = imread(‘timg1.jpg’);</p>\n<p>f = rgb2gray(f);</p>\n<p>BW = edge(f,’canny’);</p>\n<p>[H ,theta, rho] = hough(BW, ‘ThetaResolution’, 0.2);</p>\n<p>imshow(H, [],’XData’, theta,’YData’, rho, ‘InitialMagnification’, ‘fit’)</p>\n<p>axis on, axis normal</p>\n<p>xlabel(‘\\theta’),ylabel(‘\\rho’)</p>\n<p>peaks = houghpeaks(H, 5);</p>\n<p>hold on</p>\n<p>plot(theta(peaks( :, 2)), rho(peaks(:, 1)),…</p>\n<pre><code>&#39;linestyle&#39;, &#39;none&#39;, &#39;marker&#39;, &#39;s&#39;, &#39;color&#39;, &#39;w&#39;);</code></pre><p>lines = houghlines(f, theta, rho, peaks);</p>\n<p>figure, imshow(f), hold on</p>\n<p>for k = 1:length(lines)</p>\n<pre><code>xy = [lines(k).point1 ; lines(k).point2];\n\nplot(xy(:,1), xy(:,2), &#39;LineWidth&#39;, 4, &#39;color&#39;, &#39;red&#39;);</code></pre><p>end</p>\n<pre><code>结果:\n![](https://i.loli.net/2019/07/24/5d381d8d80bff63571.jpg)\n![](https://i.loli.net/2019/07/24/5d381de2778c421022.jpg)</code></pre>","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"图像分割\"><a href=\"#图像分割\" class=\"headerlink\" title=\"图像分割\"></a>图像分割</h1><h2 id=\"基本边缘检测\"><a href=\"#基本边缘检测\" class=\"headerlink\" title=\"基本边缘检测\"></a>基本边缘检测</h2><h3 id=\"边缘模型\"><a href=\"#边缘模型\" class=\"headerlink\" title=\"边缘模型\"></a>边缘模型</h3><ul>\n<li>台阶模型<br>在一个像素的距离上发生两次灰度级间理想的过渡</li>\n<li>斜坡模型<br>数字图像存在被模糊或有噪声的边缘，这时的边缘被建模成一个更接近灰度斜坡的剖面，斜坡的斜度与边缘的模糊程度成反比</li>\n<li>屋顶模型<br>通过一个区域的线的模型，屋顶边缘的基底(宽度)由该线的宽度和尖锐度决定<br><img src=\"https://i.loli.net/2019/07/24/5d382004cd3e437707.jpg\" alt></li>\n</ul>\n<p>结合前面提到的一阶导数和二阶导数的性质，可以得出结论:</p>\n<ol>\n<li>一阶导数的幅值可用于检测图像中的某个点处是否存在一个边缘</li>\n<li>二阶导数的符号可用于确定一个边缘像素位于该边缘的暗的一侧还是亮的一侧</li>\n<li>对图像的每个边缘，二阶导数生成两个值</li>\n<li>二阶导数的零交叉点可用于定位粗边缘的中心</li>\n</ol>\n<ul>\n<li>执行边缘检测的三个步骤:    <ol>\n<li>为降噪对图像进行平滑处理</li>\n<li>边缘点的检测</li>\n<li>边缘定位</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"梯度\"><a href=\"#梯度\" class=\"headerlink\" title=\"梯度\"></a>梯度</h3><ul>\n<li>二维函数f(x,y)的梯度定义为一个向量：<br>$$\\triangledown f = \\begin{bmatrix} g_x \\\\ g_y \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$<br>这个向量的幅值<br>$$\\triangledown f = mag(\\triangledown f)=[g_x^2+g_y^2]^{1/2}= [(\\partial f/\\partial x)^2+(\\partial f/\\partial y)^2]^{1/2}$$<br>为了简化计算，通常省略平方根或取绝对值<br>$$\\triangledown f = |g_x| + |g_y|$$<br>通常用梯度没的幅值或者近似值来简单作为’梯度’<br>梯度的性质是:梯度向量指向(x,y)坐标处f的最大变换率方向。最大变化率发生的角度是:<br>$$\\alpha (x,y) = tan^{-1}(\\frac{g_x}{g_y})$$</li>\n</ul>\n<h3 id=\"使用函数edge的边缘检测\"><a href=\"#使用函数edge的边缘检测\" class=\"headerlink\" title=\"使用函数edge的边缘检测\"></a>使用函数edge的边缘检测</h3><ul>\n<li>语法<pre><code>[g,t] = edge(f, &#39;method&#39;, parameters);</code></pre>f是输入图像，method是边缘检测方法，parameters是附加参数<h3 id=\"边缘检测算子\"><a href=\"#边缘检测算子\" class=\"headerlink\" title=\"边缘检测算子\"></a>边缘检测算子</h3>图像邻域如下图所示:</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">$z_1$</th>\n<th align=\"center\">$z_2$</th>\n<th align=\"center\">$z_3$</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$z_4$</td>\n<td align=\"center\">$z_5$</td>\n<td align=\"center\">$z_6$</td>\n</tr>\n<tr>\n<td align=\"center\">$z_7$</td>\n<td align=\"center\">$z_8$</td>\n<td align=\"center\">$z_9$</td>\n</tr>\n</tbody></table>\n<h4 id=\"Sobel边缘检测算子\"><a href=\"#Sobel边缘检测算子\" class=\"headerlink\" title=\"Sobel边缘检测算子\"></a>Sobel边缘检测算子</h4><ul>\n<li>Sobel边缘检测算子模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-2</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_x=(z_7+2z_8+z_9)-(z_1+2z_2+z_3)$$</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">0</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-2</td>\n<td align=\"center\">0</td>\n<td align=\"center\">2</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_y = (z_3+2z_6+z_9)-(z_1+2z_4+z_7)$$<br>每一行和每一列的中心像素用2来加权以提供平滑</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;sobel&#39;, T, dir);</code></pre>f是输入的图像，T是指定的阀值，dir是指定的检测边缘的首选方向:’horizontal’,’vertical’,’both’(默认值)<br>t是可选的，T未指定，则t自动设置</li>\n</ul>\n<h4 id=\"Prewitt边缘检测算子\"><a href=\"#Prewitt边缘检测算子\" class=\"headerlink\" title=\"Prewitt边缘检测算子\"></a>Prewitt边缘检测算子</h4><ul>\n<li>Prewitt边缘检测算子模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n<th align=\"center\">-1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_x = (z_7 + z_8 + z_9)-(z_1 + z_2 + z_3)$$</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">0</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">-1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$$</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;prewitt&#39;, T ,dir);</code></pre>计算简单，但容易产生噪声</li>\n</ul>\n<h4 id=\"Roberts边缘检测算子\"><a href=\"#Roberts边缘检测算子\" class=\"headerlink\" title=\"Roberts边缘检测算子\"></a>Roberts边缘检测算子</h4><ul>\n<li>Roberts边缘检测算子模板</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">-1</th>\n<th align=\"center\">0</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<p>$$g_x = z_9 - z_5$$</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">0</th>\n<th align=\"center\">1</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n</tbody></table>\n<p>$$g_y = z_8 - z_6$$</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;roberts&#39;, T , dir);</code></pre><h4 id=\"LoG检测算子\"><a href=\"#LoG检测算子\" class=\"headerlink\" title=\"LoG检测算子\"></a>LoG检测算子</h4></li>\n<li>LoG</li>\n</ul>\n<p>考虑高斯函数<br>$$G(x,y) = e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}$$<br>$\\sigma$是标准差。这是平滑函数，如果和图像卷积，会使图像变模糊，模糊程度由$\\sigma$决定<br>这个函数的Laplace算法是:<br>$$\\triangledown^2G(x,y) = \\frac{\\partial ^2 G(x,y)}{\\partial x^2}+\\frac{\\partial ^2 G(x,y)}{\\partial y^2} = [\\frac{x^2 + y^2-2\\sigma ^2}{\\sigma ^4}]^{e^{-\\frac{x^2 + y^2}{2\\sigma ^2}}}$$</p>\n<p>用$\\triangledown ^2G(x,y)$卷积(滤波)这幅图像与先用平滑函数对图像卷积，再对结果进行Laplace变换的结果是一样的<br>用$\\triangledown ^2G(x,y)$卷积图像，可以得到两个效果:平滑图像(因而减少了噪声);计算Laplace，从而产生双边缘图像，然后在双边缘之间定位由发现的零交叉组成的边缘</p>\n<ul>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;log&#39;, T , sigma);</code></pre>sigma默认值是2</li>\n</ul>\n<h4 id=\"零交叉检测算子\"><a href=\"#零交叉检测算子\" class=\"headerlink\" title=\"零交叉检测算子\"></a>零交叉检测算子</h4><ul>\n<li>基于LoG，卷积使用特殊的滤波函数H来完成</li>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;zerocross&#39;, T , H);</code></pre><h4 id=\"Canny检测算子\"><a href=\"#Canny检测算子\" class=\"headerlink\" title=\"Canny检测算子\"></a>Canny检测算子</h4></li>\n<li>edge函数中最强的边缘检测算子</li>\n<li>MATLAB语法<pre><code>[g, t] = edge(f, &#39;canny&#39;, T , sigma);</code></pre><h3 id=\"MATLAB实现\"><a href=\"#MATLAB实现\" class=\"headerlink\" title=\"MATLAB实现\"></a>MATLAB实现</h3></li>\n<li>几种边缘检测算法的比较(Sobel,LoG,Canny)<pre><code>f = imread(&#39;timg1.jpg&#39;);\nimshow(f),title(&#39;currect image&#39;);\nf = rgb2gray(f);\n%Default Output\n[gSobel_default,ts] = edge(f, &#39;sobel&#39;);\n[gLoG_default, tlog] = edge(f, &#39;log&#39;);\n[gCanny_default, tc] = edge(f,&#39;canny&#39;);\n</code></pre></li>\n</ul>\n<p>%Best Output</p>\n<p>gSobel_best = edge(f,’sobel’,0.165);<br>gLoG_best = edge(f,’log’,0.008, 2.25);<br>gCanny_best = edge(f,’canny’,[0.05, 0.4], 1.5);</p>\n<p>figure,imshow(f),title(‘Gary images’);<br>figure,imshow(gSobel_default),title(‘gSobel default’);<br>figure,imshow(gSobel_best),title(‘gSobel best’);<br>figure,imshow(gLoG_default),title(‘gLoG default’);<br>figure,imshow(gLoG_best),title(‘gLoG best’);<br>figure,imshow(gCanny_default),title(‘gCanny default’);<br>figure,imshow(gCanny_best),title(‘gCanny best’);</p>\n<pre><code>其中最佳输出的阀值是根据得到的ts,tlog,tc的值来确定的\n结果:\n![](https://i.loli.net/2019/07/24/5d37d6b4bec1777947.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b5886d994031.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3ad9b270352.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b573bae72055.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b61724d14715.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b51df2874618.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b65663011930.jpg)\n![](https://i.loli.net/2019/07/24/5d37d6b3e566366232.jpg)\n综合结果来看，Canny边缘检测算子可以得到最好的结果\n\n## 霍夫变换\n### 介绍与应用场景\n\n[霍夫变换](https://zh.wikipedia.org/wiki/%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2)(Hough Transform)是图像处理中的一种特征提取技术，该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。经典霍夫变换用来检测图像中的直线，后来霍夫变换扩展到任意形状物体的识别，多为圆和椭圆。霍夫变换运用两个坐标空间之间的变换将在一个空间中具有相同形状的曲线或直线映射到另一个坐标空间的一个点上形成峰值，从而把检测任意形状的问题转化为统计峰值问题。\n\n### 基本原理\n考虑点$(x_i,y_i)$及通过这个点的线,有无穷多的线通过点$(x_i,y_i)$，针对a和b的一些值，满足斜截式$y_i = ax_i + b$的所有线都通过该点。该公式也可以写为$b = -ax_i + y_i$，考虑ab平面(即**参数空间**)对固定点$(x_i,y_i)$得到一条线的方程。另外，第二个点$(x_j,y_j)$也有一条在参数空间中与之相关的线，这条线和与$(x_i,y_i)$**相关**的线交于点$(a&#39;,b&#39;)$，其中$a&#39;$是斜率，$b&#39;$是在**xy平面**上包含点$(x_i,y_i)$和$(x_j,y_j)$的线的截距。在**参数空间**中，这条线包含的所有点都有相交于$(a&#39;,b&#39;)$点的直线。    \n简单理解，直线由两个点$A(x_1,y_1)$和$B(x_2,y_2)$定义，在参数空间中，两条直线的唯一公共点是在原图像空间中表示连接点A和B的唯一存在的直线\n![](https://i.loli.net/2019/07/24/5d38129f0e9f156720.jpg)\n因此，给定很多点，判断这些点是否共线的问题，经由霍夫变换之后，变成判断一堆曲线(每一个点在$(r, \\theta)$平面上代表一条曲线)是否 在 $(r,\\theta)$平面上相交于同一点的问题\n另外用法线表示法:\n$$xcos\\theta + ysin\\theta = \\rho$$\n水平线的$\\theta$=0,$\\rho$等于正的x的截距，垂直线的$\\theta=90$度，$\\rho$等于正的y的截距\n![](https://i.loli.net/2019/07/24/5d382004e2bab23873.jpg)\n\n在坐标(i, j)的单元位置，累加器的值是 A(i, j)，对应于参数空间坐标$(\\rho_i,\\theta_j)$的正方形。最初， 这些单元位置为零。然后，对于每个图像平面上的非背景点$(x_k,y_k)$(就是 xy 平面)，我们令 θ 等 于在 θ 轴上允许的细分值，并通过公式$\\rho = x_kcos\\theta+y_ksin\\theta$解出相应的 ρ 值。然后，得到的 ρ 值四 舍五入为最接近的 ρ 轴上允许的单元值。相应的累加器单元增加一个增量。在这个过程的最后， 累加单元 A(i, j)中的值 Q 就意味着 xy 平面上位于线$xcos\\theta_j+ysin\\theta_j = \\rho_i$上的点有 Q 个。在$\\rho\\theta$平面上，细分的数目决定了这些点的共线的精确度。累加器数组在工具箱中叫做霍夫变换矩阵，简称霍夫变换。\n\n### MATLAB工具箱函数\n#### hough函数\n默认语法</code></pre><p>[H, theta, rho] = hough(f)</p>\n<pre><code>H是霍夫变换矩阵，theta和rho是$\\theta$和$\\rho$的值    \n下面这个例子可以加深对霍夫变换的理解</code></pre><p>f = zeros(101,101);</p>\n<p>f(1,1) = 1;</p>\n<p>f(101,1) = 1;</p>\n<p>f(1,101) = 1;</p>\n<p>f(101, 101) = 1;</p>\n<p>f(51, 51) = 1;</p>\n<p>% H = hough(f);</p>\n<p>[H, theta, rho] = hough(f);</p>\n<p>imshow(H, [],’XData’, theta,’YData’, rho, ‘InitialMagnification’, ‘fit’)</p>\n<p>axis on, axis normal</p>\n<p>xlabel(‘\\theta’),ylabel(‘\\rho’)</p>\n<pre><code>结果:\n![](https://i.loli.net/2019/07/24/5d381e6cd3ce994397.jpg)\n观察图可以看打到三条曲线在+45度和-45度处的交点指出:f中有两组三个共线的点。两条曲线在$(\\rho,\\theta)$ = (0,-90)、(-100,-90)、(0,0)、(100,0)处的交点指出:有4组位于**垂直线**和**水平线**上的公共点\n\n#### houghpeaks函数\n寻找指定的峰值数    \n默认语法</code></pre><p>peaks = houghpeaks(H, NumPeaks)</p>\n<pre><code>H是霍夫变换矩阵\n\n#### houghlines函数\n决定线的起点和终点\n默认语法</code></pre><p>lines = houghlines(f, theta, rho, peaks)</p>\n<pre><code>输出lines是结构数组，长度等于找到的线段。结构中的每个元素可以看成一条线，并含有下列字段:    \n  1. point1:两元素向量[r1,c1]，指定了线段终点的行列坐标。\n  2. point2:两元素向量[r2,c2]，指定了线段其他终点的行列坐标。\n  3. theta:与线相关的霍夫变换的以度计量的角度。\n  4. rho:与线相关的霍夫变换的$\\rho$轴位置。\n#### MATLAB使用霍夫变换检测和连接线\n</code></pre><p>f = imread(‘timg1.jpg’);</p>\n<p>f = rgb2gray(f);</p>\n<p>BW = edge(f,’canny’);</p>\n<p>[H ,theta, rho] = hough(BW, ‘ThetaResolution’, 0.2);</p>\n<p>imshow(H, [],’XData’, theta,’YData’, rho, ‘InitialMagnification’, ‘fit’)</p>\n<p>axis on, axis normal</p>\n<p>xlabel(‘\\theta’),ylabel(‘\\rho’)</p>\n<p>peaks = houghpeaks(H, 5);</p>\n<p>hold on</p>\n<p>plot(theta(peaks( :, 2)), rho(peaks(:, 1)),…</p>\n<pre><code>&#39;linestyle&#39;, &#39;none&#39;, &#39;marker&#39;, &#39;s&#39;, &#39;color&#39;, &#39;w&#39;);</code></pre><p>lines = houghlines(f, theta, rho, peaks);</p>\n<p>figure, imshow(f), hold on</p>\n<p>for k = 1:length(lines)</p>\n<pre><code>xy = [lines(k).point1 ; lines(k).point2];\n\nplot(xy(:,1), xy(:,2), &#39;LineWidth&#39;, 4, &#39;color&#39;, &#39;red&#39;);</code></pre><p>end</p>\n<pre><code>结果:\n![](https://i.loli.net/2019/07/24/5d381d8d80bff63571.jpg)\n![](https://i.loli.net/2019/07/24/5d381de2778c421022.jpg)</code></pre>"},{"title":"Day18","date":"2019-08-01T08:50:05.000Z","cover":false,"img":"https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png","_content":"# LBP算法实现及人脸检测\n\n## OpenCV模块\n- core：简洁核心模块，基本函数，基本数据结构\n- imgproc：图像处理模块，线性和非线性图像滤波，几何图像转换，颜色空间转换，直方图等。\n- video：视频分析模块，运动估计，背景消除，物体跟踪算法\n- calib3d：基本多视角几何算法，单体和立体相机的标定，对象姿势估计，双目立体匹配算法和元素的三维重建\n- features2d：包含了显著特征检测算法，描述算子和算子匹配算法\n- objdetect：物体检测和一些预定义的物体的检测（如人脸，眼睛，杯子，人，汽车等)\n- ml：多种机器学习算法，如K均值，支持向量机和神经网络\n- highgui：简单易用接口，有视频捕捉，图像和视频编码功能，简单UI接口，iOS的是其中一个子集\n- gpu：GPU加速算法，iOS不可用\n- ocl：OpenCL通用算法，iOS不可用\n- 其它辅助模块，如用户贡献的算法\n\n## 原始LBP特征\n``` c++\n//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i < img.rows - 1; i++){\n    for (int j = 1; j < img.cols -1; j++){\n      uchar center = img.at<uchar>(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at<uchar>(i - 1, j - 1) >= center) << 7;\n      lbpcode |= (img.at<uchar>(i - 1, j) >= center) << 6;\n      lbpcode |= (img.at<uchar>(i - 1, j + 1) >= center) << 5;\n      lbpcode |= (img.at<uchar>(i, j -1) >= center) << 4;\n      lbpcode |= (img.at<uchar>(i, j + 1) >= center) << 3;\n      lbpcode |= (img.at<uchar>(i + 1, j - 1) >= center) << 2;\n      lbpcode |= (img.at<uchar>(i + 1, j) >= center) << 1;\n      lbpcode |= (img.at<uchar>(i + 1, j + 1) >= center) << 0;\n      result.at<uchar>(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}\n```\n![](https://i.loli.net/2019/07/31/5d4161dac5f0b23887.png)\n\n\n## 圆形LBP特征\n\n``` c++\n//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i<img.rows-radius;i++)\n  {\n      for(int j=radius;j<img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at<uchar>(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k<neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast<float>(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast<float>(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast<int>(floor(x));\n                int x2 = static_cast<int>(ceil(x));\n                int y1 = static_cast<int>(floor(y));\n                int y2 = static_cast<int>(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(x1,y1) * w1 + img.at<uchar>(x1,y2) *w2 + img.at<uchar>(x2,y1) * w3 +img.at<uchar>(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor>center) <<(neighbors-k-1);\n            }\n            result.at<uchar>(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}\n```\n结果:\n![](https://i.loli.net/2019/08/01/5d42b5d2e345026549.png)\n\n第一幅图设置半径为4,第二幅图设置半径为1,可以看到半径越小处理的越精细。\n\n## 旋转不变LBP特征\n\n``` c++\n//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k<neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast<int>(floor(rx));\n        int x2 = static_cast<int>(ceil(rx));\n        int y1 = static_cast<int>(floor(ry));\n        int y2 = static_cast<int>(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i<img.rows-radius;i++)\n        {\n            for(int j=radius;j<img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at<uchar>(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(i+x1,j+y1) * w1 + img.at<uchar>(i+x1,j+y2) *w2 + img.at<uchar>(i+x2,j+y1) * w3 +img.at<uchar>(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i<result.rows;i++)\n    {\n        for(int j=0;j<result.cols;j++)\n        {\n            uchar currentValue = result.at<uchar>(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k<neighbors;k++)\t\t//循环左移\n            {\n                uchar temp = (currentValue>>(neighbors-k)) | (currentValue<<k);\n                if(temp < minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at<uchar>(i,j) = minValue;\n        }\n    }\n    return result;\n}\n\n```\n结果:\n![](https://i.loli.net/2019/08/01/5d42b5d30749958722.png)\n\n第一幅图neighbors值设置为8,第二幅设置为6,可以看出neighbors值越大，得到的LBP特征亮度越高。\n\n## 完整代码如下\n``` c++\n#include <opencv2/highgui/highgui.hpp>\n\nusing namespace cv;\n\n//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i < img.rows - 1; i++){\n    for (int j = 1; j < img.cols -1; j++){\n      uchar center = img.at<uchar>(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at<uchar>(i - 1, j - 1) >= center) << 7;\n      lbpcode |= (img.at<uchar>(i - 1, j) >= center) << 6;\n      lbpcode |= (img.at<uchar>(i - 1, j + 1) >= center) << 5;\n      lbpcode |= (img.at<uchar>(i, j -1) >= center) << 4;\n      lbpcode |= (img.at<uchar>(i, j + 1) >= center) << 3;\n      lbpcode |= (img.at<uchar>(i + 1, j - 1) >= center) << 2;\n      lbpcode |= (img.at<uchar>(i + 1, j) >= center) << 1;\n      lbpcode |= (img.at<uchar>(i + 1, j + 1) >= center) << 0;\n      result.at<uchar>(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}\n\n//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i<img.rows-radius;i++)\n  {\n      for(int j=radius;j<img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at<uchar>(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k<neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast<float>(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast<float>(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast<int>(floor(x));\n                int x2 = static_cast<int>(ceil(x));\n                int y1 = static_cast<int>(floor(y));\n                int y2 = static_cast<int>(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(x1,y1) * w1 + img.at<uchar>(x1,y2) *w2 + img.at<uchar>(x2,y1) * w3 +img.at<uchar>(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor>center) <<(neighbors-k-1);\n            }\n            result.at<uchar>(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}\n\n//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k<neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast<int>(floor(rx));\n        int x2 = static_cast<int>(ceil(rx));\n        int y1 = static_cast<int>(floor(ry));\n        int y2 = static_cast<int>(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i<img.rows-radius;i++)\n        {\n            for(int j=radius;j<img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at<uchar>(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(i+x1,j+y1) * w1 + img.at<uchar>(i+x1,j+y2) *w2 + img.at<uchar>(i+x2,j+y1) * w3 +img.at<uchar>(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i<result.rows;i++)\n    {\n        for(int j=0;j<result.cols;j++)\n        {\n            uchar currentValue = result.at<uchar>(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k<neighbors;k++)\t\t//循环左移\n            {\n                uchar temp = (currentValue>>(neighbors-k)) | (currentValue<<k);\n                if(temp < minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at<uchar>(i,j) = minValue;\n        }\n    }\n    return result;\n}\n\nint main(int argc, char* argv[])\n{\n  Mat src = imread(argv[1], 0);\n  Mat dst = get_original_LBP_feature(src);\n  Mat odst1 = get_circular_LBP_feature(src, 1, 8);\n  //Mat odst4 = get_circular_LBP_feature(src, 4, 8);\n  Mat rif8 = get_rotation_invariant_LBP_feature(src, 1, 8);\n  Mat rif6 = get_rotation_invariant_LBP_feature(src, 1, 6);\n\n\n  imshow(\"原始图片\", src);\n  imshow(\"原始LBP\", dst);\n  imshow(\"圆形LBP\", odst1);\n  //imshow(\"圆形LBP4\", odst4);\n  imshow(\"旋转不变LBP\", rif8);\n  //imshow(\"旋转不变LBP6\", rif6);\n\n  waitKey(0);\n  return 0;\n}\n```\n## 人脸检测\n\n在OpenCV中，主要使用两种特征进行人脸检测，Haar特征和LBP特征，下面使用的是LBP特征。    \n实现人脸检测主要依赖于detectMultiScale()函数\n``` c++\nCV_WRAP virtual void detectMultiScale\n( const Mat& image,\n  CV_OUT vector<Rect>& objects,\n  double scaleFactor=1.1,\n  int minNeighbors=3, int flags=0,\n  Size minSize=Size(),\n  Size maxSize=Size() );\n```\n各参数含义如下：\n**const Mat& image**: 需要被检测的图像（灰度图）。\n**vector<Rect>& objects**: 保存被检测出的人脸位置坐标序列。\n**double scaleFactor**: 每次图片缩放的比例。\n**int minNeighbors**: 每一个人脸至少要检测到多少次才算是真的人脸。\n**doubleint flags**： 决定是缩放分类器来检测，还是缩放图像。\n**Size()**: 表示人脸的最大最小尺寸。\n\n具体实现代码如下:\n``` c++\n#include<opencv2/highgui/highgui.hpp>\n#include<opencv2/imgproc/imgproc.hpp>\n#include<opencv2/objdetect/objdetect.hpp>\n#include<iostream>\n#include<opencv2/core.hpp>\n \n\nusing namespace std;\nusing namespace cv;\n \n#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)\nCascadeClassifier faceCascade;\nint main(int argc, char* argv[])\n{\n Mat img;\n\n CascadeClassifier faceDetector(\"lbpcascade_frontalface.xml\");//读取分类器\n img = imread(argv[1]);  //读取检测的图片原图\n vector<Rect> objects;  //存放检测的对象\n faceDetector.detectMultiScale(img, objects);  //执行检测\n for (int i = 0; i < objects.size(); i++) //遍历检测到的脸\n {\n  rectangle(img, objects[i], CV_COLOR_RED);  //画出检测到的脸\n }\n imshow(\"result\", img);  //显示结果\n waitKey(0);\n\n return 0;\n}\n```\n检测结果:\n![](https://i.loli.net/2019/08/01/5d42b5d26727057681.png)\n![](https://i.loli.net/2019/08/01/5d42b5d26fea564434.png)\n![](https://i.loli.net/2019/08/01/5d42b5d2b360c81753.png)\n","source":"_posts/Day18.md","raw":"---\ntitle: Day18\ndate: 2019-08-01 16:50:05\ntags: 实习\ncategories: \n  - OpenCV \n  - C++\ncover: false\nimg: https://i.loli.net/2019/07/17/5d2e73bb14bd344648.png\n---\n# LBP算法实现及人脸检测\n\n## OpenCV模块\n- core：简洁核心模块，基本函数，基本数据结构\n- imgproc：图像处理模块，线性和非线性图像滤波，几何图像转换，颜色空间转换，直方图等。\n- video：视频分析模块，运动估计，背景消除，物体跟踪算法\n- calib3d：基本多视角几何算法，单体和立体相机的标定，对象姿势估计，双目立体匹配算法和元素的三维重建\n- features2d：包含了显著特征检测算法，描述算子和算子匹配算法\n- objdetect：物体检测和一些预定义的物体的检测（如人脸，眼睛，杯子，人，汽车等)\n- ml：多种机器学习算法，如K均值，支持向量机和神经网络\n- highgui：简单易用接口，有视频捕捉，图像和视频编码功能，简单UI接口，iOS的是其中一个子集\n- gpu：GPU加速算法，iOS不可用\n- ocl：OpenCL通用算法，iOS不可用\n- 其它辅助模块，如用户贡献的算法\n\n## 原始LBP特征\n``` c++\n//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i < img.rows - 1; i++){\n    for (int j = 1; j < img.cols -1; j++){\n      uchar center = img.at<uchar>(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at<uchar>(i - 1, j - 1) >= center) << 7;\n      lbpcode |= (img.at<uchar>(i - 1, j) >= center) << 6;\n      lbpcode |= (img.at<uchar>(i - 1, j + 1) >= center) << 5;\n      lbpcode |= (img.at<uchar>(i, j -1) >= center) << 4;\n      lbpcode |= (img.at<uchar>(i, j + 1) >= center) << 3;\n      lbpcode |= (img.at<uchar>(i + 1, j - 1) >= center) << 2;\n      lbpcode |= (img.at<uchar>(i + 1, j) >= center) << 1;\n      lbpcode |= (img.at<uchar>(i + 1, j + 1) >= center) << 0;\n      result.at<uchar>(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}\n```\n![](https://i.loli.net/2019/07/31/5d4161dac5f0b23887.png)\n\n\n## 圆形LBP特征\n\n``` c++\n//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i<img.rows-radius;i++)\n  {\n      for(int j=radius;j<img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at<uchar>(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k<neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast<float>(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast<float>(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast<int>(floor(x));\n                int x2 = static_cast<int>(ceil(x));\n                int y1 = static_cast<int>(floor(y));\n                int y2 = static_cast<int>(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(x1,y1) * w1 + img.at<uchar>(x1,y2) *w2 + img.at<uchar>(x2,y1) * w3 +img.at<uchar>(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor>center) <<(neighbors-k-1);\n            }\n            result.at<uchar>(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}\n```\n结果:\n![](https://i.loli.net/2019/08/01/5d42b5d2e345026549.png)\n\n第一幅图设置半径为4,第二幅图设置半径为1,可以看到半径越小处理的越精细。\n\n## 旋转不变LBP特征\n\n``` c++\n//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k<neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast<int>(floor(rx));\n        int x2 = static_cast<int>(ceil(rx));\n        int y1 = static_cast<int>(floor(ry));\n        int y2 = static_cast<int>(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i<img.rows-radius;i++)\n        {\n            for(int j=radius;j<img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at<uchar>(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(i+x1,j+y1) * w1 + img.at<uchar>(i+x1,j+y2) *w2 + img.at<uchar>(i+x2,j+y1) * w3 +img.at<uchar>(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i<result.rows;i++)\n    {\n        for(int j=0;j<result.cols;j++)\n        {\n            uchar currentValue = result.at<uchar>(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k<neighbors;k++)\t\t//循环左移\n            {\n                uchar temp = (currentValue>>(neighbors-k)) | (currentValue<<k);\n                if(temp < minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at<uchar>(i,j) = minValue;\n        }\n    }\n    return result;\n}\n\n```\n结果:\n![](https://i.loli.net/2019/08/01/5d42b5d30749958722.png)\n\n第一幅图neighbors值设置为8,第二幅设置为6,可以看出neighbors值越大，得到的LBP特征亮度越高。\n\n## 完整代码如下\n``` c++\n#include <opencv2/highgui/highgui.hpp>\n\nusing namespace cv;\n\n//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i < img.rows - 1; i++){\n    for (int j = 1; j < img.cols -1; j++){\n      uchar center = img.at<uchar>(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at<uchar>(i - 1, j - 1) >= center) << 7;\n      lbpcode |= (img.at<uchar>(i - 1, j) >= center) << 6;\n      lbpcode |= (img.at<uchar>(i - 1, j + 1) >= center) << 5;\n      lbpcode |= (img.at<uchar>(i, j -1) >= center) << 4;\n      lbpcode |= (img.at<uchar>(i, j + 1) >= center) << 3;\n      lbpcode |= (img.at<uchar>(i + 1, j - 1) >= center) << 2;\n      lbpcode |= (img.at<uchar>(i + 1, j) >= center) << 1;\n      lbpcode |= (img.at<uchar>(i + 1, j + 1) >= center) << 0;\n      result.at<uchar>(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}\n\n//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i<img.rows-radius;i++)\n  {\n      for(int j=radius;j<img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at<uchar>(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k<neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast<float>(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast<float>(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast<int>(floor(x));\n                int x2 = static_cast<int>(ceil(x));\n                int y1 = static_cast<int>(floor(y));\n                int y2 = static_cast<int>(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(x1,y1) * w1 + img.at<uchar>(x1,y2) *w2 + img.at<uchar>(x2,y1) * w3 +img.at<uchar>(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor>center) <<(neighbors-k-1);\n            }\n            result.at<uchar>(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}\n\n//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k<neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast<int>(floor(rx));\n        int x2 = static_cast<int>(ceil(rx));\n        int y1 = static_cast<int>(floor(ry));\n        int y2 = static_cast<int>(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i<img.rows-radius;i++)\n        {\n            for(int j=radius;j<img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at<uchar>(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(i+x1,j+y1) * w1 + img.at<uchar>(i+x1,j+y2) *w2 + img.at<uchar>(i+x2,j+y1) * w3 +img.at<uchar>(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i<result.rows;i++)\n    {\n        for(int j=0;j<result.cols;j++)\n        {\n            uchar currentValue = result.at<uchar>(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k<neighbors;k++)\t\t//循环左移\n            {\n                uchar temp = (currentValue>>(neighbors-k)) | (currentValue<<k);\n                if(temp < minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at<uchar>(i,j) = minValue;\n        }\n    }\n    return result;\n}\n\nint main(int argc, char* argv[])\n{\n  Mat src = imread(argv[1], 0);\n  Mat dst = get_original_LBP_feature(src);\n  Mat odst1 = get_circular_LBP_feature(src, 1, 8);\n  //Mat odst4 = get_circular_LBP_feature(src, 4, 8);\n  Mat rif8 = get_rotation_invariant_LBP_feature(src, 1, 8);\n  Mat rif6 = get_rotation_invariant_LBP_feature(src, 1, 6);\n\n\n  imshow(\"原始图片\", src);\n  imshow(\"原始LBP\", dst);\n  imshow(\"圆形LBP\", odst1);\n  //imshow(\"圆形LBP4\", odst4);\n  imshow(\"旋转不变LBP\", rif8);\n  //imshow(\"旋转不变LBP6\", rif6);\n\n  waitKey(0);\n  return 0;\n}\n```\n## 人脸检测\n\n在OpenCV中，主要使用两种特征进行人脸检测，Haar特征和LBP特征，下面使用的是LBP特征。    \n实现人脸检测主要依赖于detectMultiScale()函数\n``` c++\nCV_WRAP virtual void detectMultiScale\n( const Mat& image,\n  CV_OUT vector<Rect>& objects,\n  double scaleFactor=1.1,\n  int minNeighbors=3, int flags=0,\n  Size minSize=Size(),\n  Size maxSize=Size() );\n```\n各参数含义如下：\n**const Mat& image**: 需要被检测的图像（灰度图）。\n**vector<Rect>& objects**: 保存被检测出的人脸位置坐标序列。\n**double scaleFactor**: 每次图片缩放的比例。\n**int minNeighbors**: 每一个人脸至少要检测到多少次才算是真的人脸。\n**doubleint flags**： 决定是缩放分类器来检测，还是缩放图像。\n**Size()**: 表示人脸的最大最小尺寸。\n\n具体实现代码如下:\n``` c++\n#include<opencv2/highgui/highgui.hpp>\n#include<opencv2/imgproc/imgproc.hpp>\n#include<opencv2/objdetect/objdetect.hpp>\n#include<iostream>\n#include<opencv2/core.hpp>\n \n\nusing namespace std;\nusing namespace cv;\n \n#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)\nCascadeClassifier faceCascade;\nint main(int argc, char* argv[])\n{\n Mat img;\n\n CascadeClassifier faceDetector(\"lbpcascade_frontalface.xml\");//读取分类器\n img = imread(argv[1]);  //读取检测的图片原图\n vector<Rect> objects;  //存放检测的对象\n faceDetector.detectMultiScale(img, objects);  //执行检测\n for (int i = 0; i < objects.size(); i++) //遍历检测到的脸\n {\n  rectangle(img, objects[i], CV_COLOR_RED);  //画出检测到的脸\n }\n imshow(\"result\", img);  //显示结果\n waitKey(0);\n\n return 0;\n}\n```\n检测结果:\n![](https://i.loli.net/2019/08/01/5d42b5d26727057681.png)\n![](https://i.loli.net/2019/08/01/5d42b5d26fea564434.png)\n![](https://i.loli.net/2019/08/01/5d42b5d2b360c81753.png)\n","slug":"Day18","published":1,"updated":"2019-08-10T10:47:34.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltw001me5g6c1arh6zw","content":"<h1 id=\"LBP算法实现及人脸检测\"><a href=\"#LBP算法实现及人脸检测\" class=\"headerlink\" title=\"LBP算法实现及人脸检测\"></a>LBP算法实现及人脸检测</h1><h2 id=\"OpenCV模块\"><a href=\"#OpenCV模块\" class=\"headerlink\" title=\"OpenCV模块\"></a>OpenCV模块</h2><ul>\n<li>core：简洁核心模块，基本函数，基本数据结构</li>\n<li>imgproc：图像处理模块，线性和非线性图像滤波，几何图像转换，颜色空间转换，直方图等。</li>\n<li>video：视频分析模块，运动估计，背景消除，物体跟踪算法</li>\n<li>calib3d：基本多视角几何算法，单体和立体相机的标定，对象姿势估计，双目立体匹配算法和元素的三维重建</li>\n<li>features2d：包含了显著特征检测算法，描述算子和算子匹配算法</li>\n<li>objdetect：物体检测和一些预定义的物体的检测（如人脸，眼睛，杯子，人，汽车等)</li>\n<li>ml：多种机器学习算法，如K均值，支持向量机和神经网络</li>\n<li>highgui：简单易用接口，有视频捕捉，图像和视频编码功能，简单UI接口，iOS的是其中一个子集</li>\n<li>gpu：GPU加速算法，iOS不可用</li>\n<li>ocl：OpenCL通用算法，iOS不可用</li>\n<li>其它辅助模块，如用户贡献的算法</li>\n</ul>\n<h2 id=\"原始LBP特征\"><a href=\"#原始LBP特征\" class=\"headerlink\" title=\"原始LBP特征\"></a>原始LBP特征</h2><pre class=\" language-c++\"><code class=\"language-c++\">//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i < img.rows - 1; i++){\n    for (int j = 1; j < img.cols -1; j++){\n      uchar center = img.at<uchar>(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at<uchar>(i - 1, j - 1) >= center) << 7;\n      lbpcode |= (img.at<uchar>(i - 1, j) >= center) << 6;\n      lbpcode |= (img.at<uchar>(i - 1, j + 1) >= center) << 5;\n      lbpcode |= (img.at<uchar>(i, j -1) >= center) << 4;\n      lbpcode |= (img.at<uchar>(i, j + 1) >= center) << 3;\n      lbpcode |= (img.at<uchar>(i + 1, j - 1) >= center) << 2;\n      lbpcode |= (img.at<uchar>(i + 1, j) >= center) << 1;\n      lbpcode |= (img.at<uchar>(i + 1, j + 1) >= center) << 0;\n      result.at<uchar>(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}</code></pre>\n<p><img src=\"https://i.loli.net/2019/07/31/5d4161dac5f0b23887.png\" alt></p>\n<h2 id=\"圆形LBP特征\"><a href=\"#圆形LBP特征\" class=\"headerlink\" title=\"圆形LBP特征\"></a>圆形LBP特征</h2><pre class=\" language-c++\"><code class=\"language-c++\">//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i<img.rows-radius;i++)\n  {\n      for(int j=radius;j<img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at<uchar>(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k<neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast<float>(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast<float>(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast<int>(floor(x));\n                int x2 = static_cast<int>(ceil(x));\n                int y1 = static_cast<int>(floor(y));\n                int y2 = static_cast<int>(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(x1,y1) * w1 + img.at<uchar>(x1,y2) *w2 + img.at<uchar>(x2,y1) * w3 +img.at<uchar>(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor>center) <<(neighbors-k-1);\n            }\n            result.at<uchar>(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}</code></pre>\n<p>结果:<br><img src=\"https://i.loli.net/2019/08/01/5d42b5d2e345026549.png\" alt></p>\n<p>第一幅图设置半径为4,第二幅图设置半径为1,可以看到半径越小处理的越精细。</p>\n<h2 id=\"旋转不变LBP特征\"><a href=\"#旋转不变LBP特征\" class=\"headerlink\" title=\"旋转不变LBP特征\"></a>旋转不变LBP特征</h2><pre class=\" language-c++\"><code class=\"language-c++\">//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k<neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast<int>(floor(rx));\n        int x2 = static_cast<int>(ceil(rx));\n        int y1 = static_cast<int>(floor(ry));\n        int y2 = static_cast<int>(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i<img.rows-radius;i++)\n        {\n            for(int j=radius;j<img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at<uchar>(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(i+x1,j+y1) * w1 + img.at<uchar>(i+x1,j+y2) *w2 + img.at<uchar>(i+x2,j+y1) * w3 +img.at<uchar>(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i<result.rows;i++)\n    {\n        for(int j=0;j<result.cols;j++)\n        {\n            uchar currentValue = result.at<uchar>(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k<neighbors;k++)        //循环左移\n            {\n                uchar temp = (currentValue>>(neighbors-k)) | (currentValue<<k);\n                if(temp < minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at<uchar>(i,j) = minValue;\n        }\n    }\n    return result;\n}\n</code></pre>\n<p>结果:<br><img src=\"https://i.loli.net/2019/08/01/5d42b5d30749958722.png\" alt></p>\n<p>第一幅图neighbors值设置为8,第二幅设置为6,可以看出neighbors值越大，得到的LBP特征亮度越高。</p>\n<h2 id=\"完整代码如下\"><a href=\"#完整代码如下\" class=\"headerlink\" title=\"完整代码如下\"></a>完整代码如下</h2><pre class=\" language-c++\"><code class=\"language-c++\">#include <opencv2/highgui/highgui.hpp>\n\nusing namespace cv;\n\n//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i < img.rows - 1; i++){\n    for (int j = 1; j < img.cols -1; j++){\n      uchar center = img.at<uchar>(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at<uchar>(i - 1, j - 1) >= center) << 7;\n      lbpcode |= (img.at<uchar>(i - 1, j) >= center) << 6;\n      lbpcode |= (img.at<uchar>(i - 1, j + 1) >= center) << 5;\n      lbpcode |= (img.at<uchar>(i, j -1) >= center) << 4;\n      lbpcode |= (img.at<uchar>(i, j + 1) >= center) << 3;\n      lbpcode |= (img.at<uchar>(i + 1, j - 1) >= center) << 2;\n      lbpcode |= (img.at<uchar>(i + 1, j) >= center) << 1;\n      lbpcode |= (img.at<uchar>(i + 1, j + 1) >= center) << 0;\n      result.at<uchar>(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}\n\n//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i<img.rows-radius;i++)\n  {\n      for(int j=radius;j<img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at<uchar>(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k<neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast<float>(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast<float>(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast<int>(floor(x));\n                int x2 = static_cast<int>(ceil(x));\n                int y1 = static_cast<int>(floor(y));\n                int y2 = static_cast<int>(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(x1,y1) * w1 + img.at<uchar>(x1,y2) *w2 + img.at<uchar>(x2,y1) * w3 +img.at<uchar>(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor>center) <<(neighbors-k-1);\n            }\n            result.at<uchar>(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}\n\n//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k<neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast<int>(floor(rx));\n        int x2 = static_cast<int>(ceil(rx));\n        int y1 = static_cast<int>(floor(ry));\n        int y2 = static_cast<int>(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i<img.rows-radius;i++)\n        {\n            for(int j=radius;j<img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at<uchar>(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at<uchar>(i+x1,j+y1) * w1 + img.at<uchar>(i+x1,j+y2) *w2 + img.at<uchar>(i+x2,j+y1) * w3 +img.at<uchar>(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i<result.rows;i++)\n    {\n        for(int j=0;j<result.cols;j++)\n        {\n            uchar currentValue = result.at<uchar>(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k<neighbors;k++)        //循环左移\n            {\n                uchar temp = (currentValue>>(neighbors-k)) | (currentValue<<k);\n                if(temp < minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at<uchar>(i,j) = minValue;\n        }\n    }\n    return result;\n}\n\nint main(int argc, char* argv[])\n{\n  Mat src = imread(argv[1], 0);\n  Mat dst = get_original_LBP_feature(src);\n  Mat odst1 = get_circular_LBP_feature(src, 1, 8);\n  //Mat odst4 = get_circular_LBP_feature(src, 4, 8);\n  Mat rif8 = get_rotation_invariant_LBP_feature(src, 1, 8);\n  Mat rif6 = get_rotation_invariant_LBP_feature(src, 1, 6);\n\n\n  imshow(\"原始图片\", src);\n  imshow(\"原始LBP\", dst);\n  imshow(\"圆形LBP\", odst1);\n  //imshow(\"圆形LBP4\", odst4);\n  imshow(\"旋转不变LBP\", rif8);\n  //imshow(\"旋转不变LBP6\", rif6);\n\n  waitKey(0);\n  return 0;\n}</code></pre>\n<h2 id=\"人脸检测\"><a href=\"#人脸检测\" class=\"headerlink\" title=\"人脸检测\"></a>人脸检测</h2><p>在OpenCV中，主要使用两种特征进行人脸检测，Haar特征和LBP特征，下面使用的是LBP特征。<br>实现人脸检测主要依赖于detectMultiScale()函数</p>\n<pre class=\" language-c++\"><code class=\"language-c++\">CV_WRAP virtual void detectMultiScale\n( const Mat& image,\n  CV_OUT vector<Rect>& objects,\n  double scaleFactor=1.1,\n  int minNeighbors=3, int flags=0,\n  Size minSize=Size(),\n  Size maxSize=Size() );</code></pre>\n<p>各参数含义如下：<br><strong>const Mat&amp; image</strong>: 需要被检测的图像（灰度图）。<br><strong>vector<rect>&amp; objects</rect></strong>: 保存被检测出的人脸位置坐标序列。<br><strong>double scaleFactor</strong>: 每次图片缩放的比例。<br><strong>int minNeighbors</strong>: 每一个人脸至少要检测到多少次才算是真的人脸。<br><strong>doubleint flags</strong>： 决定是缩放分类器来检测，还是缩放图像。<br><strong>Size()</strong>: 表示人脸的最大最小尺寸。</p>\n<p>具体实现代码如下:</p>\n<pre class=\" language-c++\"><code class=\"language-c++\">#include<opencv2/highgui/highgui.hpp>\n#include<opencv2/imgproc/imgproc.hpp>\n#include<opencv2/objdetect/objdetect.hpp>\n#include<iostream>\n#include<opencv2/core.hpp>\n\n\nusing namespace std;\nusing namespace cv;\n\n#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)\nCascadeClassifier faceCascade;\nint main(int argc, char* argv[])\n{\n Mat img;\n\n CascadeClassifier faceDetector(\"lbpcascade_frontalface.xml\");//读取分类器\n img = imread(argv[1]);  //读取检测的图片原图\n vector<Rect> objects;  //存放检测的对象\n faceDetector.detectMultiScale(img, objects);  //执行检测\n for (int i = 0; i < objects.size(); i++) //遍历检测到的脸\n {\n  rectangle(img, objects[i], CV_COLOR_RED);  //画出检测到的脸\n }\n imshow(\"result\", img);  //显示结果\n waitKey(0);\n\n return 0;\n}</code></pre>\n<p>检测结果:<br><img src=\"https://i.loli.net/2019/08/01/5d42b5d26727057681.png\" alt><br><img src=\"https://i.loli.net/2019/08/01/5d42b5d26fea564434.png\" alt><br><img src=\"https://i.loli.net/2019/08/01/5d42b5d2b360c81753.png\" alt></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"LBP算法实现及人脸检测\"><a href=\"#LBP算法实现及人脸检测\" class=\"headerlink\" title=\"LBP算法实现及人脸检测\"></a>LBP算法实现及人脸检测</h1><h2 id=\"OpenCV模块\"><a href=\"#OpenCV模块\" class=\"headerlink\" title=\"OpenCV模块\"></a>OpenCV模块</h2><ul>\n<li>core：简洁核心模块，基本函数，基本数据结构</li>\n<li>imgproc：图像处理模块，线性和非线性图像滤波，几何图像转换，颜色空间转换，直方图等。</li>\n<li>video：视频分析模块，运动估计，背景消除，物体跟踪算法</li>\n<li>calib3d：基本多视角几何算法，单体和立体相机的标定，对象姿势估计，双目立体匹配算法和元素的三维重建</li>\n<li>features2d：包含了显著特征检测算法，描述算子和算子匹配算法</li>\n<li>objdetect：物体检测和一些预定义的物体的检测（如人脸，眼睛，杯子，人，汽车等)</li>\n<li>ml：多种机器学习算法，如K均值，支持向量机和神经网络</li>\n<li>highgui：简单易用接口，有视频捕捉，图像和视频编码功能，简单UI接口，iOS的是其中一个子集</li>\n<li>gpu：GPU加速算法，iOS不可用</li>\n<li>ocl：OpenCL通用算法，iOS不可用</li>\n<li>其它辅助模块，如用户贡献的算法</li>\n</ul>\n<h2 id=\"原始LBP特征\"><a href=\"#原始LBP特征\" class=\"headerlink\" title=\"原始LBP特征\"></a>原始LBP特征</h2><pre><code class=\"c++\">//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i &lt; img.rows - 1; i++){\n    for (int j = 1; j &lt; img.cols -1; j++){\n      uchar center = img.at&lt;uchar&gt;(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at&lt;uchar&gt;(i - 1, j - 1) &gt;= center) &lt;&lt; 7;\n      lbpcode |= (img.at&lt;uchar&gt;(i - 1, j) &gt;= center) &lt;&lt; 6;\n      lbpcode |= (img.at&lt;uchar&gt;(i - 1, j + 1) &gt;= center) &lt;&lt; 5;\n      lbpcode |= (img.at&lt;uchar&gt;(i, j -1) &gt;= center) &lt;&lt; 4;\n      lbpcode |= (img.at&lt;uchar&gt;(i, j + 1) &gt;= center) &lt;&lt; 3;\n      lbpcode |= (img.at&lt;uchar&gt;(i + 1, j - 1) &gt;= center) &lt;&lt; 2;\n      lbpcode |= (img.at&lt;uchar&gt;(i + 1, j) &gt;= center) &lt;&lt; 1;\n      lbpcode |= (img.at&lt;uchar&gt;(i + 1, j + 1) &gt;= center) &lt;&lt; 0;\n      result.at&lt;uchar&gt;(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}</code></pre>\n<p><img src=\"https://i.loli.net/2019/07/31/5d4161dac5f0b23887.png\" alt></p>\n<h2 id=\"圆形LBP特征\"><a href=\"#圆形LBP特征\" class=\"headerlink\" title=\"圆形LBP特征\"></a>圆形LBP特征</h2><pre><code class=\"c++\">//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i&lt;img.rows-radius;i++)\n  {\n      for(int j=radius;j&lt;img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at&lt;uchar&gt;(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k&lt;neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast&lt;float&gt;(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast&lt;float&gt;(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast&lt;int&gt;(floor(x));\n                int x2 = static_cast&lt;int&gt;(ceil(x));\n                int y1 = static_cast&lt;int&gt;(floor(y));\n                int y2 = static_cast&lt;int&gt;(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at&lt;uchar&gt;(x1,y1) * w1 + img.at&lt;uchar&gt;(x1,y2) *w2 + img.at&lt;uchar&gt;(x2,y1) * w3 +img.at&lt;uchar&gt;(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);\n            }\n            result.at&lt;uchar&gt;(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}</code></pre>\n<p>结果:<br><img src=\"https://i.loli.net/2019/08/01/5d42b5d2e345026549.png\" alt></p>\n<p>第一幅图设置半径为4,第二幅图设置半径为1,可以看到半径越小处理的越精细。</p>\n<h2 id=\"旋转不变LBP特征\"><a href=\"#旋转不变LBP特征\" class=\"headerlink\" title=\"旋转不变LBP特征\"></a>旋转不变LBP特征</h2><pre><code class=\"c++\">//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k&lt;neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast&lt;float&gt;(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast&lt;float&gt;(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast&lt;int&gt;(floor(rx));\n        int x2 = static_cast&lt;int&gt;(ceil(rx));\n        int y1 = static_cast&lt;int&gt;(floor(ry));\n        int y2 = static_cast&lt;int&gt;(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i&lt;img.rows-radius;i++)\n        {\n            for(int j=radius;j&lt;img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at&lt;uchar&gt;(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at&lt;uchar&gt;(i+x1,j+y1) * w1 + img.at&lt;uchar&gt;(i+x1,j+y2) *w2 + img.at&lt;uchar&gt;(i+x2,j+y1) * w3 +img.at&lt;uchar&gt;(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at&lt;uchar&gt;(i-radius,j-radius) |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i&lt;result.rows;i++)\n    {\n        for(int j=0;j&lt;result.cols;j++)\n        {\n            uchar currentValue = result.at&lt;uchar&gt;(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k&lt;neighbors;k++)        //循环左移\n            {\n                uchar temp = (currentValue&gt;&gt;(neighbors-k)) | (currentValue&lt;&lt;k);\n                if(temp &lt; minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at&lt;uchar&gt;(i,j) = minValue;\n        }\n    }\n    return result;\n}\n</code></pre>\n<p>结果:<br><img src=\"https://i.loli.net/2019/08/01/5d42b5d30749958722.png\" alt></p>\n<p>第一幅图neighbors值设置为8,第二幅设置为6,可以看出neighbors值越大，得到的LBP特征亮度越高。</p>\n<h2 id=\"完整代码如下\"><a href=\"#完整代码如下\" class=\"headerlink\" title=\"完整代码如下\"></a>完整代码如下</h2><pre><code class=\"c++\">#include &lt;opencv2/highgui/highgui.hpp&gt;\n\nusing namespace cv;\n\n//Original_LBP\nMat get_original_LBP_feature(Mat img){\n  Mat result;\n  result.create(img.rows - 2, img.cols -2, img.type());\n  result.setTo(0);\n  for (int i = 1; i &lt; img.rows - 1; i++){\n    for (int j = 1; j &lt; img.cols -1; j++){\n      uchar center = img.at&lt;uchar&gt;(i, j);\n      uchar lbpcode = 0;\n      lbpcode |= (img.at&lt;uchar&gt;(i - 1, j - 1) &gt;= center) &lt;&lt; 7;\n      lbpcode |= (img.at&lt;uchar&gt;(i - 1, j) &gt;= center) &lt;&lt; 6;\n      lbpcode |= (img.at&lt;uchar&gt;(i - 1, j + 1) &gt;= center) &lt;&lt; 5;\n      lbpcode |= (img.at&lt;uchar&gt;(i, j -1) &gt;= center) &lt;&lt; 4;\n      lbpcode |= (img.at&lt;uchar&gt;(i, j + 1) &gt;= center) &lt;&lt; 3;\n      lbpcode |= (img.at&lt;uchar&gt;(i + 1, j - 1) &gt;= center) &lt;&lt; 2;\n      lbpcode |= (img.at&lt;uchar&gt;(i + 1, j) &gt;= center) &lt;&lt; 1;\n      lbpcode |= (img.at&lt;uchar&gt;(i + 1, j + 1) &gt;= center) &lt;&lt; 0;\n      result.at&lt;uchar&gt;(i - 1, j - 1) = lbpcode;\n    }\n  }\n  return result;\n}\n\n//Circular_LBP_feature\nMat get_circular_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  //循环处理每个像素\n  for(int i=radius;i&lt;img.rows-radius;i++)\n  {\n      for(int j=radius;j&lt;img.cols-radius;j++)\n      {\n          //获得中心像素点的灰度值\n          uchar center = img.at&lt;uchar&gt;(i,j);\n          uchar lbpCode = 0;\n          for(int k=0;k&lt;neighbors;k++)\n          {\n              //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin\n              float x = i + static_cast&lt;float&gt;(radius * \\\n                  cos(2.0 * CV_PI * k / neighbors));\n              float y = j - static_cast&lt;float&gt;(radius * \\\n                  sin(2.0 * CV_PI * k / neighbors));\n                //根据取整结果进行双线性插值，得到第k个采样点的灰度值\n                //1.分别对x，y进行上下取整\n                int x1 = static_cast&lt;int&gt;(floor(x));\n                int x2 = static_cast&lt;int&gt;(ceil(x));\n                int y1 = static_cast&lt;int&gt;(floor(y));\n                int y2 = static_cast&lt;int&gt;(ceil(y));\n\n                //将坐标映射到0-1之间\n                float tx = x - x1;\n                float ty = y - y1;\n                //根据0-1之间的x，y的权重计算公式计算权重\n                float w1 = (1-tx) * (1-ty);\n                float w2 =    tx  * (1-ty);\n                float w3 = (1-tx) *    ty;\n                float w4 =    tx  *    ty;\n                //3.根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at&lt;uchar&gt;(x1,y1) * w1 + img.at&lt;uchar&gt;(x1,y2) *w2 + img.at&lt;uchar&gt;(x2,y1) * w3 +img.at&lt;uchar&gt;(x2,y2) *w4;\n                //通过比较获得LBP值，并按顺序排列起来\n                lbpCode |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);\n            }\n            result.at&lt;uchar&gt;(i-radius,j-radius) = lbpCode;\n        }\n    }\n  return result;\n}\n\n//Rotation_Invariant_LBP_feature\nMat get_rotation_invariant_LBP_feature(Mat img, int radius, int neighbors)\n{\n  Mat result;\n  result.create(img.rows - radius * 2, img.cols - radius * 2, img.type());\n  result.setTo(0);\n  for(int k=0;k&lt;neighbors;k++)\n    {\n        //计算采样点对于中心点坐标的偏移量rx，ry\n        float rx = static_cast&lt;float&gt;(radius * cos(2.0 * CV_PI * k / neighbors));\n        float ry = -static_cast&lt;float&gt;(radius * sin(2.0 * CV_PI * k / neighbors));\n        //为双线性插值做准备\n        //对采样点偏移量分别进行上下取整\n        int x1 = static_cast&lt;int&gt;(floor(rx));\n        int x2 = static_cast&lt;int&gt;(ceil(rx));\n        int y1 = static_cast&lt;int&gt;(floor(ry));\n        int y2 = static_cast&lt;int&gt;(ceil(ry));\n        //将坐标偏移量映射到0-1之间\n        float tx = rx - x1;\n        float ty = ry - y1;\n        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关\n        float w1 = (1-tx) * (1-ty);\n        float w2 =    tx  * (1-ty);\n        float w3 = (1-tx) *    ty;\n        float w4 =    tx  *    ty;\n        //循环处理每个像素\n        for(int i=radius;i&lt;img.rows-radius;i++)\n        {\n            for(int j=radius;j&lt;img.cols-radius;j++)\n            {\n                //获得中心像素点的灰度值\n                uchar center = img.at&lt;uchar&gt;(i,j);\n                //根据双线性插值公式计算第k个采样点的灰度值\n                float neighbor = img.at&lt;uchar&gt;(i+x1,j+y1) * w1 + img.at&lt;uchar&gt;(i+x1,j+y2) *w2 + img.at&lt;uchar&gt;(i+x2,j+y1) * w3 +img.at&lt;uchar&gt;(i+x2,j+y2) *w4;\n                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得\n                result.at&lt;uchar&gt;(i-radius,j-radius) |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);\n            }\n        }\n    }\n    //进行旋转不变处理\n    for(int i=0;i&lt;result.rows;i++)\n    {\n        for(int j=0;j&lt;result.cols;j++)\n        {\n            uchar currentValue = result.at&lt;uchar&gt;(i,j);\n            uchar minValue = currentValue;\n            for(int k=1;k&lt;neighbors;k++)        //循环左移\n            {\n                uchar temp = (currentValue&gt;&gt;(neighbors-k)) | (currentValue&lt;&lt;k);\n                if(temp &lt; minValue)\n                {\n                    minValue = temp;\n                }\n            }\n            result.at&lt;uchar&gt;(i,j) = minValue;\n        }\n    }\n    return result;\n}\n\nint main(int argc, char* argv[])\n{\n  Mat src = imread(argv[1], 0);\n  Mat dst = get_original_LBP_feature(src);\n  Mat odst1 = get_circular_LBP_feature(src, 1, 8);\n  //Mat odst4 = get_circular_LBP_feature(src, 4, 8);\n  Mat rif8 = get_rotation_invariant_LBP_feature(src, 1, 8);\n  Mat rif6 = get_rotation_invariant_LBP_feature(src, 1, 6);\n\n\n  imshow(&quot;原始图片&quot;, src);\n  imshow(&quot;原始LBP&quot;, dst);\n  imshow(&quot;圆形LBP&quot;, odst1);\n  //imshow(&quot;圆形LBP4&quot;, odst4);\n  imshow(&quot;旋转不变LBP&quot;, rif8);\n  //imshow(&quot;旋转不变LBP6&quot;, rif6);\n\n  waitKey(0);\n  return 0;\n}</code></pre>\n<h2 id=\"人脸检测\"><a href=\"#人脸检测\" class=\"headerlink\" title=\"人脸检测\"></a>人脸检测</h2><p>在OpenCV中，主要使用两种特征进行人脸检测，Haar特征和LBP特征，下面使用的是LBP特征。<br>实现人脸检测主要依赖于detectMultiScale()函数</p>\n<pre><code class=\"c++\">CV_WRAP virtual void detectMultiScale\n( const Mat&amp; image,\n  CV_OUT vector&lt;Rect&gt;&amp; objects,\n  double scaleFactor=1.1,\n  int minNeighbors=3, int flags=0,\n  Size minSize=Size(),\n  Size maxSize=Size() );</code></pre>\n<p>各参数含义如下：<br><strong>const Mat&amp; image</strong>: 需要被检测的图像（灰度图）。<br><strong>vector<rect>&amp; objects</rect></strong>: 保存被检测出的人脸位置坐标序列。<br><strong>double scaleFactor</strong>: 每次图片缩放的比例。<br><strong>int minNeighbors</strong>: 每一个人脸至少要检测到多少次才算是真的人脸。<br><strong>doubleint flags</strong>： 决定是缩放分类器来检测，还是缩放图像。<br><strong>Size()</strong>: 表示人脸的最大最小尺寸。</p>\n<p>具体实现代码如下:</p>\n<pre><code class=\"c++\">#include&lt;opencv2/highgui/highgui.hpp&gt;\n#include&lt;opencv2/imgproc/imgproc.hpp&gt;\n#include&lt;opencv2/objdetect/objdetect.hpp&gt;\n#include&lt;iostream&gt;\n#include&lt;opencv2/core.hpp&gt;\n\n\nusing namespace std;\nusing namespace cv;\n\n#define CV_COLOR_GREEN cv::Scalar(0, 255, 0)\nCascadeClassifier faceCascade;\nint main(int argc, char* argv[])\n{\n Mat img;\n\n CascadeClassifier faceDetector(&quot;lbpcascade_frontalface.xml&quot;);//读取分类器\n img = imread(argv[1]);  //读取检测的图片原图\n vector&lt;Rect&gt; objects;  //存放检测的对象\n faceDetector.detectMultiScale(img, objects);  //执行检测\n for (int i = 0; i &lt; objects.size(); i++) //遍历检测到的脸\n {\n  rectangle(img, objects[i], CV_COLOR_RED);  //画出检测到的脸\n }\n imshow(&quot;result&quot;, img);  //显示结果\n waitKey(0);\n\n return 0;\n}</code></pre>\n<p>检测结果:<br><img src=\"https://i.loli.net/2019/08/01/5d42b5d26727057681.png\" alt><br><img src=\"https://i.loli.net/2019/08/01/5d42b5d26fea564434.png\" alt><br><img src=\"https://i.loli.net/2019/08/01/5d42b5d2b360c81753.png\" alt></p>\n"},{"title":"Hello World","date":"2019-07-01T08:52:05.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2019-07-01 16:52:05\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"updated":"2019-08-10T10:47:34.326Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltx001pe5g6eg1jcp5s","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo new <span class=\"token string\">\"My New Post\"</span></code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo server</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo generate</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo deploy</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><pre><code class=\"bash\">$ hexo new &quot;My New Post&quot;</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><pre><code class=\"bash\">$ hexo server</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><pre><code class=\"bash\">$ hexo generate</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><pre><code class=\"bash\">$ hexo deploy</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"PCA算法实现","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2019-08-07T01:48:10.000Z","password":null,"summary":"PCA算法实例及C++实现","_content":"# PCA算法实例及C++实现\n\n## PCA算法\n总结一下PCA的算法步骤：\n\n设有m条n维数据。\n\n1. 将原始数据按列组成n行m列矩阵X\n2. 将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值\n3. 求出协方差矩阵 $C=\\frac{1}{m}XX^\\mathsf{T}$\n4. 求出协方差矩阵的特征值及对应的特征向量\n5. 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P\n6. $Y = PX$即为降维到k维后的数据\n\n## 实例\n\n以\n$$ \\begin{pmatrix}\n  -1 & -1 & 0 & 2 & 0 \\\\\\\\\n  -2 & 0 & 0 & 1 & 1 \\\\\n\\end{pmatrix} $$\n为例，我们用PCA方法将这组二维数据其降到一维。\n\n因为这个矩阵的每行已经是零均值，这里我们直接求协方差矩阵：\n$$ C=\\frac{1}{5}\\begin{pmatrix}\n  -1 & -1 & 0 & 2 & 0 \\\\\\\\\n  -2 & 0 & 0 & 1 & 1 \\\\\n\\end{pmatrix}\\begin{pmatrix}\n  -1 & -2 \\\\\\\\\n  -1 & 0  \\\\\\\\\n  0  & 0  \\\\\\\\\n  2  & 1  \\\\\\\\\n  0  & 1 \\\\\n\\end{pmatrix}=\\begin{pmatrix}\n  \\frac{6}{5} & \\frac{4}{5} \\\\\\\\\n  \\frac{4}{5} & \\frac{6}{5} \\\\\n\\end{pmatrix}$$\n然后求其特征值和特征向量，具体求解方法不再详述，可以参考相关资料。求解后特征值为：\n$$\\lambda_1=2,\\lambda_2=2/5$$\n其对应的特征向量分别是：\n$$c_1\\begin{pmatrix}\n  1 \\\\\\\\\n  1\n\\end{pmatrix},c_2\\begin{pmatrix}\n  -1 \\\\\\\\\n  1\n\\end{pmatrix}$$\n其中对应的特征向量分别是一个通解， $c_1$和 $c_2$ 可取任意实数。那么标准化后的特征向量为：\n$$\\begin{pmatrix}\n  1/\\sqrt{2} \\\\\\\\\n  1/\\sqrt{2}\n\\end{pmatrix},\\begin{pmatrix}\n  -1/\\sqrt{2} \\\\\\\\\n  1/\\sqrt{2}\n\\end{pmatrix}$$\n因此我们的矩阵P是：\n$$P=\\begin{pmatrix}\n  1/\\sqrt{2}  & 1/\\sqrt{2}  \\\\\\\\\n  -1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}$$\n最后我们用P的第一行乘以数据矩阵，就得到了降维后的表示：\n$$Y=\\begin{pmatrix}\n  1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}\\begin{pmatrix}\n  -1 & -1 & 0 & 2 & 0 \\\\\\\\\n  -2 & 0 & 0 & 1 & 1\n\\end{pmatrix}=\\begin{pmatrix}\n  -3/\\sqrt{2} & -1/\\sqrt{2} & 0 & 3/\\sqrt{2} & -1/\\sqrt{2}\n\\end{pmatrix}$$\n可以验证协方差矩阵C的对角化：\n$$PCP^\\mathsf{T}=\\begin{pmatrix}\n  1/\\sqrt{2}  & 1/\\sqrt{2}  \\\\\\\\\n  -1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}\\begin{pmatrix}\n  6/5 & 4/5 \\\\\\\\\n  4/5 & 6/5\n\\end{pmatrix}\\begin{pmatrix}\n  1/\\sqrt{2} & -1/\\sqrt{2}  \\\\\\\\\n  1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}=\\begin{pmatrix}\n  2 & 0  \\\\\\\\\n  0 & 2/5\n\\end{pmatrix}$$\n![](02.png)\n\n### C++实现\n因为要对一组图片信息进行训练，所以我写了一部分通过摄像头截取图片帧的代码，`get_img()`函数。这里提取了5个特征脸和一个均值脸\n\n```cpp\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/objdetect/objdetect.hpp>\n\n#include <iostream>\n#include <fstream>\n#include <sstream>\n#define img_num 300 //训练图片的张数\nusing namespace cv;\nusing namespace std;\n//通过摄像头保存要训练的图片\n\n//打开摄像头\nint get_img(){\n  VideoCapture cap(0);\n  if(!cap.isOpened())\n  {\n    return -1;\n  }\n  Mat frame;\n  bool stop = false;\n  int i = 1;\n  while(!stop){\n    cap >> frame;\n    printf(\"%d\\n\", i);\n    if (frame.empty())\n      stop = true;\n    //string filename = format(\"%d.jpg\", i);\n    char filename[20];\n    sprintf(filename, \"Img/%d.jpg\", i);\n    imwrite(filename, frame);\n    i++;\n    imshow(\"frame\", frame);\n    waitKey(30);\n    if(i > img_num)\n      break;\n    \n  }\nreturn -1;\n\n}\n//把图像归一化为0-255\nMat norm_0_255(const Mat& src){\n  Mat dst;\n  switch(src.channels()){\n    case 1:\n        cv::normalize(src, dst, 0, 255, NORM_MINMAX, CV_8UC1);\n        break;\n    case 3:\n        cv::normalize(src, dst, 0, 255, NORM_MINMAX, CV_8UC3);\n        break;\n    default:\n        src.copyTo(dst);\n        break;\n  }\n  return dst;\n}\n\n//将给定的图像转化为行矩阵\nMat asRowMatrix(const vector<Mat>& src, int rtype, double alpha = 1, double beta = 0){\n  // 样本数量\n  size_t n = src.size();\n  //没有样本，返回空矩阵\n  if (n == 0)\n    return Mat();\n\n  //样本的维数\n  size_t d = src[0].total();\n\n  Mat data(n, d, rtype);\n\n  //拷贝数据\n  for (int i = 0; i < n; i++){\n    if(src[i].empty()){\n      string error_message = format(\"Image number %d was empty, please check your input data.\", i);\n      CV_Error(CV_StsBadArg, error_message);\n    }\n\n    //确保数据能被reshape\n    if(src[i].total() != d){\n      string error_message = format(\"Wrong number of elements in matrix #%d! Expected %d was %d.\", i, d, src[i].total());\n      CV_Error(CV_StsBadArg, error_message);\n    }\n    Mat xi = data.row(i);\n    //转化为1行，n列的格式\n    if(src[i].isContinuous()){\n      src[i].reshape(1, 1).convertTo(xi, rtype, alpha, beta);\n    }\n    else {\n      src[i].clone().reshape(1, 1).convertTo(xi, rtype, alpha, beta);\n    }\n  }\n  return data;\n}\n\nint main(int argc, const char* argv[]){\n  vector<Mat> db;\n  //get_img();\n  for(int i=1; i<img_num;i++){\n\n    string filename = format(\"Img/%d.jpg\", i);\n    db.push_back(imread(filename, IMREAD_GRAYSCALE));\n  }\n  // Build a matrix with the observations in row:\n    Mat data = asRowMatrix(db, CV_32FC1);\n\n    // PCA算法保持5主成分分量\n    int num_components = 5;\n\n    //执行pca算法\n    PCA pca(data, Mat(), CV_PCA_DATA_AS_ROW, num_components);\n\n    //copy  pca算法结果\n    Mat mean = pca.mean.clone();\n    Mat eigenvalues = pca.eigenvalues.clone();\n    Mat eigenvectors = pca.eigenvectors.clone();\n        //均值脸\n    imshow(\"avg\", norm_0_255(mean.reshape(1, db[0].rows)));\n\n    //五个特征脸\n    imshow(\"pc1\", norm_0_255(pca.eigenvectors.row(0)).reshape(1, db[0].rows));\n    imshow(\"pc2\", norm_0_255(pca.eigenvectors.row(1)).reshape(1, db[0].rows));\n    imshow(\"pc3\", norm_0_255(pca.eigenvectors.row(2)).reshape(1, db[0].rows));\n    imshow(\"pc4\", norm_0_255(pca.eigenvectors.row(3)).reshape(1, db[0].rows));\n    imshow(\"pc5\", norm_0_255(pca.eigenvectors.row(4)).reshape(1, db[0].rows));\n\n    while(1)\n        waitKey(0);\n\n    // Success!\n    return 0;\n\n}\n```\n![](01.png)\n","source":"_posts/PCA算法实现.md","raw":"---\ntitle: PCA算法实现\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2019-08-07 09:48:10\npassword:\nsummary: PCA算法实例及C++实现\ntags: 实习\ncategories:\n---\n# PCA算法实例及C++实现\n\n## PCA算法\n总结一下PCA的算法步骤：\n\n设有m条n维数据。\n\n1. 将原始数据按列组成n行m列矩阵X\n2. 将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值\n3. 求出协方差矩阵 $C=\\frac{1}{m}XX^\\mathsf{T}$\n4. 求出协方差矩阵的特征值及对应的特征向量\n5. 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P\n6. $Y = PX$即为降维到k维后的数据\n\n## 实例\n\n以\n$$ \\begin{pmatrix}\n  -1 & -1 & 0 & 2 & 0 \\\\\\\\\n  -2 & 0 & 0 & 1 & 1 \\\\\n\\end{pmatrix} $$\n为例，我们用PCA方法将这组二维数据其降到一维。\n\n因为这个矩阵的每行已经是零均值，这里我们直接求协方差矩阵：\n$$ C=\\frac{1}{5}\\begin{pmatrix}\n  -1 & -1 & 0 & 2 & 0 \\\\\\\\\n  -2 & 0 & 0 & 1 & 1 \\\\\n\\end{pmatrix}\\begin{pmatrix}\n  -1 & -2 \\\\\\\\\n  -1 & 0  \\\\\\\\\n  0  & 0  \\\\\\\\\n  2  & 1  \\\\\\\\\n  0  & 1 \\\\\n\\end{pmatrix}=\\begin{pmatrix}\n  \\frac{6}{5} & \\frac{4}{5} \\\\\\\\\n  \\frac{4}{5} & \\frac{6}{5} \\\\\n\\end{pmatrix}$$\n然后求其特征值和特征向量，具体求解方法不再详述，可以参考相关资料。求解后特征值为：\n$$\\lambda_1=2,\\lambda_2=2/5$$\n其对应的特征向量分别是：\n$$c_1\\begin{pmatrix}\n  1 \\\\\\\\\n  1\n\\end{pmatrix},c_2\\begin{pmatrix}\n  -1 \\\\\\\\\n  1\n\\end{pmatrix}$$\n其中对应的特征向量分别是一个通解， $c_1$和 $c_2$ 可取任意实数。那么标准化后的特征向量为：\n$$\\begin{pmatrix}\n  1/\\sqrt{2} \\\\\\\\\n  1/\\sqrt{2}\n\\end{pmatrix},\\begin{pmatrix}\n  -1/\\sqrt{2} \\\\\\\\\n  1/\\sqrt{2}\n\\end{pmatrix}$$\n因此我们的矩阵P是：\n$$P=\\begin{pmatrix}\n  1/\\sqrt{2}  & 1/\\sqrt{2}  \\\\\\\\\n  -1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}$$\n最后我们用P的第一行乘以数据矩阵，就得到了降维后的表示：\n$$Y=\\begin{pmatrix}\n  1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}\\begin{pmatrix}\n  -1 & -1 & 0 & 2 & 0 \\\\\\\\\n  -2 & 0 & 0 & 1 & 1\n\\end{pmatrix}=\\begin{pmatrix}\n  -3/\\sqrt{2} & -1/\\sqrt{2} & 0 & 3/\\sqrt{2} & -1/\\sqrt{2}\n\\end{pmatrix}$$\n可以验证协方差矩阵C的对角化：\n$$PCP^\\mathsf{T}=\\begin{pmatrix}\n  1/\\sqrt{2}  & 1/\\sqrt{2}  \\\\\\\\\n  -1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}\\begin{pmatrix}\n  6/5 & 4/5 \\\\\\\\\n  4/5 & 6/5\n\\end{pmatrix}\\begin{pmatrix}\n  1/\\sqrt{2} & -1/\\sqrt{2}  \\\\\\\\\n  1/\\sqrt{2} & 1/\\sqrt{2}\n\\end{pmatrix}=\\begin{pmatrix}\n  2 & 0  \\\\\\\\\n  0 & 2/5\n\\end{pmatrix}$$\n![](02.png)\n\n### C++实现\n因为要对一组图片信息进行训练，所以我写了一部分通过摄像头截取图片帧的代码，`get_img()`函数。这里提取了5个特征脸和一个均值脸\n\n```cpp\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/objdetect/objdetect.hpp>\n\n#include <iostream>\n#include <fstream>\n#include <sstream>\n#define img_num 300 //训练图片的张数\nusing namespace cv;\nusing namespace std;\n//通过摄像头保存要训练的图片\n\n//打开摄像头\nint get_img(){\n  VideoCapture cap(0);\n  if(!cap.isOpened())\n  {\n    return -1;\n  }\n  Mat frame;\n  bool stop = false;\n  int i = 1;\n  while(!stop){\n    cap >> frame;\n    printf(\"%d\\n\", i);\n    if (frame.empty())\n      stop = true;\n    //string filename = format(\"%d.jpg\", i);\n    char filename[20];\n    sprintf(filename, \"Img/%d.jpg\", i);\n    imwrite(filename, frame);\n    i++;\n    imshow(\"frame\", frame);\n    waitKey(30);\n    if(i > img_num)\n      break;\n    \n  }\nreturn -1;\n\n}\n//把图像归一化为0-255\nMat norm_0_255(const Mat& src){\n  Mat dst;\n  switch(src.channels()){\n    case 1:\n        cv::normalize(src, dst, 0, 255, NORM_MINMAX, CV_8UC1);\n        break;\n    case 3:\n        cv::normalize(src, dst, 0, 255, NORM_MINMAX, CV_8UC3);\n        break;\n    default:\n        src.copyTo(dst);\n        break;\n  }\n  return dst;\n}\n\n//将给定的图像转化为行矩阵\nMat asRowMatrix(const vector<Mat>& src, int rtype, double alpha = 1, double beta = 0){\n  // 样本数量\n  size_t n = src.size();\n  //没有样本，返回空矩阵\n  if (n == 0)\n    return Mat();\n\n  //样本的维数\n  size_t d = src[0].total();\n\n  Mat data(n, d, rtype);\n\n  //拷贝数据\n  for (int i = 0; i < n; i++){\n    if(src[i].empty()){\n      string error_message = format(\"Image number %d was empty, please check your input data.\", i);\n      CV_Error(CV_StsBadArg, error_message);\n    }\n\n    //确保数据能被reshape\n    if(src[i].total() != d){\n      string error_message = format(\"Wrong number of elements in matrix #%d! Expected %d was %d.\", i, d, src[i].total());\n      CV_Error(CV_StsBadArg, error_message);\n    }\n    Mat xi = data.row(i);\n    //转化为1行，n列的格式\n    if(src[i].isContinuous()){\n      src[i].reshape(1, 1).convertTo(xi, rtype, alpha, beta);\n    }\n    else {\n      src[i].clone().reshape(1, 1).convertTo(xi, rtype, alpha, beta);\n    }\n  }\n  return data;\n}\n\nint main(int argc, const char* argv[]){\n  vector<Mat> db;\n  //get_img();\n  for(int i=1; i<img_num;i++){\n\n    string filename = format(\"Img/%d.jpg\", i);\n    db.push_back(imread(filename, IMREAD_GRAYSCALE));\n  }\n  // Build a matrix with the observations in row:\n    Mat data = asRowMatrix(db, CV_32FC1);\n\n    // PCA算法保持5主成分分量\n    int num_components = 5;\n\n    //执行pca算法\n    PCA pca(data, Mat(), CV_PCA_DATA_AS_ROW, num_components);\n\n    //copy  pca算法结果\n    Mat mean = pca.mean.clone();\n    Mat eigenvalues = pca.eigenvalues.clone();\n    Mat eigenvectors = pca.eigenvectors.clone();\n        //均值脸\n    imshow(\"avg\", norm_0_255(mean.reshape(1, db[0].rows)));\n\n    //五个特征脸\n    imshow(\"pc1\", norm_0_255(pca.eigenvectors.row(0)).reshape(1, db[0].rows));\n    imshow(\"pc2\", norm_0_255(pca.eigenvectors.row(1)).reshape(1, db[0].rows));\n    imshow(\"pc3\", norm_0_255(pca.eigenvectors.row(2)).reshape(1, db[0].rows));\n    imshow(\"pc4\", norm_0_255(pca.eigenvectors.row(3)).reshape(1, db[0].rows));\n    imshow(\"pc5\", norm_0_255(pca.eigenvectors.row(4)).reshape(1, db[0].rows));\n\n    while(1)\n        waitKey(0);\n\n    // Success!\n    return 0;\n\n}\n```\n![](01.png)\n","slug":"PCA算法实现","published":1,"updated":"2019-08-10T10:47:34.322Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3ltz001se5g6r787ewfd","content":"<h1 id=\"PCA算法实例及C-实现\"><a href=\"#PCA算法实例及C-实现\" class=\"headerlink\" title=\"PCA算法实例及C++实现\"></a>PCA算法实例及C++实现</h1><h2 id=\"PCA算法\"><a href=\"#PCA算法\" class=\"headerlink\" title=\"PCA算法\"></a>PCA算法</h2><p>总结一下PCA的算法步骤：</p>\n<p>设有m条n维数据。</p>\n<ol>\n<li>将原始数据按列组成n行m列矩阵X</li>\n<li>将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值</li>\n<li>求出协方差矩阵 $C=\\frac{1}{m}XX^\\mathsf{T}$</li>\n<li>求出协方差矩阵的特征值及对应的特征向量</li>\n<li>将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P</li>\n<li>$Y = PX$即为降维到k维后的数据</li>\n</ol>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><p>以<br>$$ \\begin{pmatrix}<br>  -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>  -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\<br>\\end{pmatrix} $$<br>为例，我们用PCA方法将这组二维数据其降到一维。</p>\n<p>因为这个矩阵的每行已经是零均值，这里我们直接求协方差矩阵：<br>$$ C=\\frac{1}{5}\\begin{pmatrix}<br>  -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>  -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\<br>\\end{pmatrix}\\begin{pmatrix}<br>  -1 &amp; -2 \\\\\\<br>  -1 &amp; 0  \\\\\\<br>  0  &amp; 0  \\\\\\<br>  2  &amp; 1  \\\\\\<br>  0  &amp; 1 \\<br>\\end{pmatrix}=\\begin{pmatrix}<br>  \\frac{6}{5} &amp; \\frac{4}{5} \\\\\\<br>  \\frac{4}{5} &amp; \\frac{6}{5} \\<br>\\end{pmatrix}$$<br>然后求其特征值和特征向量，具体求解方法不再详述，可以参考相关资料。求解后特征值为：<br>$$\\lambda_1=2,\\lambda_2=2/5$$<br>其对应的特征向量分别是：<br>$$c_1\\begin{pmatrix}<br>  1 \\\\\\<br>  1<br>\\end{pmatrix},c_2\\begin{pmatrix}<br>  -1 \\\\\\<br>  1<br>\\end{pmatrix}$$<br>其中对应的特征向量分别是一个通解， $c_1$和 $c_2$ 可取任意实数。那么标准化后的特征向量为：<br>$$\\begin{pmatrix}<br>  1/\\sqrt{2} \\\\\\<br>  1/\\sqrt{2}<br>\\end{pmatrix},\\begin{pmatrix}<br>  -1/\\sqrt{2} \\\\\\<br>  1/\\sqrt{2}<br>\\end{pmatrix}$$<br>因此我们的矩阵P是：<br>$$P=\\begin{pmatrix}<br>  1/\\sqrt{2}  &amp; 1/\\sqrt{2}  \\\\\\<br>  -1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}$$<br>最后我们用P的第一行乘以数据矩阵，就得到了降维后的表示：<br>$$Y=\\begin{pmatrix}<br>  1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}\\begin{pmatrix}<br>  -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>  -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1<br>\\end{pmatrix}=\\begin{pmatrix}<br>  -3/\\sqrt{2} &amp; -1/\\sqrt{2} &amp; 0 &amp; 3/\\sqrt{2} &amp; -1/\\sqrt{2}<br>\\end{pmatrix}$$<br>可以验证协方差矩阵C的对角化：<br>$$PCP^\\mathsf{T}=\\begin{pmatrix}<br>  1/\\sqrt{2}  &amp; 1/\\sqrt{2}  \\\\\\<br>  -1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}\\begin{pmatrix}<br>  6/5 &amp; 4/5 \\\\\\<br>  4/5 &amp; 6/5<br>\\end{pmatrix}\\begin{pmatrix}<br>  1/\\sqrt{2} &amp; -1/\\sqrt{2}  \\\\\\<br>  1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}=\\begin{pmatrix}<br>  2 &amp; 0  \\\\\\<br>  0 &amp; 2/5<br>\\end{pmatrix}$$<br><img src=\"02.png\" alt></p>\n<h3 id=\"C-实现\"><a href=\"#C-实现\" class=\"headerlink\" title=\"C++实现\"></a>C++实现</h3><p>因为要对一组图片信息进行训练，所以我写了一部分通过摄像头截取图片帧的代码，<code>get_img()</code>函数。这里提取了5个特征脸和一个均值脸</p>\n<pre class=\" language-cpp\"><code class=\"language-cpp\"><span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/core/core.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/highgui/highgui.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/imgproc/imgproc.hpp></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;opencv2/objdetect/objdetect.hpp></span></span>\n\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;iostream></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;fstream></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;sstream></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">define</span> img_num 300 </span><span class=\"token comment\" spellcheck=\"true\">//训练图片的张数</span>\n<span class=\"token keyword\">using</span> <span class=\"token keyword\">namespace</span> cv<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">using</span> <span class=\"token keyword\">namespace</span> std<span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">//通过摄像头保存要训练的图片</span>\n\n<span class=\"token comment\" spellcheck=\"true\">//打开摄像头</span>\n<span class=\"token keyword\">int</span> <span class=\"token function\">get_img</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  VideoCapture <span class=\"token function\">cap</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>cap<span class=\"token punctuation\">.</span><span class=\"token function\">isOpened</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  Mat frame<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">bool</span> stop <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>stop<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    cap <span class=\"token operator\">>></span> frame<span class=\"token punctuation\">;</span>\n    <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"%d\\n\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>frame<span class=\"token punctuation\">.</span><span class=\"token function\">empty</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      stop <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\" spellcheck=\"true\">//string filename = format(\"%d.jpg\", i);</span>\n    <span class=\"token keyword\">char</span> filename<span class=\"token punctuation\">[</span><span class=\"token number\">20</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">sprintf</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> <span class=\"token string\">\"Img/%d.jpg\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">imwrite</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> frame<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    i<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"frame\"</span><span class=\"token punctuation\">,</span> frame<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">waitKey</span><span class=\"token punctuation\">(</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>i <span class=\"token operator\">></span> img_num<span class=\"token punctuation\">)</span>\n      <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token punctuation\">}</span>\n<span class=\"token comment\" spellcheck=\"true\">//把图像归一化为0-255</span>\nMat <span class=\"token function\">norm_0_255</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> Mat<span class=\"token operator\">&amp;</span> src<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  Mat dst<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">switch</span><span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">.</span><span class=\"token function\">channels</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">case</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span>\n        cv<span class=\"token operator\">::</span><span class=\"token function\">normalize</span><span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">,</span> dst<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">255</span><span class=\"token punctuation\">,</span> NORM_MINMAX<span class=\"token punctuation\">,</span> CV_8UC1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">case</span> <span class=\"token number\">3</span><span class=\"token operator\">:</span>\n        cv<span class=\"token operator\">::</span><span class=\"token function\">normalize</span><span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">,</span> dst<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">255</span><span class=\"token punctuation\">,</span> NORM_MINMAX<span class=\"token punctuation\">,</span> CV_8UC3<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">default</span><span class=\"token operator\">:</span>\n        src<span class=\"token punctuation\">.</span><span class=\"token function\">copyTo</span><span class=\"token punctuation\">(</span>dst<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> dst<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\" spellcheck=\"true\">//将给定的图像转化为行矩阵</span>\nMat <span class=\"token function\">asRowMatrix</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> vector<span class=\"token operator\">&lt;</span>Mat<span class=\"token operator\">></span><span class=\"token operator\">&amp;</span> src<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> rtype<span class=\"token punctuation\">,</span> <span class=\"token keyword\">double</span> alpha <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">double</span> beta <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  <span class=\"token comment\" spellcheck=\"true\">// 样本数量</span>\n  size_t n <span class=\"token operator\">=</span> src<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\" spellcheck=\"true\">//没有样本，返回空矩阵</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>n <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token function\">Mat</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\" spellcheck=\"true\">//样本的维数</span>\n  size_t d <span class=\"token operator\">=</span> src<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">total</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  Mat <span class=\"token function\">data</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span> d<span class=\"token punctuation\">,</span> rtype<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\" spellcheck=\"true\">//拷贝数据</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">empty</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n      string error_message <span class=\"token operator\">=</span> <span class=\"token function\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Image number %d was empty, please check your input data.\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token function\">CV_Error</span><span class=\"token punctuation\">(</span>CV_StsBadArg<span class=\"token punctuation\">,</span> error_message<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">//确保数据能被reshape</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">total</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n      string error_message <span class=\"token operator\">=</span> <span class=\"token function\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Wrong number of elements in matrix #%d! Expected %d was %d.\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">,</span> d<span class=\"token punctuation\">,</span> src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">total</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token function\">CV_Error</span><span class=\"token punctuation\">(</span>CV_StsBadArg<span class=\"token punctuation\">,</span> error_message<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    Mat xi <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span><span class=\"token function\">row</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\" spellcheck=\"true\">//转化为1行，n列的格式</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">isContinuous</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n      src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">convertTo</span><span class=\"token punctuation\">(</span>xi<span class=\"token punctuation\">,</span> rtype<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">,</span> beta<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n      src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">clone</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">convertTo</span><span class=\"token punctuation\">(</span>xi<span class=\"token punctuation\">,</span> rtype<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">,</span> beta<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> data<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> argc<span class=\"token punctuation\">,</span> <span class=\"token keyword\">const</span> <span class=\"token keyword\">char</span><span class=\"token operator\">*</span> argv<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  vector<span class=\"token operator\">&lt;</span>Mat<span class=\"token operator\">></span> db<span class=\"token punctuation\">;</span>\n  <span class=\"token comment\" spellcheck=\"true\">//get_img();</span>\n  <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">&lt;</span>img_num<span class=\"token punctuation\">;</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n\n    string filename <span class=\"token operator\">=</span> <span class=\"token function\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Img/%d.jpg\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    db<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span><span class=\"token function\">imread</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> IMREAD_GRAYSCALE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\" spellcheck=\"true\">// Build a matrix with the observations in row:</span>\n    Mat data <span class=\"token operator\">=</span> <span class=\"token function\">asRowMatrix</span><span class=\"token punctuation\">(</span>db<span class=\"token punctuation\">,</span> CV_32FC1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// PCA算法保持5主成分分量</span>\n    <span class=\"token keyword\">int</span> num_components <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">//执行pca算法</span>\n    PCA <span class=\"token function\">pca</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> <span class=\"token function\">Mat</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> CV_PCA_DATA_AS_ROW<span class=\"token punctuation\">,</span> num_components<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">//copy  pca算法结果</span>\n    Mat mean <span class=\"token operator\">=</span> pca<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">.</span><span class=\"token function\">clone</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    Mat eigenvalues <span class=\"token operator\">=</span> pca<span class=\"token punctuation\">.</span>eigenvalues<span class=\"token punctuation\">.</span><span class=\"token function\">clone</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    Mat eigenvectors <span class=\"token operator\">=</span> pca<span class=\"token punctuation\">.</span>eigenvectors<span class=\"token punctuation\">.</span><span class=\"token function\">clone</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\" spellcheck=\"true\">//均值脸</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"avg\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">norm_0_255</span><span class=\"token punctuation\">(</span>mean<span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> db<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>rows<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">//五个特征脸</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pc1\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">norm_0_255</span><span class=\"token punctuation\">(</span>pca<span class=\"token punctuation\">.</span>eigenvectors<span class=\"token punctuation\">.</span><span class=\"token function\">row</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> db<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>rows<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pc2\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">norm_0_255</span><span class=\"token punctuation\">(</span>pca<span class=\"token punctuation\">.</span>eigenvectors<span class=\"token punctuation\">.</span><span class=\"token function\">row</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> db<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>rows<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pc3\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">norm_0_255</span><span class=\"token punctuation\">(</span>pca<span class=\"token punctuation\">.</span>eigenvectors<span class=\"token punctuation\">.</span><span class=\"token function\">row</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> db<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>rows<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pc4\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">norm_0_255</span><span class=\"token punctuation\">(</span>pca<span class=\"token punctuation\">.</span>eigenvectors<span class=\"token punctuation\">.</span><span class=\"token function\">row</span><span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> db<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>rows<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">imshow</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pc5\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">norm_0_255</span><span class=\"token punctuation\">(</span>pca<span class=\"token punctuation\">.</span>eigenvectors<span class=\"token punctuation\">.</span><span class=\"token function\">row</span><span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">reshape</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> db<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>rows<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token function\">waitKey</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// Success!</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token punctuation\">}</span></code></pre>\n<p><img src=\"01.png\" alt></p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"PCA算法实例及C-实现\"><a href=\"#PCA算法实例及C-实现\" class=\"headerlink\" title=\"PCA算法实例及C++实现\"></a>PCA算法实例及C++实现</h1><h2 id=\"PCA算法\"><a href=\"#PCA算法\" class=\"headerlink\" title=\"PCA算法\"></a>PCA算法</h2><p>总结一下PCA的算法步骤：</p>\n<p>设有m条n维数据。</p>\n<ol>\n<li>将原始数据按列组成n行m列矩阵X</li>\n<li>将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值</li>\n<li>求出协方差矩阵 $C=\\frac{1}{m}XX^\\mathsf{T}$</li>\n<li>求出协方差矩阵的特征值及对应的特征向量</li>\n<li>将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P</li>\n<li>$Y = PX$即为降维到k维后的数据</li>\n</ol>\n<h2 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h2><p>以<br>$$ \\begin{pmatrix}<br>  -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>  -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\<br>\\end{pmatrix} $$<br>为例，我们用PCA方法将这组二维数据其降到一维。</p>\n<p>因为这个矩阵的每行已经是零均值，这里我们直接求协方差矩阵：<br>$$ C=\\frac{1}{5}\\begin{pmatrix}<br>  -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>  -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\<br>\\end{pmatrix}\\begin{pmatrix}<br>  -1 &amp; -2 \\\\\\<br>  -1 &amp; 0  \\\\\\<br>  0  &amp; 0  \\\\\\<br>  2  &amp; 1  \\\\\\<br>  0  &amp; 1 \\<br>\\end{pmatrix}=\\begin{pmatrix}<br>  \\frac{6}{5} &amp; \\frac{4}{5} \\\\\\<br>  \\frac{4}{5} &amp; \\frac{6}{5} \\<br>\\end{pmatrix}$$<br>然后求其特征值和特征向量，具体求解方法不再详述，可以参考相关资料。求解后特征值为：<br>$$\\lambda_1=2,\\lambda_2=2/5$$<br>其对应的特征向量分别是：<br>$$c_1\\begin{pmatrix}<br>  1 \\\\\\<br>  1<br>\\end{pmatrix},c_2\\begin{pmatrix}<br>  -1 \\\\\\<br>  1<br>\\end{pmatrix}$$<br>其中对应的特征向量分别是一个通解， $c_1$和 $c_2$ 可取任意实数。那么标准化后的特征向量为：<br>$$\\begin{pmatrix}<br>  1/\\sqrt{2} \\\\\\<br>  1/\\sqrt{2}<br>\\end{pmatrix},\\begin{pmatrix}<br>  -1/\\sqrt{2} \\\\\\<br>  1/\\sqrt{2}<br>\\end{pmatrix}$$<br>因此我们的矩阵P是：<br>$$P=\\begin{pmatrix}<br>  1/\\sqrt{2}  &amp; 1/\\sqrt{2}  \\\\\\<br>  -1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}$$<br>最后我们用P的第一行乘以数据矩阵，就得到了降维后的表示：<br>$$Y=\\begin{pmatrix}<br>  1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}\\begin{pmatrix}<br>  -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>  -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1<br>\\end{pmatrix}=\\begin{pmatrix}<br>  -3/\\sqrt{2} &amp; -1/\\sqrt{2} &amp; 0 &amp; 3/\\sqrt{2} &amp; -1/\\sqrt{2}<br>\\end{pmatrix}$$<br>可以验证协方差矩阵C的对角化：<br>$$PCP^\\mathsf{T}=\\begin{pmatrix}<br>  1/\\sqrt{2}  &amp; 1/\\sqrt{2}  \\\\\\<br>  -1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}\\begin{pmatrix}<br>  6/5 &amp; 4/5 \\\\\\<br>  4/5 &amp; 6/5<br>\\end{pmatrix}\\begin{pmatrix}<br>  1/\\sqrt{2} &amp; -1/\\sqrt{2}  \\\\\\<br>  1/\\sqrt{2} &amp; 1/\\sqrt{2}<br>\\end{pmatrix}=\\begin{pmatrix}<br>  2 &amp; 0  \\\\\\<br>  0 &amp; 2/5<br>\\end{pmatrix}$$<br><img src=\"02.png\" alt></p>\n<h3 id=\"C-实现\"><a href=\"#C-实现\" class=\"headerlink\" title=\"C++实现\"></a>C++实现</h3><p>因为要对一组图片信息进行训练，所以我写了一部分通过摄像头截取图片帧的代码，<code>get_img()</code>函数。这里提取了5个特征脸和一个均值脸</p>\n<pre><code class=\"cpp\">#include &lt;opencv2/core/core.hpp&gt;\n#include &lt;opencv2/highgui/highgui.hpp&gt;\n#include &lt;opencv2/imgproc/imgproc.hpp&gt;\n#include &lt;opencv2/objdetect/objdetect.hpp&gt;\n\n#include &lt;iostream&gt;\n#include &lt;fstream&gt;\n#include &lt;sstream&gt;\n#define img_num 300 //训练图片的张数\nusing namespace cv;\nusing namespace std;\n//通过摄像头保存要训练的图片\n\n//打开摄像头\nint get_img(){\n  VideoCapture cap(0);\n  if(!cap.isOpened())\n  {\n    return -1;\n  }\n  Mat frame;\n  bool stop = false;\n  int i = 1;\n  while(!stop){\n    cap &gt;&gt; frame;\n    printf(&quot;%d\\n&quot;, i);\n    if (frame.empty())\n      stop = true;\n    //string filename = format(&quot;%d.jpg&quot;, i);\n    char filename[20];\n    sprintf(filename, &quot;Img/%d.jpg&quot;, i);\n    imwrite(filename, frame);\n    i++;\n    imshow(&quot;frame&quot;, frame);\n    waitKey(30);\n    if(i &gt; img_num)\n      break;\n\n  }\nreturn -1;\n\n}\n//把图像归一化为0-255\nMat norm_0_255(const Mat&amp; src){\n  Mat dst;\n  switch(src.channels()){\n    case 1:\n        cv::normalize(src, dst, 0, 255, NORM_MINMAX, CV_8UC1);\n        break;\n    case 3:\n        cv::normalize(src, dst, 0, 255, NORM_MINMAX, CV_8UC3);\n        break;\n    default:\n        src.copyTo(dst);\n        break;\n  }\n  return dst;\n}\n\n//将给定的图像转化为行矩阵\nMat asRowMatrix(const vector&lt;Mat&gt;&amp; src, int rtype, double alpha = 1, double beta = 0){\n  // 样本数量\n  size_t n = src.size();\n  //没有样本，返回空矩阵\n  if (n == 0)\n    return Mat();\n\n  //样本的维数\n  size_t d = src[0].total();\n\n  Mat data(n, d, rtype);\n\n  //拷贝数据\n  for (int i = 0; i &lt; n; i++){\n    if(src[i].empty()){\n      string error_message = format(&quot;Image number %d was empty, please check your input data.&quot;, i);\n      CV_Error(CV_StsBadArg, error_message);\n    }\n\n    //确保数据能被reshape\n    if(src[i].total() != d){\n      string error_message = format(&quot;Wrong number of elements in matrix #%d! Expected %d was %d.&quot;, i, d, src[i].total());\n      CV_Error(CV_StsBadArg, error_message);\n    }\n    Mat xi = data.row(i);\n    //转化为1行，n列的格式\n    if(src[i].isContinuous()){\n      src[i].reshape(1, 1).convertTo(xi, rtype, alpha, beta);\n    }\n    else {\n      src[i].clone().reshape(1, 1).convertTo(xi, rtype, alpha, beta);\n    }\n  }\n  return data;\n}\n\nint main(int argc, const char* argv[]){\n  vector&lt;Mat&gt; db;\n  //get_img();\n  for(int i=1; i&lt;img_num;i++){\n\n    string filename = format(&quot;Img/%d.jpg&quot;, i);\n    db.push_back(imread(filename, IMREAD_GRAYSCALE));\n  }\n  // Build a matrix with the observations in row:\n    Mat data = asRowMatrix(db, CV_32FC1);\n\n    // PCA算法保持5主成分分量\n    int num_components = 5;\n\n    //执行pca算法\n    PCA pca(data, Mat(), CV_PCA_DATA_AS_ROW, num_components);\n\n    //copy  pca算法结果\n    Mat mean = pca.mean.clone();\n    Mat eigenvalues = pca.eigenvalues.clone();\n    Mat eigenvectors = pca.eigenvectors.clone();\n        //均值脸\n    imshow(&quot;avg&quot;, norm_0_255(mean.reshape(1, db[0].rows)));\n\n    //五个特征脸\n    imshow(&quot;pc1&quot;, norm_0_255(pca.eigenvectors.row(0)).reshape(1, db[0].rows));\n    imshow(&quot;pc2&quot;, norm_0_255(pca.eigenvectors.row(1)).reshape(1, db[0].rows));\n    imshow(&quot;pc3&quot;, norm_0_255(pca.eigenvectors.row(2)).reshape(1, db[0].rows));\n    imshow(&quot;pc4&quot;, norm_0_255(pca.eigenvectors.row(3)).reshape(1, db[0].rows));\n    imshow(&quot;pc5&quot;, norm_0_255(pca.eigenvectors.row(4)).reshape(1, db[0].rows));\n\n    while(1)\n        waitKey(0);\n\n    // Success!\n    return 0;\n\n}</code></pre>\n<p><img src=\"01.png\" alt></p>\n"},{"title":"hexo大坑","date":"2019-07-22T09:20:52.000Z","cover":false,"img":"https://i.loli.net/2019/07/22/5d358d83b3a0315599.png","_content":"\n## 坑一、Template render error 模板渲染错误\n写了一下午博文，高高兴兴地hexo g却发现报错了！   \n`INFO  Start processing\nFATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\nNunjucks Error:  [Line 2, Column 6] unexpected token: }}\n at formatNunjucksError (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:102:13)\n    at Promise.fromCallback.catch.err (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:124:34)\n    at tryCatcher (/home/kevin/blog/node_modules/bluebird/js/release/util.js:16:23)\n    at Promise._settlePromiseFromHandler (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:517:31)\n    at Promise._settlePromise (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:574:18)\n    at Promise._settlePromise0 (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:619:10)\n    at Promise._settlePromises (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:695:18)\n    at _drainQueueStep (/home/kevin/blog/node_modules/bluebird/js/release/async.js:138:12)\n    at _drainQueue (/home/kevin/blog/node_modules/bluebird/js/release/async.js:131:9)\n    at Async._drainQueues (/home/kevin/blog/node_modules/bluebird/js/release/async.js:147:5)\n    at Immediate.Async.drainQueues [as _onImmediate] (/home/kevin/blog/node_modules/bluebird/js/release/async.js:17:14)\n    at processImmediate (internal/timers.js:443:21)`\n    \n原因是nunjucks模板标签导致MD文件解析报错的问题，我试验了一下，在md文档中出现`双大括号`,`左大括号+#`,`左大括号+%`等都会报错(原谅我这么打，因为我打出来符号的话这篇博客就发不出来了)，下面是一位大神的[解决办法](http://xcoding.tech/2018/08/08/hexo/%E5%A6%82%E4%BD%95%E4%BB%8E%E6%A0%B9%E6%9C%AC%E8%A7%A3%E5%86%B3hexo%E4%B8%8D%E5%85%BC%E5%AE%B9%7B%7B%7D%7D%E6%A0%87%E7%AD%BE%E9%97%AE%E9%A2%98/)，他提供了几种解决办法，讲的很详细，可以参考一下\n\n我觉得有点麻烦就没采用(说多了就是菜～),下面是我的办法:\n1. 既然出现上面的内容就会报错，那就尽量避免出现呗...(说的都是废话)\n2. 使用`\\lbrace`代替`\\{`,使用`\\rbrace`代替`\\}`\n推荐大神的解决办法，一劳永逸，以后就不用管了\n\n\n## 坑二、Markdown的空行\n在写表格的时候要把表格体前后各空一行，不然你写的表格是这样式儿的，崩溃啊！\n![](https://i.loli.net/2019/07/22/5d358cfee55f989745.png)\n\n有可能是hexo解析的问题，我在使用markdown-preview的时候看的是正常的\n","source":"_posts/hexo大坑.md","raw":"---\ntitle: hexo大坑\ndate: 2019-07-22 17:20:52\ntags: hexo\ncover: false\nimg: https://i.loli.net/2019/07/22/5d358d83b3a0315599.png\n---\n\n## 坑一、Template render error 模板渲染错误\n写了一下午博文，高高兴兴地hexo g却发现报错了！   \n`INFO  Start processing\nFATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\nNunjucks Error:  [Line 2, Column 6] unexpected token: }}\n at formatNunjucksError (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:102:13)\n    at Promise.fromCallback.catch.err (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:124:34)\n    at tryCatcher (/home/kevin/blog/node_modules/bluebird/js/release/util.js:16:23)\n    at Promise._settlePromiseFromHandler (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:517:31)\n    at Promise._settlePromise (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:574:18)\n    at Promise._settlePromise0 (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:619:10)\n    at Promise._settlePromises (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:695:18)\n    at _drainQueueStep (/home/kevin/blog/node_modules/bluebird/js/release/async.js:138:12)\n    at _drainQueue (/home/kevin/blog/node_modules/bluebird/js/release/async.js:131:9)\n    at Async._drainQueues (/home/kevin/blog/node_modules/bluebird/js/release/async.js:147:5)\n    at Immediate.Async.drainQueues [as _onImmediate] (/home/kevin/blog/node_modules/bluebird/js/release/async.js:17:14)\n    at processImmediate (internal/timers.js:443:21)`\n    \n原因是nunjucks模板标签导致MD文件解析报错的问题，我试验了一下，在md文档中出现`双大括号`,`左大括号+#`,`左大括号+%`等都会报错(原谅我这么打，因为我打出来符号的话这篇博客就发不出来了)，下面是一位大神的[解决办法](http://xcoding.tech/2018/08/08/hexo/%E5%A6%82%E4%BD%95%E4%BB%8E%E6%A0%B9%E6%9C%AC%E8%A7%A3%E5%86%B3hexo%E4%B8%8D%E5%85%BC%E5%AE%B9%7B%7B%7D%7D%E6%A0%87%E7%AD%BE%E9%97%AE%E9%A2%98/)，他提供了几种解决办法，讲的很详细，可以参考一下\n\n我觉得有点麻烦就没采用(说多了就是菜～),下面是我的办法:\n1. 既然出现上面的内容就会报错，那就尽量避免出现呗...(说的都是废话)\n2. 使用`\\lbrace`代替`\\{`,使用`\\rbrace`代替`\\}`\n推荐大神的解决办法，一劳永逸，以后就不用管了\n\n\n## 坑二、Markdown的空行\n在写表格的时候要把表格体前后各空一行，不然你写的表格是这样式儿的，崩溃啊！\n![](https://i.loli.net/2019/07/22/5d358cfee55f989745.png)\n\n有可能是hexo解析的问题，我在使用markdown-preview的时候看的是正常的\n","slug":"hexo大坑","published":1,"updated":"2019-08-10T10:47:34.326Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lu0001ue5g6721u7vyn","content":"<h2 id=\"坑一、Template-render-error-模板渲染错误\"><a href=\"#坑一、Template-render-error-模板渲染错误\" class=\"headerlink\" title=\"坑一、Template render error 模板渲染错误\"></a>坑一、Template render error 模板渲染错误</h2><p>写了一下午博文，高高兴兴地hexo g却发现报错了！<br><code>INFO  Start processing\nFATAL Something&#39;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\nNunjucks Error:  [Line 2, Column 6] unexpected token: }}\n at formatNunjucksError (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:102:13)\n    at Promise.fromCallback.catch.err (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:124:34)\n    at tryCatcher (/home/kevin/blog/node_modules/bluebird/js/release/util.js:16:23)\n    at Promise._settlePromiseFromHandler (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:517:31)\n    at Promise._settlePromise (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:574:18)\n    at Promise._settlePromise0 (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:619:10)\n    at Promise._settlePromises (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:695:18)\n    at _drainQueueStep (/home/kevin/blog/node_modules/bluebird/js/release/async.js:138:12)\n    at _drainQueue (/home/kevin/blog/node_modules/bluebird/js/release/async.js:131:9)\n    at Async._drainQueues (/home/kevin/blog/node_modules/bluebird/js/release/async.js:147:5)\n    at Immediate.Async.drainQueues [as _onImmediate] (/home/kevin/blog/node_modules/bluebird/js/release/async.js:17:14)\n    at processImmediate (internal/timers.js:443:21)</code></p>\n<p>原因是nunjucks模板标签导致MD文件解析报错的问题，我试验了一下，在md文档中出现<code>双大括号</code>,<code>左大括号+#</code>,<code>左大括号+%</code>等都会报错(原谅我这么打，因为我打出来符号的话这篇博客就发不出来了)，下面是一位大神的<a href=\"http://xcoding.tech/2018/08/08/hexo/%E5%A6%82%E4%BD%95%E4%BB%8E%E6%A0%B9%E6%9C%AC%E8%A7%A3%E5%86%B3hexo%E4%B8%8D%E5%85%BC%E5%AE%B9%7B%7B%7D%7D%E6%A0%87%E7%AD%BE%E9%97%AE%E9%A2%98/\" target=\"_blank\" rel=\"noopener\">解决办法</a>，他提供了几种解决办法，讲的很详细，可以参考一下</p>\n<p>我觉得有点麻烦就没采用(说多了就是菜～),下面是我的办法:</p>\n<ol>\n<li>既然出现上面的内容就会报错，那就尽量避免出现呗…(说的都是废话)</li>\n<li>使用<code>\\lbrace</code>代替<code>\\{</code>,使用<code>\\rbrace</code>代替<code>\\}</code><br>推荐大神的解决办法，一劳永逸，以后就不用管了</li>\n</ol>\n<h2 id=\"坑二、Markdown的空行\"><a href=\"#坑二、Markdown的空行\" class=\"headerlink\" title=\"坑二、Markdown的空行\"></a>坑二、Markdown的空行</h2><p>在写表格的时候要把表格体前后各空一行，不然你写的表格是这样式儿的，崩溃啊！<br><img src=\"https://i.loli.net/2019/07/22/5d358cfee55f989745.png\" alt></p>\n<p>有可能是hexo解析的问题，我在使用markdown-preview的时候看的是正常的</p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h2 id=\"坑一、Template-render-error-模板渲染错误\"><a href=\"#坑一、Template-render-error-模板渲染错误\" class=\"headerlink\" title=\"坑一、Template render error 模板渲染错误\"></a>坑一、Template render error 模板渲染错误</h2><p>写了一下午博文，高高兴兴地hexo g却发现报错了！<br><code>INFO  Start processing\nFATAL Something&#39;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\nNunjucks Error:  [Line 2, Column 6] unexpected token: }}\n at formatNunjucksError (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:102:13)\n    at Promise.fromCallback.catch.err (/home/kevin/blog/node_modules/hexo/lib/extend/tag.js:124:34)\n    at tryCatcher (/home/kevin/blog/node_modules/bluebird/js/release/util.js:16:23)\n    at Promise._settlePromiseFromHandler (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:517:31)\n    at Promise._settlePromise (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:574:18)\n    at Promise._settlePromise0 (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:619:10)\n    at Promise._settlePromises (/home/kevin/blog/node_modules/bluebird/js/release/promise.js:695:18)\n    at _drainQueueStep (/home/kevin/blog/node_modules/bluebird/js/release/async.js:138:12)\n    at _drainQueue (/home/kevin/blog/node_modules/bluebird/js/release/async.js:131:9)\n    at Async._drainQueues (/home/kevin/blog/node_modules/bluebird/js/release/async.js:147:5)\n    at Immediate.Async.drainQueues [as _onImmediate] (/home/kevin/blog/node_modules/bluebird/js/release/async.js:17:14)\n    at processImmediate (internal/timers.js:443:21)</code></p>\n<p>原因是nunjucks模板标签导致MD文件解析报错的问题，我试验了一下，在md文档中出现<code>双大括号</code>,<code>左大括号+#</code>,<code>左大括号+%</code>等都会报错(原谅我这么打，因为我打出来符号的话这篇博客就发不出来了)，下面是一位大神的<a href=\"http://xcoding.tech/2018/08/08/hexo/%E5%A6%82%E4%BD%95%E4%BB%8E%E6%A0%B9%E6%9C%AC%E8%A7%A3%E5%86%B3hexo%E4%B8%8D%E5%85%BC%E5%AE%B9%7B%7B%7D%7D%E6%A0%87%E7%AD%BE%E9%97%AE%E9%A2%98/\" target=\"_blank\" rel=\"noopener\">解决办法</a>，他提供了几种解决办法，讲的很详细，可以参考一下</p>\n<p>我觉得有点麻烦就没采用(说多了就是菜～),下面是我的办法:</p>\n<ol>\n<li>既然出现上面的内容就会报错，那就尽量避免出现呗…(说的都是废话)</li>\n<li>使用<code>\\lbrace</code>代替<code>\\{</code>,使用<code>\\rbrace</code>代替<code>\\}</code><br>推荐大神的解决办法，一劳永逸，以后就不用管了</li>\n</ol>\n<h2 id=\"坑二、Markdown的空行\"><a href=\"#坑二、Markdown的空行\" class=\"headerlink\" title=\"坑二、Markdown的空行\"></a>坑二、Markdown的空行</h2><p>在写表格的时候要把表格体前后各空一行，不然你写的表格是这样式儿的，崩溃啊！<br><img src=\"https://i.loli.net/2019/07/22/5d358cfee55f989745.png\" alt></p>\n<p>有可能是hexo解析的问题，我在使用markdown-preview的时候看的是正常的</p>\n"},{"title":"实习第一周","date":"2019-07-14T08:43:59.000Z","_content":"\n### 先P一下第一周要学到的技术栈：\n\n1. 图形变换\n2. 空间滤波\n3. 卷积、傅里叶变换\n4. 边缘滤波\n5. 二维离散及其反变换\n6. 各种滤波器的原理\n7. MatLab代码实现\n\n\n","source":"_posts/实习第一周.md","raw":"---\ntitle: 实习第一周\ndate: 2019-07-14 16:43:59\n\ntags:\n---\n\n### 先P一下第一周要学到的技术栈：\n\n1. 图形变换\n2. 空间滤波\n3. 卷积、傅里叶变换\n4. 边缘滤波\n5. 二维离散及其反变换\n6. 各种滤波器的原理\n7. MatLab代码实现\n\n\n","slug":"实习第一周","published":1,"updated":"2019-08-10T10:47:34.326Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lu1001xe5g6pn7b61ca","content":"<h3 id=\"先P一下第一周要学到的技术栈：\"><a href=\"#先P一下第一周要学到的技术栈：\" class=\"headerlink\" title=\"先P一下第一周要学到的技术栈：\"></a>先P一下第一周要学到的技术栈：</h3><ol>\n<li>图形变换</li>\n<li>空间滤波</li>\n<li>卷积、傅里叶变换</li>\n<li>边缘滤波</li>\n<li>二维离散及其反变换</li>\n<li>各种滤波器的原理</li>\n<li>MatLab代码实现</li>\n</ol>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h3 id=\"先P一下第一周要学到的技术栈：\"><a href=\"#先P一下第一周要学到的技术栈：\" class=\"headerlink\" title=\"先P一下第一周要学到的技术栈：\"></a>先P一下第一周要学到的技术栈：</h3><ol>\n<li>图形变换</li>\n<li>空间滤波</li>\n<li>卷积、傅里叶变换</li>\n<li>边缘滤波</li>\n<li>二维离散及其反变换</li>\n<li>各种滤波器的原理</li>\n<li>MatLab代码实现</li>\n</ol>\n"},{"title":"实习第二周","date":"2019-07-21T09:34:19.000Z","_content":"\n# 第二周：\n1. 图像分割\n2. 点 线边缘检测\n3. 各种边缘检测算子\n4. 霍夫变换\n5. 实现基于霍夫变换的原型检测及计数\n6. 完成椭圆检测项目\n","source":"_posts/实习第二周.md","raw":"---\ntitle: 实习第二周\ndate: 2019-07-21 17:34:19\ntags:\n---\n\n# 第二周：\n1. 图像分割\n2. 点 线边缘检测\n3. 各种边缘检测算子\n4. 霍夫变换\n5. 实现基于霍夫变换的原型检测及计数\n6. 完成椭圆检测项目\n","slug":"实习第二周","published":1,"updated":"2019-08-10T10:47:34.326Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lu20020e5g6mo57ljhs","content":"<h1 id=\"第二周：\"><a href=\"#第二周：\" class=\"headerlink\" title=\"第二周：\"></a>第二周：</h1><ol>\n<li>图像分割</li>\n<li>点 线边缘检测</li>\n<li>各种边缘检测算子</li>\n<li>霍夫变换</li>\n<li>实现基于霍夫变换的原型检测及计数</li>\n<li>完成椭圆检测项目</li>\n</ol>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<h1 id=\"第二周：\"><a href=\"#第二周：\" class=\"headerlink\" title=\"第二周：\"></a>第二周：</h1><ol>\n<li>图像分割</li>\n<li>点 线边缘检测</li>\n<li>各种边缘检测算子</li>\n<li>霍夫变换</li>\n<li>实现基于霍夫变换的原型检测及计数</li>\n<li>完成椭圆检测项目</li>\n</ol>\n"},{"title":"PCA原理分析","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2019-08-05T07:22:19.000Z","password":null,"summary":"PCA的数学原理","_content":"参考资料\n[PCA原理分析](PCA.pdf)\n# PCA的数学原理\nPCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。\n\n## 数据的向量表示以及降维问题\n\n一般情况下，在数据挖掘和机器学习中，数据被表示为向量。例如某个外卖商家2018年全年的流量及交易记录可以看成是一组数据的集合，其中每一天的数据是一条记录。记录的格式如下:    \n(日期, 浏览量，访客数，下单数，成交数，成交金额)    \n其中\"日期\"是一个记录标志而非度量值，而数据挖掘关心的大多是度量值，因此如果我们忽略日期这个字段后，我们得到一组记录，每条记录可以被表示为一个五维向量，其中一条看起来大约是这个样子：    \n$$(1000, 580, 300, 240, 3000)^T$$\n注意这里用了转置，习惯上使用列向量来表示一条记录。本文说到的向量默认都是列向量。    \n\n我们当然可以对这一组五维向量进行分析和挖掘，不过很多机器学习算法的复杂度和数据的维数有着密切关系，甚至与维数呈指数级关联。当然，这里区区五维的数据，也许还无所谓，但是实际机器学习中处理成千上万甚至几十万维的情况也并不罕见，在这种情况下，机器学习的资源消耗是不可接受的，因此我们必须对数据进行降维。\n\n降维当然意味着信息的丢失，不过鉴于实际数据本身常常存在的相关性，我们可以想办法在降维的同时将信息的损失尽量降低。    \n\n举一个例子，假如某学籍数据有两列M和F，其中M列的取值是如何此学生为男性取值1，为女性取值0；而F列是学生为女性取值1，男性取值0。此时如果我们统计全部学籍数据，会发现对于任何一条记录来说，当M为1时F必定为0，反之当M为0时F必定为1。在这种情况下，我们将M或F去掉实际上没有任何信息的损失，因为只要保留一列就可以完全还原另一列。    \n当然上面是一个极端的情况，在现实中也许不会出现，不过类似的情况还是很常见的。例如上面淘宝店铺的数据，从经验我们可以知道，“浏览量”和“访客数”往往具有较强的相关关系，而“下单数”和“成交数”也具有较强的相关关系。这里我们非正式的使用“ **相关关系**”这个词，可以直观理解为“当某一天这个店铺的浏览量较高（或较低）时，我们应该很大程度上认为这天的访客数也较高（或较低）”。    \n这种情况表明，如果我们删除浏览量或访客数其中一个指标，我们应该期待并不会丢失太多信息。因此我们可以删除一个，以降低机器学习算法的复杂度。    \n\n上面给出的是降维的朴素思想描述，可以有助于直观理解降维的动机和可行性，但并不具有操作指导意义。例如，我们到底删除哪一列损失的信息才最小？亦或根本不是单纯删除几列，而是通过某些变换将原始数据变为更少的列但又使得丢失的信息最小？到底如何度量丢失信息的多少？如何根据原始数据决定具体的降维操作步骤？下面对降维问题进行数学化和形式化的讨论\n\n## 向量的表示及基变换\n\n### 内积与投影\n\n下面先来看一个高中就学过的向量运算：内积。两个维数相同的向量的内积被定义为：\n\n$$(a_1, a_2, \\dots ,a_n)^T \\cdot (b_1, b_2, \\dots , b_n)^T = a_1b_1 + a_2b_2 + \\dots + a_nb_n)$$\n内积运算将两个向量映射为一个实数。其计算方式非常容易理解，但是其意义并不明显。下面我们分析内积的几何意义。假设A和B是两个n维向量，我们知道n维向量可以等价表示为n维空间中的一条从原点发射的有向线段，为了简单起见我们假设A和B均为二维向量,则 $A = (x_1,y_1)$, $B = (x_2,y_2)$. 则在二维平面上A和B可以用两条发自原点的有向线段表示，见下图：\n![](01.png)\n好，现在我们从A点向B所在直线引一条垂线。我们知道垂线与B的交点叫做A在B上的投影，再设A与B的夹角是a，则投影的矢量长度为|A|cos(a),其中 $|A| = \\sqrt{x_1^2 + y_1^2}$ 是向量A的模，也就是A线段的标量长度。    \n注意这里我们专门区分了矢量长度和标量长度，标量长度总是大于等于0，值就是线段的长度；而矢量长度可能为负，其绝对值是线段长度，而符号取决于其方向与标准方向相同或相反。    \n到这里还是看不出内积和这东西有什么关系，不过如果我们将内积表示为另一种我们熟悉的形式：\n$$ A \\cdot B = |A||B|cos(a)$$\n\n现在事情似乎是有点眉目了：A与B的内积等于A到B的投影长度乘以B的模。再进一步，如果我们假设B的模为1，即让|B|=1，那么就变成了：\n$$A \\cdot B = |A|cos(a)$$\n也就是说， **设向量B的模为1，则A与B的内积值等于A向B所在直线投影的矢量长度！**这就是内积的一种几何解释，也是我们得到的第一个重要结论。在后面的推导中，将反复使用这个结论。\n\n### 基\n下面我们继续在二维空间内讨论向量。上文说过，一个二维向量可以对应二维笛卡尔直角坐标系中从原点出发的一个有向线段。例如下面这个向量：\n![](02.png)\n在代数表示方面，我们经常用线段终点的点坐标表示向量，例如上面的向量可以表示为(3,2)，这是我们再熟悉不过的向量表示。    \n不过我们常常忽略， **只有一个(3,2)本身是不能够精确表示一个向量的**。我们仔细看一下，这里的3实际表示的是向量在x轴上的投影值是3，在y轴上的投影值是2。也就是说我们其实隐式引入了一个定义：以x轴和y轴上正方向长度为1的向量为标准。那么一个向量(3,2)实际是说在x轴投影为3而y轴的投影为2。注意投影是一个矢量，所以可以为负。    \n更正式的说，向量(x,y)实际上表示线性组合：\n$$x(1,0)^T + y(0,1)^T$$\n不难证明所有二维向量都可以表示为这样的线性组合。此处(1,0)和(0,1)叫做二维空间中的一组基。\n![](03.png)\n所以， **要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了**。只不过我们经常省略第一步，而默认以(1,0)和(0,1)为基。    \n我们之所以默认选择(1,0)和(0,1)为基，当然是比较方便，因为它们分别是x和y轴正方向上的单位向量，因此就使得二维平面上点坐标和向量一一对应，非常方便。但实际上任何两个线性无关的二维向量都可以成为一组基，所谓线性无关在二维平面内可以直观认为是两个不在一条直线上的向量。    \n\n例如，(1,1)和(-1,1)也可以成为一组基。一般来说，我们希望基的模是1，因为从内积的意义可以看到，如果基的模是1，那么就可以方便的用向量点乘基而直接获得其在新基上的坐标了！实际上，对应任何一个向量我们总可以找到其同方向上模为1的向量，只要让两个分量分别除以模就好了。例如，上面的基可以变为 $(\\frac{1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$ 和 $(\\frac{-1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$.    \n现在，我们想获得(3,2)在新基上的坐标，即在两个方向上的投影矢量值，那么根据内积的几何意义，我们只要分别计算(3,2)和两个基的内积，不难得到新的坐标为 $(\\frac{5}{\\sqrt 2},\\frac{-1}{\\sqrt 2})$。下图给出了新的基以及(3,2)在新基上坐标值的示意图：\n![](05.png)\n一要求就是线性无关，非正交的基也是可以的。不过因为正交基有较好的性质，所以一般使用的基都是正交的。\n\n### 基变换的矩阵表示\n\n下面我们找一种简便的方式来表示基变换。还是拿上面的例子，想一下，将(3,2)变换为新基上的坐标，就是用(3,2)与第一个基做内积运算，作为第一个新的坐标分量，然后用(3,2)与第二个基做内积运算，作为第二个新坐标的分量。实际上，我们可以用矩阵相乘的形式简洁的表示这个变换：\n$$\\begin{pmatrix} \n1/ \\sqrt 2 & 1/ \\sqrt 2 \\\\\\\\\n-1/ \\sqrt 2 & 1/ \\sqrt 2 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n3 \\\\\\\\\n2 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n5 / \\sqrt 2 \\\\\\\\\n-1/ \\sqrt 2 \\\\\n\\end{pmatrix}$$\n\n太漂亮了！其中矩阵的两行分别为两个基，乘以原向量，其结果刚好为新基的坐标。可以稍微推广一下，如果我们有m个二维向量，只要将二维向量按列排成一个两行m列矩阵，然后用“基矩阵”乘以这个矩阵，就得到了所有这些向量在新基下的值。例如 $(1,1)，(2,2)，(3,3)$，想变换到刚才那组基上，则可以这样表示：\n\n$$\\begin{pmatrix}\n1 / \\sqrt 2 & 1/ \\sqrt 2 \\\\\\\\\n-1 / \\sqrt 2 & 1/ \\sqrt 2 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 2 & 3 \\\\\\\\\n1 & 2 & 3 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n2 / \\sqrt 2 & 4 / \\sqrt 2 & 6 / \\sqrt 2 \\\\\\\\\n0 & 0 & 0 \\\\\n\\end{pmatrix}$$\n\n于是一组向量的基变换被干净的表示为矩阵的相乘。    \n**一般的，如果我们有M个N维向量，想将其变换为由R个N维向量表示的新空间中，那么首先将R个基按行组成矩阵A，然后将向量按列组成矩阵B，那么两矩阵的乘积AB就是变换结果，其中AB的第m列为A中第m列变换后的结果。**    \n数学表示为：\n$$\\begin{pmatrix}\np_1 \\\\\\\\\np_2 \\\\\\\\\n\\vdots \\\\\\\\\np_R \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\na_1 & a_2 & \\dots & a_M \\\\\n\\end{pmatrix} = \\begin{pmatrix}\np_1a_1 & p_1a_2 & \\dots & p_1a_M \\\\\\\\\np_2a_1 & p_2a_2 & \\dots & p_2a_M \\\\\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\\np_Ra_1 & p_Ra_2 & \\dots & p_Ra_M \\\\\n\\end{pmatrix}$$\n其中 $p_i$是一个行向量，表示第i个基， $a_j$是一个列向量，表示第j个原始数据记录。    \n特别要注意的是，这里R可以小于N，而R决定了变换后数据的维数。也就是说，我们可以将一N维数据变换到更低维度的空间中去，变换后的维度取决于基的数量。因此这种矩阵相乘的表示也可以表示降维变换。    \n最后，上述分析同时给矩阵相乘找到了一种物理解释： **两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去**。更抽象的说，一个矩阵可以表示一种线性变换。很多同学在学线性代数时对矩阵相乘的方法感到奇怪，但是如果明白了矩阵相乘的物理意义，其合理性就一目了然了。    \n\n### 协方差矩阵及优化目标\n\n上面我们讨论了选择不同的基可以对同样一组数据给出不同的表示，而且如果基的数量少于向量本身的维数，则可以达到降维的效果。但是我们还没有回答一个最最关键的问题：如何选择基才是最优的。或者说，如果我们有一组N维向量，现在要将其降到K维（K小于N），那么我们应该如何选择K个基才能最大程度保留原有的信息？    \n要完全数学化这个问题非常繁杂，这里我们用一种非形式化的直观方法来看这个问题。\n\n为了避免过于抽象的讨论，我们仍以一个具体的例子展开。假设我们的数据由五条记录组成，将它们表示成矩阵形式：\n$$ \\begin{pmatrix}\n1 & 1 &2 & 4 & 2 \\\\\\\\\n1 & 3 & 3 & 4 & 4 \\\\\n\\end{pmatrix}$$\n其中每一列为一条数据记录，而一行为一个字段。为了后续处理方便，我们首先将每个字段内所有值都减去字段均值，其结果是将每个字段都变为均值为0（这样做的道理和好处后面会看到）。    \n我们看上面的数据，第一个字段均值为2，第二个字段均值为3，所以变换后：\n$$ \\begin{pmatrix}\n-1 & -1 & 0 & 2 & 0 \\\\\\\\\n-2 & 0 & 0 & 1 & 1 \\\\\n\\end{pmatrix}$$\n我们可以看下五条数据在平面直角坐标系内的样子：\n![](06.png)\n现在问题来了：如果我们必须使用一维来表示这些数据，又希望尽量保留原始的信息，你要如何选择？    \n\n通过上一节对基变换的讨论我们知道，这个问题实际上是要在二维平面中选择一个方向，将所有数据都投影到这个方向所在直线上，用投影值表示原始记录。这是一个实际的二维降到一维的问题。    \n\n那么如何选择这个方向（或者说基）才能尽量保留最多的原始信息呢？一种直观的看法是：希望投影后的投影值尽可能分散。    \n\n以上图为例，可以看出如果向x轴投影，那么最左边的两个点会重叠在一起，中间的两个点也会重叠在一起，于是本身四个各不相同的二维点投影后只剩下两个不同的值了，这是一种严重的信息丢失，同理，如果向y轴投影最上面的两个点和分布在x轴上的两个点也会重叠。所以看来x和y轴都不是最好的投影选择。我们直观目测，如果向通过第一象限和第三象限的斜线投影，则五个点在投影后还是可以区分的。    \n下面，我们用数学方法表述这个问题。\n\n### 方差\n\n上文说到，我们希望投影后投影值尽可能分散，而这种分散程度，可以用数学上的方差来表述。此处，一个字段的方差可以看做是每个元素与字段均值的差的平方和的均值，即：\n$$Var(a)=\\frac{1}{m} \\sum_{i=1}^{m}(a_i- \\mu)^2$$\n由于上面我们已经将每个字段的均值都化为0了，因此方差可以直接用每个元素的平方和除以元素个数表示：\n$$Var(a) = \\frac{1}{m} \\sum_{i=1}^{m}a_i^2$$\n于是上面的问题被形式化表述为：寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。    \n\n### 协方差\n对于上面二维降成一维的问题来说，找到那个使得方差最大的方向就可以了。不过对于更高维，还有一个问题需要解决。考虑三维降到二维问题。与之前相同，首先我们希望找到一个方向使得投影后方差最大，这样就完成了第一个方向的选择，继而我们选择第二个投影方向。    \n如果我们还是单纯只选择方差最大的方向，很明显，这个方向与第一个方向应该是“几乎重合在一起”，显然这样的维度是没有用的，因此，应该有其他约束条件。从直观上说，让两个字段尽可能表示更多的原始信息，我们是不希望它们之间存在（线性）相关性的，因为相关性意味着两个字段不是完全独立，必然存在重复表示的信息。    \n数学上可以用两个字段的协方差表示其相关性，由于已经让每个字段均值为0，则：\n$$Cov(a,b)=\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i$$\n可以看到，在字段均值为0的情况下，两个字段的协方差简洁的表示为其内积除以元素数m。\n\n当协方差为0时，表示两个字段完全独立。为了让协方差为0，我们选择第二个基时只能在与第一个基正交的方向上选择。因此最终选择的两个方向一定是正交的。\n\n至此，我们得到了降维问题的优化目标：**将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）**。\n\n### 协方差矩阵\n\n上面我们导出了优化目标，但是这个目标似乎不能直接作为操作指南（或者说算法），因为它只说要什么，但根本没有说怎么做。所以我们要继续在数学上研究计算方案。\n\n我们看到，最终要达到的目的与字段内方差及字段间协方差有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们来了灵感：\n\n假设我们只有a和b两个字段，那么我们将它们按行组成矩阵X：\n\n$$ X = \\begin{pmatrix}\na_1 & a_2 & \\dots & a_m \\\\\\\\\nb_1 & b_2 & \\dots & b_m \\\\\n\\end{pmatrix}$$\n然后我们用X乘以X的转置，并乘上系数 $\\frac{1}{m}$：\n$$\\frac{1}{m} \\begin{pmatrix}\n\\frac{1}{m} \\sum_{i=1}^{m}a_i^2 & \\frac{1}{m} \\sum_{i=1}^{m}a_ib_i \\\\\\\\\n\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i & \\frac{1}{m} \\sum_{i=1}^{m}b_i^2 \\\\\n\\end{pmatrix}$$\n\n奇迹出现了！这个矩阵对角线上的两个元素分别是两个字段的方差，而其它元素是a和b的协方差。两者被统一到了一个矩阵的。\n\n根据矩阵相乘的运算法则，这个结论很容易被推广到一般情况：\n\n**设我们有m个n维数据记录，将其按列排成n乘m的矩阵X，设 $C = \\frac{1}{m}XX^T$,则C是一个对称矩阵，其对角线分别个各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。**\n\n### 协方差矩阵对角化\n\n根据上述推导，我们发现要达到优化目前，等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将元素按大小从上到下排列，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系：\n\n设原始数据矩阵X对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，我们推导一下D与C的关系：\n$$\\begin{align}\nD &= \\frac{1}{m}YY^T \\\\\\\\\n  &= \\frac{1}{m}(PX)(PX)^T \\\\\\\\\n  &= \\frac{1}{m}PXX^T P^T \\\\\\\\\n  &= P(\\frac{1}{m}XX^T)P^T \\\\\\\\\n  &= PCP^T\n\\end{align}$$\n\n现在事情很明白了！我们要找的P不是别的，而是能让原始协方差矩阵对角化的P。换句话说，优化目标变成了寻找一个矩阵P，满足 $PCP^T$ 是一个对角矩阵，并且对角元素按从大到小依次排列，那么P的前K行就是要寻找的基，用P的前K行组成的矩阵乘以X就使得X从N维降到了K维并满足上述优化条件。    \n现在所有焦点都聚焦在了协方差矩阵对角化问题上，有时，我们真应该感谢数学家的先行，因为矩阵对角化在线性代数领域已经属于被玩烂了的东西，所以这在数学上根本不是问题。\n\n由上文知道，协方差矩阵C是一个是对称矩阵，在线性代数上，实对称矩阵有一系列非常好的性质：\n1. 实对称矩阵不同特征值对应的特征向量必然正交\n2. 设特征向量λ重数为r，则必然存在r个线性无关的特征向量对应于λ，因此可以将这r个特征向量单位正交化。    \n由上面两条可知，一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量，设这n个特征向量为 $e_1,e_2,\\dots,e_n,$ 我们将其按列组成矩阵：\n$$E = \\begin{pmatrix}\ne_1 & e_2 & \\dots & e_n \\\\\n\\end{pmatrix}$$\n则对协方差矩阵C有如下结论：\n$$E_TCE = \\Lambda = \\begin{pmatrix}\n\\lambda_1 & & & \\\\\\\\\n & \\lambda_2 & & \\\\\\\\\n & & \\ddots & \\\\\\\\\n & & & \\lambda_n \\\\\n \\end{pmatrix}$$\n其中 $Lambda$为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。\n\n以上结论不再给出严格的数学证明，对证明感兴趣的朋友可以参考线性代数书籍关于“实对称矩阵对角化”的内容。\n\n到这里，我们发现我们已经找到了需要的矩阵P：\n$$P = E^T$$\n\nP是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。如果设P按照Λ中特征值的从大到小，将特征向量从上到下排列，则用P的前K行组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。\n","source":"_posts/PCA原理分析.md","raw":"---\ntitle: PCA原理分析\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2019-08-05 15:22:19\npassword:\nsummary: PCA的数学原理\ntags: \n- 实习\n- PCA\ncategories: 算法\n---\n参考资料\n[PCA原理分析](PCA.pdf)\n# PCA的数学原理\nPCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。\n\n## 数据的向量表示以及降维问题\n\n一般情况下，在数据挖掘和机器学习中，数据被表示为向量。例如某个外卖商家2018年全年的流量及交易记录可以看成是一组数据的集合，其中每一天的数据是一条记录。记录的格式如下:    \n(日期, 浏览量，访客数，下单数，成交数，成交金额)    \n其中\"日期\"是一个记录标志而非度量值，而数据挖掘关心的大多是度量值，因此如果我们忽略日期这个字段后，我们得到一组记录，每条记录可以被表示为一个五维向量，其中一条看起来大约是这个样子：    \n$$(1000, 580, 300, 240, 3000)^T$$\n注意这里用了转置，习惯上使用列向量来表示一条记录。本文说到的向量默认都是列向量。    \n\n我们当然可以对这一组五维向量进行分析和挖掘，不过很多机器学习算法的复杂度和数据的维数有着密切关系，甚至与维数呈指数级关联。当然，这里区区五维的数据，也许还无所谓，但是实际机器学习中处理成千上万甚至几十万维的情况也并不罕见，在这种情况下，机器学习的资源消耗是不可接受的，因此我们必须对数据进行降维。\n\n降维当然意味着信息的丢失，不过鉴于实际数据本身常常存在的相关性，我们可以想办法在降维的同时将信息的损失尽量降低。    \n\n举一个例子，假如某学籍数据有两列M和F，其中M列的取值是如何此学生为男性取值1，为女性取值0；而F列是学生为女性取值1，男性取值0。此时如果我们统计全部学籍数据，会发现对于任何一条记录来说，当M为1时F必定为0，反之当M为0时F必定为1。在这种情况下，我们将M或F去掉实际上没有任何信息的损失，因为只要保留一列就可以完全还原另一列。    \n当然上面是一个极端的情况，在现实中也许不会出现，不过类似的情况还是很常见的。例如上面淘宝店铺的数据，从经验我们可以知道，“浏览量”和“访客数”往往具有较强的相关关系，而“下单数”和“成交数”也具有较强的相关关系。这里我们非正式的使用“ **相关关系**”这个词，可以直观理解为“当某一天这个店铺的浏览量较高（或较低）时，我们应该很大程度上认为这天的访客数也较高（或较低）”。    \n这种情况表明，如果我们删除浏览量或访客数其中一个指标，我们应该期待并不会丢失太多信息。因此我们可以删除一个，以降低机器学习算法的复杂度。    \n\n上面给出的是降维的朴素思想描述，可以有助于直观理解降维的动机和可行性，但并不具有操作指导意义。例如，我们到底删除哪一列损失的信息才最小？亦或根本不是单纯删除几列，而是通过某些变换将原始数据变为更少的列但又使得丢失的信息最小？到底如何度量丢失信息的多少？如何根据原始数据决定具体的降维操作步骤？下面对降维问题进行数学化和形式化的讨论\n\n## 向量的表示及基变换\n\n### 内积与投影\n\n下面先来看一个高中就学过的向量运算：内积。两个维数相同的向量的内积被定义为：\n\n$$(a_1, a_2, \\dots ,a_n)^T \\cdot (b_1, b_2, \\dots , b_n)^T = a_1b_1 + a_2b_2 + \\dots + a_nb_n)$$\n内积运算将两个向量映射为一个实数。其计算方式非常容易理解，但是其意义并不明显。下面我们分析内积的几何意义。假设A和B是两个n维向量，我们知道n维向量可以等价表示为n维空间中的一条从原点发射的有向线段，为了简单起见我们假设A和B均为二维向量,则 $A = (x_1,y_1)$, $B = (x_2,y_2)$. 则在二维平面上A和B可以用两条发自原点的有向线段表示，见下图：\n![](01.png)\n好，现在我们从A点向B所在直线引一条垂线。我们知道垂线与B的交点叫做A在B上的投影，再设A与B的夹角是a，则投影的矢量长度为|A|cos(a),其中 $|A| = \\sqrt{x_1^2 + y_1^2}$ 是向量A的模，也就是A线段的标量长度。    \n注意这里我们专门区分了矢量长度和标量长度，标量长度总是大于等于0，值就是线段的长度；而矢量长度可能为负，其绝对值是线段长度，而符号取决于其方向与标准方向相同或相反。    \n到这里还是看不出内积和这东西有什么关系，不过如果我们将内积表示为另一种我们熟悉的形式：\n$$ A \\cdot B = |A||B|cos(a)$$\n\n现在事情似乎是有点眉目了：A与B的内积等于A到B的投影长度乘以B的模。再进一步，如果我们假设B的模为1，即让|B|=1，那么就变成了：\n$$A \\cdot B = |A|cos(a)$$\n也就是说， **设向量B的模为1，则A与B的内积值等于A向B所在直线投影的矢量长度！**这就是内积的一种几何解释，也是我们得到的第一个重要结论。在后面的推导中，将反复使用这个结论。\n\n### 基\n下面我们继续在二维空间内讨论向量。上文说过，一个二维向量可以对应二维笛卡尔直角坐标系中从原点出发的一个有向线段。例如下面这个向量：\n![](02.png)\n在代数表示方面，我们经常用线段终点的点坐标表示向量，例如上面的向量可以表示为(3,2)，这是我们再熟悉不过的向量表示。    \n不过我们常常忽略， **只有一个(3,2)本身是不能够精确表示一个向量的**。我们仔细看一下，这里的3实际表示的是向量在x轴上的投影值是3，在y轴上的投影值是2。也就是说我们其实隐式引入了一个定义：以x轴和y轴上正方向长度为1的向量为标准。那么一个向量(3,2)实际是说在x轴投影为3而y轴的投影为2。注意投影是一个矢量，所以可以为负。    \n更正式的说，向量(x,y)实际上表示线性组合：\n$$x(1,0)^T + y(0,1)^T$$\n不难证明所有二维向量都可以表示为这样的线性组合。此处(1,0)和(0,1)叫做二维空间中的一组基。\n![](03.png)\n所以， **要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了**。只不过我们经常省略第一步，而默认以(1,0)和(0,1)为基。    \n我们之所以默认选择(1,0)和(0,1)为基，当然是比较方便，因为它们分别是x和y轴正方向上的单位向量，因此就使得二维平面上点坐标和向量一一对应，非常方便。但实际上任何两个线性无关的二维向量都可以成为一组基，所谓线性无关在二维平面内可以直观认为是两个不在一条直线上的向量。    \n\n例如，(1,1)和(-1,1)也可以成为一组基。一般来说，我们希望基的模是1，因为从内积的意义可以看到，如果基的模是1，那么就可以方便的用向量点乘基而直接获得其在新基上的坐标了！实际上，对应任何一个向量我们总可以找到其同方向上模为1的向量，只要让两个分量分别除以模就好了。例如，上面的基可以变为 $(\\frac{1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$ 和 $(\\frac{-1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$.    \n现在，我们想获得(3,2)在新基上的坐标，即在两个方向上的投影矢量值，那么根据内积的几何意义，我们只要分别计算(3,2)和两个基的内积，不难得到新的坐标为 $(\\frac{5}{\\sqrt 2},\\frac{-1}{\\sqrt 2})$。下图给出了新的基以及(3,2)在新基上坐标值的示意图：\n![](05.png)\n一要求就是线性无关，非正交的基也是可以的。不过因为正交基有较好的性质，所以一般使用的基都是正交的。\n\n### 基变换的矩阵表示\n\n下面我们找一种简便的方式来表示基变换。还是拿上面的例子，想一下，将(3,2)变换为新基上的坐标，就是用(3,2)与第一个基做内积运算，作为第一个新的坐标分量，然后用(3,2)与第二个基做内积运算，作为第二个新坐标的分量。实际上，我们可以用矩阵相乘的形式简洁的表示这个变换：\n$$\\begin{pmatrix} \n1/ \\sqrt 2 & 1/ \\sqrt 2 \\\\\\\\\n-1/ \\sqrt 2 & 1/ \\sqrt 2 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n3 \\\\\\\\\n2 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n5 / \\sqrt 2 \\\\\\\\\n-1/ \\sqrt 2 \\\\\n\\end{pmatrix}$$\n\n太漂亮了！其中矩阵的两行分别为两个基，乘以原向量，其结果刚好为新基的坐标。可以稍微推广一下，如果我们有m个二维向量，只要将二维向量按列排成一个两行m列矩阵，然后用“基矩阵”乘以这个矩阵，就得到了所有这些向量在新基下的值。例如 $(1,1)，(2,2)，(3,3)$，想变换到刚才那组基上，则可以这样表示：\n\n$$\\begin{pmatrix}\n1 / \\sqrt 2 & 1/ \\sqrt 2 \\\\\\\\\n-1 / \\sqrt 2 & 1/ \\sqrt 2 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 2 & 3 \\\\\\\\\n1 & 2 & 3 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n2 / \\sqrt 2 & 4 / \\sqrt 2 & 6 / \\sqrt 2 \\\\\\\\\n0 & 0 & 0 \\\\\n\\end{pmatrix}$$\n\n于是一组向量的基变换被干净的表示为矩阵的相乘。    \n**一般的，如果我们有M个N维向量，想将其变换为由R个N维向量表示的新空间中，那么首先将R个基按行组成矩阵A，然后将向量按列组成矩阵B，那么两矩阵的乘积AB就是变换结果，其中AB的第m列为A中第m列变换后的结果。**    \n数学表示为：\n$$\\begin{pmatrix}\np_1 \\\\\\\\\np_2 \\\\\\\\\n\\vdots \\\\\\\\\np_R \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\na_1 & a_2 & \\dots & a_M \\\\\n\\end{pmatrix} = \\begin{pmatrix}\np_1a_1 & p_1a_2 & \\dots & p_1a_M \\\\\\\\\np_2a_1 & p_2a_2 & \\dots & p_2a_M \\\\\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\\np_Ra_1 & p_Ra_2 & \\dots & p_Ra_M \\\\\n\\end{pmatrix}$$\n其中 $p_i$是一个行向量，表示第i个基， $a_j$是一个列向量，表示第j个原始数据记录。    \n特别要注意的是，这里R可以小于N，而R决定了变换后数据的维数。也就是说，我们可以将一N维数据变换到更低维度的空间中去，变换后的维度取决于基的数量。因此这种矩阵相乘的表示也可以表示降维变换。    \n最后，上述分析同时给矩阵相乘找到了一种物理解释： **两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去**。更抽象的说，一个矩阵可以表示一种线性变换。很多同学在学线性代数时对矩阵相乘的方法感到奇怪，但是如果明白了矩阵相乘的物理意义，其合理性就一目了然了。    \n\n### 协方差矩阵及优化目标\n\n上面我们讨论了选择不同的基可以对同样一组数据给出不同的表示，而且如果基的数量少于向量本身的维数，则可以达到降维的效果。但是我们还没有回答一个最最关键的问题：如何选择基才是最优的。或者说，如果我们有一组N维向量，现在要将其降到K维（K小于N），那么我们应该如何选择K个基才能最大程度保留原有的信息？    \n要完全数学化这个问题非常繁杂，这里我们用一种非形式化的直观方法来看这个问题。\n\n为了避免过于抽象的讨论，我们仍以一个具体的例子展开。假设我们的数据由五条记录组成，将它们表示成矩阵形式：\n$$ \\begin{pmatrix}\n1 & 1 &2 & 4 & 2 \\\\\\\\\n1 & 3 & 3 & 4 & 4 \\\\\n\\end{pmatrix}$$\n其中每一列为一条数据记录，而一行为一个字段。为了后续处理方便，我们首先将每个字段内所有值都减去字段均值，其结果是将每个字段都变为均值为0（这样做的道理和好处后面会看到）。    \n我们看上面的数据，第一个字段均值为2，第二个字段均值为3，所以变换后：\n$$ \\begin{pmatrix}\n-1 & -1 & 0 & 2 & 0 \\\\\\\\\n-2 & 0 & 0 & 1 & 1 \\\\\n\\end{pmatrix}$$\n我们可以看下五条数据在平面直角坐标系内的样子：\n![](06.png)\n现在问题来了：如果我们必须使用一维来表示这些数据，又希望尽量保留原始的信息，你要如何选择？    \n\n通过上一节对基变换的讨论我们知道，这个问题实际上是要在二维平面中选择一个方向，将所有数据都投影到这个方向所在直线上，用投影值表示原始记录。这是一个实际的二维降到一维的问题。    \n\n那么如何选择这个方向（或者说基）才能尽量保留最多的原始信息呢？一种直观的看法是：希望投影后的投影值尽可能分散。    \n\n以上图为例，可以看出如果向x轴投影，那么最左边的两个点会重叠在一起，中间的两个点也会重叠在一起，于是本身四个各不相同的二维点投影后只剩下两个不同的值了，这是一种严重的信息丢失，同理，如果向y轴投影最上面的两个点和分布在x轴上的两个点也会重叠。所以看来x和y轴都不是最好的投影选择。我们直观目测，如果向通过第一象限和第三象限的斜线投影，则五个点在投影后还是可以区分的。    \n下面，我们用数学方法表述这个问题。\n\n### 方差\n\n上文说到，我们希望投影后投影值尽可能分散，而这种分散程度，可以用数学上的方差来表述。此处，一个字段的方差可以看做是每个元素与字段均值的差的平方和的均值，即：\n$$Var(a)=\\frac{1}{m} \\sum_{i=1}^{m}(a_i- \\mu)^2$$\n由于上面我们已经将每个字段的均值都化为0了，因此方差可以直接用每个元素的平方和除以元素个数表示：\n$$Var(a) = \\frac{1}{m} \\sum_{i=1}^{m}a_i^2$$\n于是上面的问题被形式化表述为：寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。    \n\n### 协方差\n对于上面二维降成一维的问题来说，找到那个使得方差最大的方向就可以了。不过对于更高维，还有一个问题需要解决。考虑三维降到二维问题。与之前相同，首先我们希望找到一个方向使得投影后方差最大，这样就完成了第一个方向的选择，继而我们选择第二个投影方向。    \n如果我们还是单纯只选择方差最大的方向，很明显，这个方向与第一个方向应该是“几乎重合在一起”，显然这样的维度是没有用的，因此，应该有其他约束条件。从直观上说，让两个字段尽可能表示更多的原始信息，我们是不希望它们之间存在（线性）相关性的，因为相关性意味着两个字段不是完全独立，必然存在重复表示的信息。    \n数学上可以用两个字段的协方差表示其相关性，由于已经让每个字段均值为0，则：\n$$Cov(a,b)=\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i$$\n可以看到，在字段均值为0的情况下，两个字段的协方差简洁的表示为其内积除以元素数m。\n\n当协方差为0时，表示两个字段完全独立。为了让协方差为0，我们选择第二个基时只能在与第一个基正交的方向上选择。因此最终选择的两个方向一定是正交的。\n\n至此，我们得到了降维问题的优化目标：**将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）**。\n\n### 协方差矩阵\n\n上面我们导出了优化目标，但是这个目标似乎不能直接作为操作指南（或者说算法），因为它只说要什么，但根本没有说怎么做。所以我们要继续在数学上研究计算方案。\n\n我们看到，最终要达到的目的与字段内方差及字段间协方差有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们来了灵感：\n\n假设我们只有a和b两个字段，那么我们将它们按行组成矩阵X：\n\n$$ X = \\begin{pmatrix}\na_1 & a_2 & \\dots & a_m \\\\\\\\\nb_1 & b_2 & \\dots & b_m \\\\\n\\end{pmatrix}$$\n然后我们用X乘以X的转置，并乘上系数 $\\frac{1}{m}$：\n$$\\frac{1}{m} \\begin{pmatrix}\n\\frac{1}{m} \\sum_{i=1}^{m}a_i^2 & \\frac{1}{m} \\sum_{i=1}^{m}a_ib_i \\\\\\\\\n\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i & \\frac{1}{m} \\sum_{i=1}^{m}b_i^2 \\\\\n\\end{pmatrix}$$\n\n奇迹出现了！这个矩阵对角线上的两个元素分别是两个字段的方差，而其它元素是a和b的协方差。两者被统一到了一个矩阵的。\n\n根据矩阵相乘的运算法则，这个结论很容易被推广到一般情况：\n\n**设我们有m个n维数据记录，将其按列排成n乘m的矩阵X，设 $C = \\frac{1}{m}XX^T$,则C是一个对称矩阵，其对角线分别个各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。**\n\n### 协方差矩阵对角化\n\n根据上述推导，我们发现要达到优化目前，等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将元素按大小从上到下排列，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系：\n\n设原始数据矩阵X对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，我们推导一下D与C的关系：\n$$\\begin{align}\nD &= \\frac{1}{m}YY^T \\\\\\\\\n  &= \\frac{1}{m}(PX)(PX)^T \\\\\\\\\n  &= \\frac{1}{m}PXX^T P^T \\\\\\\\\n  &= P(\\frac{1}{m}XX^T)P^T \\\\\\\\\n  &= PCP^T\n\\end{align}$$\n\n现在事情很明白了！我们要找的P不是别的，而是能让原始协方差矩阵对角化的P。换句话说，优化目标变成了寻找一个矩阵P，满足 $PCP^T$ 是一个对角矩阵，并且对角元素按从大到小依次排列，那么P的前K行就是要寻找的基，用P的前K行组成的矩阵乘以X就使得X从N维降到了K维并满足上述优化条件。    \n现在所有焦点都聚焦在了协方差矩阵对角化问题上，有时，我们真应该感谢数学家的先行，因为矩阵对角化在线性代数领域已经属于被玩烂了的东西，所以这在数学上根本不是问题。\n\n由上文知道，协方差矩阵C是一个是对称矩阵，在线性代数上，实对称矩阵有一系列非常好的性质：\n1. 实对称矩阵不同特征值对应的特征向量必然正交\n2. 设特征向量λ重数为r，则必然存在r个线性无关的特征向量对应于λ，因此可以将这r个特征向量单位正交化。    \n由上面两条可知，一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量，设这n个特征向量为 $e_1,e_2,\\dots,e_n,$ 我们将其按列组成矩阵：\n$$E = \\begin{pmatrix}\ne_1 & e_2 & \\dots & e_n \\\\\n\\end{pmatrix}$$\n则对协方差矩阵C有如下结论：\n$$E_TCE = \\Lambda = \\begin{pmatrix}\n\\lambda_1 & & & \\\\\\\\\n & \\lambda_2 & & \\\\\\\\\n & & \\ddots & \\\\\\\\\n & & & \\lambda_n \\\\\n \\end{pmatrix}$$\n其中 $Lambda$为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。\n\n以上结论不再给出严格的数学证明，对证明感兴趣的朋友可以参考线性代数书籍关于“实对称矩阵对角化”的内容。\n\n到这里，我们发现我们已经找到了需要的矩阵P：\n$$P = E^T$$\n\nP是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。如果设P按照Λ中特征值的从大到小，将特征向量从上到下排列，则用P的前K行组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。\n","slug":"PCA原理分析","published":1,"updated":"2019-08-10T10:47:34.114Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz5f3lu40022e5g6v95j0bmy","content":"<p>参考资料<br><a href=\"PCA.pdf\">PCA原理分析</a></p>\n<h1 id=\"PCA的数学原理\"><a href=\"#PCA的数学原理\" class=\"headerlink\" title=\"PCA的数学原理\"></a>PCA的数学原理</h1><p>PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。</p>\n<h2 id=\"数据的向量表示以及降维问题\"><a href=\"#数据的向量表示以及降维问题\" class=\"headerlink\" title=\"数据的向量表示以及降维问题\"></a>数据的向量表示以及降维问题</h2><p>一般情况下，在数据挖掘和机器学习中，数据被表示为向量。例如某个外卖商家2018年全年的流量及交易记录可以看成是一组数据的集合，其中每一天的数据是一条记录。记录的格式如下:<br>(日期, 浏览量，访客数，下单数，成交数，成交金额)<br>其中”日期”是一个记录标志而非度量值，而数据挖掘关心的大多是度量值，因此如果我们忽略日期这个字段后，我们得到一组记录，每条记录可以被表示为一个五维向量，其中一条看起来大约是这个样子：<br>$$(1000, 580, 300, 240, 3000)^T$$<br>注意这里用了转置，习惯上使用列向量来表示一条记录。本文说到的向量默认都是列向量。    </p>\n<p>我们当然可以对这一组五维向量进行分析和挖掘，不过很多机器学习算法的复杂度和数据的维数有着密切关系，甚至与维数呈指数级关联。当然，这里区区五维的数据，也许还无所谓，但是实际机器学习中处理成千上万甚至几十万维的情况也并不罕见，在这种情况下，机器学习的资源消耗是不可接受的，因此我们必须对数据进行降维。</p>\n<p>降维当然意味着信息的丢失，不过鉴于实际数据本身常常存在的相关性，我们可以想办法在降维的同时将信息的损失尽量降低。    </p>\n<p>举一个例子，假如某学籍数据有两列M和F，其中M列的取值是如何此学生为男性取值1，为女性取值0；而F列是学生为女性取值1，男性取值0。此时如果我们统计全部学籍数据，会发现对于任何一条记录来说，当M为1时F必定为0，反之当M为0时F必定为1。在这种情况下，我们将M或F去掉实际上没有任何信息的损失，因为只要保留一列就可以完全还原另一列。<br>当然上面是一个极端的情况，在现实中也许不会出现，不过类似的情况还是很常见的。例如上面淘宝店铺的数据，从经验我们可以知道，“浏览量”和“访客数”往往具有较强的相关关系，而“下单数”和“成交数”也具有较强的相关关系。这里我们非正式的使用“ <strong>相关关系</strong>”这个词，可以直观理解为“当某一天这个店铺的浏览量较高（或较低）时，我们应该很大程度上认为这天的访客数也较高（或较低）”。<br>这种情况表明，如果我们删除浏览量或访客数其中一个指标，我们应该期待并不会丢失太多信息。因此我们可以删除一个，以降低机器学习算法的复杂度。    </p>\n<p>上面给出的是降维的朴素思想描述，可以有助于直观理解降维的动机和可行性，但并不具有操作指导意义。例如，我们到底删除哪一列损失的信息才最小？亦或根本不是单纯删除几列，而是通过某些变换将原始数据变为更少的列但又使得丢失的信息最小？到底如何度量丢失信息的多少？如何根据原始数据决定具体的降维操作步骤？下面对降维问题进行数学化和形式化的讨论</p>\n<h2 id=\"向量的表示及基变换\"><a href=\"#向量的表示及基变换\" class=\"headerlink\" title=\"向量的表示及基变换\"></a>向量的表示及基变换</h2><h3 id=\"内积与投影\"><a href=\"#内积与投影\" class=\"headerlink\" title=\"内积与投影\"></a>内积与投影</h3><p>下面先来看一个高中就学过的向量运算：内积。两个维数相同的向量的内积被定义为：</p>\n<p>$$(a_1, a_2, \\dots ,a_n)^T \\cdot (b_1, b_2, \\dots , b_n)^T = a_1b_1 + a_2b_2 + \\dots + a_nb_n)$$<br>内积运算将两个向量映射为一个实数。其计算方式非常容易理解，但是其意义并不明显。下面我们分析内积的几何意义。假设A和B是两个n维向量，我们知道n维向量可以等价表示为n维空间中的一条从原点发射的有向线段，为了简单起见我们假设A和B均为二维向量,则 $A = (x_1,y_1)$, $B = (x_2,y_2)$. 则在二维平面上A和B可以用两条发自原点的有向线段表示，见下图：<br><img src=\"01.png\" alt><br>好，现在我们从A点向B所在直线引一条垂线。我们知道垂线与B的交点叫做A在B上的投影，再设A与B的夹角是a，则投影的矢量长度为|A|cos(a),其中 $|A| = \\sqrt{x_1^2 + y_1^2}$ 是向量A的模，也就是A线段的标量长度。<br>注意这里我们专门区分了矢量长度和标量长度，标量长度总是大于等于0，值就是线段的长度；而矢量长度可能为负，其绝对值是线段长度，而符号取决于其方向与标准方向相同或相反。<br>到这里还是看不出内积和这东西有什么关系，不过如果我们将内积表示为另一种我们熟悉的形式：<br>$$ A \\cdot B = |A||B|cos(a)$$</p>\n<p>现在事情似乎是有点眉目了：A与B的内积等于A到B的投影长度乘以B的模。再进一步，如果我们假设B的模为1，即让|B|=1，那么就变成了：<br>$$A \\cdot B = |A|cos(a)$$<br>也就是说， <strong>设向量B的模为1，则A与B的内积值等于A向B所在直线投影的矢量长度！</strong>这就是内积的一种几何解释，也是我们得到的第一个重要结论。在后面的推导中，将反复使用这个结论。</p>\n<h3 id=\"基\"><a href=\"#基\" class=\"headerlink\" title=\"基\"></a>基</h3><p>下面我们继续在二维空间内讨论向量。上文说过，一个二维向量可以对应二维笛卡尔直角坐标系中从原点出发的一个有向线段。例如下面这个向量：<br><img src=\"02.png\" alt><br>在代数表示方面，我们经常用线段终点的点坐标表示向量，例如上面的向量可以表示为(3,2)，这是我们再熟悉不过的向量表示。<br>不过我们常常忽略， <strong>只有一个(3,2)本身是不能够精确表示一个向量的</strong>。我们仔细看一下，这里的3实际表示的是向量在x轴上的投影值是3，在y轴上的投影值是2。也就是说我们其实隐式引入了一个定义：以x轴和y轴上正方向长度为1的向量为标准。那么一个向量(3,2)实际是说在x轴投影为3而y轴的投影为2。注意投影是一个矢量，所以可以为负。<br>更正式的说，向量(x,y)实际上表示线性组合：<br>$$x(1,0)^T + y(0,1)^T$$<br>不难证明所有二维向量都可以表示为这样的线性组合。此处(1,0)和(0,1)叫做二维空间中的一组基。<br><img src=\"03.png\" alt><br>所以， <strong>要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了</strong>。只不过我们经常省略第一步，而默认以(1,0)和(0,1)为基。<br>我们之所以默认选择(1,0)和(0,1)为基，当然是比较方便，因为它们分别是x和y轴正方向上的单位向量，因此就使得二维平面上点坐标和向量一一对应，非常方便。但实际上任何两个线性无关的二维向量都可以成为一组基，所谓线性无关在二维平面内可以直观认为是两个不在一条直线上的向量。    </p>\n<p>例如，(1,1)和(-1,1)也可以成为一组基。一般来说，我们希望基的模是1，因为从内积的意义可以看到，如果基的模是1，那么就可以方便的用向量点乘基而直接获得其在新基上的坐标了！实际上，对应任何一个向量我们总可以找到其同方向上模为1的向量，只要让两个分量分别除以模就好了。例如，上面的基可以变为 $(\\frac{1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$ 和 $(\\frac{-1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$.<br>现在，我们想获得(3,2)在新基上的坐标，即在两个方向上的投影矢量值，那么根据内积的几何意义，我们只要分别计算(3,2)和两个基的内积，不难得到新的坐标为 $(\\frac{5}{\\sqrt 2},\\frac{-1}{\\sqrt 2})$。下图给出了新的基以及(3,2)在新基上坐标值的示意图：<br><img src=\"05.png\" alt><br>一要求就是线性无关，非正交的基也是可以的。不过因为正交基有较好的性质，所以一般使用的基都是正交的。</p>\n<h3 id=\"基变换的矩阵表示\"><a href=\"#基变换的矩阵表示\" class=\"headerlink\" title=\"基变换的矩阵表示\"></a>基变换的矩阵表示</h3><p>下面我们找一种简便的方式来表示基变换。还是拿上面的例子，想一下，将(3,2)变换为新基上的坐标，就是用(3,2)与第一个基做内积运算，作为第一个新的坐标分量，然后用(3,2)与第二个基做内积运算，作为第二个新坐标的分量。实际上，我们可以用矩阵相乘的形式简洁的表示这个变换：<br>$$\\begin{pmatrix}<br>1/ \\sqrt 2 &amp; 1/ \\sqrt 2 \\\\\\<br>-1/ \\sqrt 2 &amp; 1/ \\sqrt 2 \\<br>\\end{pmatrix}<br>\\begin{pmatrix}<br>3 \\\\\\<br>2 \\<br>\\end{pmatrix} = \\begin{pmatrix}<br>5 / \\sqrt 2 \\\\\\<br>-1/ \\sqrt 2 \\<br>\\end{pmatrix}$$</p>\n<p>太漂亮了！其中矩阵的两行分别为两个基，乘以原向量，其结果刚好为新基的坐标。可以稍微推广一下，如果我们有m个二维向量，只要将二维向量按列排成一个两行m列矩阵，然后用“基矩阵”乘以这个矩阵，就得到了所有这些向量在新基下的值。例如 $(1,1)，(2,2)，(3,3)$，想变换到刚才那组基上，则可以这样表示：</p>\n<p>$$\\begin{pmatrix}<br>1 / \\sqrt 2 &amp; 1/ \\sqrt 2 \\\\\\<br>-1 / \\sqrt 2 &amp; 1/ \\sqrt 2 \\<br>\\end{pmatrix}<br>\\begin{pmatrix}<br>1 &amp; 2 &amp; 3 \\\\\\<br>1 &amp; 2 &amp; 3 \\<br>\\end{pmatrix} = \\begin{pmatrix}<br>2 / \\sqrt 2 &amp; 4 / \\sqrt 2 &amp; 6 / \\sqrt 2 \\\\\\<br>0 &amp; 0 &amp; 0 \\<br>\\end{pmatrix}$$</p>\n<p>于是一组向量的基变换被干净的表示为矩阵的相乘。<br><strong>一般的，如果我们有M个N维向量，想将其变换为由R个N维向量表示的新空间中，那么首先将R个基按行组成矩阵A，然后将向量按列组成矩阵B，那么两矩阵的乘积AB就是变换结果，其中AB的第m列为A中第m列变换后的结果。</strong><br>数学表示为：<br>$$\\begin{pmatrix}<br>p_1 \\\\\\<br>p_2 \\\\\\<br>\\vdots \\\\\\<br>p_R \\<br>\\end{pmatrix}<br>\\begin{pmatrix}<br>a_1 &amp; a_2 &amp; \\dots &amp; a_M \\<br>\\end{pmatrix} = \\begin{pmatrix}<br>p_1a_1 &amp; p_1a_2 &amp; \\dots &amp; p_1a_M \\\\\\<br>p_2a_1 &amp; p_2a_2 &amp; \\dots &amp; p_2a_M \\\\\\<br>\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\<br>p_Ra_1 &amp; p_Ra_2 &amp; \\dots &amp; p_Ra_M \\<br>\\end{pmatrix}$$<br>其中 $p_i$是一个行向量，表示第i个基， $a_j$是一个列向量，表示第j个原始数据记录。<br>特别要注意的是，这里R可以小于N，而R决定了变换后数据的维数。也就是说，我们可以将一N维数据变换到更低维度的空间中去，变换后的维度取决于基的数量。因此这种矩阵相乘的表示也可以表示降维变换。<br>最后，上述分析同时给矩阵相乘找到了一种物理解释： <strong>两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去</strong>。更抽象的说，一个矩阵可以表示一种线性变换。很多同学在学线性代数时对矩阵相乘的方法感到奇怪，但是如果明白了矩阵相乘的物理意义，其合理性就一目了然了。    </p>\n<h3 id=\"协方差矩阵及优化目标\"><a href=\"#协方差矩阵及优化目标\" class=\"headerlink\" title=\"协方差矩阵及优化目标\"></a>协方差矩阵及优化目标</h3><p>上面我们讨论了选择不同的基可以对同样一组数据给出不同的表示，而且如果基的数量少于向量本身的维数，则可以达到降维的效果。但是我们还没有回答一个最最关键的问题：如何选择基才是最优的。或者说，如果我们有一组N维向量，现在要将其降到K维（K小于N），那么我们应该如何选择K个基才能最大程度保留原有的信息？<br>要完全数学化这个问题非常繁杂，这里我们用一种非形式化的直观方法来看这个问题。</p>\n<p>为了避免过于抽象的讨论，我们仍以一个具体的例子展开。假设我们的数据由五条记录组成，将它们表示成矩阵形式：<br>$$ \\begin{pmatrix}<br>1 &amp; 1 &amp;2 &amp; 4 &amp; 2 \\\\\\<br>1 &amp; 3 &amp; 3 &amp; 4 &amp; 4 \\<br>\\end{pmatrix}$$<br>其中每一列为一条数据记录，而一行为一个字段。为了后续处理方便，我们首先将每个字段内所有值都减去字段均值，其结果是将每个字段都变为均值为0（这样做的道理和好处后面会看到）。<br>我们看上面的数据，第一个字段均值为2，第二个字段均值为3，所以变换后：<br>$$ \\begin{pmatrix}<br>-1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>-2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\<br>\\end{pmatrix}$$<br>我们可以看下五条数据在平面直角坐标系内的样子：<br><img src=\"06.png\" alt><br>现在问题来了：如果我们必须使用一维来表示这些数据，又希望尽量保留原始的信息，你要如何选择？    </p>\n<p>通过上一节对基变换的讨论我们知道，这个问题实际上是要在二维平面中选择一个方向，将所有数据都投影到这个方向所在直线上，用投影值表示原始记录。这是一个实际的二维降到一维的问题。    </p>\n<p>那么如何选择这个方向（或者说基）才能尽量保留最多的原始信息呢？一种直观的看法是：希望投影后的投影值尽可能分散。    </p>\n<p>以上图为例，可以看出如果向x轴投影，那么最左边的两个点会重叠在一起，中间的两个点也会重叠在一起，于是本身四个各不相同的二维点投影后只剩下两个不同的值了，这是一种严重的信息丢失，同理，如果向y轴投影最上面的两个点和分布在x轴上的两个点也会重叠。所以看来x和y轴都不是最好的投影选择。我们直观目测，如果向通过第一象限和第三象限的斜线投影，则五个点在投影后还是可以区分的。<br>下面，我们用数学方法表述这个问题。</p>\n<h3 id=\"方差\"><a href=\"#方差\" class=\"headerlink\" title=\"方差\"></a>方差</h3><p>上文说到，我们希望投影后投影值尽可能分散，而这种分散程度，可以用数学上的方差来表述。此处，一个字段的方差可以看做是每个元素与字段均值的差的平方和的均值，即：<br>$$Var(a)=\\frac{1}{m} \\sum_{i=1}^{m}(a_i- \\mu)^2$$<br>由于上面我们已经将每个字段的均值都化为0了，因此方差可以直接用每个元素的平方和除以元素个数表示：<br>$$Var(a) = \\frac{1}{m} \\sum_{i=1}^{m}a_i^2$$<br>于是上面的问题被形式化表述为：寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。    </p>\n<h3 id=\"协方差\"><a href=\"#协方差\" class=\"headerlink\" title=\"协方差\"></a>协方差</h3><p>对于上面二维降成一维的问题来说，找到那个使得方差最大的方向就可以了。不过对于更高维，还有一个问题需要解决。考虑三维降到二维问题。与之前相同，首先我们希望找到一个方向使得投影后方差最大，这样就完成了第一个方向的选择，继而我们选择第二个投影方向。<br>如果我们还是单纯只选择方差最大的方向，很明显，这个方向与第一个方向应该是“几乎重合在一起”，显然这样的维度是没有用的，因此，应该有其他约束条件。从直观上说，让两个字段尽可能表示更多的原始信息，我们是不希望它们之间存在（线性）相关性的，因为相关性意味着两个字段不是完全独立，必然存在重复表示的信息。<br>数学上可以用两个字段的协方差表示其相关性，由于已经让每个字段均值为0，则：<br>$$Cov(a,b)=\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i$$<br>可以看到，在字段均值为0的情况下，两个字段的协方差简洁的表示为其内积除以元素数m。</p>\n<p>当协方差为0时，表示两个字段完全独立。为了让协方差为0，我们选择第二个基时只能在与第一个基正交的方向上选择。因此最终选择的两个方向一定是正交的。</p>\n<p>至此，我们得到了降维问题的优化目标：<strong>将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）</strong>。</p>\n<h3 id=\"协方差矩阵\"><a href=\"#协方差矩阵\" class=\"headerlink\" title=\"协方差矩阵\"></a>协方差矩阵</h3><p>上面我们导出了优化目标，但是这个目标似乎不能直接作为操作指南（或者说算法），因为它只说要什么，但根本没有说怎么做。所以我们要继续在数学上研究计算方案。</p>\n<p>我们看到，最终要达到的目的与字段内方差及字段间协方差有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们来了灵感：</p>\n<p>假设我们只有a和b两个字段，那么我们将它们按行组成矩阵X：</p>\n<p>$$ X = \\begin{pmatrix}<br>a_1 &amp; a_2 &amp; \\dots &amp; a_m \\\\\\<br>b_1 &amp; b_2 &amp; \\dots &amp; b_m \\<br>\\end{pmatrix}$$<br>然后我们用X乘以X的转置，并乘上系数 $\\frac{1}{m}$：<br>$$\\frac{1}{m} \\begin{pmatrix}<br>\\frac{1}{m} \\sum_{i=1}^{m}a_i^2 &amp; \\frac{1}{m} \\sum_{i=1}^{m}a_ib_i \\\\\\<br>\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i &amp; \\frac{1}{m} \\sum_{i=1}^{m}b_i^2 \\<br>\\end{pmatrix}$$</p>\n<p>奇迹出现了！这个矩阵对角线上的两个元素分别是两个字段的方差，而其它元素是a和b的协方差。两者被统一到了一个矩阵的。</p>\n<p>根据矩阵相乘的运算法则，这个结论很容易被推广到一般情况：</p>\n<p><strong>设我们有m个n维数据记录，将其按列排成n乘m的矩阵X，设 $C = \\frac{1}{m}XX^T$,则C是一个对称矩阵，其对角线分别个各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。</strong></p>\n<h3 id=\"协方差矩阵对角化\"><a href=\"#协方差矩阵对角化\" class=\"headerlink\" title=\"协方差矩阵对角化\"></a>协方差矩阵对角化</h3><p>根据上述推导，我们发现要达到优化目前，等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将元素按大小从上到下排列，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系：</p>\n<p>设原始数据矩阵X对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，我们推导一下D与C的关系：<br>$$\\begin{align}<br>D &amp;= \\frac{1}{m}YY^T \\\\\\<br>  &amp;= \\frac{1}{m}(PX)(PX)^T \\\\\\<br>  &amp;= \\frac{1}{m}PXX^T P^T \\\\\\<br>  &amp;= P(\\frac{1}{m}XX^T)P^T \\\\\\<br>  &amp;= PCP^T<br>\\end{align}$$</p>\n<p>现在事情很明白了！我们要找的P不是别的，而是能让原始协方差矩阵对角化的P。换句话说，优化目标变成了寻找一个矩阵P，满足 $PCP^T$ 是一个对角矩阵，并且对角元素按从大到小依次排列，那么P的前K行就是要寻找的基，用P的前K行组成的矩阵乘以X就使得X从N维降到了K维并满足上述优化条件。<br>现在所有焦点都聚焦在了协方差矩阵对角化问题上，有时，我们真应该感谢数学家的先行，因为矩阵对角化在线性代数领域已经属于被玩烂了的东西，所以这在数学上根本不是问题。</p>\n<p>由上文知道，协方差矩阵C是一个是对称矩阵，在线性代数上，实对称矩阵有一系列非常好的性质：</p>\n<ol>\n<li>实对称矩阵不同特征值对应的特征向量必然正交</li>\n<li>设特征向量λ重数为r，则必然存在r个线性无关的特征向量对应于λ，因此可以将这r个特征向量单位正交化。<br>由上面两条可知，一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量，设这n个特征向量为 $e_1,e_2,\\dots,e_n,$ 我们将其按列组成矩阵：<br>$$E = \\begin{pmatrix}<br>e_1 &amp; e_2 &amp; \\dots &amp; e_n \\<br>\\end{pmatrix}$$<br>则对协方差矩阵C有如下结论：<br>$$E_TCE = \\Lambda = \\begin{pmatrix}<br>\\lambda_1 &amp; &amp; &amp; \\\\\\<br>&amp; \\lambda_2 &amp; &amp; \\\\\\<br>&amp; &amp; \\ddots &amp; \\\\\\<br>&amp; &amp; &amp; \\lambda_n \\<br>\\end{pmatrix}$$<br>其中 $Lambda$为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。</li>\n</ol>\n<p>以上结论不再给出严格的数学证明，对证明感兴趣的朋友可以参考线性代数书籍关于“实对称矩阵对角化”的内容。</p>\n<p>到这里，我们发现我们已经找到了需要的矩阵P：<br>$$P = E^T$$</p>\n<p>P是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。如果设P按照Λ中特征值的从大到小，将特征向量从上到下排列，则用P的前K行组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。</p>\n","site":{"data":{"friends":[{"name":"Github","url":"https://github.com/liuyaanng","title":"访问主页","introduction":"我是练习时长两年半的小白程序员，喜欢唱，跳，Music和写代码","avatar":"https://avatars3.githubusercontent.com/u/41953649?s=460&v=4"}],"musics":[{"name":"We Can not Stop","artist":"Boyce Avenue&Bea Miller","url":"/medias/music/wecantstop.mp3","cover":"https://i.loli.net/2019/08/03/Z2ABnhKQ8fY6pVP.jpg"},{"name":"Leaving Akina","artist":"Leon","url":"/medias/music/LeavingAkina.mp3","cover":"https://i.loli.net/2019/08/03/fqFWCVij25rLITc.jpg"}]}},"excerpt":"","more":"<p>参考资料<br><a href=\"PCA.pdf\">PCA原理分析</a></p>\n<h1 id=\"PCA的数学原理\"><a href=\"#PCA的数学原理\" class=\"headerlink\" title=\"PCA的数学原理\"></a>PCA的数学原理</h1><p>PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。</p>\n<h2 id=\"数据的向量表示以及降维问题\"><a href=\"#数据的向量表示以及降维问题\" class=\"headerlink\" title=\"数据的向量表示以及降维问题\"></a>数据的向量表示以及降维问题</h2><p>一般情况下，在数据挖掘和机器学习中，数据被表示为向量。例如某个外卖商家2018年全年的流量及交易记录可以看成是一组数据的集合，其中每一天的数据是一条记录。记录的格式如下:<br>(日期, 浏览量，访客数，下单数，成交数，成交金额)<br>其中”日期”是一个记录标志而非度量值，而数据挖掘关心的大多是度量值，因此如果我们忽略日期这个字段后，我们得到一组记录，每条记录可以被表示为一个五维向量，其中一条看起来大约是这个样子：<br>$$(1000, 580, 300, 240, 3000)^T$$<br>注意这里用了转置，习惯上使用列向量来表示一条记录。本文说到的向量默认都是列向量。    </p>\n<p>我们当然可以对这一组五维向量进行分析和挖掘，不过很多机器学习算法的复杂度和数据的维数有着密切关系，甚至与维数呈指数级关联。当然，这里区区五维的数据，也许还无所谓，但是实际机器学习中处理成千上万甚至几十万维的情况也并不罕见，在这种情况下，机器学习的资源消耗是不可接受的，因此我们必须对数据进行降维。</p>\n<p>降维当然意味着信息的丢失，不过鉴于实际数据本身常常存在的相关性，我们可以想办法在降维的同时将信息的损失尽量降低。    </p>\n<p>举一个例子，假如某学籍数据有两列M和F，其中M列的取值是如何此学生为男性取值1，为女性取值0；而F列是学生为女性取值1，男性取值0。此时如果我们统计全部学籍数据，会发现对于任何一条记录来说，当M为1时F必定为0，反之当M为0时F必定为1。在这种情况下，我们将M或F去掉实际上没有任何信息的损失，因为只要保留一列就可以完全还原另一列。<br>当然上面是一个极端的情况，在现实中也许不会出现，不过类似的情况还是很常见的。例如上面淘宝店铺的数据，从经验我们可以知道，“浏览量”和“访客数”往往具有较强的相关关系，而“下单数”和“成交数”也具有较强的相关关系。这里我们非正式的使用“ <strong>相关关系</strong>”这个词，可以直观理解为“当某一天这个店铺的浏览量较高（或较低）时，我们应该很大程度上认为这天的访客数也较高（或较低）”。<br>这种情况表明，如果我们删除浏览量或访客数其中一个指标，我们应该期待并不会丢失太多信息。因此我们可以删除一个，以降低机器学习算法的复杂度。    </p>\n<p>上面给出的是降维的朴素思想描述，可以有助于直观理解降维的动机和可行性，但并不具有操作指导意义。例如，我们到底删除哪一列损失的信息才最小？亦或根本不是单纯删除几列，而是通过某些变换将原始数据变为更少的列但又使得丢失的信息最小？到底如何度量丢失信息的多少？如何根据原始数据决定具体的降维操作步骤？下面对降维问题进行数学化和形式化的讨论</p>\n<h2 id=\"向量的表示及基变换\"><a href=\"#向量的表示及基变换\" class=\"headerlink\" title=\"向量的表示及基变换\"></a>向量的表示及基变换</h2><h3 id=\"内积与投影\"><a href=\"#内积与投影\" class=\"headerlink\" title=\"内积与投影\"></a>内积与投影</h3><p>下面先来看一个高中就学过的向量运算：内积。两个维数相同的向量的内积被定义为：</p>\n<p>$$(a_1, a_2, \\dots ,a_n)^T \\cdot (b_1, b_2, \\dots , b_n)^T = a_1b_1 + a_2b_2 + \\dots + a_nb_n)$$<br>内积运算将两个向量映射为一个实数。其计算方式非常容易理解，但是其意义并不明显。下面我们分析内积的几何意义。假设A和B是两个n维向量，我们知道n维向量可以等价表示为n维空间中的一条从原点发射的有向线段，为了简单起见我们假设A和B均为二维向量,则 $A = (x_1,y_1)$, $B = (x_2,y_2)$. 则在二维平面上A和B可以用两条发自原点的有向线段表示，见下图：<br><img src=\"01.png\" alt><br>好，现在我们从A点向B所在直线引一条垂线。我们知道垂线与B的交点叫做A在B上的投影，再设A与B的夹角是a，则投影的矢量长度为|A|cos(a),其中 $|A| = \\sqrt{x_1^2 + y_1^2}$ 是向量A的模，也就是A线段的标量长度。<br>注意这里我们专门区分了矢量长度和标量长度，标量长度总是大于等于0，值就是线段的长度；而矢量长度可能为负，其绝对值是线段长度，而符号取决于其方向与标准方向相同或相反。<br>到这里还是看不出内积和这东西有什么关系，不过如果我们将内积表示为另一种我们熟悉的形式：<br>$$ A \\cdot B = |A||B|cos(a)$$</p>\n<p>现在事情似乎是有点眉目了：A与B的内积等于A到B的投影长度乘以B的模。再进一步，如果我们假设B的模为1，即让|B|=1，那么就变成了：<br>$$A \\cdot B = |A|cos(a)$$<br>也就是说， <strong>设向量B的模为1，则A与B的内积值等于A向B所在直线投影的矢量长度！</strong>这就是内积的一种几何解释，也是我们得到的第一个重要结论。在后面的推导中，将反复使用这个结论。</p>\n<h3 id=\"基\"><a href=\"#基\" class=\"headerlink\" title=\"基\"></a>基</h3><p>下面我们继续在二维空间内讨论向量。上文说过，一个二维向量可以对应二维笛卡尔直角坐标系中从原点出发的一个有向线段。例如下面这个向量：<br><img src=\"02.png\" alt><br>在代数表示方面，我们经常用线段终点的点坐标表示向量，例如上面的向量可以表示为(3,2)，这是我们再熟悉不过的向量表示。<br>不过我们常常忽略， <strong>只有一个(3,2)本身是不能够精确表示一个向量的</strong>。我们仔细看一下，这里的3实际表示的是向量在x轴上的投影值是3，在y轴上的投影值是2。也就是说我们其实隐式引入了一个定义：以x轴和y轴上正方向长度为1的向量为标准。那么一个向量(3,2)实际是说在x轴投影为3而y轴的投影为2。注意投影是一个矢量，所以可以为负。<br>更正式的说，向量(x,y)实际上表示线性组合：<br>$$x(1,0)^T + y(0,1)^T$$<br>不难证明所有二维向量都可以表示为这样的线性组合。此处(1,0)和(0,1)叫做二维空间中的一组基。<br><img src=\"03.png\" alt><br>所以， <strong>要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了</strong>。只不过我们经常省略第一步，而默认以(1,0)和(0,1)为基。<br>我们之所以默认选择(1,0)和(0,1)为基，当然是比较方便，因为它们分别是x和y轴正方向上的单位向量，因此就使得二维平面上点坐标和向量一一对应，非常方便。但实际上任何两个线性无关的二维向量都可以成为一组基，所谓线性无关在二维平面内可以直观认为是两个不在一条直线上的向量。    </p>\n<p>例如，(1,1)和(-1,1)也可以成为一组基。一般来说，我们希望基的模是1，因为从内积的意义可以看到，如果基的模是1，那么就可以方便的用向量点乘基而直接获得其在新基上的坐标了！实际上，对应任何一个向量我们总可以找到其同方向上模为1的向量，只要让两个分量分别除以模就好了。例如，上面的基可以变为 $(\\frac{1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$ 和 $(\\frac{-1}{\\sqrt 2},\\frac{1}{\\sqrt 2})$.<br>现在，我们想获得(3,2)在新基上的坐标，即在两个方向上的投影矢量值，那么根据内积的几何意义，我们只要分别计算(3,2)和两个基的内积，不难得到新的坐标为 $(\\frac{5}{\\sqrt 2},\\frac{-1}{\\sqrt 2})$。下图给出了新的基以及(3,2)在新基上坐标值的示意图：<br><img src=\"05.png\" alt><br>一要求就是线性无关，非正交的基也是可以的。不过因为正交基有较好的性质，所以一般使用的基都是正交的。</p>\n<h3 id=\"基变换的矩阵表示\"><a href=\"#基变换的矩阵表示\" class=\"headerlink\" title=\"基变换的矩阵表示\"></a>基变换的矩阵表示</h3><p>下面我们找一种简便的方式来表示基变换。还是拿上面的例子，想一下，将(3,2)变换为新基上的坐标，就是用(3,2)与第一个基做内积运算，作为第一个新的坐标分量，然后用(3,2)与第二个基做内积运算，作为第二个新坐标的分量。实际上，我们可以用矩阵相乘的形式简洁的表示这个变换：<br>$$\\begin{pmatrix}<br>1/ \\sqrt 2 &amp; 1/ \\sqrt 2 \\\\\\<br>-1/ \\sqrt 2 &amp; 1/ \\sqrt 2 \\<br>\\end{pmatrix}<br>\\begin{pmatrix}<br>3 \\\\\\<br>2 \\<br>\\end{pmatrix} = \\begin{pmatrix}<br>5 / \\sqrt 2 \\\\\\<br>-1/ \\sqrt 2 \\<br>\\end{pmatrix}$$</p>\n<p>太漂亮了！其中矩阵的两行分别为两个基，乘以原向量，其结果刚好为新基的坐标。可以稍微推广一下，如果我们有m个二维向量，只要将二维向量按列排成一个两行m列矩阵，然后用“基矩阵”乘以这个矩阵，就得到了所有这些向量在新基下的值。例如 $(1,1)，(2,2)，(3,3)$，想变换到刚才那组基上，则可以这样表示：</p>\n<p>$$\\begin{pmatrix}<br>1 / \\sqrt 2 &amp; 1/ \\sqrt 2 \\\\\\<br>-1 / \\sqrt 2 &amp; 1/ \\sqrt 2 \\<br>\\end{pmatrix}<br>\\begin{pmatrix}<br>1 &amp; 2 &amp; 3 \\\\\\<br>1 &amp; 2 &amp; 3 \\<br>\\end{pmatrix} = \\begin{pmatrix}<br>2 / \\sqrt 2 &amp; 4 / \\sqrt 2 &amp; 6 / \\sqrt 2 \\\\\\<br>0 &amp; 0 &amp; 0 \\<br>\\end{pmatrix}$$</p>\n<p>于是一组向量的基变换被干净的表示为矩阵的相乘。<br><strong>一般的，如果我们有M个N维向量，想将其变换为由R个N维向量表示的新空间中，那么首先将R个基按行组成矩阵A，然后将向量按列组成矩阵B，那么两矩阵的乘积AB就是变换结果，其中AB的第m列为A中第m列变换后的结果。</strong><br>数学表示为：<br>$$\\begin{pmatrix}<br>p_1 \\\\\\<br>p_2 \\\\\\<br>\\vdots \\\\\\<br>p_R \\<br>\\end{pmatrix}<br>\\begin{pmatrix}<br>a_1 &amp; a_2 &amp; \\dots &amp; a_M \\<br>\\end{pmatrix} = \\begin{pmatrix}<br>p_1a_1 &amp; p_1a_2 &amp; \\dots &amp; p_1a_M \\\\\\<br>p_2a_1 &amp; p_2a_2 &amp; \\dots &amp; p_2a_M \\\\\\<br>\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\<br>p_Ra_1 &amp; p_Ra_2 &amp; \\dots &amp; p_Ra_M \\<br>\\end{pmatrix}$$<br>其中 $p_i$是一个行向量，表示第i个基， $a_j$是一个列向量，表示第j个原始数据记录。<br>特别要注意的是，这里R可以小于N，而R决定了变换后数据的维数。也就是说，我们可以将一N维数据变换到更低维度的空间中去，变换后的维度取决于基的数量。因此这种矩阵相乘的表示也可以表示降维变换。<br>最后，上述分析同时给矩阵相乘找到了一种物理解释： <strong>两个矩阵相乘的意义是将右边矩阵中的每一列列向量变换到左边矩阵中每一行行向量为基所表示的空间中去</strong>。更抽象的说，一个矩阵可以表示一种线性变换。很多同学在学线性代数时对矩阵相乘的方法感到奇怪，但是如果明白了矩阵相乘的物理意义，其合理性就一目了然了。    </p>\n<h3 id=\"协方差矩阵及优化目标\"><a href=\"#协方差矩阵及优化目标\" class=\"headerlink\" title=\"协方差矩阵及优化目标\"></a>协方差矩阵及优化目标</h3><p>上面我们讨论了选择不同的基可以对同样一组数据给出不同的表示，而且如果基的数量少于向量本身的维数，则可以达到降维的效果。但是我们还没有回答一个最最关键的问题：如何选择基才是最优的。或者说，如果我们有一组N维向量，现在要将其降到K维（K小于N），那么我们应该如何选择K个基才能最大程度保留原有的信息？<br>要完全数学化这个问题非常繁杂，这里我们用一种非形式化的直观方法来看这个问题。</p>\n<p>为了避免过于抽象的讨论，我们仍以一个具体的例子展开。假设我们的数据由五条记录组成，将它们表示成矩阵形式：<br>$$ \\begin{pmatrix}<br>1 &amp; 1 &amp;2 &amp; 4 &amp; 2 \\\\\\<br>1 &amp; 3 &amp; 3 &amp; 4 &amp; 4 \\<br>\\end{pmatrix}$$<br>其中每一列为一条数据记录，而一行为一个字段。为了后续处理方便，我们首先将每个字段内所有值都减去字段均值，其结果是将每个字段都变为均值为0（这样做的道理和好处后面会看到）。<br>我们看上面的数据，第一个字段均值为2，第二个字段均值为3，所以变换后：<br>$$ \\begin{pmatrix}<br>-1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\\\\\<br>-2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\<br>\\end{pmatrix}$$<br>我们可以看下五条数据在平面直角坐标系内的样子：<br><img src=\"06.png\" alt><br>现在问题来了：如果我们必须使用一维来表示这些数据，又希望尽量保留原始的信息，你要如何选择？    </p>\n<p>通过上一节对基变换的讨论我们知道，这个问题实际上是要在二维平面中选择一个方向，将所有数据都投影到这个方向所在直线上，用投影值表示原始记录。这是一个实际的二维降到一维的问题。    </p>\n<p>那么如何选择这个方向（或者说基）才能尽量保留最多的原始信息呢？一种直观的看法是：希望投影后的投影值尽可能分散。    </p>\n<p>以上图为例，可以看出如果向x轴投影，那么最左边的两个点会重叠在一起，中间的两个点也会重叠在一起，于是本身四个各不相同的二维点投影后只剩下两个不同的值了，这是一种严重的信息丢失，同理，如果向y轴投影最上面的两个点和分布在x轴上的两个点也会重叠。所以看来x和y轴都不是最好的投影选择。我们直观目测，如果向通过第一象限和第三象限的斜线投影，则五个点在投影后还是可以区分的。<br>下面，我们用数学方法表述这个问题。</p>\n<h3 id=\"方差\"><a href=\"#方差\" class=\"headerlink\" title=\"方差\"></a>方差</h3><p>上文说到，我们希望投影后投影值尽可能分散，而这种分散程度，可以用数学上的方差来表述。此处，一个字段的方差可以看做是每个元素与字段均值的差的平方和的均值，即：<br>$$Var(a)=\\frac{1}{m} \\sum_{i=1}^{m}(a_i- \\mu)^2$$<br>由于上面我们已经将每个字段的均值都化为0了，因此方差可以直接用每个元素的平方和除以元素个数表示：<br>$$Var(a) = \\frac{1}{m} \\sum_{i=1}^{m}a_i^2$$<br>于是上面的问题被形式化表述为：寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。    </p>\n<h3 id=\"协方差\"><a href=\"#协方差\" class=\"headerlink\" title=\"协方差\"></a>协方差</h3><p>对于上面二维降成一维的问题来说，找到那个使得方差最大的方向就可以了。不过对于更高维，还有一个问题需要解决。考虑三维降到二维问题。与之前相同，首先我们希望找到一个方向使得投影后方差最大，这样就完成了第一个方向的选择，继而我们选择第二个投影方向。<br>如果我们还是单纯只选择方差最大的方向，很明显，这个方向与第一个方向应该是“几乎重合在一起”，显然这样的维度是没有用的，因此，应该有其他约束条件。从直观上说，让两个字段尽可能表示更多的原始信息，我们是不希望它们之间存在（线性）相关性的，因为相关性意味着两个字段不是完全独立，必然存在重复表示的信息。<br>数学上可以用两个字段的协方差表示其相关性，由于已经让每个字段均值为0，则：<br>$$Cov(a,b)=\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i$$<br>可以看到，在字段均值为0的情况下，两个字段的协方差简洁的表示为其内积除以元素数m。</p>\n<p>当协方差为0时，表示两个字段完全独立。为了让协方差为0，我们选择第二个基时只能在与第一个基正交的方向上选择。因此最终选择的两个方向一定是正交的。</p>\n<p>至此，我们得到了降维问题的优化目标：<strong>将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）</strong>。</p>\n<h3 id=\"协方差矩阵\"><a href=\"#协方差矩阵\" class=\"headerlink\" title=\"协方差矩阵\"></a>协方差矩阵</h3><p>上面我们导出了优化目标，但是这个目标似乎不能直接作为操作指南（或者说算法），因为它只说要什么，但根本没有说怎么做。所以我们要继续在数学上研究计算方案。</p>\n<p>我们看到，最终要达到的目的与字段内方差及字段间协方差有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们来了灵感：</p>\n<p>假设我们只有a和b两个字段，那么我们将它们按行组成矩阵X：</p>\n<p>$$ X = \\begin{pmatrix}<br>a_1 &amp; a_2 &amp; \\dots &amp; a_m \\\\\\<br>b_1 &amp; b_2 &amp; \\dots &amp; b_m \\<br>\\end{pmatrix}$$<br>然后我们用X乘以X的转置，并乘上系数 $\\frac{1}{m}$：<br>$$\\frac{1}{m} \\begin{pmatrix}<br>\\frac{1}{m} \\sum_{i=1}^{m}a_i^2 &amp; \\frac{1}{m} \\sum_{i=1}^{m}a_ib_i \\\\\\<br>\\frac{1}{m} \\sum_{i=1}^{m}a_ib_i &amp; \\frac{1}{m} \\sum_{i=1}^{m}b_i^2 \\<br>\\end{pmatrix}$$</p>\n<p>奇迹出现了！这个矩阵对角线上的两个元素分别是两个字段的方差，而其它元素是a和b的协方差。两者被统一到了一个矩阵的。</p>\n<p>根据矩阵相乘的运算法则，这个结论很容易被推广到一般情况：</p>\n<p><strong>设我们有m个n维数据记录，将其按列排成n乘m的矩阵X，设 $C = \\frac{1}{m}XX^T$,则C是一个对称矩阵，其对角线分别个各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。</strong></p>\n<h3 id=\"协方差矩阵对角化\"><a href=\"#协方差矩阵对角化\" class=\"headerlink\" title=\"协方差矩阵对角化\"></a>协方差矩阵对角化</h3><p>根据上述推导，我们发现要达到优化目前，等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将元素按大小从上到下排列，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系：</p>\n<p>设原始数据矩阵X对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，我们推导一下D与C的关系：<br>$$\\begin{align}<br>D &amp;= \\frac{1}{m}YY^T \\\\\\<br>  &amp;= \\frac{1}{m}(PX)(PX)^T \\\\\\<br>  &amp;= \\frac{1}{m}PXX^T P^T \\\\\\<br>  &amp;= P(\\frac{1}{m}XX^T)P^T \\\\\\<br>  &amp;= PCP^T<br>\\end{align}$$</p>\n<p>现在事情很明白了！我们要找的P不是别的，而是能让原始协方差矩阵对角化的P。换句话说，优化目标变成了寻找一个矩阵P，满足 $PCP^T$ 是一个对角矩阵，并且对角元素按从大到小依次排列，那么P的前K行就是要寻找的基，用P的前K行组成的矩阵乘以X就使得X从N维降到了K维并满足上述优化条件。<br>现在所有焦点都聚焦在了协方差矩阵对角化问题上，有时，我们真应该感谢数学家的先行，因为矩阵对角化在线性代数领域已经属于被玩烂了的东西，所以这在数学上根本不是问题。</p>\n<p>由上文知道，协方差矩阵C是一个是对称矩阵，在线性代数上，实对称矩阵有一系列非常好的性质：</p>\n<ol>\n<li>实对称矩阵不同特征值对应的特征向量必然正交</li>\n<li>设特征向量λ重数为r，则必然存在r个线性无关的特征向量对应于λ，因此可以将这r个特征向量单位正交化。<br>由上面两条可知，一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量，设这n个特征向量为 $e_1,e_2,\\dots,e_n,$ 我们将其按列组成矩阵：<br>$$E = \\begin{pmatrix}<br>e_1 &amp; e_2 &amp; \\dots &amp; e_n \\<br>\\end{pmatrix}$$<br>则对协方差矩阵C有如下结论：<br>$$E_TCE = \\Lambda = \\begin{pmatrix}<br>\\lambda_1 &amp; &amp; &amp; \\\\\\<br>&amp; \\lambda_2 &amp; &amp; \\\\\\<br>&amp; &amp; \\ddots &amp; \\\\\\<br>&amp; &amp; &amp; \\lambda_n \\<br>\\end{pmatrix}$$<br>其中 $Lambda$为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。</li>\n</ol>\n<p>以上结论不再给出严格的数学证明，对证明感兴趣的朋友可以参考线性代数书籍关于“实对称矩阵对角化”的内容。</p>\n<p>到这里，我们发现我们已经找到了需要的矩阵P：<br>$$P = E^T$$</p>\n<p>P是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。如果设P按照Λ中特征值的从大到小，将特征向量从上到下排列，则用P的前K行组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。</p>\n"}],"PostAsset":[{"_id":"source/_posts/Enjoy-PyTorch-Task1/1.png","slug":"1.png","post":"cjz5f3lti0010e5g689hs8t1h","modified":0,"renderable":0},{"_id":"source/_posts/Face-Recognition-with-OpenCV/att_faces.zip","slug":"att_faces.zip","post":"cjz5f3ltl0015e5g6bh9w9qsu","modified":0,"renderable":0},{"_id":"source/_posts/Enjoy-PyTorch/1.png","slug":"1.png","post":"cjz5f3ltk0013e5g663pwqdiz","modified":0,"renderable":0},{"_id":"source/_posts/PCA算法实现/01.png","slug":"01.png","post":"cjz5f3ltz001se5g6r787ewfd","modified":0,"renderable":0},{"_id":"source/_posts/PCA算法实现/02.png","slug":"02.png","post":"cjz5f3ltz001se5g6r787ewfd","modified":0,"renderable":0},{"_id":"source/_posts/PCA原理分析/01.png","slug":"01.png","post":"cjz5f3lu40022e5g6v95j0bmy","modified":0,"renderable":0},{"_id":"source/_posts/PCA原理分析/02.png","slug":"02.png","post":"cjz5f3lu40022e5g6v95j0bmy","modified":0,"renderable":0},{"_id":"source/_posts/PCA原理分析/03.png","slug":"03.png","post":"cjz5f3lu40022e5g6v95j0bmy","modified":0,"renderable":0},{"_id":"source/_posts/PCA原理分析/05.png","slug":"05.png","post":"cjz5f3lu40022e5g6v95j0bmy","modified":0,"renderable":0},{"_id":"source/_posts/PCA原理分析/06.png","slug":"06.png","post":"cjz5f3lu40022e5g6v95j0bmy","modified":0,"renderable":0},{"_id":"source/_posts/PCA原理分析/07.png","slug":"07.png","post":"cjz5f3lu40022e5g6v95j0bmy","modified":0,"renderable":0},{"_id":"source/_posts/PCA原理分析/PCA.pdf","slug":"PCA.pdf","post":"cjz5f3lu40022e5g6v95j0bmy","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cjz5f3lth000xe5g6zpro8zd1","category_id":"cjz5f3ltj0011e5g68ocr600o","_id":"cjz5f3ltq001ee5g6prabw9b6"},{"post_id":"cjz5f3lth000xe5g6zpro8zd1","category_id":"cjz5f3ltn0019e5g6tay44ux3","_id":"cjz5f3ltq001ge5g6yj08zutr"},{"post_id":"cjz5f3ltw001me5g6c1arh6zw","category_id":"cjz5f3ltj0011e5g68ocr600o","_id":"cjz5f3lu1001ve5g69plhtytq"},{"post_id":"cjz5f3ltw001me5g6c1arh6zw","category_id":"cjz5f3ltn0019e5g6tay44ux3","_id":"cjz5f3lu2001ye5g6q1hr438e"},{"post_id":"cjz5f3lu40022e5g6v95j0bmy","category_id":"cjz5f3lu50023e5g6bch872nf","_id":"cjz5f3lu60027e5g6ln7k7xpo"}],"PostTag":[{"post_id":"cjz5f3lsy0006e5g6blrfkulr","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lt20009e5g6st5krfb5"},{"post_id":"cjz5f3lsk0002e5g6z4zfajte","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lt3000be5g6uk1hz0xl"},{"post_id":"cjz5f3lsz0007e5g6i3228eqs","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lt5000ee5g69inyckbf"},{"post_id":"cjz5f3lt2000ae5g67png8b0i","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lt8000ge5g6fqysabni"},{"post_id":"cjz5f3lss0003e5g6jra3ljn3","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lta000ie5g6xzn6ipaz"},{"post_id":"cjz5f3lt3000ce5g6q3qte1wp","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltb000ke5g6otmxqp6m"},{"post_id":"cjz5f3lt5000fe5g6gbq5ofue","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltc000me5g6n7yd9rt3"},{"post_id":"cjz5f3lsw0005e5g6ew0ni2nj","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltd000oe5g61frbazuh"},{"post_id":"cjz5f3lt8000he5g6fkd7eis8","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lte000qe5g6g28a91tb"},{"post_id":"cjz5f3ltb000le5g6b0n06up0","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltf000se5g6oj46hips"},{"post_id":"cjz5f3ltc000ne5g61a05847j","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltg000ue5g6oq2vydyq"},{"post_id":"cjz5f3ltd000pe5g67w5w6u9n","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lth000we5g6c64rmiy8"},{"post_id":"cjz5f3lte000re5g61q774frn","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lti000ze5g67d6k3ma3"},{"post_id":"cjz5f3ltf000te5g6ecx0hxrh","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltj0012e5g6jpvdta6b"},{"post_id":"cjz5f3lth000xe5g6zpro8zd1","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltk0014e5g6oz9wzn5j"},{"post_id":"cjz5f3ltg000ve5g6dwqnsjlw","tag_id":"cjz5f3lti000ye5g6lshsvqu0","_id":"cjz5f3ltl0016e5g6ylnzx0ay"},{"post_id":"cjz5f3ltn0018e5g6emkb5xbn","tag_id":"cjz5f3ltp001be5g6lnzsqrwm","_id":"cjz5f3ltq001fe5g6292t82uj"},{"post_id":"cjz5f3lto001ae5g6lutat315","tag_id":"cjz5f3ltq001de5g6qfd3bedf","_id":"cjz5f3ltr001ie5g6cgt6isi5"},{"post_id":"cjz5f3ltp001ce5g68esna7o6","tag_id":"cjz5f3ltq001he5g6hlgqjfwa","_id":"cjz5f3ltr001je5g6jd7grr42"},{"post_id":"cjz5f3ltu001ke5g60whxxyfi","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltx001oe5g6qpdona2u"},{"post_id":"cjz5f3ltw001me5g6c1arh6zw","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3ltz001re5g6red8pm3x"},{"post_id":"cjz5f3ltz001se5g6r787ewfd","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lu1001we5g6xg9tzx0v"},{"post_id":"cjz5f3lu0001ue5g6721u7vyn","tag_id":"cjz5f3lu2001ze5g63ni3m8k1","_id":"cjz5f3lu30021e5g60hk4064e"},{"post_id":"cjz5f3lu40022e5g6v95j0bmy","tag_id":"cjz5f3lsu0004e5g6w4372kte","_id":"cjz5f3lu60025e5g67f01m3vv"},{"post_id":"cjz5f3lu40022e5g6v95j0bmy","tag_id":"cjz5f3lu50024e5g694x88w81","_id":"cjz5f3lu60026e5g6r1zxam70"}],"Tag":[{"name":"实习","_id":"cjz5f3lsu0004e5g6w4372kte"},{"name":"实习 OpenCV","_id":"cjz5f3lti000ye5g6lshsvqu0"},{"name":"Markdown","_id":"cjz5f3ltp001be5g6lnzsqrwm"},{"name":"plan","_id":"cjz5f3ltq001de5g6qfd3bedf"},{"name":"OpenCV","_id":"cjz5f3ltq001he5g6hlgqjfwa"},{"name":"hexo","_id":"cjz5f3lu2001ze5g63ni3m8k1"},{"name":"PCA","_id":"cjz5f3lu50024e5g694x88w81"}]}}